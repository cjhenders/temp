id,title,content,tags
1,What right approach write spin controller soccer robot?,"Imagine programming 3 wheel soccer robot. What type controller would use spinning it? P? PID? The goal controller make robot stand defined angle ( 0 degree ) turn back rotated hand robot. I use stepper motors robot servos I need implement software! I written sample P type controller already movement fairly good. But I would like make better possible. The code follows: correction range , robot movement. degree number -127 128 returned compass. motorSpeed number 0 255 applied PWM.",soccer control
2,How I modify low cost hobby servo run 'freely'?,"I've got hobby servos (Power HD 1501MGs) I'd like able control (via Arduino) either go angle I set, put 'free running' mode, load take wherever goes. Is even possible, I going end stripping gears? My first thought simply kill power servo, force required move state I'd like. If possible, I looking hardware change, could I software?",control rcservo
3,"What useful gaits exist six legged robot, pros cons?","lists three gaits: tripod wave, ripple. Can improved, relative pros cons altered, gaits worth considering?",gait walk
4,Good Microcontrollers/SOCs Robotics Project,"I looking starting point project, preferably using popular systems (ones lot support for). I Arduino Uno, Raspberry Pi, lot willpower :) Anyone built project using systems above? Observation: I'd like start simple line-following vehicle build afterwards.",microcontroller arduino raspberry-pi
5,Nearest-neighbor data structure non-Euclidean configuration space,"I'm trying implement nearest-neighbor structure use RRT motion planner. In order better linear brute-force nearest-neighbor search, I'd like implement something like kd-tree. However, seems like classical implementation kd-tree assumes dimension space split ""left"" ""right"". This notion doesn't seem apply non-Euclidean spaces like SO(2), instance. I'm working serial manipulator arm fully rotational links, meaning dimension robot's configuration space SO(2), therefore non-Euclidean. Can kd-tree algorithm modified handle kinds subspaces? If not, another nearest-neighbor structure handle non-Euclidean subspaces still easy update query? I also took look FLANN, wasn't clear documentation whether handle non-Euclidean subspaces.",motion-planning rrt
6,What good robotics software platforms / operating systems available?,"My company soon starting brand new robotics project, still trying decide whether design code robotics software platform scratch, good existing ones. It would useful software platform commonly used among academics industry robotic system generally compatible others, people already familiar it. We would like software platform able to: Integrate new robotic hardware components easily. Already contain wide array useful data processing visualisation tools Make efficient use computing hardware",software platform
11,What software use design PCB robotics field?,"What best software (despite price) designing circuits PCB boards robots? I mean lots components, different designing methods, best accuracy, ... I use Altium Designer I think answers needs, maybe better ones market don't know about!",software circuit
18,What good methods tuning process noise Kalman filters?,Most often tuning Kalman filter noise matrices done trial error domain knowledge. Are principled ways tuning Kalman filter parameters?,odometry localization kalman-filter
19,Keyboard control map scalar based movement?,I'm working Wild Thumper 6 wheel chasis designed use RC controller. However I'd like mapping keyboard control well. Can suggest set keys behaviors you've used deal continuous value control normally offered joystick pair joysticks? The standard wasd keys + accelerate/decelerate pair? I'd also take pointer videogame think well.,untagged
20,Ideas shooting ball soccer robot,"What best option use shooting system soccer robot? I already implemented solenoid-based system shooting works perfectly. However, I'd like methods check better mine.",soccer mechanism
23,F/OSS Optical Object Avoidance,"I beginning work larger scale, 250-350 lbs wheeled robot looking use optical means object avoidance. I concerned robot large causing issues running things, including people top speed 15mph would cause issues safety. I starting remote control looking robot become self contained. I loosely following DARPA driver-less car project anywhere near fiscal power budget sensors computers. Am I thinking far afield idea self-contained robot 250-300 lbs range break bank optical object avoidance? Any comments experiences greatly appreciated.",computer-vision wheeled-robot
25,How choose right propeller/motor combination quadcopter?,There many sites explain briefly problem even propose combinations. I however would like much detailed explanation. What going give quad agility? Do I need bigger motors/props heavy quad achieve level agility lighter quad? EDIT: Here I understood subject: A quadcopter doesn't need high revving motors 4 propellers providing thrust high revving motors require battery power. Larger propellers give thrust per revolution motor. The question focused general characteristics various combinations specific questions spring mind: For given combination would effect upgrading propeller size comparison installing higher revving motors? What changes would need made lift heavier quad? How I achieve agility quad?,quadcopter
26,Cheap web buy robotic pieces,"I love computer programming, I interact world programming, it's even better. I used steal school, make little robots bounce collided wall, I want go further, I don't needed pieces, I don't know good place buy pieces , like servos, etc. either. Also, I'm Spanish, page sell places Spain, even better. I would highly appreciate help, Aritzh",servos
37,Mobile robot localization known map,"I want localize mobile robot equipped 2D laser scanner known indoor environment. The map 2D occupancy grid, perfect. What algorithms appropriate mobile robot localization?",localization mobile-robot
39,I'd like use gesture based input robot. What pros cons Xtion Live Kinect?,"As title, I'd like implement gesture recognition robot I'm looking pros cons Kinect Xtion - also sensible options available. I'm thinking following, open suggestions: Accuracy Price Driver quality Power draw",kinect input
42,What tyre tread would best suited road robot expected deal frequently muddy conditions?,"I'm looking potentially build autonomous robot frequently venture road, remain autonomous 6 hours time. I've found limited information however best tyre tread purpose, could suitable? I'm especially looking tread pattern won't need regular cleaning, save setting automatically (a tread gets ""clogged"" quickly clearly won't effective tackling tough terrain autonomously.)",wheel
43,What algorithm I use balancing two wheeled robot using gyroscope?,"Is good, popular reliable algorithm I use taking input gyroscope using control two independant wheels keep balanced robot reliably upright? I'm looking algorithm let use drive robot around well keep upright stationary. The ability deal inclines people nudging would also bonus, essential.",control gyroscope balance two-wheeled
44,Choosing right dimensions underwater glider,"I'm looking potentially build underwater glider, type submarine that's slow operate extremely low power draw. However, order work effectively I've found several sources hinting dimensions components, especially wings, critical success. However, I've found sparse information dimensions be! I'm happy bit trial error comes it, save work anyone information critical dimensions be?",design underwater auv
46,What's effective type rechargeable battery taking account size / weight / Ah?,"I'm looking build underwater glider robot need remain autonomous long periods time, perhaps even months. Power draw minimal, I'm thinking including form charging device (such solar charger) however I'd also like battery capacity large enough I don't hugely need worry this. Large current draw isn't really needed, battery need hold charge effectively long periods time. Considering underwater vehicle, weight size also concern. Cost isn't much issue, long it's within reason hobbyist project. I looking understand pros cons technology (Lead acid, LiPo, NiCad, fuel cell?), I decide type battery would best suited purpose. As such, I'm looking battery technology rather looking specific shopping recommendation.",underwater battery auv
48,How I best protect sensitive components damage vibration?,"It's common components types robots experience large environmental stresses, one key one vibration. Is something I need worry typical electronics sensitive components, really? If is, I secure components? I've heard two main philosophies behind this, first use damping system springs absorb shock. The second keep everything rigidly place can't move, therefore can't hit anything else break. Which one I follow, answer ""it depends"" I use guide best protect sensitive components?",electronics protection
49,What's accurate way obtain locational fix using GPS?,"Obviously GPS obvious accessible technology obtaining locational ""fix"" robot particular time. However, it's great sometimes, locations situations it's accurate I'd like, I'm investigating whether there's relatively easy way improve accuracy (or not, turns case.) I've considered following options, found limited information online: Would using much better antenna help, especially low signal areas? I'm thinking yes this, would I construct antenna know it's improvement? Are good guides this? I could use ready made antenna they're expensive. Would using multiple separate receivers tandem help, would likely similar amount, would I able extract meaningful average approach? What sort characteristics I look choosing good GPS receiver help accuracy? Is anything else I consider I've missed?",localization gps
53,What algorithm I use constructing map explored area using number ultrasound sensors?,"Ultrasound sensors incredibly cheap days makes popular choice many hobbyist robotic applications, I'd like use bunch (say 10) around robot algorithm build rough map area (as robot explores it.) I'm interested dealing moving objects stage, pinpointing stationary ones, I'll using GPS location. I realise components laser scanner would produce much accurate results, however devices also astronomically expensive. Does algorithm exist purpose?",slam localization gps mapping acoustic-rangefinder
55,Adding external heat sinking Dynamixel RX-24F servo?,"Hobby servos generally sufficient real robotics number reasons: Quality, precision, range motion, torque, etc. Meanwhile, industrial servos, ABB, Emerson, GE, etc, generally heavy expensive, suitable small-humanoid scale actuation. Similarly, building servo motors, gearboxes, encoders, akin trying design CPU control motor -- much detail getting way real work. There exists in-between level servos -- reasonably priced, reasonable performance, reasonably controllable -- form competing brands Dynamixel HerculeX servos. The smallest offerings lines generally strong enough real-world interaction, next step hold lot promise. For Robotis Dynamixel line, RX-24F servo (priced cheap AX-12F next step MX-28R.) Asking around, seems specs interface servo great, shuts thermal overload actually try run rated load -- something I'd expect hobby servo, robotics servo. Now, stepping MX-28R doubles price. Thus, RX-24F heat flaw could fixed, would positioned nice price/performance point. Does anyone experience providing additional cooling servo? Anything thermal-gluing heat sinks case, drilling holes running cooling fluid tubing hot parts interior would reasonable approaches. However, I spend significant time effort investigating this, I'd like second opinion -- possible, anyone experience this, worth it?",servos heat-management cooling
57,How I detect DC motor robot starting fail?,"What characteristics I look could reliable early warning signs DC motor robot, say one used drive, could failing? I'm looking answer deals terms sensors rather manual inspection, circuit could constructed warn potential failure happens. I ideas increase current draw decrease rotation speed / voltage, I want guard false warnings caused reasonable wear tear, robot struggling tough terrain. Obviously system never foolproof, points I look for?",sensors failure motor
60,Is possible move stabilize two wheeled robot gyroscopes?,"With two wheeled robot like one, I managed stabilize keeping stationary. This done using digital feedback control system reading position wheels determine position, natural back electromotive force wheel motors used feedback loop determine velocity. It kept stable PID controller, designed using root locus algorithm keep stable modulate performance parameters (such percent overshoot, settling time, etc.). I wanted attempt keep stable simultaneously propelling forward, I couldn't figure go designing linear controller could that. Is possible propel robot forward keep stable using feedback controller wheels, gyroscope necessary?",two-wheeled stability
65,Calculating efficiency Mecanum wheels,"I'm part FIRST Robotics team, we're looking using Mecanum wheels robot. What advantages disadvantages using Mecanum wheel versus regular ones? From looking Google, looks like Mecanum wheels give mobility don't much traction. Are advantages disadvantages? Compared regular wheels, Mecanum wheels less efficient efficient way? And so, quantifiable way determine much? Are equations I use calculate efficiency (or inefficiency) and/or speed moving forwards, sideways, arbitrary angles? A picture robot mecanum wheels:",mobile-robot design movement wheel first-robotics
75,Using Arduino control ON / OFF connection two pins,"I've got driver: ... A4988 stepper motor driver carrier I'm attempting control connection RESET SLEEP pins logic ( code ) running Arduino. The motor runs perfectly two pins connected however I'd like control stepper powered Arduino ( thus generating extra heat ) I'd like to: designate pin control connection two pins use ""digitalWrite"" pin HIGH LOW switch power stepper NOTE: The data sheet mentioned driver powering stepper RESET SLEEP needed switched ( HIGH )",arduino logic-control stepper-motor stepper-driver
85,Shape Memory Alloy wire robot gripper arm actuation: How vary grip pressure?,"For robotic gripper arm designing factory floor use small components, propose use electrically activated Shape Memory Alloy (SMA) wire harnesses actuation. The device designed akin Pick & Place machines used circuit assembly, moves aircraft-hanger sized work surface wheels. It manipulates irregular shaped porous objects 0.5 cu.cm 8 cu.cm - hence traditional vacuum P&P mechanism appeal. Also, individual objects assembly line varying hardness weights. Our design constraints are: Ensuring minimal zero vibration sound Using minimal volume within mechanism (batteries wheelbase, providing stability, weight concern) Fine variation gripper pressure We believe SMA meets first two constraints well, need guidance achieving constraint 3, i.e. different levels pressure gripper controlled electronically. My questions: Can PWM current activation threshold (320 mA 0.005 inch Flexinol HT) provide variable, repeatable actuation force? Would need pressure sensors fingertip closed loop control grip, gripper calibrated periodically maintain repeatable force? Is well-documented precedent study referring to?",mobile-robot
88,Mechanical design motorized spherical caster wheels,"Design goal mobile robot operates 3 large casters, essentially 2 4 inch diameter steel ball bearings, motorized. No mechanism would touch surface. The robot thus able move XY direction flat surface, steering achieved varying speed rolling direction wheels. The robot designated ""front"" side, need (and to) bodily turn, order move given direction. Conventional wheels tracks preferred approach. Looking suggested mechanical layouts multiple rubber wheels, pressing onto steel ball within castor housing, drive ball direction. A single wheel stepper, rotated around vertical axis using sail-winch servo, one approach consideration. Would ideal, serious flaws approach? Alternatively, suggested method driving steel ball arbitrary direction electronic control?",servos mobile-robot stepper-motor
91,What determines amount noise actuator produces?,"Many robots mechanical devices produce signature whirring noise move, produce less. What makes difference? What restrictions silence requirement places robot?",motor actuator noise
93,What BLDC servo drive takes sinusoidal hall sensor signals?,"I looking servo drive control brushless DC motor, least 10A, 30V rating. However, I want know exist take sinusoidal hall sensor signals directly. I already know servo drives taking hall sensor pulses (with 6 different phases), trapezoidal control. Note: servo drive includes driving electronics (no additional transistors required).",brushless-motor hall-sensor
94,"Developing 8-bit AVR-s, current, open free libraries there?","I would interested ask list repos free open code, applicable 8-bit avr-s relation robotics - object avoidance, process controllers, battery management, etc. This would huge help me, preventing wasting weeks months invent wheel.",software microcontroller
99,How manage interrupts AVR?,"I number interrupt service routines AVR. These include interrupts USART serial communication, timers, SPI communication. For these, I use circular queues (using start end pointer, without boundary checking). Some problems start occur AVR starts get overloaded. The circular queues lose chunks data. To solve this, I reduce load AVR (for example, skipping cycles timer). However, manual process, reduced AVR appears problems. This partly I want relatively consistent timer periods. However, even 70% average processor load, queues fill randomly chance. In case spurious overloading times, I make adaptive avoid queue overflows?",microcontroller avr interrupts
100,What connectors reliable?,"If used connectors signal wiring length time, may find unreliable. Specifically, I find unreliable used long time, number disconnections re-connections: This due loss springy-ness crimped metal end wire, causes contact problems. Which connectors (with rapid connection time) reliable multiple re-connections simple signal wiring? This excludes screw terminals connectors screws (eg. D-subminiature connectors), simple plug-in connectors.",wiring
106,What suitable model two-wheeled robots?,"What suitable model two-wheeled robots? That is, equations motion describe dynamics two-wheeled robot. Model varying fidelity welcome. This includes non-linear models, well linearized models.",mobile-robot two-wheeled
112,How emergency stops wired?,"Emergency stops obviously good idea robots, wired? What systems killed immediately, stay working?",mobile-robot errors
113,How model noise range sensor's return?,"Range sensors (for example sonar, infrared, lidar) notoriously noisy. How I characterize noise characteristics include probabilistic localization sensor model?",sensors noise
117,What difference 4-point 8-point connectivity graph based planning?,"In graph-based planning (say, A*), states connected neighbors. How one decide whether connect 4 neighbors 8 neighbors? What pros cons approach?",motion-planning artificial-intelligence planning
118,Properly flashing firmware Lego Mindstorms NXT,"I attempting upload custom firmware Lego Mindstorms NXT issues. First all, I'm attempting use nxtOSEK, would let run C++ programs it. The problem is, everytime I put firmware update mode, download doesn't seem actually occur. What I mean that, according output terminal (both Mac Windows), download successful, however NXT reboots, I still see normal logo (not nxtOSEK). So, I'm first holding button seconds, hitting orange button, giving tic-tic-tic sound. Then I run firmware update (either using Windows NextTool Mac OSX GUI NextTool) attempt download. I get success message, yet robot still using old firmware. What could cause problem I solve it?",mindstorms nxt
119,Is better weight distributed wheels center robot?,"When designing standard 4 6 wheel robot, better weight distributed primarily center robot, wheels, difference? Specifically, weight distribution make robot less likely tip over?",mobile-robot design stability wheeled-robot
128,How mature real-time programming robotics?,"Edit: I don't know why, question seems confusing many people. I aware when/where/why/how use real-time. I interested knowing whether people real-time task would actually care enough implement real-time not. There's need mention real-time operations important robot. My question however, much actually used robotics? Take question example. Only one answer mentions platform real-time capabilities, far top too. ROS apparently, popular platform real-time. In real-time world however, RTAI1 seems workable free real-time platform use. It however, limited Linux (no problem), badly documented slowly developed. So, much real-time behavior sought among robotics developers? The question is, much developers inclined write real-time applications real-time behavior actually needed? If much, why? For example, reflexive behavior based tactile data, cannot go ROS would lose real-time property. But people really come real-time solution use ROS anyway, ignoring real-time property? 1 similarly Xenomai",software platform real-time
131,Connecting two microcontrollers using I2C,I Have ATmega16 mc master i2c ATMega8 mc slave i2c. I connected two mcs' sda scl ports alongside pullup resistor. Now I want read register ATMega8 using ATMega16. The problem I don't want assign variables manually. Is libs headers thing me?,software microcontroller i2c
138,Mathematical prerequisites beginning graduate student robotics,A beginning graduate student robotics asked areas mathematics brush (prerequisites) begin masters research program robotics. What good materials/books indispensable research student? Which ones suggest order student develops solid foundation robotics?,research
142,Technology behind Kiva Systems mobile robots,What kind sensors algorithms mobile robots Kiva Systems equipped with?,mobile-robot industrial-robot
143,How I calculate required loop frequency servo controller?,"I motor drives string connected load cell. I would like implement closed loop controller control load applied motor string. How I go determining required loop frequency order create stable control system? Is something like Nyquist frequency, loop speed least twice highest frequency inherent mechanical system?",control motor force
146,What rail material best used linear bearings?,"For 3d printer RepRap Prusa several rails (smooth rods) guide printer head different axises. The printer head uses several linear bearings glide along rails. There isn't specification kind material would best suited purpose linear bearings. My first assumption would stainless steel won't corrode (rust) surface, I'm sure true printers (whether 3D printers not) different material may allow linear bearings glide easily. Aluminum would second choice I reservations grade would least resistant. This resource limited information help would best suited particular application. What material best suited purpose?",reprap 3d-printing linear-bearing
148,Detect Nao robot Kinect,"I sure tried I trying use Kinect detect gestures made Nao robot. I made Kinect application, gesture based picture viewer detects humans fine(Obviously does!) What I wanted try (lazy I am), see I could use (say, voice) command tell Nao Swipe Right gesture application identify gesture. The Nao easily identify command gesture. The problem however is, I put Nao front Kinect sensor, Kinect track it. What I want know is, basics behind Kinect's human body motion tracking essentially fails robot placed front instead human? PS: I kept Nao right distance sensor. I also checked entire robot field view sensor. EDIT: This posted stackoverflow msdn target large audience problem encountered anyone past.",kinect
150,Preventing leaks motor shafts underwater bots,"Whenever building aquatic bot, always take care prevent leakages, obvious reasons. Now, holes wires made watertight easily--but motors? We easily seal casing place (and fill holes casing), part axle meets casing still left unprotected. Water leaking motor still quite bad. I doubt there's way seal area properly, since solid seal let axle move, liquid seal (or something like grease) rub eventually. I thinking putting second casing around motor, maybe custom rubber orifice shaft. Something like (forgive bad drawing, used GIMP): This would probably stop leakage, would reduce torque/rpm significantly via friction. So, one prevent water leaking motor without significantly affecting motor's performance? (To clarify, I don't want buy special underwater motor, I'd prefer way make motors watertight)",motor underwater auv protection
154,Fixed point arithmetic microcontrollers,"Often use microcontrollers things robots, need make calculations decimal. Using floating point variables slow, software floating point library automatically included (unless high-end microcontroller). Therefore, generally use fixed point arithmetic. Whenever I this, I use integer, remember decimal place is. However, take care ensure everything consistent, especially calculations involve variables decimal point different place. I implemented fixed point atan2 function, I trying squeeze every last drop limited precision (16 bits), I would often change definition decimal point is, would change I tweaked it. In addition, I would constants, quasi look-up table, implied decimal point somewhere. I want know better way. Is library, set macros, simplify use fixed point variables, making multiplication division mixed variables easier, allowing declaration decimal numbers constant expressions, automatically converting desired fixed point representation compile time?",microcontroller c
155,How choose good IMU wheeled robot?,"At lab, several ""Kurt"" type robots (about size Pioneer, six wheels, differential drive). The built-in gyroscopes really outdated; main problem gyroscopes large drift increases gyro heats (the error 3°/s). We mainly use IMU get initial pose estimates later corrected localization algorithm, even large initial pose error caused IMU often annoying. We've temporarily used Android phone (Galaxy S2) replacement IMU, results much better compared old IMUs. However, I don't like depending WiFi connection IMU control computer (a laptop running ROS/Ubuntu), we're looking buy new IMU. What IMU choose? What criteria important consider application? Please share experiences! :-)",ros imu odometry gyroscope ugv
167,What good strategies tuning PID loops?,"Tuning controller gains difficult, general strategies work well get stable system converges right solution?",control pid tuning
172,Absolute positioning without GPS,"Using IMU robot estimate current position relative starting position, incurs error time. GPS especially useful providing position information biased local error accumulation. But GPS cannot used indoors, even outdoors spotty. So methods sensors robot use localize (relative frame reference) without using GPS?",localization gps sensors slam
178,HMMs vs. CRFs model time-series force data robots interacting environment?,"I time-series force data robots interacting environment objects various textures. I would like develop models various textures using time-series data classify textures smooth, rough, moderate, etc. categories. For purpose, Hidden Markov Models sufficient use Conditional Random Fields? If I decide classify categories distinction categories subtle, case would good choice? Will force-data sufficient capture information I need classify textures categories? Thanks replies :)",artificial-intelligence
182,Suitable control algorithm Air Muscle based joint?,"I joint actuated antagonistic pair Pneumatic Muscles. There two valves per muscle, one fill one empty muscle. The joint angle sensor, muscle also contain air pressure sensor. What suitable control algorithm set up? A PID controller controlling valve orifice sizes? A PID controller controlling mass flow rate? A PID controller controlling pressure using two PID pressure controllers? A Fuzzy Logic controller? A Neural Network?",control pid air-muscle
184,Robotics Trends,"Robotics always one engineering fields promised much, taking long time deliver things people imagine. When someone asks: ""How long [X] type robots?"" Are resources call upon try calculate rough answer. These resources might include: Rate progress computational power, estimate much needed various types AI. Rate progress electrical energy storage density, estimate much needed various types robot. Rate progress actuation systems, estimate would needed various types robot. Lists milestones towards various types robot, ones achieved when. Are types studies performed, results published? Added: In response Jakob's comment, I looking opinions discussions subject. What I looking published studies might shed light question.",research
205,"Creating fast, uniform, linear actuator","Most linear actuators I've seen nonuniform and/or slow. Those using cam crankshaft-like mechanism (and nearly anything hydraulic/pneumatic) cannot moved constant speed without programming. Those using screw-like mechanism uniform, slow. Aside rack pinion/rope wound around stick, fast, uniform linear actuators exist? By uniform, I mean speed uniform (Or distance moved linearly dependant angle rotated motor)",actuator
209,How determine quality ICP matches?,"In SLAM frontends use Iterative Closest Point (ICP) algorithm identifying association two matching point clouds, determine algorithm stuck local minimum returns wrong result? The problem defined matching two pointclouds samples arbitrary surface structure, sampled areas overlap 0-100% unknown. I know Trimmed ICP variant works iteratively trying determine overlap, even one stuck local minimum. A naive approach would look mean square error identified point pairs. But without estimate sampling seems risky thresholding. In manual Leica Cyclone suggest manual inspection pair error histogram. If Gaussian shape fit good. If linear fall-off match probably bad. This seems plausible me, I've never seen used algorithm.",slam
210,How I automatically adjust PID parameters fly?,"I simple servo system uses PID controller implemented MCU perform feedback. However, properties system change dynamically, PID parameters never tuned circumstances. My robot light weight arm back-drivable electric motors, similar one: The arm performs several tasks, including picking heavy weights, pushing pulling objects across desk. Each tasks requires different PID tuning parameters I cannot easily predict. What I would really like higher level function carefully adjust parameters response arm's behaviour. For example, notices arm oscillating, might reduce P increase D. Or noticed arm wasn't reaching target, might increase I. Do algorithms exist? I would happy even algorithm didn't perfect parameters immediately. E.G. arm could oscillate times parameters adjusted new values.",control pid automatic tuning
213,How I integrate smart phone robotics project?,"Smart phones days typically come gyroscope, accelerometer, compass, camera, GPS sensor board. They also usually connection internet Wifi mobile data networks. I've seen many cases using phone remote control robot, me, seems like phone perfect lightweight computing sensing platform autonomous robot. The main obstacle I see interfacing actuators. Being able control motors steer even table-top robot, control servos, example. Connecting communicating microcontroller could obstacle well. As robot hobbyist, I'd like know I overcome obstacles able harness power smart phone robotics projects.",actuator
215,Starting advice making robots tinkering microcontrollers,"I'd like start making robots tinkering microcontrollers. Where I start, I need? I'd like make robots. I'm comfortable programming (assembly C) I've got part covered, electronics/circuits knowledge little weak. I idea material start tools I need, put stuff together. For microcontroller, I'm thinking going Pololu Orangutan LV-168 Arduino Duemilanove, although I'm leaning towards Orangutan built-in LCD pushbuttons (which I would expect use, especially debugging user interaction). Am I right track? It seems like number I/O ports small, case practice?",arduino microcontroller beginner
222,Floor Segmentation Determine Navigable Paths,"In application, robot following physical setup: Differential drive mechanics feedback (wheel encoders) Commercially available webcam mounted known transform base robot (RGB, depth) The robot navigating structured, indoor type environment (think office, home, university), I would like able determine navigable paths environment using vision sensor. What best way approach problem finding safe paths travel given single vision sensor? Edit: I think I interested vision processing techniques actual path-planning mechanics.",computer-vision
229,Red [ERROR] output python ROS,"In ROS, I cannot get [ERROR] logs print red I use python. How I make appear red instead black? For example, following Python: produces output black: [ERROR] [WallTime: 135601422.876123] No analog input received. whereas following C++: ROS_ERROR(""No analog input received.""); produces following output red. [ERROR] [135601551.192412]: No analog input received.",ros python
230,Can ROS run Raspberry Pi?,"Can ROS run Raspberry Pi? ROS resigned run network machines, different machines, even different cores machine different jobs. Can one machines Raspberry Pi? I considering using R-Pi EtherCAT master mobile robot, communicating main PC WiFi, using dongle. Can R-Pi even run ROS all? Would R-Pi enough processing power 1kHz servoing? Would possible run servoing host WiFi connecion?",ros raspberry-pi wifi
231,What frequency quadcopter output-sense-calculate-output update loop need stay stable?,"With 600 mm (2 foot) motor-to-motor quadcopter, frequency output-sense-calculate-output update loop need stay stable? I'm estimating total takeoff weight roughly 2 pounds ( 0.9 kg ), I expect mostly motors batteries.",stability quadcopter
235,Is better batteries distributed rotors center multicopter?,"I've seen 3 approaches mounting batteries multicopter: All batteries rigidly mounted near center airframe All batteries bag hanging center airframe Each rotor share batteries rigidly mounted near/under it. (For example, quadcopter 1/4 batteries mounted underneath motor). Which design best, why? If one best design, advantages/tradeoffs designs? Is design I'm overlooking better way? (This question focuses multirotor flying machines. For ground vehicles, see "" Is better weight distributed wheels center robot? "").",design stability quadcopter
237,How calculate serial speed buffer requirements PC microcontroller communications?,"A common scenario PC sends commands microcontroller via RS232. My PC program sending commands (each composed multiple bytes) fast small robot. The microcontroller robot Parallax Propellor. I noticed I don't process bytes quickly enough microcontroller side things, quickly overflow default buffers popular serial port drivers available Propellor. (The buffers generally anywhere 16 256 bytes). I arbitrarily increase buffers create larger circular buffer, I would like methodical approach determining appropriate size requirements and/or minimal amount time I wait pulling bytes serial port driver buffer. At 1st glance: 115200 == 115.2 bits per millisecond == ~12.8 bytes per millisecond (assuming 1 stop bit) 1) Is valid way calculate timing serial transmissions? Also, given specific setup: PC Program <--> Bluetooth Serial Profile Driver <--> Bluetooth Transceiver <-*-> BlueSMIRF Wireless Modem <--> Parallax Propellor Program 2) What maximum amount data I send given period time consistently without eventually running problems? Maybe I'm complicating things, seems like potentially multiple buffers involved transmission chain above. How others commonly deal this? Do throttle PC sending known safe rate? Implement flow control? If implementing flow control, affect bandwidth response times? (If matters, experiment use joystick PC control multiple servos instant reaction joystick movements. So every small movement joystick results multiple commands sent microcontroller. The commands simple positional commands though, also involve acceleration/deacceleration servos time reason microcontroller spends significant amount clock cycles processing new bytes.)",microcontroller serial rs232
249,How six-axis force/torque sensor work?,"I would really like six-axis force/torque sensor robot, I can't afford one. I thinking making one own. I experience using strain gauges, I can't work arrange create six-axis force/torque sensor. Is something I could feasibly make myself? How work? What theory behind them? I'm curious know work, even it's feasible make one myself. Added: Just clear, I'm talking force / torque sensors, like ATI Nano 17: I talking accelerometers gyros, MEMS IMUs.",sensors force-sensor
254,Should I switch servo system brushed brushless motors?,"I robot uses brushed motors servo system. These Maxon 3W motors, 131:1 planetary gearboxes. The motors controlled PIC microcontroller, running 1kHz PID controller. The servos low speed high torque application. There significant backlash sensor motor. Maxon offer 12W brushless motors size. These better many ways: double torque, better heat dissipation, higher efficiency. The problem, obviously, require complex drive electronics. Also, I heard couple people mention brushed motors better servo applications, though never explained why. Has anyone else implemented kind system? Are gotchas using brushed motors servos? Is possible servo low speeds I 3 integral digital Hall sensors, encoder? (I would prefer add encoder money space cost) It torque ripple likely problem?",brushless-motor servomotor
255,What UAV kit(s) would suitable beginner roboticist programming experience?,"I'm really new robotics, however I programmer familiar several different languages. I don't ton money spend I wondering really good starter kit. My criteria kit inexpensive powerful, functionality extensible -- something would allow builder creative possibly invent new ways use it, glorified model kit. Being extendable smartphones plus. I'm looking something easy introductory, something powerful, flexible, cost effective.",uav kit
256,Quadcopter Localization Beacon,"I want use RF beacon localize quadcopter autolanding, GPS precise enough, example, driveway 10 feet wide, GPS showing 20-30 ft. accuracy (with proverbial lake lava either side). The quadcopter would use GPS fly rough location strong enough signal beacon, would begin use signal come landing precise location, referenced said beacon. Can someone please explain concepts theories behind building beacon it's accompanying receiver (suitable connection Arduino via digital analog method) achieving, say, 4"" better horizontal vertical accuracy within 50' sphere? Minimally, quad range altitude, i.e. ""I 10 feet away beacon 2 feet it"". How much added complexity would take make robot fully position aware beacon, i.e. ""x ft. South, ft. West z ft. it"", coordinate system determined beacon linked sort geographic coordinate system? If beacon mounted a, say, 10 ft pole, changes made versus ground presuming activity takes place it's x-y plane? Last note- This thing would prefferably operate 72MHz band, please presume I'm operating, devices operating band.",localization quadcopter gps
261,What commutation waveforms look like brushless motor?,"I seen waveforms driving brushless motor. I guess waveform used simpler block commutation. But I want sinusoidal waveforms, PWM signal look like now? Is need carefully synchronise edges three phases?",brushless-motor pwm
262,Effectiveness Mobile Robot In Relation To Mass,"Do mobile and/or autonomous robots become less effective bigger get? For example, bigger robot bigger batteries, thus bigger motors, whereas smaller robot exact opposite, making need less energy, also smaller motors. Is known theorem models this?",mobile-robot design dynamics
267,Why capacitors added motors (in parallel); purpose?,"I've seen many motors capacitors attached parallel bots. Apparently, ""safety"" motor. As I understand it, smoothen fluctuations--and I doubt fluctuations adverse effects motor. Apparently protect motor shaft slowed/blocked, I fail see how. What exactly function capacitor? What prevent, how?",motor protection
271,Spatial tracking two UAVs,"I two Unmanned Aerial Vehicles (planes) work well. They fly various waypoints automatically using GPS. Now I would like fly together formation. I would like fly side-by-side fairly close. This close reliably use GPS guarantee keep correct relative positions safely, I looking another way. Somehow UAVs need able measure position orientation space relative one. How I this? Is kind sensor this? It would need following properties: 6 axes (position orientation) Range 0m - 5m, (from plane centres, planes won't actually ever touch wingtips) Works day night weather conditions Light weight (This 1.5m wingspan RC planes, max extra weight 100g) Probably need 50Hz - 100Hz refresh rate, might get away less, using IMU fill gaps",sensors uav multi-agent
274,Low-cost servo digital control interfaces?,"Some years ago, projects provided hardware software perform modifications standard hobby servos convert digital servos, advantages come it. OpenServo little outdated, seem worked anymore, hardware buy. Sparkfun version OpenServo, least available buying. Do know mods, even complete low cost digital servos? I mostly interested position feedback, servo chaining.",servos i2c
277,Why I need Kalman filter?,"I designing unmanned aerial vehicle, include several types sensors: 3-axis accelerometer 3-axis gyroscope 3-axis magnetometer horizon sensor GPS downward facing ultrasound. A friend mine told I need put sensor data Kalman filter, I don't understand why. Why can't I put straight micro controller. How Kalman filter help sensor data?",kalman-filter uav
284,Which type actuator suitable strong robot arm,I wish build robotic arm lift useful amount weight (such 3-6kg arm extend approx 1.25 meters). What actuators available accomplish this. The main factors design points are: Not Expensive 5 6 d.o.f. mounted yet designed mobile platform battery powered stronger hobby servos (at least 'shoulder' 'elbow' joints) slow actuate,mobile-robot robotic-arm actuator
287,Programming Robots JavaScript,"As somebody spending majority time programming JavaScript, what's best route get small-robotics without needing deviate much current language focus? Are project kits tools make use JavaScript language might make field approachable developers like myself? I would even interested virtual environments code executed simulation.",software programming-languages
299,How inverse kinematics problem solved?,"The forward kinematics robot arm solved easily. We represent joint using Denavit–Hartenberg transformation matrices. For example, $i^{th}$ joint linear actuator, may transformation matrix: $T_i = \left[\begin{matrix} 1&0&0&0\\ 0&1&0&0\\ 0&0&1&d_i\\ 0&0&0&1 \end{matrix} \right]$ extension length defined $d_i$ whereas, rotating link may be: $T_i = \left[\begin{matrix} 1&0&0&L\\ 0&\cos\alpha_i&-\sin\alpha_i&0\\ 0&\sin\alpha_i&\cos\alpha_i&0\\ 0&0&0&1 \end{matrix} \right]$ $\alpha$ angle, $L$ length link. We find position orientation end effector multiplying transformation matrices: $\prod{T_i}$. The question is, solve inverse problem? Mathematically, desired end effector position $M$, find parameters $d_i$, $\alpha_i$ $\prod{T_i} = M$. What methods exist solve equation?",inverse-kinematics kinematics joint arm
301,Which spline function would best suited trajectory differential drive,"What's best kind spline used generating trajectory adapted execution time? The use case differential drive move towards point (x,y,theta) without stopping movement (e.g. no, turn toward goal, straight move goal position, turn goal orientation). The robot provided laser scanner detecting dynamic obstacles avoided. What's best kind controller case?",control motion-planning
309,Correct way use Subsumption Architecture Robot C,"I've lot reading lately Subsumption Architecture different ways people seem advocate. For instance people use global ""flag"" variable task take control. Others use allow arbiter really choose. And I think correct. I small section RobotC code I'm working line following robot sure I right currently track method always take find method. The correct flow find guide robot line using spiral path find line. Once line found track take over. task evade(){ if(SensorValue(forwardSonarSensor) > threshold){ //box obstruction } } task find(){ if(SensorValue(lightSensor) > threshold){ //spiral robot } } task track(){ if(SensorValue(lightSensor) < threshold){ //go straight }else{ //execute turns follow line } } task main(){ while(true){ StartTask(evade,9); StartTask(track,8); StartTask(find,7); wait1Msec(250); } } I've used comments rather actual code keep brief. Are statements good enough conditions robot line, track() takes over. Is due else statement within track? If so, track() perform turns looses line without taking forage start program?",mobile-robot software two-wheeled robotc
317,How much working CNC machines teach robotics?,"I built simple X/Y/Z CNC machines. I've learned G-Code, motor control, firmware open loop systems. I see machines like rovers, big dog factory arms seem incredibly complex comparison, yet don't seem magical more. What important skills pick working CNC machines? What's next logical thing learn? What things would CNC machines never teach me?",control
323,IPC-Bridge problem,"Is anyone able help getting IPC-bridge working ubuntu lucid installation (with matlab 2012a)? I'm able finish last step (Compiling messages folders): I'm able rosmake ipc_bridge_ros, however enter ""roscd ipc_roslib && make"", seems meX recognize commands. Here get (screen shot): NOTE: i'm going use IPC-bridge control pioneer 3DX implement Fast-slam algorithm matlab.",mobile-robot software slam ros
327,Learning Algorithms Walking Quadruped,I'm building 4 legged robot (quadruped) 3 Degrees freedom per leg. The goal project make robot able learn walk. What learning algorithms I need implement work? I'm using Arduino Uno microcontroller.,arduino microcontroller machine-learning walking-robot
331,Robot Serial Communication Error,We using Koro robot PC based automation solution. But sometimes robot getting command refuses respond. Then I get serial communication timeout error. The error happening random type commands also happening time making troubleshooting difficult. I doubt driver problem. How approach problem.? Thanks,logic-control
338,Is list maneuvers related control tracked platform?,"I platform two tracks two motors. Each one uses electronic speed control ""double tap reverse"". Each ESC takes input pulse train frequency 1500 neutral +/-700. I'm interested learning algorithms list commands I use control platform executes maneuvers. For example: Lock one thread platform rotate using one Have two treads rotate opposite directions Execute U turn I'm struggling expressing code maneuvers executed. There's ""dead"" zone around 1500 pulse train frequency ESC output weak cause platform move. The double tap reverse also makes tough understand long track turned off. Thank input",control motion-planning tracks
341,Tendon longevity,"I thinking developing tendon driven robot manipulator industrial application requires high level reliability. However, I aware tendons robot prone wear tear, failure. How I go selecting suitable tendon material (steel, kevlar, spectra, etc.) use appropriately? Have studies undertaken examine longevity failure patterns robotic tendon materials? If I perform tests materials myself, I perform tests efficiently, make best use testing time (learn much possible tendon failure reasonable length time).",failure reliability
342,What common mistakes robots make?,Is taxonomy errors common robotics? Things come mind I don't names are: Getting stuck stable infinite loop Going unstable feedback loop (A balancing robot overcompensating correction) An inability generalize tasks (Pick bowl vs pick glass) An inability generalize 'similar' sensory inputs. Causing damage environment. These would things make robot look 'stupid' non-roboticist. If you're curious I want list I prepare clear answer ready people don't know various things hard.,errors
344,"With 6-axis robot, given end-effector position range orientations, find optimal joint values","Given six-axis articulated robot arm holding tool end-effector, I desired tool position tool orientation, exactly 1 solution inverse kinematics equation robot reach position. (or rather 16 different solutions, depending range joints) But robot holding something like pen, I want robot mark specific point pen target, I care pen oriented, long perpendicular marked surface. So inverse-kinematics equation infinitely many solutions. How I pick among solutions joint configuration closest current configuration: one require least amount movement reach? (or joint configuration optimal according similar criterion, joint angles furthest maximum minimum?)",localization motion-planning industrial-robot inverse-kinematics kinematics
354,Is subsumption architecture still active area research?,I interested learning subsumption architecture. I read number books talk idea none go great detail. I also read fair number Dr. Brooks papers topic however hasn't published much topic recent years. Is still active area research? Are must read papers topic?,control research
358,restricting range motion complex constraints,"I looking way restrict robot's range motion, using complex constraints tearing cable attached robot. Take articulated 6-axis robot arm shown below, attached cable (red), fixed points X (before axis A4) Y (after axis A6). The cable limit range movement robot. It stretch bend extend, something like full 360° turn axis A4, axes remaining picture, tie cable around arm rip off. If joint A5 0°, A4 A6 still move full 360°, cannot diverge much other, would twist cable. If A5 tilted, relationship becomes even complicated. How express constraint? It simple joint constraint, independently limit range joints, also positional constraint, define region robot must enter. Checking start goal posture sufficient, since along path start goal posture may still posture puts much strain cable. Without limiting robot small set pre-tested paths, limit robot movements rip cable? What standard techniques used sort problem?",motion-planning industrial-robot joint
359,What kind performance I expect using Extended Kalman Filter calibration localization?,"Currently I tricycle style robot uses extended kalman filter order track 6 state variables. The inputs system steer encoder, distance encoder, rotating laser returns bearing information known landmarks. Currently encoders located main wheel (The one steers, also powered). The 6 variables tracked Kalman Filter X, Y, Heading, Distance Scaling (calibration distance encoder), Steer Calibration (offset steer encoder), finally bearing calibration rotating laser. With kind system put together vehicle give known good location plenty landmarks, drive around bit, end well calibrated vehicle drive extended distances reliably landmarks. Its simple works great. Over time encoder drifts automatically follow drift adjust. We attempting apply principles robot multiple steer drive wheels. In case vehicle able move direction, spin place, etc. . Each steer/drive wheel steer distance encoder need calibrated. Can I expect get kind reliability performance complex system? Are common pitfalls look expanding kalman filter include variables? Is risk settling sub-optimal values?",localization kalman-filter
361,Programming line following robot reinforcement learning,"I considering programming line following robot using reinforcement learning algorithms. The question I pondering I get algorithm learn navigating arbitrary path? Having followed Sutton & Barto Book reinforcement learning, I solve exercise problem involving racetrack car agent learnt go track regulate speed. However, exercise problem got agent learn navigate track trained on. Is scope reinforcement learning get robot navigate arbitrary paths? Does agent absolutely map race circuit path? What parameters could I possibly use state space?",machine-learning artificial-intelligence reinforcement-learning line-following
369,Are inverse kinematics reinforcement learning competitive techniques?,"Are inverse kinematics reinforcement learning techniques contending techniques solve problem viz. movement robotic manipulators arm? By glance wikipedia article, appears inverse kinematics seems attempt achieve solution opposed reinforcement learning attempts optimizes problem. Have I misunderstood anything?",inverse-kinematics reinforcement-learning machine-learning
380,Processor command interface preference robot arm,"I want build robot arm that'll approximately 1.25 meter long able lift 2 kilograms. It'll 6 dof expensive project. And importantly, programmer brand new robotics facility ours. :) The robot want build led Inverse Kinematics, parameters matrices, think i'll need tough processor (Not sure). Assuming robots control interface Android tablet, thought also could develop program Android, send necessary commands control chip via RS-232 interface. So, question is, standart 1 GHz Android tablets suitable tasks? If not, anybody got advice me?",software inverse-kinematics arm rs232
382,How fuse linear angular data sensors,"My team I setting outdoor robot encoders, commercial-grade IMU, GPS sensor. The robot basic tank drive, encoders sufficiently supply ticks left right wheels. The IMU gives roll, pitch, yaw, linear accelerations x, y, z. We could later add IMUs, would give redundancy, could also additionally provide angular rates roll, pitch, yaw. The GPS publishes global x, y, z coordinates. Knowing robot's x position heading useful robot localize map it's environment navigate. The robot's velocity could also useful making smooth movement decisions. It's ground-based robot, don't care much z axis. The robot also lidar sensor camera--so roll pitch useful transforming lidar camera data better orientation. I'm trying figure fuse numbers together way optimally takes advantage sensors' accuracy. Right we're using Kalman filter generate estimate simple transition matrix: [[1, dt, .5*dt*dt, 0, 0, 0], [0, 1, dt, 0, 0, 0], [0, 0, 1, 0, 0, 0], [0, 0, 0, 1, dt, .5*dt*dt], [0, 0, 0, 0, 1, dt], [0, 0, 0, 0, 0, 1]] The filter estimates state exclusively based accelerations provided IMU. (The IMU isn't best quality; within 30 seconds show robot (at rest) drifting good 20 meters initial location.) I want know use roll, pitch, yaw IMU, potentially roll, pitch, yaw rates, encoder data wheels, GPS data improve state estimate. Using bit math, use two encoders generate x, y, heading information robot, well linear angular velocities. The encoders accurate, susceptible slippage outdoor field. It seems two separate sets data here, difficult fuse: Estimates x, x-vel, x-accel, y, y-vel, y-accel Estimates roll, pitch, yaw, rates roll, pitch, yaw Even though there's crossover two sets, I'm trouble reasoning put together. For example, robot going constant speed, direction robot, determined x-vel y-vel, yaw. Although, robot rest, yaw cannot accurately determined x velocities. Also, data provided encoders, translated angular velocity, could update yaw rate... could update yaw rate end providing better positional estimates? Does make sense put 12 numbers filter, normally kept separate? Is already well-developed way dealing type problem?",sensors kalman-filter sensor-fusion
390,"Can I use IMUs improve position/posture measurement fingers ""data glove""?","I using Cyberglove control humanoid robot hand, found disappointing doesn't measure posture human hand accurately. I wondering possibility using Inertial Measurement Units (IMUs) mounted fingers track position measure posture. But I'm sure feasible is. Would IMU return enough data make tracking reliable circumstances? Would possible fool system incorrectly tracking fingers? Might possible get away using simple 3-axis accelerometers, would need 9-axis (accelerometer, gyro, magnetometer)?",imu sensor-fusion hri
397,Resources learning basics Robotics,"I interested Robotics. Practically I idea Robotics. I want start learning basics Robotics. But I confused start with. So I need suggestions best resources start Robotics with. That may books, sites, others. Please help this.",books
403,What current state Google Self Driving Car Project?,"I aware legislation's Nevada, happening technology currently. When expected commercialized ?",ugv
405,Selecting accelerometer Deduced Reckoning,"I never used accelerometer before, I aware come I2C, SPI analog outputs. If I choose use I2c SPI, device, I accumulate errors due communication time? Is fast sampling analog signal likely get accurate deduced position using I2C? Will true A robot moving room A robot moving outdoor terrain likely slip roll slope. Also, I sense Gs. I tried move hand around fast phone running andro-sensor fist saw readings saturated 20m/s2. What G I expect robot experience hit another fat moving bot bumped fast walking human?",sensors deduced-reckoning navigation accelerometer
413,Questions quadcopter radio controller,"I bought parts yet, I making quadcopter. I done research know parts I need, many guides sponsored cost thousand(s) euros/dollars explaining things entirely clearly. Firstly, I found flight control board. Would I need another microcontroller (such Arduino nano) work? (IF ANYONE experience board, let know!). Secondly, would board work radio controller. Are controllers universal? (Please tell I'm right section here, doesn't count relevant topic).",microcontroller quadcopter radio-control
416,What best way power large number (27) servos 5 V?,"I apologize question may sound little vague. I working robotics project contain 27 servos various sizes I trouble figuring powered. I hoping use several (3-6) 5 W 18650 battery boxes power them, smallest motors would use 2.5 W each, 1 battery box power two. The larger servos, obviously, use even current, plan using small number 18650's becomes infeasible. There enough room robot 12 V car battery, adding one would require recalculating sizes servomotors would needed. Furthermore, I sure convert 12 V gives 5 V servomotors. P.S. What stall current motors? Should power supply able supply stall current motors supplies (at time) working current? Should I use fuse handle (if?) servomotors stall? Should I use fuse circuit breaker? Do make 5 V fuses? If so, I get one? Something like larger version 18650 box would preferable.",design servos power
419,How implement INS accelerometer (optionally) gyros magnetometer?,"I'm building walking robot need know moves forward. I'm using on-board intelligence I plan using accelerometers, gyros, magnometers (if needed) able detect robot moves forward. The problem is, I dont know program Internal Navigation System IMU. What software algorithms needed? To clarify problem, I need know program micro controller read sensors able tell robot displaced forward since previous measurement. Also I used sensor board (or similar) could I use determine displacement.",software imu deduced-reckoning artificial-intelligence
431,Inverse Kinematics Java,"I'm planning write Inverse Kinematics controlled 6 dof virtual robot Android. I research packages avaliable couldn't choose right one satisfy needs project. I've seen work Eigen C++, used it, fine. But since i'm experienced Java, wanted ask start, someone knows appropiate packages operations. Here found far: JAMA, Vecmath, Jmathtools, EJML, JAMPACK I ask really dont want get stuck middle project. Thanks advance.",inverse-kinematics programming-languages
433,Visual Odometry options?,"What pros/cons different visual odometry options? Stereo Camera Optical Flow SLAM other? Criteria: well performs vs odometry options/sensors (lidar, radar) sensor fidelity computation accuracy precision drift native resilience repeadability sensor noise vehicle speed ease integrating IMU/GPS etc In general, course, lot different ways trade-offs go get specifics applications hardware. I'm asking curiosity, designing anything particular.",mobile-robot localization computer-vision odometry
436,How I model robot?,"The answers I received question training line following robot using reinforcement learning techniques, got think train robot. I believe essentially two ways - Train physical robot. Model robot simulate training. Did I miss something? Approach 2 definitely better approach. However, priori knowledge motion (response), certain PWM signal (stimulus) would cause robot given state required. The motion caused PWM signal may depend (1) current battery voltage, (2) mass robot (3) current velocity (did I miss something?). How I model robot? And I model quick? If I change battery add boards peripherals change mass robot, I would remodel retrain robot. Can I providing random stimulus PWMs measuring response? added: My related question dsp.SE Update: A suggested edit title Ian worth mentioning - ""How I model train robot dynamics change, need complete re-training?"" I think good question different one I asking here. I okay re-training now.",reinforcement-learning pwm
442,How dynamic effects motor current digital compass characterized compensated for?,"Digital compasses (magnetometers) require hard/soft iron calibration order accurate. This compensates magnetic disturbances caused nearby metal objects -- robot's chassis. (image ) However, digital compasses also susceptible electric fields caused relatively high amount current drawn motors. In order get accurate compass reading, best way measure (and compensate for) interference caused changing motor current levels?",mobile-robot sensors
445,How obtain dense point clouds stereo cameras?,"I trying use stereo camera scene reconstruction, I usually obtain sparse point clouds (i.e. half image proper depth information). I realize stereo processing algorithms rely presence texture images parameters tweaked obtain better results, disparity range correlation window size. As much I tune parameters, though, I never able get results even remotely close obtained using active sensor Kinect. The reason I want often point clouds corresponding adjacent regions don't enough overlap obtain match, reconstruction severely impaired. My question Computer Vision experts following: I obtain denser point clouds general (without arbitrarily modifying office environment)?",slam computer-vision
446,How much torque I need CNC machine?,"I handful 31.2oz-in stepper motors (Mouser.com - Applied Motion: HT17-268D), I curious would big enough run 3D printing/cutting/etching type (think RepRap) machine. I mind attach via simple gear screw-type drive run tool head back forth. Maximum bed size would probably ~1.5'3. Heaviest tool head would something half weight Dremel tool. Hardest substances I would use would probably hardwoods (with high speed cutter) copper (for PCB etching). How I figure amount torque needed drive head, would motors I already big enough job?",stepper-motor reprap
453,How one determine whether LiPo battery going bad?,"In lab use LiPo batteries power quadrotors. Lately experiencing stability issues using certain batteries. The batteries seem charge balance normally battery monitor indicates fine even putting load. However attempt fly quadrotor one batteries, manually autonomously, severe tendency pitch and/or roll. My guess battery supplying sufficient power motors brings question. Is behavior indicative LiPo going bad? If best way test battery confirm suspicions?",battery troubleshooting
461,"In PID control, poles zeros represent?",Whenever I read text control (e.g. PID control) often mentions 'poles' 'zeros'. What mean that? What physical state pole zero describe?,control pid
463,Connecting 6 pole motor motor driver?,"We trying power motor motor driver , using 11.1V 2.2Ah lithium-ion polymer battery. (We're heads really need help) We checked company (E-flite) motor definitely DC -- we're bit confused purpose three wires, connect motor. Any help would appreciated.",brushless-motor driver
469,"Is working implementation ""Navigation Among Movable Obstacles"" bi-pedal robot?","I would like better understanding work field ""Navigation Among Movable Obstacles"". I started Michael Stilman's thesis James Kuffner, yet sated appetite. I currently trying simulate scenario debris (Tables Table parts) disaster scenario block pathways. The debris forms part movable obstacle. The robot used bipedal humanoid. The thesis describes approach define search space possible actions leading start point goal. However, assumes mobile robot works via gliding. I think state space definitions would change bi-pedal robot. Why I wonder work done field. Perhaps work research groups could give clues design perhaps reduce search space bipedal humanoid robot. An implementation Navigation among Movable Obstacles would also aid understanding reduce search space possible actions. So anyone know working implementation Navigation among movable obstacles? Any supporting information professors research groups working similar problems would also useful. I hope edit sufficient problem description.",navigation
472,Humble beginnings,"I want learn robotics build first robot. I looking well supported kit simple enough walk through, initial stages intellectual pursuit Robotics. I want able basic things first build solid foundation robotics. And I want able use solid foundation, gain confidence ability build new interesting robotic contraptions. In words, I want able follow rules game gain solid foundation I'm comfortable I know, I want break free rules start making robots. I would like help 2 things, I would like begin robotics learning good kit walk initial stages. I expect initial stage might take quite while. So, recommendations I start and/or kit I buy, get feet wet, would helpful. I would like suggestions ""other"" actions I take, set path gain confidence knowledge robotics. A little bit myself. I BS MS IT. So I new programming. I like code golang haskell. I know possible, would awesome I write software aspect robotic projects haskell. Thanks",kit
474,USB instead RS232,"RS232 popular used mainly replaced USB [wikipedia]. Problems mentioned question doesn't help reputation either. In new system design therefore, one could think using USB instead Serial Port communication. However, still seems like RS232 serial communication protocol/port choice. Why that? I understand changing old machinery work RS232 costly, prevents new system designers using USB instead RS232?",rs232 usb
478,How I optimise control parameters stepper motor?,"As industrial roboticist I spent time working robots machines used brushless DC motors linear motors, I lots experience tuning PID parameters motors. Now I'm moving hobby robotics using stepper motors (I'm building first RepRap), I wonder I need differently. Obviously without encoder feedback I need much conservative requests motor, making sure I always keep within envelope possible, I find whether tuning optimal, sub optimal (worst case) marginally unstable? Obviously given load (in case extruder head) I need generate step pulse trains cause demanded acceleration speed motor cope with, without missing steps. My first thought test sequences, instance: Home motor precisely it's home sensor. Move $C$ steps away home slowly. Move $M$ steps away home conservative move profile. Move $N$ steps test acceleration/speed profile. Move $N$ steps back start test move conservative move profile. Move $M$ steps back home conservative move profile. Move $C$ steps back home sensor slowly, verifying sensor triggered correct position. Repeat variety $N$, $M$, acceleration/speed & load profiles. This reliably detect missed steps test profile move, seem like awfully large space test however, I wonder techniques developed optimise stepper motor control parameters.",control stepper-motor tuning
479,Particle filters: How resampling?,"I understand basic principle particle filter tried implement one. However, I got hung resampling part. Theoretically speaking, quite simple: From old (and weighted) set particles, draw new set particles replacement. While so, favor particles high weights. Particles high weights get drawn often particles low weights less often. Perhaps all. After resampling, weights get assigned weight. My first idea implement essentially this: Normalize weights Multiply weight total number particles Round scaled weights nearest integer (e.g. Python) Now I know often draw particle, due roundoff errors, I end less particles resampling step. The Question: How I ""fill up"" missing particles order get number particles resampling step? Or, case I completely track here, I resample correctly?",localization particle-filter
483,Strategies managing power electrical systems mobile robots,"What good strategies follow designing power supply electrical systems mobile robots? Such robots typically comprise systems microprocessor, microcontroller, DSP, etc units boards along immediate peripherals Motor control Analog Sensors(proximity, audio, voltage, etc) Digital Sensors (Vision, IMU, exotica) Radio comm circuits (Wifi, Bluetooth, Zigbee, etc) Other things specific purpose robot designed. Are unified approaches/architectural rules designing power systems manage clean power supply various units may distributed across boards, without issues interference, common ground, etc? Furthermore, also including aspects redundancy, failure management, 'power management/monitoring' features? well explained examples existing power systems robots would make excellent answers.",mobile-robot electronics
488,Matlab 'system' function ROS,"Is possible use matlab's ""system"" function call ROS commands? For example, using: system('rostopic pub /cmd_vel geometry.msgs.Twist {....} system('rospack find ipc_bridge) I'm trying send commands ROS without using something like IPC-Bridge. PS: I know, however, I need use IPC-Bridge subscribe topics.",mobile-robot software ros
494,More powerful alternatives Lego Mindstorm NXT 2.0?,"I'm interested build Robot imagination, I looking purchase robotic kit. I find Lego Mindstorm NXT 2.0 really interesting many reasons : You plug whatever brick want, develop language want. I developer, use kind robotic would interaction mostly (not moving, servo motors useless me, least now). But regarding spec NXT main component, I feel it's bit low (proc, ram & rom). That made wonder know something similar (where I plug whatever I want it, importantly, program reaction), powerful hardware ? Price also limitation : I like NXT also I build I want 300 USD. I don't want spend 10k USD first kit, I would appreciate buying better piece robotic price isn't distant NXT's. Do alternatives check ? Thanks help ! :)",nxt
497,Collaborative Behavior: Implementing Bucket Brigade With Robot Arms,"I wondering whether something like possible: A block ice(say) needs transferred piece piece source destination help 5 robots standing straight line source destination. The first robot picks piece block source checks next robot line busy. If yes, waits complete task proceeds, otherwise transfers piece goes back collect another piece. Please help implementing possible, I thinking make project topic. clear confusions, here's smaller prototype project i'm thinking, two cars, one wired, another wireless. wired car master here, wireless, slave. remote, send command wired car instead command wireless car move forward. wired car check wireless slave already executing previously given command no, accordingly send command. conversely, master may send command soon receives it, it's slave complete task it's doing, execute command received.",mobile-robot multi-agent
499,I don't understand Integral part PID controller,"I dont understand integral part PID controller. Let's assume pseudocode Wikipedia: Integral set zero beginning. And loop it's integrating error time. When I make (positive) change setpoint, error become positive integral ""eat"" values time (from beginning). But I dont understand is, error stabilizes back zero, integral part still value (integrated errors time) still contribute output value controller, not, error zero, output PID zero well, right? Can somebody explain please?",control pid
502,"Is place posting ""look I did"" videos?","Robots somewhat videogenic, old saying ""show me, don't tell me"" especially applicable. But course, video question, doesn't fit Stack Exchange format. Maybe video links would suitable CodeProject post. It seems like board hits right cross-section people, whose projects I would interested seeing.",untagged
504,Choosing motors 2 wheel drive robot,I making 2 wheel drive robot. Suppose I know robot going weight x kg finished I know diameter wheels (geared motors connected directly wheels). I choose several geared motors I know peak torque motor idling speed. How I calculate load specific motor take? I.e. motor given torque able move robot without overloaded? What rpm motor load?,motor
511,Where I find tutorial sample code Juniper WiFi Arduino Shield?,"I recently got arduino wifi shield known ""juniper"" (I believe cutedigi). I've tried find code examples, I saw code, un-commented little explained, I could really use tutorial sample code good explanation, anyone help find place start? I found piece code here: I want connect network, maybe send get requests, open socket. EDIT: poking around while, found documentation, I still can't get work. code: I can't seem get input wifi shield.",arduino electronics wifi
512,How I start learning robotics?,For someone interested robotics know ABC robotics mechanical/electronic engineering .What's good roadmap becoming amateur roboticist . I'm studying theoretical physics I problems physics/math . If question broad doesn't meet criteria posting site . Please inform helpful advice/study material etc. question get closed . Thanks advance.,books
519,"EKF-SLAM Update step, Kalman Gain becomes singular","I'm using EKF SLAM I'm problem update step. I'm getting warning K singular, rcond evaluates near eps NaN. I think I've traced problem inversion Z. Is way calculate Kalman Gain without inverting last term? I'm 100% positive cause problem, I've also put entire code . The main entry point slam2d. Edits: project(x(r), x(lmk)) project(x(r), x(lmk_idx)) corrected above. K goes singular little while, immediately. I think it's around 20 seconds so. I'll try changes @josh suggested I get home tonight post results. Update 1: My simulation first observes 2 landmarks, K 7x2. (P(rl,rl) * E_rl') * inv( Z ) results 5x2 matrix, can't added x next line. K becomes singular 4.82 seconds, measurements 50Hz (241 steps). Following advice (), I tried K = (P(:, rl) * E_rl')/Z results 250 steps warning K singular produced. This tells problem isn't matrix inversion, it's somewhere else that's causing problem. Update 2 My main loop (with robot object store x,P landmark pointers): = 0:sample_time:max_time P = robot.P; x = robot.x; lmks = robot.lmks; mapspace = robot.mapspace; u = robot.control(t); = robot.measure(t); % Added show eigenvalues step [val, vec] = eig(P); disp('***') disp(val) %%% Motion/Prediction [x, P] = predict(x, P, u, dt); %%% Correction lids = intersect(m(1,:), lmks(1,:)); % find observed landmarks lids_new = setdiff(m(1,:), lmks(1,:)); lid = lids % expectation idx = find (lmks(1,:) == lid, 1); lmk = lmks(2:3, idx); mid = m(1,:) == lid; yi = m(2:3, mid); [x, P] = expectation(x, P, lmk, yi); end %end correction %%% New Landmarks id = 1:length(lids_new) % id ~= 0 lid = lids_new(id); lmk = find(lmks(1,:)==false, 1); = find(mapspace, 2); ~isempty(s) mapspace(s) = 0; lmks(:,lmk) = [lid; s']; yi = m(2:3,m(1,:) == lid); [x(s), L_r, L_y] = backProject(x(r), yi); P(s,:) = L_r * P(r,:); P(:,s) = [P(s,:)'; eye(2)]; P(s,s) = L_r * P(r,r) * L_r'; end end % end new landmarks %%% Save State robot.save_state(x, P, mapspace, lmks) end end At end loop, I save x P back robot, I believe I'm propagating covariance iteration. More edits The (hopefully) correct eigenvalues here: There number eigenvalues negative. Although magnitude never large, 10^-2 most, happens iteration immediately first landmark observed added map (in ""new landmarks"" section main loop).",slam kalman-filter
520,Is practical 3D print refractive lens?,"A lot awesome optics projects like hacking cameras projectors become possible CAD lens modelling software1, also easily prototype lenses design. What materials additive subtractive 3D fabrication strategies make clear lens strong refraction ability polished? 1 Here helpful list 37 different lens design & simulation programs.",3d-printing manufacturing
521,Computing Jacobian matrix Inverse Kinematics,"When computing Jacobian matrix solving Inverse Kinematic analytically,I read many places I could use formula create columns joint Jacobian matrix: Such $a'$ rotation axis world space, $r'$ pivot point world space, $e_{pos}$ position end effector world space. However, I don't understand work joints one DOFs. Take following example: The $\theta$ rotational DOF, $e$ end effector, $g$ goal end effector, $P_1$, $P_2$ $P_3$ joints. First, I compute Jacobian matrix based formula diagram, I get something like this: $$J=\begin{bmatrix} ((0,0,1)\times \vec { e } )_{ x } & ((0,0,1)\times (\vec { e } -\vec { P_{ 1 } } ))_{ x } & ((0,0,1)\times (\vec { e } -\vec { P_{ 2 } } ))_{ x } \\ ((0,0,1)\times \vec { e } )_{ } & ((0,0,1)\times (\vec { e } -\vec { P_{ 1 } } ))_{ } & ((0,0,1)\times (\vec { e } -\vec { P_{ 2 } } ))_{ } \\ ((0,0,1)\times \vec { e } )_{ z } & ((0,0,1)\times (\vec { e } -\vec { P_{ 1 } } ))_{ z } & ((0,0,1)\times (\vec { e } -\vec { P_{ 2 } } ))_{ z } \\ 0 & 0 & 0 \\ 0 & 0 & 0 \\ 1 & 1 & 1 \end{bmatrix} $$ This assumed rotation axes $(0,0,1)$ one rotational DOF. So, I believe column one DOF, case, $\theta_\#$. Now, here's problem: What joints full 6 DOFs? Say now, every joint, I rotational DOFs axes, $\theta_x$, $\theta_y$ $\theta_z$, also translational DOFs axes, $t_x$, $t_y$ $t_z$. To make question clearer, suppose I ""forcefully"" apply formula DOFs joints, I probably get Jacobian matrix like this: (click full size) But incredibly weird 6 columns DOF every joint repeating thing. How I use formula build Jacobian matrix DOFs? How would Jacobian matrix look like case?",inverse-kinematics kinematics
524,Compatable ESC's brushless 3 phase motors,Am trying find right ESC following two motors Can't figure ESC's listed site would best? Are alternative (cheaper better?) options?,motor brushless-motor
530,Rainbowduino 3.0 - Arduino IDE fails upload,"OK, really robotics, anyone able upload Rainboduino v3.0 using Arduino IDE? I can't seem figure out, virutally documentation online. I followed blog entry, got connection board. If anyone give suggestions, I would appreciate it!",software arduino programming-languages
531,Using IMU build INS,What's needed utilize IMU ArduIMU+ V3 used INS. Is hardware needed?,arduino slam imu deduced-reckoning
533,What earliest concept robot?,I'm highschool student studying electronics assessment task history electronics I decided focus history robotics. I want begin earliest possible concept robot progress major developments robotics current day. Where I begin research?,electronics research
535,How computationally powerful Arduino Uno board?,"What Arduino board Uno really do? Of course simple things like controlling couple servos easy it. However, I don't think Uno board would able preform real-time 3D SLAM point cloud data gathered Kinect sensor mobile robot, right? If robot speed Arduino wouldn't able keep up, correct? Could 2D SLAM moving able keep up? What taking 1/10 points Kinect sensor processing those? Basically, examples resource limitations Arduino board?",arduino slam kinect
541,Wheels vs Continuous Tracks (Tank Treads),"I'm building small robot using cheap Vex Robotics tank treads. However, choice picking tank treads almost purely based fact seem like fun wheels. I don't actually know really much advantage disadvantage compared wheels. What pros cons wheels continuous tracks?",mobile-robot design wheeled-robot tracks
543,Why quadcopters common robotics configurations?,I've noticed almost research done helicopter robots done using quadcopters (four propellers). Why little work done using tricopters comparison? Or different number propellers? What four propellers made quadcopters popular choice?,quadcopter design uav
550,How To Determine Heading Without Compass,Lets say I drop robot featureless environment magnetic field based sensors (magnetometer/compass) allowed. What methods determining north is? Tracking sun/stars option reliable enough weather considered. Can pick rotation earth using gyros? Are clever solutions?,localization
554,Quadcopter liPo battery weight/capacity trade,"I'm trying find additional battery capacity becomes worthless relation added weight terms quadcopter. Currently 5500 mAh battery, 11.1V, I get 12 minutes 12:30 flight time it. My question, then, - within quads lifting capability course, way find added weight larger battery (or batteries) cancels flight time improvement? Obviously it's going long two separate flights, landing swapping batteries; I'm trying maximize continuous 'in air' time. I'm trying figure line (and I've already crossed it) tacking bigger batteries onto quad seeing diminishing returns. Thanks! (Again, presume quad strong enough lift whatever throw it. With one 5500mAh, ~ 470 grams, max throttle 70%)",battery quadcopter power
556,"Is accelerometer sufficient detect displacement, I need INS?","Do I need complex system (of gyros, accelerometers etc.) detect robot moved forward I simply use accelerometer. I'm building robot learns walk I need detect displacement machine learning. Can I use accelerometer I need complicated/expensive Internal Navigation System?",slam machine-learning deduced-reckoning gyroscope accelerometer
558,Why Mars rovers designers prefer wheels tracks?,"Typically Mars rovers use wheels tracks. I guess Spirit would better chances getting soft soil tracks. In general, Mars surface structure known advance, seems wiser prepaired difficult terrain use tracks. Why Mars rovers typically use wheels tracks?",mobile-robot design
565,Kinect - Libfreenect vs OpenNI+SensorKinect,What pros cons each? Which better maintained? Which allows functionality? Which utilizes hardware efficiently? Etc.,software sensors kinect
566,Decision trees solving 2D inverse kinematics?,"While experimenting OpenCV Machine Learning Library, I tried make example learn inverse kinematics 2D, 2 link arm using decision trees. The forward kinematics code looks like this: I generate random set 1000 (XY -> alpha) (XY -> beta) pairs, use data train two decision tree models OpenCV (one alpha, one beta). Then I use models predict joint angles given XY position. It seems like sometimes gets right answer, wildly inconsistent. I understand inverse kinematic problems like multiple solutions, answers I get back wrong. Is reasonable thing try do, never work? Are learning algorithms would better suited kind problem decision trees?",inverse-kinematics machine-learning
568,Is possible run neural network microcontroller,Could implement simple neural network microprocessor Arduino Uno used machine learning?,microcontroller machine-learning
578,Which programming language I use NXT?,"We optional course high-school robotics. We're using Lego Mindstorms NXT program original Mindstorms-software. However, want advance use major programming-language. We tried NXC LeJos. Plus, I tried Microsoft Robotics Development Studio, different possibilities little bit overwhelmed. Because (now becomes interesting), I want ask, technology best NXT especially: What easy use? I don't want need 14 steps compile program get running NXT. Also, would nice, it's extend-able language, like using C#, better easier possibilities?",programming-languages nxt
583,Inverse kinematics joint contraints,"I manipulator 4 revolute joints movement limitations. So, I apply inverse kinematics, I'm getting results limits. Please provide algorithm implements inverse kinematics considering joint limitations.",inverse-kinematics
585,King Robota: Does speak himself?,"I want know currently possible robot speak self does, someone speaking behalf? Youtube video",control software
599,"Who coined (or popularized) term ""SLAM""?","According Wikipedia's article SLAM, original idea came Randal Smith Peter Cheeseman (On Estimation Representation Spatial Uncertainty [PDF]) 1986, refined Hugh F. Durrant-Whyte J.J. Leonard (Simultaneous map building localization autonomous mobile robot) 1991. However, neither paper uses term ""SLAM"". Where (and when) term come from? Was particular author whitepaper popularized it?",slam
602,Vex motors tank treads drained 9-volt battery quickly expected,"I've got couple Vex 269 Motors hooked Arduino Duemilanove. These motors run Vex Tank Treads. I powered whole setup off-brand 9-volt battery. Everything seems run great, except able run 30 seconds worth motor movement. Then battery quickly isn't able pump energy needed move treads whole thing quickly slows unusable. What's problem here? The tank treads seem loose enough I don't think they're restricting motor pump much energy move them. There's nothing else powered except Arduino motors. Is Enercell 9-volt (alkaline) terrible battery choice? Should I expect long battery life robot 9-volt? Or something else I'm missing? Thank much!",battery tracks troubleshooting
603,How get two continuous tracks (tank treads) move rate?,I've got couple Vex 269 Motors hooked Arduino Duemilanove. These motors run Vex Tank Treads. The two motors run servos Arduino using Servo Library. The problem I'm two tracks don't turn speed sent servo angle. This clearly due fact continuous tracks many moving parts identical friction forces track hard get. How I get move speed? Should moving speed given servo angle regardless friction Vex 269 Motors aren't strong enough (meaning I use Vex 369 powerful motor)? Is best trial error long enough figure servo angle results equal speeds each? Should I tinker tracks nearly identical frictions? Thank much!,mobile-robot motor tracks
609,"Including RaspberryPi within robot... Does allow ""universal API""?","I know broad statement, you've got support TCP well full fledged computer board (to integrate/run arduino), essentially allow anything would run linux box (raspberryPi) run operate robot? I know clock speed well dependency libraries given code base (on Pi) would add complexity here, big issues I'm overlooking vertically-integrated control system? Including RaspberryPi within robot... Does allow ""universal API""?",software arduino raspberry-pi
613,What stall current free current motors?,"What stall free currents electric motor? For example, Vex motor lists stall free currents bottom page. I think I understand general idea, detailed description would helpful.",motor current
616,Arduino Vin Current Limit,"I've found Arduino (Duemilanove) current limit 40mA per pin. Does include Vin pin? Or Vin pin sort work around place board allow higher currents? If limit Vin, good way using still using power supply jack board allowing sources draw supply without needing pass chip first? Thank much. EDIT: For second part, I I wanted get something like 2 amps?",arduino current
619,Programming ESC reverse mode,"How program ESC reverse mode? We're looking control ESC servo board (for robotics project). Assuming input 0 255, we're looking 127 off, 255 fully forward 0 full reverse, achieve that?",control motor
623,"When taking VCC power arduino 12v regulator, 5v, I need two sets capacitors?","I'm building open-source bio-research hardware (ask help!) I've got guy here: My big questions are: Can I get away ground common? (I've got 12v 5v needing grounded) Do I need two sets capacitors? There 2 wired 12v regulator 2 wired 5v regulator. (These shown blue) I've generally denoted connections go UNDER shield orange, green. If anyone happens see something might backfire, feel free point out. As also first time making anything quite like this! I've verified regulator positions correct. This proto-shield Arduino R3 Uno. A larger version image seen here:",arduino electronics
627,Formatting SD card Panda Board ES,"I Panda Board ES. I able get boot. I sent back SVTronics get checked said board OK; I one able configure properly. After little research following directions Panda Board Ubuntu website, I still able get board boot. I think problem I formatting SD card. I using disk utility Mac format SD card ""MSDOS(FAT)"" partition. I would like know format ""SD Card"" Macintosh install Ubuntu Panda Board ES.",electronics operating-systems
628,What algorithm I implement program room cleaning robot?,"For question assume following things unknown: The size shape room The location robot The presence obstacles Also assume following things constant: The size shape room The number, shape location (if any) obstacles And assume robot following properties: It move forward increments absolute units turn degrees. Also operation moves return true succeeded false failed move due obstruction A reasonably unlimited source power (let's say solar powered robot placed space station faces sun times ceiling) Every movement rotation carried absolute precision every time (don't worry unreliable data) Finally please consider following properties robot's environment: Being ceiling-less space station room safe frustratingly close distance passing comets, dust (and ice) constantly littering environment. I asked much simpler version question (room rectangle obstacles, would move guaranteeing could every part least once) I started wondering would approach couldn't guarantee shape presence obstacles. I've started looking Dijkstra's algorithm, I'm fascinated hear others approach (or well accepted answer this? (How Roomba it?)",mobile-robot artificial-intelligence algorithm coverage theory
634,How charge LiFePO4 battery?,"From I've seen, LiFePO4 batteries seem like one top battery choices robotics applications. However, I've seen people mentioning can't use charger different battery charge these, I haven't seen why. If I build setup charge LiFePO4 batteries would specifically need do? What kind voltages current rates need supply charge these? More specifically, I think setting solar charger batteries. Is immediate reason bad solution? Such as, battery needs charge current amount work properly? If you're ambitious enough provide example along explanation, I'm specifically thinking 4 batteries 2 pairs 2 series parallel.",battery
636,Will turning NXT motor hand damage it?,Many people claim turning NXT motor hand damage it. Is true? Does matter motor idle set break? Are facts confirm refute argument? I know projects (e.g. etch-a-sketch) use built-in rotation sensor measure much motor turned. Does indicate hand-turning NXT motors okay? Do need put special 'rotation sensor' mode?,motor nxt mindstorms
637,Protecting electronics voltage/current extremes bad polarity,"I built robot wheelchair worked well thus far. It time take next step. I need implement permanent power circuit proper protection. The lowest level protection I think fuse, I would like take step (current/voltage/direction/switches/High/Low voltages). If one could give insight project mine info greatly appreciated. Moderator comment: Please see How address questions related subject areas? answering. This question close boundary, on-topic here.",mobile-robot wheeled-robot protection circuit
641,Good book mechanisms,"I working students (9th & 10th grade) robotics wanted get good book covers basic mechanisms. Does anyone recommendations. Searching Google Amazon yields many results, however, I thought community might standard book use.",design mechanism
642,MMA7361 Accelerometer Always Displays Same Values,"I recently purchased 3-axis accelerometer Amazon, can't seem find works. I've looking quite now, haven't found real clues. The x, y, z values always seem return values. They change I tilt move accelerometer, revert 120 reading. I currently using device Arduino Uno, using following code: Also, would I go converting tilt?",arduino sensors accelerometer
646,MEMS accelerometer calibration,"I trying calibrate MEMS accelerometer. I able calibrate current axis parallel gravity shows correctly, 1g. But two axes 0.00g showing +-0.02g instead. So, e.g., accelerometer's x axis parallel gravity, show (1g, 0g, 0g) (1g, 0.02g, -0.01g) like now. How could I eliminate values, e.g. calibrate accelerometer? EDIT: The acelerometer's datasheet says nothing calibrating except The IC interface factory calibrated sensitivity (So) Zero-g level (Off) (page 20).",design electronics accelerometer calibration
649,Does RRT* guarantee asymptotic optimality minimum clearance cost metric?,"The optimal sampling-based motion planning algorithm $\text{RRT}^*$ (described paper) shown yield collision-free paths converge optimal path planning time increases. However, far I see, optimality proofs experiments assumed path cost metric Euclidean distance configuration space. Can $\text{RRT}^*$ also yield optimality properties path quality metrics, maximizing minimum clearance obstacles throughout path? To define minimum clearance: simplicity, consider point robot moving Euclidean space. For configuration $q$ collision-free configuration space, define function $d(q)$ returns distance robot nearest C-obstacle. For path $\sigma$, minimum clearance $\text{min_clear}(\sigma)$ minimum value $d(q)$ $q \in \sigma$. In optimal motion planning, one might wish maximize minimum clearance obstacles along path. This would mean defining cost metric $c(\sigma)$ $c$ increases minimum clearance decreases. One simple function would $c(\sigma) = \exp(-\text{min_clear}(\sigma))$. In first paper introducing $\text{RRT}^*$, several assumptions made path cost metric proofs hold; one assumptions concerned additivity cost metric, doesn't hold minimum clearance metric. However, recent journal article describing algorithm, several prior assumptions weren't listed, seemed minimum clearance cost metric might also optimized algorithm. Does anyone know proofs optimality $\text{RRT}^*$ hold minimum clearance cost metric (perhaps one I gave above, another minimum), experiments performed support algorithm's usefulness metric?",motion-planning algorithm rrt theory
650,Can I make simple Bluetooth receiver?,"I control relay Android smartphone using Arduino Bluetooth seen here. However, seems costly using Arduino Bluetooth receiver driving switch. As long Bluetooth radio frequency, possible make simple Bluetooth receiver output 1 0 drive relay? If yes, tough going be? The main factor cost, \$1-$5.",sensors circuit
653,What notable limitations using Java Mindstorms NXT 2.0?,"I'm long time Java developer starting learn Lego Mindstorms NXT 2.0. Are limitations using Java API? Which language robust platform? I found post, Which programming language I use NXT? mentions many alternatives. The answer helpful, doesn't mention different languages' limitations.",nxt programming-languages mindstorms
654,What difference Kinect Windows Kinect XBox?,"As I see huge price gap two \$223 vs \$99 (at amazon). My intention use one Ubuntu linux perform depth sensing, navigation etc. naturally I prefer cheaper. However I sure I miss important point betting Kinect Xbox version. As seems Windows version overpriced license development. Here stated internal differences without exact details (The minimum sensing distance seems better Windows version.). Could anyone give comparison chart? It would good know Connectivity: USB, special connector, ... . Hardware differences: really differ weight, energy consumption, speed, sensing range, ...? Driver: could I use Xbox version Ubuntu? API usage: could I develop Xbox version, could I use same/similar API both, API Xbox mature enough? License: license Xbox version develop home/hobby/educational use? Thanks.",sensors kinect
656,"Lightweight, commercially available robotic arms","I wondering options terms lightweight (< 5 lbs) robotic arms. I see Robai Cyton Gamma 300, CrustCrawler AX18 look like interesting options. What lightweight arms people use/like?",mobile-robot arm
667,Raspberry Pi operating system robotics,"Is operating system Raspberry Pi specifically made running robotics applications? Or operating system whose purpose optimized run specific programs? I've working Arduino now. As far efficiency goes, makes sense upload specific set commands hardware need handle that, worry running full fledged operating system. Is something like possible Raspberry Pi?",raspberry-pi operating-systems
671,Check task exists Not eXactly C,"Is way check task, function variable exists Not eXactly C? I know PHP use check variable exists function_exists() function, way NXC? I specifically interested checking whether task exists alive.",nxt programming-languages mindstorms not-exactly-c
672,PID line follow three sensors Not eXactly C,"I'm currently working line-following robot uses three sensors follow black line. The sensors pretty much line right next other. Right now, I'm simple line follow: line go forward, otherwise turn left right regain line. This means robot wiggling along line time. I'm looking better way robot follow line using three sensors. The program I'm writing Not eXactly C code. I'm trying get robot utilize power PID control, I'm sure one would go writing three-sensor PID line-follower program NXC.",nxt programming-languages mindstorms algorithm not-exactly-c
679,Why Mars rovers slow?,"Mars rovers typically slow. Curiosity, example, average speed 30 meters per hour. Why designed slow? Is specific power restrictions reasons? What top reason slow?",mobile-robot design
684,Why LM2576 circuit suddenly cut power?,"I LM2576 circuit plus adjuster adjust output voltage, controlling motor speed line follower robot. The circuit works great adjusted give low voltages, I adjust higher voltages motors go faster, works great 1-2 minutes, suddenly cuts power motors start go extremely slow. Even I decrease increase output voltage, won't respond I turn power turn back again. There something mentioned LM2576 datasheet overload IC cut power load comes lower, I think might problem that. Since problem already caused us lose competitions 5+ teams, I would like solve next competition, LM2576 circuit suddenly reduce power?",motor electronics power
687,Robotics Kinect,"I want learn robotics really interested making robot based Kinect sensor. I see many projects like one : wondering works top level. I downloaded Kinect SDK basic tutorials, I don't think Microsoft SDK library use real robotics projects. Any suggestions start library use? Any good books particular online resources? Any help appreciated, thank you.",kinect
689,"Cable routing theta, x, motion control system. Better inside outside?","I'm building motion control platform 3 DoF: 1 axis rotation (theta) 2 cartesian (x,y). In applications, like wrist actuation, X-Y stage rotating servo stage's payload. This configuration works well since little power data wiring needs transit non-linear moving portion platform. For inverted application, stackup reversed. The rotating axis comes first (from mounting plane) stage connected rotating platform's payload. Now nearly wiring (power, command, sensor, otherwise) must routed non-linearly moving section. I see two broad approaches: The inside track, I route cabling center rotation. The outside track, I route cabling around outside outer diameter rotating platform. Mathematically, I see (1) results minimum cable length, maximum torsional loading, (2) results maximum cable length, minimum torsional loading wires. Having limited experience cable routing (and associated carriers, strategies, products) non-linear applications, question is... ...which approach better practice? Cost isn't really issue here. I'm interested reliability, ease construction, availability commercial components (says something popularity technique), etc... e.g. generic concepts behind pick one other. ...of course, part numbers I wouldn't upset <-- I know I'm supposed ask ;-)",control wiring routing motion
690,Noise motion measurement models,"When using EKF SLAM, I often see motion measurement models described noise term. This makes sense you're simulation, need add noise simulated measurement make stochastic. But using real robot data? Is noise already measurement thus need added, noise matrix mean something else? For example, Probabilistic Robotics (on page 319), measurement model: $z_t^i = h(y,j) + Q_t$, $Q_t$ noise covariance. Does $Q_t$ need calculated working real data?",slam kalman-filter
693,Can I use ROS Roomba?,Is anything different iRobot Roomba Create? I want go start building turtlebot playing ROS cost parts I'm going piece piece. It's pretty easy find cheap used Roombas.,ros roomba irobot-create
696,Are working instances Kilobot projects?,"The interesting Kilobot project Harvard investigating multi-robot behavior masses small dumb robots made open hardware year now. However I cannot find much activity robot creation movies results. Is hard create robots, programmer, charger isn't project interesting enough?",multi-agent
697,Standalone (or capable being) Robotics Simulator,"I'm software engineer volunteers non-profit introduces young girls technology. We recently talking methods introducing children world robotics, I curious types low-cost options have. One appealing idea would online simulator, (more preferable) off-line standalone-simulator build program simple robots with. Perhaps nothing dragging components together, programming interactions components. What solution(s) exist I might able make use outreach?",software simulator children
704,Wifly Shield Not Connecting,"I recently asked question juniper WiFi shield, working wifly spark fun. I've using updated version experimental library, attempting set webserver. Unfortunately, I attempt connect web browser, I get error saying page sent data. Here's code: I using Arduino Uno, serial monitor looks like this: Connection Succesful! 10.100.1.173 Receving Client Input... Is anything obviously wrong code? EDIT: I new shield, I'm still working problem. Is malfunction hardware? I can't figure out!",arduino software wifi c
709,Why Servo Motors noisy?,"I working project make bedside night light stuffed butterfly bird. I making mechanism make wings flap servo motor small gears. The servo motor loud moved. And whether servo moving large amounts, small amounts, fast slow. I've worked small servos realized usually pretty noisy machines, I can't really explain why. Why small servo motors noisy move? Is backlash internal gearing?",rcservo
712,Quadruped Learning Simulator,"I'm currently building robot four legs (quadruped), 3 DOF (Degrees Freedom) Its suggested I use simulator learning computer upload algorithms robot. I'm using Arduino Uno robot software could I use simulate learning able upload Arduino board?",mobile-robot arduino microcontroller machine-learning simulator
716,C++ Robust Model Fitting Library,"Often I need perform model fitting I find looking decent C++ library this. There RANSAC implementation MRPT, I wondering alternatives available. To give example type problems I would like solve: For set $A$ (approx 500) 3D point pairs $(a, b)$ I would like find Isometry transform $T$, maps points onto $|(a - Tb)| < \epsilon$. I would like get largest subset $A$ given $\epsilon$. Alternatively I guess I could subset size fixed ask lowest $\epsilon$.",c++ ransac
718,How computer vision distinguish one object contained another vs top it?,How know object contained inside another object lying top it? Lets take example cup-plate-spoon. The cup lying top plate. But spoon inside cup. How distinguish 2 situations? What criteria decide whether A contained inside B lying B? I trying solve using kinect.,kinect computer-vision algorithm
725,Least squares map joining,"There lot background here, scroll bottom question I trying map joining algorithm described How Far SLAM From Linear Least Squares Problem; specifically, formula (36). The code I written seems always take values second map landmark positions. My question is, I understanding text correctly I making sort error. I'll try explain formulas I understand show code implements that. I'm trying simple case joining two local maps. From paper (36) says joining two local maps finding state vector $X_{join,rel}$ minimizes: $$ \sum_{j=1}^{k}(\hat{X_j^L} - H_{j,rel}(X_{join,rel}))^T(P_j^L)^{-1}(\hat{X_j^L} - H_{j,rel}(X_{join,rel})) $$ Expanded two local maps $\hat{X_1^L}$ $\hat{X_2^L}$ I have: $$ (\hat{X_1^L} - H_{j,rel}(X_{join,rel}))^T(P_1^L)^{-1}(\hat{X_1^L} - H_{j,rel}(X_{join,rel})) + (\hat{X_2^L} - H_{j,rel}(X_{join,rel}))^T(P_2^L)^{-1}(\hat{X_2^L} - H_{j,rel}(X_{join,rel})) $$ As I understand it, submap viewed integrated observation global map, $P^L_j$ noise associated submap (as opposed process noise EKF I used make submap, may may different). The vector $X_{join,rel}$ pose first map, pose second map union landmarks maps. The function $H_{j,rel}$ is: $$ \begin{bmatrix} X_{r_{je}}^{r_{(j-1)e}}\\ \phi_{r_{je}}^{r_{(j-1)e}}\\ R(\phi_{r_{(j-1)e}}^{r_{m_{j1}e}}) (X^{r_{m_{j1}e}}_{f_{j1}} - X^{r_{m_{j1}e}}_{r_{(j-1)e}})\\.\\.\\.\\ R(\phi_{r_{(j-1)e}}^{r_{m_{jl}e}}) (X^{r_{m_{jl}e}}_{f_{jl}} - X^{r_{m_{jl}e}}_{r_{(j-1)e}})\\ X_{f_{j(l+1)}}^{r_{j-1e}}\\ .\\.\\.\\ X_{f_{jn}}^{r_{j-1e}} \end{bmatrix} $$ I'm convinced assessment correct: The first two elements robot's pose reference frame previous map. For example, map 1, pose initial frame $t_0$; map 2, frame map 1. The next group elements common map 1 map 2, transformed map 1's reference frame. The final rows features unique map 2, frame first map. My matlab implementation follows: I using optimization toolbox find minimum fitness function described above. The fitness function pretty straightforward I think. The function H returns vector H described above. The result is: When I run join_maps two vectors map_1 = [3.7054;1.0577;-1.9404; %robot x, y, angle 2.5305;-1.0739;81.0000]; % landmark x, y, id map_2 = [3.7054;1.0577;-1.9404; 2.3402;-1.1463;81.0000]; % note slightly different x,y [G,fv,output,exitflag] = join_maps(map_1, map_2) The output is: Warning: Gradient must provided trust-region algorithm; using line-search algorithm instead. > In fminunc 341 In join_maps 7 Local minimum found. Optimization completed size gradient less default value function tolerance. <stopping criteria details> Local minimum possible. fminunc stopped cannot decrease objective function along current search direction. <stopping criteria details> G = 3.7054 1.0577 -1.9404 3.7054 1.0577 -1.9404 2.3402 -1.1463 81.0000 fv = 1.3136e+07 output = iterations: 1 funcCount: 520 stepsize: 1.0491e-16 firstorderopt: 1.6200e+05 algorithm: 'medium-scale: Quasi-Newton line search' message: [1x362 char] exitflag = 5 The question: My program gives map 2 minimum map joining function. It seems like minimum somewhere map 1 map 2. I'm pretty sure problem matrix H. What I wrong?",slam
726,Guiding Quadrotor Towards Target,"I working quadrotor. I know position -- $a$, I would like go -- target position $b$, I calculate vector $c$ -- unit vector take target: Since quadrotor move direction without rotation, I tried rotate $c$ robots yaw angle split $x, y$ components pass robot roll pitch angles. The problem yaw 0° ±5 works, yaw near +90 -90 fails steers wrong directions. My question I missing something obvious here?",quadcopter uav navigation
730,Good method building pan tilt controller?,"Have ever seen one video games headset/goggles stand look around virtual scene with? I'm building one those, I'm trying design simple controller. I need output controller emulate mouse input. So look left, it's moving mouse left. Supposing I use optical encoders, pan tilt need separate locations (a couple inches apart). It seems many mouse hacks online components close together. Do think it's possible one encoders distance away controller chip? For OEM purposes, good mouse controller chip output USB protocol mouse movements I could buy bulk? Many thanks suggestions. Cheers",microcontroller
734,Comparing maps groundtruth,"When you've created map SLAM implementation groundtruth data, best way determine accuracy map? My first thought use Euclidean distance map groundtruth. Is measure would better? I'm wondering it's also possible take account covariance map estimate comparison.",slam mapping
736,Inter-processor communication robotic arm,"I'm building hobby 6-DOF robotic arm wondering best way communicate processors (3-4 AVRs, 18 inches max separation). I'd like control loop run computer, sends commands microprocessors via Atmega32u4 USB-to-??? bridge. Some ideas I'm considering: RS485 Pros: processors wire, differential signal robust Cons: requires additional chips, need write (or find?) protocol prevent processors transmitting time UART loop (ie, TX one processor connected RX next) Pros: simple firmware, processors UART built Cons: last connection travel length robot, processor spend cycles retransmitting messages CANbus (I know little this) My main considerations hardware firmware complexity, performance, price (I can't buy expensive out-of-box system).",microcontroller electronics arm
738,What methods dealing compass lag (rate dependent hysteresis)?,"I've got tread-driven robot, low precision wheel encoders tracking distance electronic compass determining heading. The compass significant (> 1 second) lag robot turns quickly, e.g. reaching waypoint — pivoting place point new heading. What ways dealing lag? I would think one could take lot measurements model compass response. However, seems problematic since it's rate-dependent I don't know instantaneous rate. As simple-but-slow approach, I robot turn it's roughly pointed right direction, make small incremental turns brief measurement pauses it's pointed right way. Are ways dealing this?",sensors compass
741,How determine EKF process noise pre-recorded data sets?,"I've seen question, asks determining process noise EKF. I don't see anything pre-recorded data sets. My thought determine noise parameters, assuming ground truth available, would run data several times EKF minimize mean square error, varying noise parameters. Is acceptable way determine noise pre recorded data set? Are better (or other) ways determining optimal noise values based data set?",noise ekf
748,How many amps I want Switching BEC provide?,"I'm trying power 7-12 servos, I impression one would need amp, looking around appropriate BEC supply them, I notice seem output around 1-3.5 amps. They won't running once, often, say 4 drawing enough juice move. Obviously, I'm missing link understanding. How I determine many amps needed power supply?",design power rcservo bec
751,Confused variables RobotC?,"I'm trying program advanced functions RobotC I'm sure I'm right. I want specify motor port I'm using, I assigned names motors. Funny thing though, don't exactly work regular variables. For instance, motor[port7]'s alternate name light_blue. I'm really sure new variables, specifications. Anyway, variable's signature: int motor[tMotor motor] My code plans something similar this: void testThing (Motor motorName) { motorName = someValue; } testThing(light_blue); But int/motor hybrid variable/unidentified I'm sure well would work out. Or all.",robotc
757,"How I upgrade existing robot higher torque, sensored motor @ ~100 watts?","I would like high torque motor (37 oz-in @ 5760 rpm) souping Scorbot 3 I bought. I really need encoder count number revolutions allow high start-up torque. So far, I'm difficulty finding suitable motor. The closest I've found are: Revolver S Stubby (still ready purchase) Team Novak Ballistic 25.5T I've found RC car motors, usually big. Some alternatives I thought are: adding hall sensors existing motor - hard this? rewinding motor turns increase torque (decrease Kv) Does anybody know motors fit requirements modifications I make existing ones? Update: I almost given hope, someone Homebrew Robotics suggested using Maxon motor finder. If type given torque speed, returns 3 motors, they're powered search interprets specs continuous operating point, whereas robot need much power 20% time, maybe 1 second max. If I type 12V, 5000rpm, 15 oz-in, returns 2 brushless motors, which, Motor EC 45 best fit, operating curve: However, I don't want pay Maxon charging, instead, I've contacted guy makes yet released Revolver Stubby kindly offered build custom high torque, low RPM motor me. Can anyone comment high torque, low RPM motors like one I want seem rare? Is due lack applications (robotics) intrinsic difficulty making them?",motor brushless-motor
758,"In HRI, ""uncanny valley"" experienced people autism spectrum?","I'm familiar idea uncanny valley theory human-robot interaction, robots almost human appearance perceived creepy. I also know research studies done support theory using MRI scans. The effect important consideration designing robotic systems successfully interact people. In order avoid uncanny valley, designers often create robots far humanlike. For example, many therapeutic robots (Paro, Keepon) designed look like animals ""cute"" non-threatening. Other therapeutic robots, like Kaspar, look humanlike. Kaspar excellent example uncanny valley, since I look Kaspar creeps out. However, people autism spectrum may experience Kaspar way I do. And according Shahbaz's comment, children autism responded well Kaspar. In application therapeutic robots people autism spectrum, basic principles human-robot interaction (like uncanny valley) may valid. I find anecdotal evidence (with Google) people autism spectrum don't experience uncanny valley, far I haven't seen real studies area. Does anyone know active research human-robot interaction people autism spectrum? In particular, uncanny valley apply (or doesn't apply) people autism spectrum interact humanlike robot?",research hri uncanny-valley
763,Differences Ackermann steering standard bi/tricycles concerning kinematics?,"I got following homework question: What general differences robots Ackermann steering standard bicycles tricycles concerning kinematics? But, I don't see differences be, car-like robot (with 2 fixed rear wheels 2 dependent adjustable front wheels) seen tricycle-like robot (with single adjustable front wheel middle). Then, let distance two rear wheels approach zero, get bicycle. So, I can't see difference three mobile robots. Is something I missing?",mobile-robot design kinematics theory
764,The relationship point cloud maps graph maps,"I familiar SLAM maps point clouds, usually form vector like $<x,y,\theta,f_{1x},f_{1y},...,f_{nx},f_{ny}>$. I also understand create map like using EKF. Today I came across .graph file format, would expect consists vertices edges format: EDGE2 observed_vertex_id observing_vertex_id forward sideward rotate inf_ff inf_fs inf_ss inf_rr inf_fr inf_sr I know there's connection matrices graphs (an adjacency matrix example). But it's clear graph format map equivalent point cloud map I'm familiar with. What relationship? Are vertices poses landmarks? Are global reference frame? How created say velocity information range/bearing sensor? Is transformation graph map point cloud?",slam mapping
768,How balance flying quadcopter?,Im using code create quadcopter robot. The hardware part done I need balance copter. This video current status: I tried play speed motor get balanced. It didnt go. I actually gyro accelerometer onboard. But shall I adjust motor speed based values? What rules I beware of? Is better solution try error? Where shall I begin? Any tips?,balance quadcopter
775,Getting started robotic arm design,"I would like design robotic arm hold weight X length Y (in case I want hold X=2.5 lbs Y = 4 inches). Starting simply, I would like try building arm gripper plus one servo joint. [Servo Joint] ----- Y ------ [Gripper] When designing arm, would I want say gripper enough torque hold desired weight (e.g. 2.5 lbs) minimal distance (however long fingers are) design servo joint bear weight gripper + load? I would like able hold object full extension",design servos arm
777,"Building controllable ""knob""","I trying build semi-analog timer. Something like old egg timers rotate face of. I want knob I turn read microcontroller, I also want microcontroller able position knob. I'd like implement ""stops"" letting microcontroller push knob towards certain positions. As runs down, knob turn. This first project kind; I've built small robots past, it's many years. I've considered hacking servo motor read position, small hobby servos I've tried hard turn, noisy, pick much momentum turned. They don't act like good knob. I'm considering rotary encoder connected motor, hunting several sites (SparkFun, ServoCity, DigiKey, Trossen, others), I haven't able find anything seemed appropriate. I'm certain find motor that's going right kind low torque. This seems like shouldn't really uncommon problem. Is fairly normal approach creating knob adjusted user microcontroller?",motor servos
780,What reasons autonomous robots daily activities?,"The fact I search less I find autonomous (real) robots use. The companion robots toys limited useless functionality. Whenever natural disaster don’t see operational search rescue robots news. Even military robots service remotely controlled machines. They intelligent machines. Industrial robotic arms deterministic machines. The robots levels autonomous functionality cleaning bots, warehouse operations bots farming robots. On hand, today: artificial intelligence algorithms good making decisions sensing technologies sophisticated communication technologies fast manufacture cheap parts people extremely gadget savvy So, real robot day day life? No investment domain? No market yet? Not enough knowledge domain? A missing technology? Any idea?",mobile-robot
783,Would ROS benefit multicore processor like Epiphany XMOS?,"I looking good embedded PC run ROS on. I recently came across couple little machines using new multi-core processors, Epiphany XMOS. Since one thing ROS really seems want cores, would ROS able take advantage cores? Or feeble little RAM use? Would make sense focus machines fewer, powerful cores?",ros
788,"Do ""nano bots"" (that fit inside human body) actually exist?","I wondering, real nano bots, like ones movies? I think bots move blood vessels, I right?",mobile-robot
790,"Do ""toy"" robots move technology forwards?","Over last month, I saw many robots don't real purpose, made ask myself: ""Does value?"" I saw dancing robot CES, advanced lego based robots also robots combined limited purpose. I saw ten year old children playing robots, competitions them. Someone told education logic spreading. In cases, arguments like, ""this informing people everything going forwards"". I know people buy robotic vacuum cleaners think they'll save time, robotic cleaners reliable I see marketing. Do things (children's education, dancing robots, instances selling pig poke) value terms robotics, really advancing field manufacturers say?",research
795,How Microhard 920 series modems made compatible Microhard 910 series?,"Microhard Systems currently sells several types 900MHz modems, mostly used robotics SCADA applications. One product lines, 910 series (MHX910, n910, Spectra 910), obsolete longer sold. However, older equipment built OEM versions 910 series soldered place. Microhard currently sells 920 series (MHX920, n920, Spectra 920) shares many specs 910 series, cannot establish radio link 910 series modem due differences encryption hopping pattern. Therefore, want make new equipment communicate equipment using 910 series, options are: De-solder old 910 modem replace footprint-compatible 920 modem, Reconfigure 920 series modem communicate 910 series modem. Option 1 undesirable, since I don't access firmware older equipment question. Does anyone know accomplish option 2?",radio-control
797,Plans use Vendor ID identify EtherCAT devices?,"I also asked question ROS Answers, it's getting much interest there. Currently EtherCAT package ROS uses slaves' Product IDs identify devices, load correct drivers. This works great devices manufactured single vendor, plans prevent Product ID collisions multiple vendors make ROS compatible EtherCAT devices? We manufacture EtherCAT devices, using large values Product ID, hoping don't collide anyone else's. Ideally, ROS would concatenate vendor product IDs single 64-bit value, use identify correct driver.",ros
801,Simple Neural Network hardcoded positions walk optimisation,"I'm building quadrupedal robot learn walk. From responses I got asking possible run NN micro controller I realised I needed think clever system wouldn't take 1000 years effective would still able demonstrate onboard learning. I've designed system I'm sure effective be. Firstly I hardcode 5-20 positions legs. I set (simple) neural network node different set positions legs, I write. The robot moves one node another weight joint determined far forward robot moves. Eventually strong connections best nodes/positions robot found pattern moves successful walking. How effective would learning walk? Note: instead positions I could write short gaits process would work sets work best combined.",microcontroller machine-learning walk
807,How I control fast (200Hz) realtime system slow (30Hz) system?,"We currently designing mobile robot + mounted arm multiple controlled degrees freedom sensors. I considering architecture two parts: A set realtime controllers (either Raspeberry Pis running RTOS Xenomai bare metal microcontrollers) control arm motors encoders. Let us call machines RTx, x=1,2,3… depending number microcontrollers. This control loop run 200Hz. A powerful vanilla linux machine running ROS compute SLAM, mocap, execute high-level logic (decide robot’s task compute motors' desired position speed). This control loop run 30Hz. I know framework needs scalable account motors, sensors, PCs (eg. external mocap). My main problem decide different RTx communicate PC1. I looked papers related robots architecture (e.g. HRP2), often describe high level control architecture I yet find information low level communicate high level scalable way. Did I miss something? In order connect fast RT machines ensuring motor control PC1, I considered TCP/IP, CAN UART: TCP/IP: deterministic easy put place. Is non determinism real issue (as used slow speed 30Hz anyways)? CAN: slow, reliable, targeted cars ( seen exemples using CAN robots looked exotic) UART: I one RT machine motor control I would considered UART I guess port scale well many RTx Is TCP/IP really go non-deterministic characteristics? It easy use… At moment solution really seems obvious me. And I find serious robot example using specific reliable scalable solution, I feel confident make choice. Does anyone clear view point literature point to? Are typical mainstream communication solutions used robots?",control design communication
810,Can ultrasonic button sensors run VEX analog port?,"I'm running digital ports, sensors fit definition 'analog'. Would possible run touch sensor, quadrature encoder, ultrasonic sensor analog port? I'm thinking not, I didn't run across anything said otherwise.",sensors
812,How find far motor taken vehicle?,"I small motorized vehicle gears wheels running track made gear racks. How robot know run half track? And what's best method keep running track end return start. The robot carrying water, exactly amount time, weigh same. Therefore might amount steps stepper-motor time. Here I ideas might work, though I beginner, don't know what's best solution. GPS tracking (overkill small scale?) Some kind distance measurer Have knob hit middle track, telling program delay given time Track amount steps motor performed (won't accurate?)",mobile-robot arduino sensors
815,Arduino Motor control,"I'm working rather low budget project, need way control four motors using one Arduino. I've looked motor shields little, I shield top already, It female input top though, motor shield may work. Any suggestions?",control arduino microcontroller motor power
819,Adding Rotary Encoders Electronic Wheel Chair,"We electric wheel chair, looking add rotary encoder wheel. We don't want hack motor itself, want add encoder without harming motor-to-wheel connection. We using arduino read signal. Does anyone experience adding rotary encoders already assembled wheel assemblies?",arduino microcontroller
826,Can I use digital animation software define movements humanoid robots?,"I'm working lifesize (~130cm) humanoid robot (Hubo+) looking way easily program new motions gestures him. Obviously, I could write tool, I looking solution leverage existing tools standards robot motion. My first thought trying use animation software like Blender Maya, writing script extract joint angles keyframes. However, robotics researchers probably proficient Maya. (I know I'm not!) Is already kind 3D posing tool robotics standard? The things I seen far comes close Pose Utility RoboPlus Choregraphe Nao, programs seem limited particular robots don't appear extendable Hubo. So questions are: Are standard file formats robot motion? Not 2D wheeled robot motion. Arm leg motion! Something equivalent .bvh file format used motion capture. Do know WYSIWYGish tool creating robot motion using keyframes inverse kinematics?",software motion
829,Which model best feedback control robotic manipulators: MIMO parallel SISO?,"I'm currently designing robotic arm 6-DOF, goal able give setpoints 3d position, velocity orientation ($x,y,z,\dot{x},\dot{y},\dot{z},\theta,\alpha,\gamma$). I feedback-control SISO systems far College, so, taking learning curve multivariable control consideration, I approach problem trying model system MIMO multiple SISOs? If possible please mention possible disadvantages advantages strategy.",control manipulator robotic-arm
832,"How I interpret data, received I2C controller NXT 2 brick?","I trying write code connect HiTechnic prototype board lego brick. Although I using MSRDS studio, isn't issue; reading writing serial port device connected works fine. Where I lacking I don't understand data sent received. It goes comes back form byte array. For example: [128] [15] [0] [2] [16] [2] [8] Is byte array converted hex? What response telling me? Obviously I total newbie this, I program I don't really understand electronics I trying make connection I read I2C controller works happening I send receive data serial port.",nxt i2c
835,CNCing injection mold,"I want injection-mold several thousand part fits 6"" x 6"" x 2"" bed. I would like able use tooling I make myself, I rapidly iterate tooling production problems discovered. I know typical injection-mold ""hard tooling"" created using electrical discharge machining, requires first CNCing carbon positive using electrode spark-burn negative mold hard steel. However, I equipment EDM. Instead, I would prefer directly CNC negative mold. I know soft enough steel CNCed last long injection mold, like I said, run size tiny, I ok making new mold every 500 units necessary. I open buying endmill diamond-tipped, work harder steel, limitation probably much torque CNC produce endmill. What recommendations links helpful resources? In particular, good CNC enough torque, blend steel I use? Thanks!",cnc
838,What microcontroller used QuadCopter flight control ESC?,"I working building quadcopter scratch. I noticed many solutions available online use arduino, I fan arduino. So questions are: microcontrollers used, crucial features microcontrollers etc. I would like build total scratch. I thinking PIC microcontrollers. Also used ESC, since I would build scratch too. Summing up: 4 ESCs Gyro,acceloremeter,gps transceiver 8 slaves one master microcontroller.",microcontroller quadcopter esc
839,Sonar obstacle avoidance: many sensors place them?,"For avoiding obstacles 2D robot navigation best position/angle place sonar sensors? How many be? I would like know theory examples problem placing. I realize depends way robot moves geometry, I searching general answers.",mobile-robot sensors navigation acoustic-rangefinder
840,"Is tool building analysing robots (kinematics, control) visually?","I reading research papers robotics many follow pattern: construction established kinematical formulas read mechanical structure state space analysed (e.g. far robot reach, maximum speed be, left underspecified handle mathematically incorrect systems on) Is tool software product receive (as input) mechanical structure output kinematical formulas? Preferably, would provide kind plots, analysis, suggestions optimal design parameters (e.g. length, angles sturcture, optimum parameters motors on). Does exist?",software design inverse-kinematics research kinematics
845,How Identify Objects Space,"Using depth sensing camera like Kinect, I would like retrieve position predetermined object (e.g. cup, fork etc I would ultimately able grab object). What would way achieve this?",computer-vision algorithm
848,"Why must I loop 127 times ""7-bit"" address example?","I learning I2C Arduino. I looking sample program scan I2C devices saw this: With following code. for(address = 0; address <= 127; address++ ) { // The i2c_scanner uses return value // Write.endTransmisstion see // device acknowledge address. Wire.beginTransmission(address); error = Wire.endTransmission(); (error == 0) { Serial.print(""I2C device found address 0x""); (address<16) Serial.print(""0""); Serial.print(address,HEX); Serial.println("" !""); } } As far I understand it, bit 1. So, 7 bits loop 0 - 127?",arduino i2c
851,Optimal Control simple pendulum,"I'm studying various optimal control methods (and implements Matlab), test case I choose (for now) simple pendulum (fixed ground), I want control upper position. I managed control using ""simple"" feedback method (swing-up based energy control + LQR stabilization upper position), state trajectory show figure (I forgot axis description: x theta, theta dot. Now I want try ""full"" optimal control method, starting iterative LQR method (which I found implemented ) The method requires one dynamic function one cost function ( motor torque (one motor only)): function [xdot, xdot_x, xdot_u] = ilqr_fnDyn(x, u) xdot = [x(2); -g/l * sin(x(1)) - d/(m*l^2)* x(2) + 1/(m*l^2) * u]; nargout > 1 xdot_x = [ 0, 1; -g/l*cos(x(1)), -d/(m*l^2)]; xdot_u = [0; 1/(m*l^2)]; end end function [l, l_x, l_xx, l_u, l_uu, l_ux] = ilqr_fnCost(x, u, t) %trying J = x_f' Qf x_f + int(dt*[ u^2 ]) Qf = 10000000 * eye(2); R = 1; wt = 1; x_diff = [wrapToPi(x(1) - reference(1)); x(2)-reference(2)]; isnan(t) l = x_diff'* Qf * x_diff; else l = u'*R*u; end nargout > 1 l_x = zeros(2,1); l_xx = zeros(2,2); l_u = 2*R*u; l_uu = 2 * R; l_ux = zeros(1,2); isnan(t) l_x = Qf * x_diff; l_xx = Qf; end end end Some info pendulum: origin system pendulum fixed ground. The angle theta zero stable position (and pi unstable/goal position). bob mass, l rod length, damping factor (for simplicity I put m=1, l=1, d=0.3) My cost simple: penalize control + final error. This I call ilqr function tspan = [0 10]; dt = 0.01; steps = floor(tspan(2)/dt); x0 = [pi/4; 0]; umin = -3; umax = 3; [x_, u_, L, J_opt ] = ilqg_det(@ilqr_fnDyn, @ilqr_fnCost, dt, steps, x0, 0, umin, umax); This output Time From 0 10. Initial conditions: (0.785398,0.000000). Goal: (-3.141593,0.000000) Length: 1.000000, mass: 1.000000, damping :0.300000 Using Iterative LQR control Iterations = 5; Cost = 88230673.8003 nominal trajectory (that optimal trajectory control finds) The control ""off""... doesn't even try reach goal... What I wrong? (the algorithm Todorov seems work.. least examples)",control
854,Sensors differential drive,"I following chassis along Arduino motor shield. I'm process developing tracking mechanism use differential drive. Normally, photo reflector placed adjacent wheel reflect spoke passes therefore allowing code written accurately measure wheels position. The problem I cannot see wheels inside chassis, small holes driveshaft. Placing sensors outside would look ridiculous wall crash would cause havoc. Would I able use photo reflector gears (as shown) I accurately placed count spoke gear itself? I'm bit hesitant though even small bump could misalign sensor - causing havoc. So one idea track wheel movements?",arduino two-wheeled
857,Can seed Kalman filter particle filter?,"Is way initializing Kalman filter using population particles belong ""cluster""? How determine good estimate mean value (compute weighted average ?) covariance matrix ? Each particle represented $[ x , , θ , weight]$.",localization kalman-filter particle-filter
863,How I simulate assembly line?,"I need simulate stream vehicles, assembly line. Automatons performing operations vehicles come within reach. The automatons keep track individual vehicles, simply collect data. We need choose method matching data gathered automaton vehicle belongs to. For example, could guess identity vehicle using timing arriving operation range (sensors) automaton. I check possible problems face, I would like little (hopefully simple) video/simulation tool I could play with. vehicles could symbolized moving black squares automatons/sensors could static points circles. possible change time interval two vehicles, speed, add random delays. What kind software I search for, I look? Should I consider developing scratch?",simulator
865,"How tell stepper motor's position, detect slippage","I creating CNC machine budget, using old motors printers/scanners/etc. I limited 650mA whole system, fear cutting bit touches material, stepper might moving quickly won't enough torque. This would mean become one rotation behind, could really mess CNC project. Detecting motor ""misses"" step would allow readjust motor speed reaches balance working quickly adequate torque. How I achieve this?",arduino stepper-motor current cnc
869,Building Robotic arm joint,"I new robotic design I need determine parts I need assemble arm joint. The joint contain one timing belt pulley remote motor turning, forearm pulley rotating upper-arm piece actually two parallel arms grip pulley top bottom order brace pulley axis torque timing belt. I kind lost mount together. I would like mount forearm directly pulley two parallel arms (comprising upper-arm) sandwich top pulley lower part forearm. This would attached using turn table. Any ideas shaft would mount these? Or attach pulley arms themselves? Any kind direction links would greatly appreciated, I don't even know names parts I would looking for. In ASCII art model dashed lines (-) arms. The arm left forearm two arms right two parallel parts upper arm. The stars belt bars (||) pulleys elbow |E| shoulder |S|. I thinking mounting pulley left arm directly (a bushing?) maybe using turntables mount pulley top arm another turn table mount left arm bottom arm. Here picture design help visualize:",design arm joint
872,Do I really need gyro airplane flight stabilization system?,"I'm working basic airplane flight stabilization system, precursor full autopilot system. I'm using salvaged Wii Motion Plus Nunchuk create 6DOF IMU. The first goal keep wings level, mix users commands. Am I correct saying would require gyro, 3 (2?) axis accelerometer, detect pitch roll, adjust ailerons elevator compensate? Secondly, extend design goal ""keeping wings level"" ""flying straight line"" (obviously two different things, given wind turbulence), gyro become necessary, insofar accomplished without GPS guidance? I've tried integrating gyro values get roll, pitch & yaw that, however (as evidenced question), I'm level knowledge topic I'd prefer simpler mathematics code. Thanks help!",uav accelerometer imu gyroscope
873,3D Mapping quadcopter KINECT,"I quadcopter robot KINECT want 3D mapping it. Is KINECT reliable moving robot (i.e., give stable images maps movement)? Is SDK producing 3D maps KINECT data? Will SLAM algorithms work? Is arduino board copter (ATmega 2560) powerful enough handle this?",arduino slam kinect quadcopter
876,Remote car controlling,"Before I start asking help let know I newbie electronic field. All I want know principle wheel rotation (left-right) remote car gadget. I talking changing spin rotation DC motor (up,down buttons remote), I asking left right movement wheel. I know spin change depends polarity DC motor, changing polarity changes spin, principle changing left right positions front wheels.",control wheel
878,Accurate 3D Printing W/Sketchup,"I 3D printers school, unfortunately super high quality. I want try 3D printing model I made google sketchup, I would like fairly accurate. What measures I take prevent error model? I understand I need export file STL; anything I model hand ensure accuracy? What I calibrate 3D printer best results?",3d-printing
882,Force measurement grab bars,I recently start project measure force bathroom grab bar. The force/load applied person need grab bar assistant. What I want measure load wall real-time monitoring load analysis improve design. I quite sure kind sensor would suitable measurement. I looking different load cells cannot get idea mount commercial load cells measurement. What I trying right using strain gauge measure strain near end bar(wall side) roughly calculate load. I think (might wrong) may exists kind force/load sensors clamp bar measurement. Any sensor types/models suggestion welcome. I also posted question EE forum,sensors force
883,Measuring speed movement Webots,"I experimenting different fitness functions Webots robot simulation (in short: I'm using genetic algorithm evolve interesting behaviour). The idea I reward/punish Aibo based speed movement. The movement performed setting new joint position, currently results jerky random movements. I looking nodes available Webots, apart GPS node (which available Aibo) I couldn't find anything relevant. What I want achieve measure distance previous location current location movement. How I this?",mobile-robot reinforcement-learning simulator
884,Using Sick laser Matlab Windows,Is Matlab toolbox available use Sick lasers Windows? I found one toolbox Matlab GNU/Linux. Is another way use Sick laser via Matlab Windows?,mobile-robot localization
885,Would possible connect HiTechnic prototype board Arduino?,"Does anyone know possible? It's i2c device right? I mean would cut cable make could plug pins Arduino able use wire library say something like. NXT hardware developers kit tells pins Thanks EDIT. Turns possible. The main problem HiTechnic says address 0x10 actually 0x08 short sketch reads prints device, i.e. manufacturer version. #include <Wire.h> #define ADDRESS 0x08 void setup() { Wire.begin(); Serial.begin(9600); } void loop() { readCharData(0, 7); Serial.println(); readCharData(8, 8); Serial.println(); readCharData(16, 8); Serial.println(); Serial.println(""-----------------------------""); delay(1000); } void readCharData(int startAddress, int bytesToRead) { Wire.beginTransmission(ADDRESS); Wire.write(startAddress); Wire.endTransmission(); Wire.requestFrom(ADDRESS, bytesToRead); while(Wire.available()) { char c = Wire.read(); Serial.print(c); } }",arduino
891,Arduino Nano + Raspberry Pi = UAV Ground Station?,"I'm programmer trade, amateur aerospace nut, degree-level training fields. I'm working UAV project, good people DIY Drones helpful, question little less drone-related little general robotics/electronics. Essentially, I'm looking options ground stations, current rough plan something like this: I PC joystick broken sensor base, I plan dismantle, separate handle base, insert Arduino Nano (mostly hollow) handle hook buttons hat thumbstick. Then, hole used accept stem base, I fit bracket runs horizontally hold smallish touchscreen (think Razer's Project Fiona tablet one stick), behind mounted Raspberry Pi. The Nano talks RPi USB HID input. The RPi running custom software display telemetry data sent UAV. My main question whether Nano would enough power run XBee provides telemetry link without causing lag control inputs. It's worth mentioning UAV fly-by-wire moderation, slight stutters won't result wobbly flying, serious interruptions still problematic - annoying. It's also worth mentioning used simplified ""guiding hand"" control; ALWAYS regular remote control available (not least EU flight regulations) I don't want use that. If Nano won't do, options? My first thought get second Nano get drive XBee (the RPi two USB ports all) may well better way.",arduino control uav raspberry-pi radio-control
892,Is possible achieve arbitrary precision camera calibration?,Is possible achieve arbitrary precision calibration extrinsic parameters camera minimum error wich compensated (probably dictated camera's resolution)?,computer-vision calibration
896,How select cameras stereo vision system?,I process building stereo vision system used UGV. The system robot used competition wherein robot teleoperated find relatively small colored rocks large outdoor field. I understand calibrate system process data stereo vision system. I however know select cameras system. What best practices picking cameras stereo vision system?,computer-vision stereo-vision cameras
897,High voltage motor control arduino,"I'm trying control higher voltage motor arduino source pin, arduino. I trying hook transistor. The battery pack supposed 4.8V, it's 6V, 4 D batteries. Here setup: Here arduino code I'm trying run it: Code gives errors, motor movement happens. What would make work? Thanks.",arduino motor
900,"How I select best configuration known workspace, load task?","Given workspace constraints, load task done, I select best configuration robot? How I select cartesian Scara robot instance? How I select manipulator? How I determine many axes I need? Most I seen based experience, rules thumb readily available standard devices, I would like formal answer quantify choice. Is technique (genetic algorithm?) describes task, load, workspace, budget, speed etc. rates selects optimal robot configuration maybe even multiple configurations? How I mathematically ensure I ultimately chose optimal solution? The thing I found online thesis 1999 titled Automated Synthesis Optimization Robot Configurations: An Evolutionary Approach (pdf, CMU-RI-TR-99-43). It synthesis optimization tool called Darwin2K presented thesis written Chris Leger CMU. I surprised one updated created tool similar it. To provide context question, developing robot assist elderly domestic tasks. In instance, robot identifies picks food items previously stored known location. The hand opens package place oven. The pick place locations fixed nearby robot stationary.",design algorithm industrial-robot theory manipulator
907,Calibrate 2d scanner mounted rotary axis,"A 2d laser scanner mounted rotary axis. I wish determine transformation matrix center axis center scanner, using input scanner angle rotation. The 2d scanner assumed calibrated, accurately measure position object inside plane laser, regards scanner origin. The rotary axis calibrated well, accurately measure angle movement. The scanner aligned mounted close center rotation, exact offset unknown, may drift time. Assume impractical measure position orientation scanner directly. I looking way determine exact values 6 degrees offset scanner may relation axis, determined solely 2d information scanner rotation angle axis. I mainly interested 4 offsets depicted here, since two matter regard generating consistent 3d point cloud input data. By scanning known calibration object, possible determine offsets. What mathematical formulas this? What sort calibration information required minimum? Is example possible determine parameters simply scanning flat surface, knowing nothing surface except flat? (The transformation matrix rotation axis world unknown well, one trivial determine transformation axis camera known.) Example On left camera placed exactly rotational axis. The camera scans planar object reference points A B C. Based laser distance measurements angle axis, planar object reconstructed. On right, camera unknown offset axis. It scans object. If point cloud constructed without knowing offset, planar surface maps curved surface. Can I calculate offset based surface curvature? If I know real-world distances angles A, B C, I calculate camera offsets that? What would minimum number reference points I need 4 offsets?",calibration
908,How Makeblock threaded slot work?,"I've looking Makeblock robotics kit found information web comes end-users, one main advertised features clear me: The slot threads shown straight, screw thread mate angled. Is little contact screw thread rail thread vs. regular screw hole threads? Or would screw want rest angled somewhat- head would flush rim rail? Or would screw deform aluminum rail over-torqued? This close picture slot screws:",mechanism kit
909,GPS tracking device,I'm looking GPS tracking device without screen apps. I need look current position bus send server TCP/IP protocol. This process must constant I real-time tracking. The bus already wireless access point. What device useful? Do I need another piece hardware send coordinates server? I experience but... something like arduino connected gps send data?,gps
913,Are power torque required related way?,"I designing new platform outdoor robotics I need calculate power and/or torque needed move platform. I calculated I need 720 W total power move (360W per motor), I don't know calculate torque I need. Is really required power ignoring torque way calculate easily? Already known parameters platform are: Weight whole platform: 75 kg. Number wheels: 4. Number powered wheels: 4. Diameter wheels: 30 cm. Number motors: 2. Wanted speed: 180 RPM (3 m/s). Wanted acceleration: > 0.2 m/s^2",mobile-robot design motor
918,Storing Kinect Data USB Drive,"Does anybody know Kinect Data stored directly onto USB Drive?? I Kinect Windows cannot use Linux(ROS). However plan mount Kinect robot, store captured frames USB un mount USB ,transfer Linux process ROS. Is possible?? Any suggestions.",kinect ros
921,How I send video Arduino camera module video Android screen?,"I'm trying connect camera module Arduino Mega, connect Mega Android phone (throught BlueTooth other), send live view camera mobile phone. I saw video online showed still images -- image captured camera module Arduino sent Android output image viewed couple seconds (the time send image BT). Is doable live video instead image? If yes, please guide me; no, please suggest workarounds.",arduino cameras
922,How I design target speed?,"I need make omni wheeled robot platform (4 wheels), go minimum speed 15 cm/s. I idea design, since first time something like I made lot assumptions. I decided choose TGY-S4505B servos motor system. I intend attach servos FXA308B wheels. Finally, I intend power servos one Turnigy LSD 6.0V 2300mAh Ni-MH Flat Receiver Packs (not sure LiPo better choice). I need able run servos continuously roughly 8 minutes. You ignore microcontroller stuff, relatively speaking consume much less power. The robot four wheels (thus, four servos). The basic specifications servo is: Type: Analog Gear train: Plastic Bearings: Dual Motor Type: Carbon Brushed Weight: 40g (1.41oz) Lead: 30cm Torque: 3.9kg.cm @ 4.8v / 4.8kg.cm @ 6v Speed: 0.13sec 60°@ 4.8v / 0.10 60° @ 6v So based battery pack, I running servos 6V. That gives speed 60 degrees per 0.10 seconds. I plan modifying servos continuous rotation, connected directly wheel. Since wheel diameter ~5 cm, circumference ~15 cm. Based specs, seems robot move roughly 15 cm/0.6 seconds, 25 cm/s (quite fast actually). I don't intend run constantly speed, 8 minute run, assume average speed 20 cm/s. Are assumptions reasonable, calculations correct? I would really appreciate insight, advice, recommendations, criticisms may have.",mobile-robot wheel rcservo
924,TI ARM stacked RAM,"Do TI ARM SOCs, e.g. OMAP Da Vinci, version stacked RAM? (e.g. DDR2 mDDR) For miniature robots like micro drones, would really nice need spend board area external RAM chip. Thanks!",arm
939,Will connecting two servo motors double torque?,"For robot, I using two continuous rotation servos spin threaded rod. I trying make project cheap possible. Here servos I find: Servo #1: This cheap option half torque I need. Servo #2: This torque project requires, much expensive two servo #1. Can I hook two servo #1 end rod move synchronized? I spare extra pins microprocessor I using; isn't issue. I know hooking two together increase torque, I don't want 75% torque I want situation. Also, I don't care I 98% torque ""goal"" extra weight (which probably won't happen) I don't want to, like I said earlier, 70, 80, 90% ""target goal"" torque possible. Any help appreciated. Thanks advance.",motor rcservo
940,How I convert link parameters angles (in kinematics) transformation matrices programming logic?,"I'm robotics research undergraduate, I understand conceptual math part; however, comes actually implementing code calculate forward kinematics robot, I stuck. I'm getting way book websites I've found explain it. I would like calculate X-Y-Z angles given link parameters (Denavit-Hartenberg parameters), following: $$\begin{array}{ccc} \bf{i} & \bf{\alpha_i-1} & \bf{a_i-1} & \bf{d_i} & \bf{\theta_i}\\ \\ 1 & 0 & 0 & 0 & \theta_1\\ 2 & -90^{\circ} & 0 & 0 & \theta_2\\ 3 & 0 & a_2 & d_3 & \theta_3\\ 4 & -90^{\circ} & a_3 & d_4 & \theta_4\\ 5 & 90^{\circ} & 0 & 0 & \theta_5\\ 6 & -90^{\circ} & 0 & 0 & \theta_6\\ \end{array}$$ I don't understand turn table values proper transformation matrices needed get $^0T_N$, Cartesian position rotation last link. From there, I'm hoping I figure X-Y-Z angle(s) reading book, help would appreciated.",kinematics forward-kinematics
946,How I detect edge table?,"I'm new robot making got first arduino play around. I want make robot wander table, last longer I think I could make avoid falling table. What best way make detect edge table I make stop turn around ? It something reliable preferably cheap. It also better I don't need add extra stuff table I use surface (my first idea draw path lines table make line follower robot, I don't like idea much).",sensors
948,What opposite 'Antagonistic'?,"A robotic joint connected two actuators, e.g. air muscles. One flexes joint, extends it. This arrangement called 'antagonistic'. But I electric motor instead air muscles? In case pull one tendon time, it's antagonistic. What arrangement called case? Untagonistic?",motor air-muscle
952,What's efficient way visit every reachable space grid unknown obstacles?,"I'm trying create map obstacles fairly coarse 2D grid space, using exploration. I detect obstacles attempting move one space adjacent space, fails there's obstacle destination space (there concept rangefinding sensor problem). (for example) The process complete reachable squares visited. In words, spaces might completely unreachable even don't obstacles they're surrounded. This expected. In simplest case, I could use DFS algorithm, I'm worried take excessively long time complete — robot spend time backtracking exploring new territory. I expect especially problematic attempting reach unreachable squares, robot exhaust every option. In sophisticated method, proper thing seems Boustrophedon cell decomposition. However, I can't seem find good description Boustrophedon cell decomposition algorithm (that is, complete description simple terms). There resources like one, general one vertical cell decomposition don't offer much insight high-level algorithms low-level data structures involved. How I visit (map) grid efficiently? If exists, I would like algorithm performs better $O(n^2)$ respect total number grid squares (i.e. better $O(n^4)$ $n*n$ grid).",algorithm coverage planning
953,Dropping PWM Ardrone Parrot 2.0,"I issues ARDrone Parrot 2.0 hope someone else may running thing. While hovering, drone (seemingly) randomly losing altitude recovering . It commanded velocity inputs hold altitude. We using drivers ardrone_autonomy (dev_unstable branch) github. We able watch PWM outputs sent motor dropping hover command small value exponentially returning hover value drop occurs. The issue could communication IMU onboard controller software control implementation. Has anyone seen similar problem suggestions test/troubleshoot happening?",ros quadcopter pwm
954,Controlling 12 Servos Arduino Servo library,"I'm using Teensy hardware specifically. I Teensy 2.0 Teensy 3.0, documentation seems like two 16 bit timers available, able control 12 servos. However, I've attached logic analyzer confirmed first 12 servos attached ever function. Is anything special I sketch order convince Servo library allocate second timer servos attached beyond number 12? This works: But this, below, ever shows activity first twelve pins attached: #define NUM_SERVOS 24 Servo servos[NUM_SERVOS]; // teensy 3.0 pins int pin_assignments[NUM_SERVOS] = {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23}; void setup() { for(int = 0; < NUM_SERVOS; i++) { servos[i].attach(pin_assignments[i]) ; } }",arduino rcservo
957,Adhesion heavy wall-climbing robot,I come across number methods developing wall-climbing robots. Suction Chemical Adhesion Gecko like hair adhesion Electroadhesion Which method would best heavy robots (5kg+)? Are methods I missed?,mobile-robot
963,Simulated kinect rotation around X [gazebo bug?],"I asked question answers.ros.org gazebo.ros.org still haven't got answer. I'm posting question hope someone help me. In robot, Kinect mounted side arm, shown screenshot below. When running simulation Fuerte, I found weird behaviour. As observe image, point cloud match robot model (we see partial image hand/arm bottom left screenshot, robot model). As soon I rotate kinect X axis (so kinect horizontal see second screenshot), point cloud robot model aligned properly. The kinect xacro dae one turtlebot. I'm simply attaching rotation: The code seen github. Any help greatly appreciated!",kinect ros simulator
964,Extended Kalman Filter using odometry motion model,"In prediction step EKF localization, linearization must performed (as mentioned Probabilistic Robotics [THRUN,BURGARD,FOX] page 206) Jacobian matrix using velocity motion model, defined $\begin{bmatrix} x \\ \\ \theta \end{bmatrix}' = \begin{bmatrix} x \\ \\ \theta \end{bmatrix} + \begin{bmatrix} \frac{\hat{v}_t}{\hat{\omega}_t}(-\text{sin}\theta + \text{sin}(\theta + \hat{\omega}_t{\Delta}t)) \\ \frac{\hat{v}_t}{\hat{\omega}_t}(\text{cos}\theta - \text{cos}(\theta + \hat{\omega}_t{\Delta}t)) \\ \hat{\omega}_t{\Delta}t \end{bmatrix}$ calculated $G_{T}= \begin{bmatrix} 1 & 0 & \frac{υ_{t}}{ω_{t}}(-cos {μ_{t-1,θ}} + cos(μ_{t-1,θ}+ω_{t}Δ{t})) \\ 0 & 1 & \frac{υ_{t}}{ω_{t}}(-sin {μ_{t-1,θ}} + sin(μ_{t-1,θ}+ω_{t}Δ{t})) \\ 0 & 0 & 1 \end{bmatrix}$. Does apply using odometry motion model (described book, page 133), robot motion approximated rotation $\hat{\delta}_{rot1}$, translation $\hat{\delta}$ second rotation $\hat{\delta}_{rot2}$ ? The corresponding equations are: $\begin{bmatrix} x \\ \\ \theta \end{bmatrix}' = \begin{bmatrix} x \\ \\ \theta \end{bmatrix} + \begin{bmatrix} \hat{\delta}\text{cos}(\theta + \hat{\delta}_{rot1}) \\ \hat{\delta}\text{sin}(\theta + \hat{\delta}_{rot1}) \\ \hat{\delta}_{rot1} + \hat{\delta}_{rot2} \end{bmatrix}$. In case Jacobian $G_{T}= \begin{bmatrix} 1 & 0 & -\hat{\delta} sin(θ + \hat{\delta}_{rot1}) \\ 0 & 1 & -\hat{\delta} cos(θ + \hat{\delta}_{rot1}) \\ 0 & 0 & 1 \end{bmatrix}$. Is good practise use odometry motion model instead velocity mobile robot localization?",localization kalman-filter
965,Firmata nRF24,"I'm technical problems... I'm trying use Firmata arduino nrf24, Serial interface. I tested nRF24 communication it's fine. I also tested Firmata Serial works. Base device simple ""serial relay"". When data available Serial, read send nRF24 network. If data available network, read send Serial. Node device bit complex. It custom Standard Firmata I added write read override. Read override id handeled method way: while(Firmata.available()) Firmata.processInput(); // Handle network data send Firmata process method while(network.available()) { RF24NetworkHeader header; uint8_t data; network.read(header, &data, sizeof(uint8_t)); Serial.print(data, DEC); Serial.print("" ""); Firmata.processInputOverride(data); BlinkOnBoard(50); } currentMillis = millis(); Firmata processInputOverrride little changed method processInput processInput reads data directly FirmataSerial, method pass data method network. This tested work fine. Write method overloaded different way. In Firmata.cpp I added method pointer set custom method used send data using custom method. I added custom method call FirmataSerial.write() call: Firmata.h ... size_t (*firmataSerialWriteOverride)(uint8_t); ... void FirmataClass::printVersion(void) { FirmataSerial.write(REPORT_VERSION); FirmataSerial.write(FIRMATA_MAJOR_VERSION); FirmataSerial.write(FIRMATA_MINOR_VERSION); Firmata.firmataSerialWriteOverride(REPORT_VERSION); Firmata.firmataSerialWriteOverride(FIRMATA_MAJOR_VERSION); Firmata.firmataSerialWriteOverride(FIRMATA_MINOR_VERSION); } I set overrided write method custom method writes byte network instead Serial. size_t ssignal(uint8_t data) { RF24NetworkHeader header(BaseDevice); network.write(header, &data, sizeof(uint8_t)); } void setup() { ... Firmata.firmataSerialWriteOverride = ssignal; ... } All stages pass right (I guess) I don't get response Node I request pin states ... < f0 6a 7f 7f 7f ... 7f 0 1 2 3 4 5 6 7 8 9 b c e f f7 // analog mapping > f0 6d 0 f7 // sysex request pin 0 state value > f0 6d 1 f7 > f0 6d 2 f7 ... > f0 6d 45 f7 // And I wait response... There response. Any ideas would happen? Node receive messages correctly code handling pin states exist.",arduino serial c++
970,Do magnets affect IMU values?,"Im process making robot requires 12 3x10mm cylindric magnets construction. They 30mm center robot I plan IMU. I thinking using MPU-6050. Do magnets affect values? If yes, solution it? like maybe I could shield something around IMU?",sensors imu
975,Why space probes need heating?,"I know temperature influences characteristics semiconductors materials, know take account. Furthermore, lower temperatures makes electronics efficient, sometimes even superconducting. I remember reading somewhere engineers building Curiosity even considered low temperature electronics motors driving wheels still decided end. Why it, apparently, hard build components operating temperatures matching Mars, Europa, space? Edit: None answers address question thus far. I know parts, electronic mechanical, greases relatively narrow working temperatures. My question is, don't build special cold metals cold greases cold chips narrow operating temperature band -100 C whatever? Valid answers could be: it's expensive, insufficient science done determine materials appropriate cold, cold materials cannot manufactured sweltering heat planet Earth.",heat-management cooling
976,What good approach Quadruped Gait?,"I small quadruped three degree freedom legs I working on: 3DOF Mini Quadruped. My original code simple servo controller arduino, Scala code would send servo commands wire. I Inverse Kinematics Gait logic Scala, got walk: 3dof quadruped first gait. My Gait logic Scala somewhat naive; depended legs right position beginning (one side extended fore aft, side toward other). The logic simply translate four feet backward 1mm along y, whenever coxa angle became excessively rearward, stop perform little routine foot lifted 10mm z, translated forward 60mm along y, set back down. Naive, effective. Now, I rewritten IK code arduino C, I'm trying decide move forward Gait dynamics. I've hard time finding good, easy understand resources gaits. I knowledge difference dynamically stable gaits (like creep gaits) body stable tripod times dynamically unstable gaits (walking, trotting), two legs ground time body essentially falling forward advancing leg. I thoughts state machines trying calculate whether body center falls within triangle made remaining feet decide foot safe lift, I'm sure ideas worth exploring. I know kind overly general question, I'm interested see people attacked problem, I've able find research papers.",mobile-robot walk
979,One BEC multiple ESC (Quadcopter),"I'm building quadcopter discovered ESC built-in BEC, I wondering wouldn't better use one. What I delivered power four ESC unique BEC ? Would work ? I think would easier configure (you set four ESC) would prevent ESC it's behavior. Am I wrong ? Here image I'm talking : Edit : trying find original image upload it. Given answer Ian McMahon appears schema right thing do, since I misunderstood role BECs. So would right schema would look like ? Edit : trying find original image upload it. I'm still sure I'm getting it. Do I need 4 ESCs integrated BECs connect three cables flight controller ?",electronics quadcopter bec esc
984,Does anyone know might giving error coming i2c device,"Here background. I trying write service HiTechnic prototype board. Using Appendix 2 blue tooth developers kit Lego's site I able understand going service I trying build however response I get always 221 = 0xDD = ""Communication Bus Error"" 32 = 0x20 = ""Pending communication transaction progress"". I figured HiTechnic prototype board using i2c address 0x08 I modified brick code use address instead standard 0x02. It goes configures device, I get response LSWrite seems OK I get get error LSGetStatus. I know thing works - I bit bang day long Arduino I test - see link I sure else try. Here I setting connect brick handler. I also tried setting AnyPort well hit TestPortForI2CSensorHandler I explained - seems set mode fine gets error tries read device information. Here data. - first part set input - message response - You see totally fine. Send command data. 0 5 0 11 0 receive command data. (_commState.SerialPort.Read(receiveData, 0, packetSize);) 2 5 0 Then LSWrite - everything still seems fine... You see I modified NxtComm code use 0x08 instead 0x02 would normally use, last byte also 0x08 starting address manufacturer. It's asking 16 bytes would manufacturer sensor type. like I said - I know works I print info using Arduino. 128 15 0 2 16 8 // i2c address 8 //I assume address I want read from? Got response: True Error code Success [02/25/2013 02:20:31] -- SendCommandHandler (NxtComm) [02/25/2013 02:20:31] --- RequestResponseHandler (NxtComm) [02/25/2013 02:20:31] --- CommSendImmediateHandler (NxtComm) [02/25/2013 02:20:31] Send command data. Then tries get status 0 14 0 Here response... 2 14 32 0 It's either 32 221. It's making nuts... If anyone anything might help I would much appreciate it. At point I running ideas. I see going on, I understand entire transaction can't seem figure errors like that. Also - grins I tried 0x10 tell HiTechnic website. That gets response 2,14,0,0 NXT brick - would indicate data I pointed I get data using Arduino. How could I two different I2C device addresses?",nxt i2c
985,Which easier/cheaper: Hbridge vs ESC controlling motor?,"I able find small ESC $12 ebay. If designing robot, would see think? \$12 bucks ESC connects simple pulse-wave interface - sign up! Or would think: \$12 control motor? I could throw together H-bridge $0.50 done it. My robot particular actually two motors therefor $24 control two them. But interface really easy (plus added advantage R/C vs computer controlled simple change connectors. Which way would go?",design electronics wheeled-robot
987,problem serial communication PC ATMEGA 8535(AVR),"I written code send data controller pc serialport using interrupt echos garbage value exactly 3 times back. EDIT: Function used set baud rate.. #define FOSC 16000000// Clock Speed #define BAUD 9600 #define MYUBRR FOSC/16/BAUD-1 void USART_Init( unsigned int baud ) { /* Set baud rate */ UBRRH = (unsigned char)(baud>>8); UBRRL = (unsigned char)baud; /* Enable receiver transmitter */ UCSRB = (1<<RXEN)|(1<<TXEN); /* Set frame format: 8data, 1stop bit */ UCSRC = (0<<USBS)|(3<<UCSZ0); }",serial avr
989,Local Localisation particle filter,"I Local Localisation sonar, particle filter (i.e particles initially robot pose). I grip map environment. When I execute algorithm environment (where doors closed/open), particles able followup robot. I don't random particles since I know initial position robot exactly. Adding random particle change pose robot (i find median particles robot pose). Any idea/methods improve local localisation? I want know, I need random variable I local localisation? And I improve localisation many changes map without adding random particles?",mobile-robot localization odometry particle-filter
993,Conventional Land Vehicle Dynamic Models GPS/INS augmentation,"I looking augment GPS/INS solution conventional land vehicle (car-like) model. That is, front-wheel steered, rear wheels passive axle. I don't access odometry wheel angle sensors. I aware Bicycle Model (e.g. Chapter 4 Corke), I sure apply heading/velocity constraint filter. So questions are: Are dynamic models applicable land vehicle situation, especially potential provide better accuracy? Are standard techniques applying model/constraint type filter, bearing mind I don't access odometry wheel angle? Are seminal papers topic I reading?",gps dynamics
994,Chaining Kalman filters,"My team building robot navigate autonomously outdoor environment. We recently got new integrated IMU/GPS sensor apparently extended Kalman filtering on-chip. It gives pitch, roll, yaw, north, east, velocities, latitude longitude. However, also encoders attached wheels, provide linear angular velocities. Before got new IMU/GPS sensor, made EKF estimate state using encoders low-cost sensors. We want use new sensor's on-chip filter, also incorporate encoders mix. Is problem chaining filters? What I mean is, we'd use output IMU/GPS sensor's on-chip EKF update EKF, use data read encoders update EKF. It seems reasonable me, I wondering usually supposed done case.",kalman-filter imu navigation
997,How make robot work?,As holiday project building surveillance robot capable transmitting live images using webcam also capable lifting small objects. It uses CC2500 module communicating robot. The interface designed Visual Basic 6 allows us set port computer transreceiver connected. It connected via USB RS232 port (USB side connected computer). We tried settings shown get error config unsuccessful. We tried settings 4 different computers far work. Circuit diagram robot: It designed using Atmel 89S52. Please tell us settings try make work,electronics computer-vision wheeled-robot robotic-arm
998,Motors response different high-frequency PWM,We making junior soccer robot got brilliant motors Maxon. Setting PWM timer low-frequencies (around 39kHz 156 kHz ) robot acts expected. But produces problems. It puts heavy current batteries (around 1.5A 3 motors far high). The high current causes motor drivers (L6203) heat quickly even heat-sinks won't help them. The motors make bad sound screaming normal. In contrast I configure timer high-frequencies (such 1250 kHz 10000 kHz) current drops 0.2A ideal sounds quit down. But causes problem 3 motors set run highest speed (PWM set 255) don't run rpm. like one runs slower others making robot turn specific side handling functions fail work correctly. Asking someone told drivers don't respond frequencies thus resulting different speeds low frequencies difference small I won't notice higher frequencies difference becomes bigger noticeable. So workaround problem? I continue using low frequencies? PS: I'm using ATMEGA16 main controller 10 mHz external crystal.,pwm avr
999,"For servos, implied `Holding Torque = Operating Torque * 2` like steppers?","I following guide recommends using stepper motors approximate holding operating torque. It says don't know operating torque, often half holding torque. I adapting use servo I wondering formula used servo. My servo approximately torque mean I estimate operating torque would ~1 kg/cm? A couple things: I know operating torque holding torque different. This estimate-it isn't exact science. I know servos harder find location (75 degrees, etc.) use stepper assume worked. I external means finding location.",rcservo stepper-motor
1005,Controlling Power Solenoid,I trying control force solenoid. My current system bank capacitors connected relay. In order control force (how hard I trying hit object) I increasing decreasing time relay on. The problem works either hits much force way much force. I turn relay 5 ms more. If I try turn 1 ms even respond. (I using mechanical relay.) I would like control much energy I discharge I control hard/soft solenoid moves (say discharge 10 percent total energy stored hits slower). While searching I found Solid State Relays according wikipedia switched way faster mechanical relay (of order microseconds milliseconds). So question I right track? something better achieve I trying achieve?,control
1006,Taylor Series expansion EKF,"In Probablistic Robotics S. Thrun, first section Extended Kalman Filter, talks linearizing process observation models using first order Taylor expansion. Equation 3.51 states: $g(u_t,x_{t-1}) \approx g(u_t,\mu_{t-1}) + g\prime(u_t, \mu_{t-1})(x_{t-1} - \mu_{t-1})$ I think $\mu_{t-1}$ state estimate last time step. My question is: $x_{t-1}$? Also, EKF algorithm following (on table 3.3) use factor $(x_{t-1} - \mu_{t-1})$ anywhere, $g\prime(u_t, \mu_{t-1})$. So confused $x_{t-1}$, I'm left wondering went algorithm.",kalman-filter theory ekf
1011,Charging multiple LiFePO4 batteries time?,"I'm looking use 4 3.2V LiFePO4 batteries. I intend 2 pairs 2 series parallel. So two 6.4V battery packs parallel. Because setup run this, also easiest recharge batteries using setup. To accomplish this, I'm looking charge batteries using 6.4V LiFePO4 smart charger. From simplistic standpoint, resulting voltage correct work fine. However, I know (from previous question) LiFePO4 battery chargers bit complex basic voltage supply check. Would setup I've described work correctly? And general, LiFePO4 smart charger able charge several batteries correct voltage time long doesn't try charge high amperage? Or LiFePO4 battery also minimum amperage cutoff point charge trying charge one battery time cause problems? Any issues I didn't mention? Thank much!",battery
1014,How would I go making art drawing robot like this?,I saw art drawing robot youtube: What I need learn order build something like that? What beginner oriented projects could lead building something like this? I'm experienced programmer I little hardware experience.,robotic-arm
1018,Connecting multiple different voltage servos controller,"I using Pololu Micro Serial Servo Controller connected Arduino multiple servos (4 total) make robot arm. Two four servos require 4-6 volts, 2 require 7-10 volts, I planning powering servos separate Pololu. I Arduino Pololu connecting correctly (flashing green led), servo(s) don't move plugged control pins. All servos work correctly plugged servo-tester. I think problem could fixed connecting grounds servos ground Pololu, would like advice I sure work, end frying one parts (We already fried pololu). Would connecting grounds batteries ground Pololu help, damage parts? , I couldn't figure show micro serial servo controller.",rcservo
1020,"How make ""invisible line following robot""?","I would like build robot follows virtual path (Not visible path like 'black line white surface', etc). I'm enthusiastic seeing sci-fi videos show robots carry goods materials crowded place. And really don't follow physical line. They sense obstacles, depth, etc. I would like build one robot follows specific (virtual) path point A B. I tried couple things: Using magnetic ""Hall effect"" sensor robot wire carrying current (beneath table). The problem vicinity hall effect sensor small (< 2cms) difficult judge whether robot line line. Even using series magnets couldn't solve issue, table 1 inch thick. So idea flopped :P Using ultraviolet paint (on line) using UV leds robot sensors. This give Zig-Zag motion robot. And due potential threats using UV light source, even idea flopped :P I finally thought camera top using image processing algorithms see whether robot line diverging. Is better solution this? Really looking creative simple solutions. :)",mobile-robot localization wheeled-robot industrial-robot line-following
1021,"looking miniature joystick, reverse","Does anyone know small mechanical actuators exist controlled electrically, sort like miniature joystick, reverse. Instead picking mechanical movement outputting electrical signals, I want generate mechanical movement controlled via electrical input signals. I’ve searched : electromechanical actuators, finding I need. Think pencil attached surface pivot point anywhere half dome. I’m thinking small, order inch. It load bearing. My goal programmatically control normal pointed small flat surface attached end joystick rod. Accuracy important speed. From across small room, say 10' 10', I'd like surface normal accurately point arbitrary objects room, say person walking across room. If I cheaply buy/build mechanisms control movement small flat surfaces, I would like dozens places across walls room. Its electromechanical sound project I’m planning.",control actuator
1023,Servo motor considerations quadruped,"I'm building quadruped I'm sure features I looking servo motor. e.g. digital vs analog, signal vs dual bearings. Some ones I'm considering",rcservo walking-robot
1025,Cant see Kinect Data ROS,"I working project involves using Kinect XBOX 360S ROS. I steps mentioned ROS Tutorials Openni Installed Prime sense drivers. go Openni samples see output. But ROS roscore another terminal roslaunch openni_launch openni.launch. And loads regular calibration warnings service already registered errors. Then another terminal open Rviz gives error /.rviz/display_config exist. And even though accept error go ahead see black window shows output ,even tasks mentioned RVIZ Tutorials. Also tried running ""rosrun image_view image_view image:=/camera/rgb/image_color"" shows blank window output. How resolve get ros show kinect data?? I need run RGBDSLAM use kinect later. I Ubuntu 12.04 ROS-Fuerte. Well launch openni.launch starts usual except errors ¨Tried advertise service already advertised node. And run rostopic says subscribed /camera/depth_registered/points cursor keeps blinking. Even subscribing rectified topics says subscribed nothing happens.",kinect ros
1032,How PIV control performed?,"I'm considering experimenting PIV control instead PID control. Contrary PID, PIV control little explanation internet literature. There almost single source information explaining method, technical paper Parker Motion. What I understand control method diagram (which Laplace domain) control output boils sum of: Kpp*(integral position error) -Kiv*(integral measured velocity) -Kpv*(measured velocity) Am I correct? Thank you.",control servos pid
1033,What actual physical actuated quantity controlling position servo?,"I'm trying learn servo control. I seen generic position control method servos PID, control input position error. However, I sure actuated quantity. I guessing one of: Voltage applied motor Current applied motor I guessing actuated quantity gets turned one of: Torque motor exerts Angular velocity motor runs I haven't able get hands explicitly control physical servo I cannot confirm actuated quantity these. I know little electronics controls motor. It might well controlled quantities different different series servos. My bet torque control. However, assume servo holding weight distance (so acting gravity), means approximately constant torque load. In case, position error zero servo rest, P, I D components zero, means exerted torque zero. This would cause weight sink, countered error position causing P,I components increase. Wouldn't situation cause lifted weight oscillate balance constant position significantly different goal position? This isn't case videos servos I seen lifting weights. Or case friction smoothing everything out? Please help understand.",servos pid
1036,Web mapping used autonomous vehicles/robots,"Is web mapping tool allows developers use plot GPS data autonomous vehicles/robots? forbids it. See 10.2.C. Google Earth terms use link jumps page. Bing Maps looks similar (see 3.2.(g)). What I want internet-based tool shows either/both satellite images and/or map, overlay plot using API. I'm making generic GPS plotter ROS could used slow robots fast vehicles/cars. Thanks!",gps visualization
1037,Building balancing robot differential drive,"I've already built two wheeled balancing robot using continuous rotation servos accelerometer/gyroscope. I upgraded servos geared DC motors 8-bit encoders goal robot drive around balancing. I'm kind stuck program drive around still balancing. I think one way would control input motors act sort like pushing it. So robot would momentarily unbalanced direction I want travel. That seems kind clumsy though. There must better way doing? I think I need combine dynamic model balancer differential drive bit beyond control theory I know. Update From Anorton's answer I good looking state matrix now. Now pole placement: The A matrix 4x4 based new state vector. And B 4x2 matrix since I control left/right wheel torque (u = 2x1 vector). I may need read systematic way determine A matrix pole placement? It seems example even complicated examples, determining A guess check would difficult. Update #2 After bit reading I think I understand now. I still need dynamics robot determine A matrix. Once I I pole placement using matlab octave.",mobile-robot control dynamics
1039,Resetting position e-puck Webots using Supervisor node - problem getting handle robot,"I writing method (Java) reset position e-puck Webots. I following tutorial Supervisor approach. I two controllers project: SupervisorController extends Supervisor - responsible genetic algorithm resetting e-puck's position EpuckController extends Robot - drives robot Robots communicating via Emitter Receiver, everything works fine position reset. This I'm SupervisorController: And result I get exception: [SupervisorController] Exception thread ""main"" java.lang.NullPointerException [SupervisorController] SupervisorController.initialise(SupervisorController.java:413) [SupervisorController] SupervisorController.main(SupervisorController.java:497) epuck variable null. I tried calling different methods epuck, resulted NullPointerException. The name e-puck matches world file. DEF EPUCK DifferentialWheels { translation 0.134826 -0.000327529 0.107963 rotation 0.0244439 0.999246 -0.0301538 1.95838 children [ (........) ] name ""epuck"" controller ""EpuckController"" axleLength 0.052 wheelRadius 0.0205 maxSpeed 6.28 speedUnit 0.00628 } I would appreciate advice get handle robot look issues simulation/code.",mobile-robot simulator
1046,Overview - skills needed sensor fusion?,"I want make list knowledge necessary sensor fusion. Since wide array possible applications, clear begin studying. Can please verify add topics in-scope, specify extent?: Digital Signal Processing - course: Probability - course Machine Learning - course Coursera Stanford University Programming robotic car - course Udacity Knowledge Matlab Simulink - tutorials mathworks webpage offline help. Basic knowledge integrals, matrices operations, differential equations.",sensors sensor-fusion
1047,"Source learn Kalman Fusion, explanatory code snippets","Currently I reading book Mr. Thrun: Probabilistic Robotics. I find really helpfull understand concept filters, however I would like see code eg. Matlab. Is book ""Kalman Filter Beginners: MATLAB Examples"" worth buying, would suggest source learn code snippets from?",kalman-filter books
1049,Is possible interface android mobile GSM GPS module arduino based robotic applications?,I want built robot need bunch modules track like GSM/GPS Wifi Camera If try buy module separately cost 300 dollar aprox Pakistan. On hand android enable phone purchased 250$ them. I wondring possible interface android phones like (Huawaii google nexus) 8-bit microcontrollers Arduino? The port available android phones USB Arduino supports USB. It possible attach them?,arduino usb
1050,How space rovers survive low temperatures?,"For example, rover working temperature range -70 +120 Celsius, survive restore temperature drops -150 degrees several months?",electronics ugv reliability
1051,What human-friendly terms mobile-robot orientation relative direction non-robot objects?,"Within robotics programming, orientation primarily given terms x, y, & z coordinates, central location. However x, y, z coordinates aren't convenient rapid human understanding many locations select (e.g., {23, 34, 45}, {34, 23, 45}, {34, 32, 45}, {23, 43, 45} particularly human friendly, highly prone human error). Yet common English orientation descriptors frequently either wordy imprecise rapid selection (e.g., ""front-facing camera robot 1's right front shoulder"" wordy; ""front""/ ""forward"" imprecise - camera leading edge pointing forward?) In naval aeronautical fields vehicle locations generically talked fore, aft (or stern), port, starboard. While, direction movement relative vehicle frequently given reference clockface (e.g., forward fore would ""at 12"", rear aft would ""at 6"", right starboard left port would ""at 3"" ""at 9"", respectively). This language supports rapid human communication precise terms ""front"" ""forward"". Are equivalent terms within mobile robotics?",mobile-robot control design localization navigation
1056,Perfecting Tripod Gait - Building R-Hex Robot,"I need help figuring following things: I'm developing hexapod R-Hex type model tripod gait. However, angles obtained robot's walking real life perfectly aligned. Because robot often collapses falls even perfectly straight terrain. My configuration is: 60 rpm dc motors leg H-bridge motor drivers dc motor Atmega 8 Should I change gait type? Or Tripod sufficiently stable? Are DC motors providing fine enough control I need servos? Do I need DC motor Encoder? What benefits? What could done improve performance robot? Added: Would Stepper motor work well, instead servo?",motor wheeled-robot gait
1060,Self learning maze solving robot using 8bit microcontroller?,"I want know best algorithm technique implement self learning maze solving robot 8 bit limited resource micro-controller? I looking well optimized algorithm and/or technique. Maze type. Of-course first time walk way keep tracking obstacles found. I think best technique would neural networks possible short resources 8bit? Any example online similar kind problem? My wall detection based units, well, I counted wheel turns almost 95% accurate integers. For sensing walls Ultrasonic range finding used. Wheel remeber current position let say, 3 feet staight, 2 feet right, etc.",algorithm machine-learning mapping micromouse
1064,"Prototyping device 25-100 small DC 3.0V motors, Arduino good fit?","I want prototype therapeutic device lot tiny mobile-phone type vibration motors like one it, I want able activate configuration I want. I'm going need analogue control, support logic like perlin noise functions on. I'm really going need sensor data kind feedback beyond buttons control. I need fine control lots little motors. Depending results I get of, say, 25 motors initial prototype, I may decide I'm done, needs motors. I also don't enormous budget. So question is, Arduino good fit project like this? Is feasible get many motors working controller? I know Arduino boards 50-something serial outputs, I tell, may translate 25 motors, I'd need way extend board serial outputs I wanted try more. Additionally, Arduino isn't good fit, would better? Could I try something directly serial port PC? I've never tried home-cook robotics application before, I'm really aware options.",arduino motor
1066,How invert D-H parameters,"I currently working kinematic chain made set ten links D-H convention (with usual parameters [ $A_i, D_i, \alpha_i, \theta_i$]). But task currently requires inversion them. Basically, I would part chain read end-effector origin, using links (and thus parameters). Is possible? How so? Please notice related inversion kinematic chain. It's basic: I want find dh parameters inverted forward kinematic chain. Let's put simple: I dh parameters 2 link planar chain joint 0 joint 1, I compute direct kinematics. But I want compute direct kinematics joint 1 joint 0? Given DH parameters [ $A_i, D_i, \alpha_i, \theta_i$], I retrieve transform matrix formula: $G = \left[\begin{matrix} cos(\theta) & -sin(\theta)*cos(\alpha) & sin(\theta)*sin(\alpha) & cos(\theta)*a \\ sin(\theta) & cos(\theta)*cos(\alpha) & -cos(\theta)*sin(\alpha) & sin(\theta)*a \\ 0 & sin(\alpha) & cos(\alpha) & \\ 0 & 0 & 0 & 1 \end{matrix} \right]$ This transform matrix i-th link (i+1)-th link. Thus, I invert obtain transform matrix (i+1)-th link i-th link, problem working. I believe reason related fact DH convention doesn't work is. Any help?",control inverse-kinematics kinematics
1068,Mindsensor Motor Multiplexer jump run_unlimited,"I trying run nxt motor using mindsensors motor multiplexer slow speed. When I turn on, tends jump approx 20 40 degrees moving slow speed. Has anyone seen behavior? I using NXT 1.0 firmware loaded . Sample code NXC (I using Bricx Command Center IDE) follows: MMX_Run_Degrees (SensorPort, Addr, MMX_Motor_2, MMX_Direction_Reverse, MMX_Speed_Slow, 220, MMX_Completion_Wait_For, MMX_Next_Action_Brake); Wait(500); MMX_Run_Unlimited( SensorPort, Addr, MMX_Motor_2,MMX_Direction_Forward, 5); // The jump happens here. while(Sensor(IN_2)< SENSORTHRESHOLD);",nxt mindstorms not-exactly-c
1069,Is way use single dc motor output two different loads?,"Is way use single dc motor output two different loads (by using gears, relays etc) ? Please see illustration below: To clarify illustration, I get dc motor power ""output 1"" gear extended idler gear output 2 gear. All three contact (though picture doesn't quite show it). Load 1 Load 2 two separate gears connected different loads (wheels etc) initially contact bottom gears. On switching relays 1, 2 - load bearing gears, move towards output1 output2 mesh drive Load 1, 2.",motor
1072,Is possible make Kite flying robot?,This question asked electronics stackexchange. I want know possible make robot fly kites. Is idea practical? I thinking making kite like making flying quadcopter helicopter. I want know idea really implementable? Is example similar work reference this?,control quadcopter radio-control
1074,How assemble brushless motors propellers?,"I'm building quadcopter I've received motors propellers. What's right way assemble together? I'm confident I've done, I'm sure propeller would stay place clockwise rotating motor. I mean, motor rotates clockwise, screw stay tightly place, even prop's inertia pushing counter-clockwise? Here's I've done (of course i'll tighten screw...) :",brushless-motor
1078,How I measure distance cord (string) moved?,"For pet project, I trying fly kite using computer. I need measure far cord extends device. I also need somehow read results computer. So I need connect pc, preferably using something standard like USB. Since budget small, would best I could get old home appliances build myself. What technology I need make measurement?",wheel usb encoding
1082,Stabilizing Robot Arm Specified Height,"I 4-bar linkage arm (or similar design) telerobot used VEX Robotics Competition. I want able press buttons PS3-style controller arm raise certain angles. I potentiometer measure 4-bar's angle. The potentiometer measures angle one joints shoulder mechanism, similar this: What type control I use stabilize arm angles?",mobile-robot control arm
1083,Assigning Frames Deriving Link Parameters,"The textbook I'm using doesn't answers practice questions, I'm sure I'm doing. Are following DH parameters correct given frames I assigned? The original question follows: The arm 3DOF shown like one example 3.3, except joint 1's axis parallel two. Instead, twist 90 degrees magnitude axes 1 2. Derive link parameters kinematic equations $^bT_w$ (where b means base frame w means wrist frame). Link Parameters: $$\begin{array}{ccc} & const. & & & \\ & angle & distance & & \\ & \alpha_{i-1} & a_{i-1} & d_i & \bf{\theta_i} \\ \\ 1 & 0 & 0 & 0 & \theta_1 \\ 2 & -90 & L_1 & 0 & \theta_2 \\ 3 & 0 & L_2 & 0 & \theta_3 \\ \end{array}$$ Frame Assignments:",inverse-kinematics kinematics forward-kinematics
1086,Increasing rotation range servo motor,"How I increase rotation range standard servo? Most servos rotation range ~ 180 degrees. I would like access entire 360 degree range servo, partially I would attaching servo's shaft robotic wheel would like able make full rotations. Or possible? I would like however lose 'encoder' part servo allows clearly specify angular position wheel stop at. If I use gears order transform system range, would lead loss precision? In addition, would transform allow wheels continuously rotate one direction? From I understand, won't work. Would stepper motor external encoder dc motor external encoder work?",motor rcservo
1089,How perform reference system transformation?,"I two quaternions indicate initial orientation four wheel robot, one relative one reference systems. The robot's orientation given quaternion q two reference systems: For one reference system quaternion q1 might refer robot looking positive x quaternion components q1 second reference system might refer robot looking negative x. I two matrices indicate position robot time correspondent reference system. I want find correspondent points first matrix second reference system. Each matrix built different sensor, results similar exactly same. I think I find transformation first reference system second apply point first matrix. How I find transformation? The translation part I think clear, rotation all. Edit: @WildCrustacean The solution proposed solve problem, I think reason system represents robot different way. In initial one (A) robot moving forward rotation would increase X axis. In goal referential system (B) robot moving forward rotation would increase Z axis. (See figure details) I think I apply extra rotation change initial quaternion belongs first system accordance second system applying transformation post. One rotation 180 degrees around x followed one 90 around y. Would rotate A B This I tried solve it: # Quaternion adjust reference system first_quat = make_quaternion(unitary_x, pi) # Generates quaternion rotates pi around X second_quat = make_quaternion(unitary_y, pi/2.0) # Generates quaternion rotates pi/2 around Y composed_fs_q = first_quat*second_quat # Quaternion rotate one reference system quaternion_ini_A = quaternion_ini_A*composed_fs_q A2B_quaternion = quaternion_ini_B*(quaternion_ini_A.inverse()) A2B_quaternion quaternion I use rotation still doesn't perform right rotation. Any idea?",mobile-robot localization odometry
1091,Python libraries image processing feedback control raspberry pi,"I'm building motion detection object recognition camera feedback control hexy robot. Fortunately servo control handled analog servo controls high-level logic implemented python raspberry pi. What's right combination python modules implement: daemon/service trigger execute image capture processing daemon/service regularly update hexy latest motion plan servo setpoints image processing recognition tracking objects webcam I'm currently using python-daemon services comparing various pypi opencv libraries see look promising. Anyone experience raspberry pi ARM processor robotics application? remotecv - remotecv OpenCV server face recognition ctypes-opencv - ctypes-opencv - A Python wrapper OpenCV using ctypes pyopencv - PyOpenCV - Boost.Python NumPy opencv-cython - An alternative OpenCV wrapper CVtypes - Python OpenCV wrapper using ctypes Tippy - another Toolbox Image Processing, based OpenCV These depend deep list low-level libraries and/or compilers like Boost->numpy->gfortran cython->gcc ctypes. I'm concerned compatibility performance lowlevel libraries Raspbian ARM processor. Anyone known working architecture image processing real-time control python ARM processor get answer upvoted and/or accepted.",raspberry-pi real-time
1092,Numpy alternatives linear algebra kinematics python?,"Are decent python numerical package libraries besides numpy python? Numpy relies gfortan must compiled correctly platform avoid hidden/insidious numerical errors numpy. I need matrix algebra package kinematics, path planing, machine learning python isn't sensitive gfortran version compiler options.",kinematics python
1097,At stage filtering applied sensors data?,"Shall I filter (kalman/lowpass) getting raw values sensor converting raw values usable data? Does matter? If so, why? Example: Filter getting raw values IMU filter converting raw values usable data eg. flight dynamics parameters.",kalman-filter imu
1100,Why industrial machines called robots?,"The definition robot follow: ""A robotic paradigm described relationship three primitives robotics: Sense, Plan, Act."" An example could famous ""Kuka Robots"". The Kuka robot preprogrammed mainly one loop again. Some could measurement sensors all. They think plan make decisions. An automatic door opener, used building robot either according robotic paradigm definition robot Kuka machine. They actually get data sensor followed planning acting. So Kuka machines called robots?",industrial-robot
1110,Robots minimum distance,I trying implement mechanism make robots avoid close (Say distance less ). I familiar systems I implement strategy avoid robots close other. Could anyone recommend readings problem set keywords search for? I don't know yet start.,algorithm movement
1113,Torque kg/cm?,I looking motor parameters stepper motor listed torque motor different current/voltage torque listed kg/cm. How kg/cm even remotely acceptable unit torque? How I calculate torque Nm kg/cm? Clarity note: Its kgcm represents [0.098 kilogram force = 1 Nm.] Website happens.,stepper-motor torque
1117,How obtain stereo correspondences exactly disparity map?,"I currently reading topic stereo vision, using book Hartley&Zimmerman alongside papers, I trying develop algorithm capable creating elevation maps two images. I trying come basic steps algorithm. This I think I do: If I two images I somehow find fundamental matrix, F, order find actual elevation values points triangulation later on. If cameras calibrated straightforward slightly complex (plenty methods found H&Z). It necessary know F order obtain epipolar lines. These lines used order find image point x first image back second image. Now comes part gets bit confusing me: Now I would start taking image point x_i first picture try find corresponding point x_i’ second picture, using matching algorithm. Using triangulation possible compute real world point X it’s elevation. This process repeated every pixel right image. In perfect world (no noise etc) triangulation done based In real world necessary find best fit instead. Doing pixels lead complete elevation map desired, pixels however impossible match therefore can't triangulated. What confuses I feeling Hartley&Zimmerman skip entire discussion obtain point correspondences (matching?) papers I read addition book talk lot disparity maps aren’t mentioned H&Z all. However I think I understood correctly disparity simply difference x1_i- x2_i? Is approach correct, I make mistakes?",computer-vision stereo-vision
1120,Has robot ever taken complete IQ test?,"And so, highest score far? Some news articles suggest parts tests aced. Update since people censored question closed it. There AI taken IQ test scored similar 4 year old. The AI system used ConceptNet, open-source project run MIT Common Sense Computing Initiative. Results: It scored WPPSI-III VIQ average four-year-old child, average 5 7 year-olds Abstract We administered Verbal IQ (VIQ) part Wechsler Preschool Primary Scale Intelligence (WPPSI-III) ConceptNet 4 AI system. The test questions (e.g., ""Why shake hands?"") translated ConceptNet 4 inputs using combination simple natural language processing tools come ConceptNet together short Python programs wrote. The question answering used version ConceptNet based spectral methods. The ConceptNet system scored WPPSI-III VIQ average four-year-old child, average 5 7 year-olds. Large variations among subtests indicate potential areas improvement. In particular, results strongest Vocabulary Similarities subtests, intermediate Information subtest, lowest Comprehension Word Reasoning subtests. Comprehension subtest strongly associated common sense. The large variations among subtests ordinary common sense strongly suggest WPPSI-III VIQ results show ""ConceptNet verbal abilities four-year-old."" Rather, children's IQ tests offer one objective metric evaluation comparison AI systems. Also, work continues previous research Psychometric AI. Update. A robot passed Japanese college entrance test 80% chance accepted. Since scored average, would make IQ > 100, especially since college applicants IQ greater average, especially since Japanese smarter average humans. The Wall Street Journal reports program, developed Japan’s National Institute Informatics, took multi-subject college entrance exam passed above-average score 511 points possible 950. (The national average 416.) With scores like that, 8 10 chance admitted 441 private institutions Japan, 33 national ones.",artificial-intelligence
1128,Why electro motor going slower?,"From old dust buster I've got electro motor, included battery pack charger: I ripped everything apart (the dust buster broken) motor still works. After playing around letting lying around two weeks suddenly revs lot slower. I supposed battery pack drained I hooked battery pack charger let charge night. Unfortunately motor still turns slow. Since I want use motor first home robotics project (making kite fly computer), I went local electronics store measured charger give 16V (even though says 21V) battery pack give 5V. I hooked motor directly charger, unfortunately doesn't even move inch then. So I wonder: Why doesn't motor spin hooking charger? (Could 250mA low?) Why doesn't battery pack charge all? (this bothers most!) All tips welcome!",motor battery
1130,What name mechanical linkage?,"I trying find joint like robot I'm building. It often called swivel joint universal joint, modified spider. I can't find one anywhere would prefer make it. Searching 'universal joint' returns standard automotive type. Any help would appreciated",joint
1132,How Should I Choose Educational Robotics Kits Beginner Programmers?,"I high school student, research project AI Robotics. How I choose robotics kit (for example, better learn basics using hexapod robotic arm?) I know C good level.",arduino artificial-intelligence beginner
1143,How I interface TLC5947 small motors?,"This follow-up question: Prototyping device 25-100 small DC 3.0V motors, Arduino good fit? I've decided based answer sending control signals multiple TLC5947 chips, sending PWM signal motors best way go. What I need know turn PWM signals something required power, since TLC5947's won't able drive motors themselves. I'm guessing amplifier I'll need make, what's best way boost many signals?",motor power pwm
1145,What would best way handle food grains?,"I'm trying handle food grains like rice, wheat automated way (to cook simple dishes). For I transfer grain larger container weighing scale. I know I use solenoid valves liquids solid handling valves seem big (gate valves etc) larger applications. Is better way ?",automatic
1148,Dynamic programming algorithm aka Bellman equation Robotics?,"The dynamic programming algorithm refers Bellman equation. An open-loop control decides movement initial point closed-loop control decides control movement. Now robotic application looks like closed-loop control: every point, checks respect reward function, thinking. Now participants threads How mature real-time programming robotics? differentiate scope, perhaps haven't thought it. Anyway, I interested know: How dynamic programming used robotics? Is research DP usage robotics?",research dynamic-programming
1153,When FPGAs used Robotics?,"FPGA good points lot IO points need think things low level flip-flops pioneer areas things yet mature -- example see question development-tools FPGAs -- understanding currently! Now FPGA used create excellent dexterity robotic hands like here. Now people market FPGA fast prototyping ""forward looking"" designs like here, I don't fully understand them: don't need lot IO points things sensors, choose FPGA robot? So When FPGA chosen project robotics?",design research logic-control
1158,Equation limit rate change end-effector X Y coordinates,"Some vector math involved prepare yourself. I developing robotic arm moves two dimensions. It rotary-rotary design looks roughly like picture post: Building Robotic arm joint I trying limit speed end-effector. I using Simulink believe best way limit speed limit rate change X Y coordinates I tell move to. Now, I also want end-effector able move straight line believe I accomplish defining functions calculate maximum rate movement X Y direction based distance arm trying travel. The equasion I came : So basically, XRate: distance x / max distance X distance Y. Now, actual problem. Because limits speed X Y, end-effector travel (for instance) 1 in./sec directions time. Meaning travelling OVER 1 in./sec overall. If, however, moving ONE direction move 1 in./sec speed second component. It boils fact max speed arm move 'sqrt(2)' minimum '1'. My main question is: Given I need calculate max xRate max yRate, I limit overall speed end-effector? Secondarily, way implement rate control limit overall rate instead limiting X Y independantly using Simulink?",design
1160,Can I use RaspberryPi receive GameCube remote's RF signals?,"I old gamecube doesn't work I want gut fill Arduino boards and/or Raspberry Pi necessary. I want project eventually kind AI aspect, I'm also toying idea using wireless GameCube remote wavebird issue commands push button. I guess would mostly good testing purposes, I'm mostly curious I would go making RaspberryPi understand Gamecube remote input. Furthermore, would kind idea feasible?",control arduino raspberry-pi
1163,How know Li-Po battery discharged?,"I'm building quadcopter I've seen Li-Po battery must entirely discharged, otherwise could damage it. How know stop quadcopter robot order prevent damages, since voltage doesn't drop? Which part control battery charge? ESCs? BEC? Flight controller?",battery
1167,Can rate peristaltic pump's flow accurate across changes fluid viscosity?,"I'm building arduino controlled pump system able move fluids around. I need fairly accurate, extreme precision isn't required. Since variety liquids moved pump, I've determined peristaltic pump best fit. But I don't think I fully understand them, questions.. Since I'll need purge system... Can peristaltic pump push air? Let's assume 2m tubing, pump bunch water it. Can remove tube water reservoir open air, effectively purge system remaining water? Since I want fairly accurately measure flow, could I simply count milliseconds instead using flowmeter? ... Will peristaltic pump ALWAYS pump constant rate, regardless viscosity fluid? That is, maple syrup come rate water? Shopping question, ignore I suppose ... Anyone know I may find fast/high flow peristaltic pump? I'm looking able pump, minimum, .5oz/sec Would determinant upon #3 ... What sort relay would I want toggling on/off arduino?",arduino
1170,Where Gazebo set GAZEBO_MODEL_PATH environment variable?,"I'm starting Gazebo (1.5) moment following tutorial internet. In order get Gazebo find model, author advocates manually exporting environment variable via export GAZEBO_MODEL_PATH=[...]/models:$GAZEBO_MODEL_PATH But work current terminal. So I wanted change environment variable permanently. The Gazebo User Guide claims GAZEBO_MODEL_PATH, along environment variables, set /usr/share/gazebo-1.5/setup.sh (virgin) Gazebo install doesn't list it: export GAZEBO_MASTER_URI= export GAZEBO_MODEL_DATABASE_URI= export GAZEBO_RESOURCE_PATH=/usr/share/gazebo-1.5:/usr/share/gazebo_models export GAZEBO_PLUGIN_PATH=/usr/lib/gazebo-1.5/plugins export LD_LIBRARY_PATH=/usr/lib/gazebo-1.5/plugins:${LD_LIBRARY_PATH} export OGRE_RESOURCE_PATH=/usr/lib/i386-linux-gnu/OGRE-1.7.4 # This line needed we're relying ROS's urdfdom library export LD_LIBRARY_PATH=/opt/ros/fuerte/lib:${LD_LIBRARY_PATH} But I start Gazebo, GAZEBO_MODEL_PATH already set $HOME/.gazebo/models, must set somewhere. I guess I could probably simply add GAZEBO_MODEL_PATH setup.sh script, since set somewhere, I'd still like know whether better practice set there.",gazebo
1174,PID tuning make balancing robot better,"See video balancing robot. Balancing robot I trouble getting balance hard surfaces finally got playing PID gains lot. Previously balancing fine carpet. I set PID gains picking Kp, increasing Ki robot oscillated badly tried smash it's self ground, increasing Kd finally stable. Here's gains I'm using video. It sit one spot balancing without problem. You see video even stop falling I give pretty good kick. The problem stops falling greatly overshoots direction. In video see I give small tap runs way finally becoming stable again. Any suggestions try next?",pid
1175,Minimum speed controller refresh rate,In quadrotor need change motor's speed depends position space. More frequency result stability ( I mean change motor's speed 400 times per second instead 100 times per second may stabilize UAV quadrotor far better ). Now question targeting people made UAV quadrotor information ESCs. I wanna know whats minimum refresh rate ESCs quadrotor make stable ? For example may ESC 50hz refresh rate enough stabilizing quadrotor ? I'm asking question high speed ESCs expensive lower speed ones. I one. May work ?,quadcopter esc
1178,How I calculate processing speed microcontroller,I need microcontroller process minimum 2mb data per second. How I determine processors able this? Also I calculate processing speed per second microcontroller? I much scared college project I need help.,microcontroller
1180,information filter instead kalman filter approach,"I read many sources kalman filter, yet approach filtering, canonical parametrization instead moments parametrization used. What difference? Other questions: Using IF I forget KF,but remember prediction complicated link How I imagine uncertainty matrix turning ellipse? (generally I see, area uncertainty, I mean boundaries) Simple addition information IF possible assumption sensor read different object? (hence association problem, I posted",kalman-filter algorithm sensor-fusion
1181,object level sensor fusion multiobject tracking,"I want fuse objects coming several sensors, different (sometimes overlapping!) fields view. Having object lists, I determine whether objects observed different sensors fact object? Only I truly write algorithm predict future state object. From literature I read 4 steps: Plot track association (first update tracks estimates associate ""acceptance gate"" statistical approach PDAF JPDAF) Track smoothing (lots algorithms generating new improved estimate, e.g.: EKF, UKF, PF) Track initiation (create new tracks unassociated plots) Track maintenance (delete track associated last M turns. also: predict tracks associated, new location based previous heading speed) So basically I questioning point 1, acceptance gate. For single sensor I imagine comparison xy position object sensor measurement, velocity heading eventually. My case however, I already ready object lists sensor every cycle, algorithms merge informations object collected different sensors (great source e.g. here: ), question decide objects fused, left were? Fields view may overlap partly, totally.",kalman-filter algorithm sensor-fusion
1182,"Shedding light ""cyber-physical systems""","These days, one often hears cyber-physical systems. Reading subject, though, unclear systems differ distributed and/or embedded systems. Examples Wikipedia make look like traditional distributed systems. For example: A real-world example system Distributed Robot Garden MIT team robots tend garden tomato plants. This system combines distributed sensing (each plant equipped sensor node monitoring status), navigation, manipulation wireless networking. Obviously, distributed system consists sensing, actuations (which easily include navigation) networking. My question is, exactly cyber-physical systems differ traditional distributed systems? Is fancy name, something considerably different it?",distributed-systems embedded-systems
1192,Fastest maze algorithm robot,"I'm planning programming prebuilt robot solve maze fast possible. The robot forward obstacle sensors (no side sensors) 3-axis accelerometer. I'm planning using wall following algorithm. Is fastest possible algorithm? Also, since side sensors, robot needs continuously turn check wall side, clever way use accelerometer sensors?",mobile-robot
1195,Where I get A3 poster size Mars Exploration Rover Spirit/Opportunity?,I looking A3 size poster Mars Exploration Rover Spirit/Opportunity robotic education. gives little postcard-size MER along components board buy toy. But large enough classroom purpose. Does anyone know buy A3 size poster MER robotic education?,wheeled-robot
1198,Dynamic braille interface,"I'm newbie robotics, I'm project dynamic Braille interface. Basically it's 8*8 array pins, either totally down. How use least motor possible? I'm thinking using Arduino easy interface computer.",design
1200,What wire used hand movement robot called ? I find online ?,I looking specific name wire used robotic arm movement control I find online. I want control using micro controller please suggest good development kit.,microcontroller robotic-arm movement
1202,Problem vibrations air bearing,"We air bearing planar xy motion. Today consists four pockets according picture. In current design sealings around peripheries pockets suspect reason get vibrations. In current design control pressure, recesses. The flow adjustable individually recess. In practice hard tune it. For non recess surfaces used Slydway need able operate without pressure occasionally. To try solve problem plan develop prototype try effect using sealings around periphery pockets. The idea something like this: Questions Is idea adding sealings good? (sanity check) Suggestions sealings? (I'm thinking porous material like felt cigarette filter) Of course suggestions welcome. Edit I'm going try add grooves around recesses evaquate air leaks. My thinking give us defined area pressure.",linear-bearing
1205,Plastic shaft supports,"I would like prevent shaft pulled it's bearings - is, press plastic ring around either side. What rings called? They're bearings hubs. And I find them?",mechanism
1207,Read Multiple Channels RX-TX arduino,I 9 channel RF RX/TX want connect 3 motors it. I able connect channel 1 motor 1 unable connect channel 2 motor 2 simultaneously arduino. Here code I currently using:,arduino
1209,How stabilize quadcopter,"Today quadcopter's first ""flight"". I'm running megapirate Crius AIOP v2 Turnigy Talon v2 frame. I touched throttle stick remote, nothing else. When I felt quadcopter take off, I pushed throttle little bit more, quadcopter oscillated 2 3 times flipped over, landing propellers. So, I broke 2 props, frame feels bit loose, I'll probably tighten screws (I hope...). How I tune software stabilize nicely take off? Edit : I don't know true oscillation random air flows making unstable. I made tests yesterday quite OK (even I crashed times). This time, really oscillating quite windy outside quadcopter managed stabilize all. So i'll probably tune PIDs find way without crashing. Edit 2 : After PID tuning, I managed stabilize quadcopter pretty well it's still oscillating little bit. I guess I'll slightly change values get perfect stabilization.",quadcopter stability
1211,What kind sensor need knowing something placed position?,"I small device that's picking small rocks pile moving another place. Its kind crude way trying push whole pile onto bigger gear hoping one pushed one spaces gears taken around falls side spinning gear. Here want know machine successfully got rock here, spin gear turns single rock side it. If rock present spot, gear stop spinning rock taken care rest machine. What kind device I use sensor I successfully succeeded getting rock side gear? This part bigger system, sum up, I need sensor signal rock signalled separated rest continue work single rock. I building using ardiuno move gear around, sensor need something controlled arduino",motor sensors
1214,"Space elevator: What still needed, apart cable propulsion?","In order build operate space elevator moving crafts people space, two big challenges solved yet: Finding cable enough tensile strength, Moving stuff along cable reasonnable speed. Apart two ones, technical challenges solve, especially things exist yet robotics, need invented?",mobile-robot research
1218,How I adjust objects conveyor belt proper orientation?,"This part two larger robot, follows happens small rocks here: What kind sensor need knowing something placed position? Now taking rocks tube placement. In case need altered always stand enter tube. Obvioulsy rectangular rock wont fit comes sideways. The dimensions pretty small. The rocks 15 mm x 10 mm. The tube use actually plastic drinking straw. And material use rest robot Lego powered step motors draw conveyor belts move rocks. The control Arduino. (sorry lousy illustration, know good paint program mac like one used draw picture post, please tell :-)) The rocks always enter one time much time need adjusted fit enter tube fall down. The question is, ensure rocks turned right way get straw. Im sure using Lego building robot topic here, solution involving lego preferable. And controlled Arduino. General tips split complex task subtasks robots also good, theory behind common sub tasks job requires designing multiple robots it?",arduino motor microcontroller motion
1219,Drone targeting,"Imagine ""drone"" target point 2d plane. Assuming target stationary, eight parameters: The drone's job get target fast possible, obeying max torque max thrust. There two ways apply torque, since 2d plane. Thrust restricted go one direction relative orientation craft, cannot aimed without rotating drone. Neglect resistance, pretend floating around 2d outer space. Let's say drone checks equation time interval (maybe something like every .01 seconds), plugs parameters, adjusts torque thrust accordingly. What equations thrust torque be? What tried? We know time takes drone reach target x-direction time y-direction. There going integral time dimension account changing thrust based total thrust, total thrust direction given changing angular position. I idea tie torque thrust together practical way function called give thrust torque applied interval unless technique.",design algorithm kinematics navigation
1221,Quadrotor control using ArduIMU,"We using ArduIMU (V3) Quadrotor's inertial measurement unit. (we separate board control motors, ArduIMU itself). As mentioned , output rate module 8hz. Isn't super slow control quadrotor ? I'm asking mentioned answer quadrotor needs least 200hz control frequency easily stay one spot, ESCs configured work 450hz refresh rate. Any working PID controller I saw Quadrotors used least 200-400hz control frequency. I asked similar question Ahmad Byagowi (one developers ArduIMU ) answered: The arduimu calculates dcm matrices makes slow. If disable dcm output, get 100 hz gyro, acc on. So, happen I disable DCM firmware ? Is really important ? We simulation PID controller works pretty well without DCM.",arduino quadcopter imu pid
1227,Connecting More Than Six Analog Input Pins arduino,"I'm planning stages project using Arduino Uno control 8 distance sensors, run little road block, Uno six input pins. So I'm wondering, way work? If so, how?",arduino microcontroller input
1229,"Limits PWM, Timers Interrupts?","I robot two wheels/motors quadrature encoder odometry. Using wheel/motor/encoder combo Pololu, I get 48 transition changes per rotation motors give max 400RPM. I've found seems miss encoder state changes Pololu wheel encoder library. Would I run issues limitations Arduino Uno using interrupts track quadrature encoders using PWM drive motors H-bridge chip?",arduino pwm encoding interrupts
1232,How I use Arduino PID library drive robot straight line?,"I would like create Arduino based robot 2 wheels, quadrature encoders wheel, H-bridge driver chip (or motor controller) caster. I want use PID library ensure speed proportional distance travel. At conceptual level, (assuming motors respond identically PWM levels) I implement PID control travels straight line speed proportional distance left travel?",arduino pid driver encoding
1235,How rocker bogie keep body almost flat?,How rocker-bogie mechanism keep body flat / keep solar panel almost flat time? I know differential system connect rocker bogie (left right) together. But actually work? Edited: Please provide relevant references.,wheeled-robot
1246,Using Xbox controller fly Quadrocopter,"So I quadrocopter, come remote I intend run certain modifications copter, like installing camera, mechanical manipulator, random modifications. The remote comes copter isn't flexible enough help functions plus lacks buttons. I wondering I could somehow program quadrocopter respond Xbox controller. I planning using laptop's Bluetooth connection talk copter. The Xbox controller connected computer would used control quadrocopter. So question is, exactly I program controller? How I go making possible? I understand question really vague many options there, I need help figuring out.",quadcopter
1249,Would strength speed robot skeleton danger wearer?,"Expanding upon title, I querying use robotic skeletons augment human strength speed. If robot capacity example bear weight 5 times heavier wearer move robotic limbs twice fast wearer, danger powerful sharp movements could break bones seriously injure moves beyond human capabilities? The robots means producing movement I would think important unsure so. The nature passive actively powered movement mode used also determine performance exoskeleton. I well versed area appreciate feedback.",mobile-robot
1253,What difference Task-Level Joint-Level Control Systems?,"While literature review mobile robots general mobile hexapods particular I came across control system defined ""Task level open loop"" ""Joint level closed loop"" system. The present prototype robot external sensors body state may estimated. Thus, simulations experiments, used joint space closed loop (“proprioceptive”) task space open loop control strategies. The relevant paper A simple highly mobile hexapod What meaning terms ""joint-level"" ""task-level"" context Rhex hexapod?",mobile-robot control walking-robot hexapod
1257,How I get Windows Kinect working Angstrom Beaglebone?,"I tried following number guides internet fall libfreenect exist opkg, apt-get Angstrom. Has anyone got working method?",kinect
1259,How measure dispense finite amount powder liquid,"I've watching much How It's Made, I've wondering build devices spray/inject/dispense finite amount liquid (to within amount error). I wanted try hobby project. I'm working dispenses dry goods amount I specify. Do I use kind special nozzle/valve open close high speeds? How I dispense known quantity reservoir fluid substance onto individual unit passing along assembly line, amount specified user another container?",mechanism manufacturing
1263,What easiest way install ROS OSX Mountain Lion?,"The latest OSX documentation I found website 2011, latest build year ago. I'm complete n00b things ROS wanted start playing it. What easiest way? Edit: version installation instructions recent (April 2013), says OSX officially supported ROS installation might fail several reasons. This page (yet) contain instructions higher level ROS packages, base system. This includes middleware command line tools much more. ""Does contain instructions"" also means doesn't work? What OSX users work ROS usually do? Run Ubuntu VM? Install fine OSX, even though aren't detailed instructions website?",ros
1266,What reward function results optimal learning?,"Let's think following situations: You teaching robot play ping pong You teaching program calculate square root You teaching math kid school These situations (i.e. supervised learning), many others one thing (among others) common: learner gets reward based performance. My question is, reward function look like? Is ""best"" answer, depend situation? If depends situation, one determine reward function pick? For example, take following three reward functions: Function says: certain point, bad worse same: get nothing clear difference almost good perfect Function B says: get reward linearly proportional performance Function C says: performance bad, it's ok, best: still get reward much difference perfect almost good Intuitively, I'd think A would make robot focused learn exact pattern, become stupid dealing similar patterns, C would make adaptable change cost losing perfection. One might also think complex functions, show few: So, one know function pick? Is known behavior would emerge (at least) basic A, B C functions? A side question would fundamentally different robots human kids?",machine-learning
1270,How detect stepper motor stalled?,"How I detect stepper motor stalled? A google search led people say stepper motor stalls, current spikes up, easily detectable Hall sensor. (Or, I suppose, current sensors mentioned ""How I sense motor's current?"" ). However, I measured current (one 4 wires of) stepper motor, it's always within percent 0.5 A, whether stepper driver holding one position, moving normally (which application slowly), stepper driver thinks telling stepper move normally, motor pegged hard limit. Measuring current +12V power supply going stepper motor driver, also seemed give fairly constant current. This may I turned current limit amount ""chopper"" stepper motor driver. Am I missing key detail ""measure current"" approach? A google search led people measure back-EMF (BEMF) one coil stepper time stepper driver driving coil. But seems distinguish ""a motor moving quickly"" vs ""a motor stopped"", doesn't seem distinguish case ""a motor moving slowly"" vs ""a motor stopped"". Is way apply BEMF approach even system I always drive stepper slowly, never spin quickly? I'm currently using stepper driver board TI DRV8825 chip it, I hoped ""fault"" pin would tell stepper motor stalled hard stop. But doesn't seem anything -- supposed tell stall, I wired wrong? Is chip drive technique detects stepper stalled hard stop? Is technique detecting hard stall I ""add on"" system using off-the-shelf stepper motor driver? (Is StackExchange site appropriate questions motors motor drivers?)",stepper-motor stepper-driver force-sensor
1274,How connect infrared remote control PC Arduino Raspberry Pi?,"I bought kid robotics kit several motors infrared remote control (you steer robot using IR remote control). Now I want take next level control robots PC Raspberry Pi. What simplest approach this? I thinking 2 possible ways: Find protocol existing remote control uses emulate IR signals using Arduino (Arduino sending IR signals). Find piece hardware, presses buttons remote control control via Arduino (Arduino sending signals button pushers, remote control sending IR signals robot).",mobile-robot arduino raspberry-pi
1276,How load balanced multiple AC electric drive motors?,I three wheeled vehicle tricycle configuration attached fixed frame. Each wheel powered AC electric motor. The AC motors fed motor controllers take speed demand. The single main wheel (which also steerable) lower gear ratio rear wheels theoretical higher top speed. When vehicle drives straight line motor controllers given identical speed requests. Unfortunately feedback controller indicates motors pushing pulling. In particular common scenario one rear wheel pushing front wheel trying slow down. The third wheel often almost current. What done make three motors work together avoid situations fight? Is way change request motor controller encourage drives work together? Do switch speed request setup current control setup? If appropriate way control motors then? Let know I haven't included important details I update question.,control motor
1277,How I convert RGB colors CMYK airbrush robot?,"I developing robot paints using airbrush (3D painting). I intend use several colors CMYK printer, I know conversion RGB colors computer dosage colors CMYK.",robotic-arm
1279,How I create robot like EZ-B using regular Arduino?,"I interested building robot like EZ-B, sold ez-robot.com. It comes SDK Visual Studio direct scripting runtime USB, Bluetooth, Wi-Fi, IRC HTTPS connection. If I get regular Arduino board, I able control remotely way? From I've read, Arduino needs hold instructions memory, I would rather brain computer, feeding signals back forth microcontroller. Also, Arduino alone, step website niceley puts it?",arduino microcontroller research machine-learning artificial-intelligence
1286,Is benefit using 2 IMU units UAV set different sensitivities?,"I noticed IMU units tuned sensitive small changes, large changes adjusted different sensitivities. I familiar use Kalman filter normalize readings, I wondering UAV could benefit second IMU two set high low sensitivities get even accurate timely information.",kalman-filter quadcopter imu uav
1290,Issues upgrading Arduino code Kinect controlled arm 2 servos 4,"I arduino code operating 2 servos, using 4 servos trouble getting 2 talk. The program far I make angles servos calculated processing side sent one (shoulder, elbow, wrist, wrist2) repeated. The arduino program gets data stores array written pin appropriate array segment. So 0 shoulder, 1 elbow, 2 wrist 3 wirst2. I easily get 2 servos run problem. But I try add 1 2 get response. Can anyone please help get 2 servos work? My knowledge code rather limited, help appreciated. processing Data sent arduino: Arduino Code: #include <Servo.h> //Declares servos. Servo shoulder; Servo elbow; Servo wrist; Servo wrist2; //Setup servo positions. int nextServo = 0; int servoAngles[] = {0, 0}; //Define pins servo. void setup() { shoulder.attach(50); elbow.attach(51); wrist.attach(52); wrist2.attach(53); Serial.begin(9600); } void loop() { if(Serial.available()) { int servoAngle = Serial.read(); servoAngles[nextServo] = servoAngle; nextServo++; if(nextServo > 3) { nextServo = 0; } shoulder.write(servoAngles[0]); elbow.write(servoAngles[1]); wrist.write(servoAngles[2]); wrist2.write(servoAngles[3]); } } Sorry lengthy post stuck while.",arduino kinect robotic-arm
1294,What mechanics translational drift?,"Concerning robots rotate high speed spinning drive motors opposite directions, still able simultaneously move direction (translate): As far I know originated competitive fighting robots, known ""melty brain"" ""tornado drive,"" according wikipedia, based alternately slowing motors either side revolve around centre mass. However, whole body spinning fast current ""heading"" robot established maintained?",navigation movement
1299,Send Arduino sensor data server GPRS shield,"I'm trying send Arduino sensor data server using GPRS shield (SIM900 shield Geeetech). I particular set data updated website device roaming. I can't use best knowledge updates every 15 minutes, I need update every 5-10 seconds. In order connect I tried code form UDP connection get sent receiving IP port. I don't know why. No errors occur Arduino side, server side shown work iPhone app sends UDP message. The server side follows (written python): import SocketServer PORTNO = 14 class handler(SocketServer.DatagramRequestHandler): def handle(self): newmsg = self.rfile.readline().rstrip() print (newmsg) self.wfile.write(self.server.oldmsg) self.server.oldmsg = newmsg = SocketServer.UDPServer(('',PORTNO), handler) print ""Awaiting UDP messages port %d"" % PORTNO s.oldmsg = ""This starting message."" s.serve_forever() I see possible solution might change TCP connection, I don't know that...",arduino sensors raspberry-pi programming-languages python
1301,What signs servo might broken?,"I got kit im sure appears one continuous servos might broken. What happened first I plugged microcontroller, made humming sound I sent commands. The second continuous servo didnt work I played around different ports aurdino based board, avail, hum. Then I removed humming servo altogether placed second servo alone. second continuous servo started move whatever direction I asked to. I plugged first one in, second moved. I tried spinning hand, second much resistance, first one dramatically less resistance, maybe 60% easier spin hand. Is something I fix? Has anyone experienced problems before? Thanks advance, guys great!",arduino microcontroller servos wheeled-robot
1302,Rotation ratio left rocker right rocker rocker-bogie system,"Following, previous question, I trying calculate much one rocker would rotate rotated. I attached calculation here. I trying calculate rotation gear B connects right rocket. Given gear A rotates 0.05 rad, rotation gear B rad? Gear ratio A:D 4:1, D:B 1:4. At end, I ended rotational gear A = gear B. This somewhat puzzles me. Is calculation correct?",wheeled-robot
1305,Controlling Robots Through Serial,"I recently working little project. Unfortunately, I've ran bit road block controlling servos using serial commands. The servos appear move put character serial, little. When type say, 90 characters random gibberish, servos connected arduino move several degrees. Here's code: Any help would much appreciated. EDIT: Another note, nothing printed serial monitor. Also, micro towerpro rc servos.",arduino rcservo serial c++
1306,Why IRB 1410's servos running even joints moving?,I jogging ABB IRB1410 I noticed servo motors humming even joints moving. The motor cuts guard switch flex pendant released. What kind mechanism require drive motors keep running even joints moving ? I went manual luck. I suppose holding torque provided braking mechanism I think I rule out.,industrial-robot servomotor
1314,Visualizing debugging EKF,"I currently debugging tuning EKF (Extended Kalman Filter). The task classical mobile robot pose tracking landmarks AR markers. Sometimes I surprised measurement affects estimate. When I look calculate numbers matrices involved, I work update step got executed, exactly happened, tedious. So I wonder anyone using technique, trick clever visualization get better feel happening EKF update step? UPDATE #1 (will specific show first approximation I mind) What I looking for, way visualize one update step way gives feel component measurement affects component state. My first idea plot measurement it's prediction together vectors taken K matrix. The vectors K represent innovation vector (measurement - measurement prediction, plotted) affect component state. Currently I working EKF state 2D pose (x,y,angle) measurements also 2D poses. In attached image(open new page/tab see full resolution), (scaled) vector K(1,1:2) (MATLAB syntax take submatrix 3x3 matrix) give idea first component EKF state change current innovation vector, K(2,1:2) second component EKF change, etc. In example, innovation vector relatively large x component aligned vector K(2,1:2) - second component state (y coordinate) change most. One problem plot give feel third component(angle) innovation vector affects state. The first component state increases bit, contrary K(1:1:2) indicates - third component innovation causes this, currently I visualize this. First improvement would visualize third component innovation affects state. Then would nice add covariance data get feel K matrix created. UPDATE #2 Now plot vectors state-space show component measurement changes position. From plot, I see third component measurement changes state most.",ekf visualization
1315,Non-Vision Based Target Tracking,"I building 4-wheeled, knee-high robot music speakers top follow target person target moves around. I would like help setup tracking target. The obvious solutions Ultrasound Infrared sensors kind vision tracking, application, I don't want use them. Imagine robot placed crowded area asked move towards particular person area (for sake simplicity, assume person less 5 meters away, could obscured object). Ideally, someone walked target robot, robot would lose it's path (as would happen vision-based sensing). Thanks!",sensors computer-vision navigation
1318,Robotics Location Following Tracking?,"I building robot follow target target moves around. I would like help setup tracking target. The obvious solutions Ultrasound Infrared sensors, application, won't work. Imagine robot placed crowded area asked move towards particular person area (for sake simplicity, assume person less 5 meters away). Is kind radar radio solution this, anything?",mobile-robot sensors electronics
1320,Problem uploading Roboduino AtMega328,"I bought new Roboduino atmega 328 board. Basically Roboduino modded version Arduino UNO made robokits.co.in. The problem On Windows Plaform: When I tried upload simple Blink program that's listed examples Arduino IDE 1.0.4, I got error avrdude: stk500_getsync(): sync: resp=0x00 I chose correct COM port verifying Device manager. I installed Prolific Drivers board. I selected board Arduino UNO Arduino IDE. The complete verbose upload follow: When I plug board power LED on. The 13 pin LED blinks once. When IDE shows uploading 13 pin LED blinks 3-4 times error appears screen. In also sometimes blinks randomly 5-6 times. I also tried example programs follows. I'm using 32 bit Windows 7 Ultimate baud rate set 9600. On Ubuntu 13.04: I downloaded IDE Software Center. I added dialouts group first run. After connecting board pc I ran two commands lsusb returned following output: Bus 004 Device 003: ID 067b:2303 Prolific Technology, Inc. PL2303 Serial Port Bus 001 Device 001: ID 1d6b:0002 Linux Foundation 2.0 root hub Bus 002 Device 001: ID 1d6b:0001 Linux Foundation 1.1 root hub Bus 003 Device 001: ID 1d6b:0001 Linux Foundation 1.1 root hub Bus 004 Device 001: ID 1d6b:0001 Linux Foundation 1.1 root hub Bus 005 Device 001: ID 1d6b:0001 Linux Foundation 1.1 root hub dmesg. After I tried upload program blink, gave following error:avrdude: stk500_recv(): programmer responding. I'm using 64 bit ubuntu 13.04 selected Arduino UNO board. Thank reading long. Please provide suggestions problem.",arduino
1324,Additional Power DC Motor via Second Power Source,"How I provide power DC motor series behind receiver circuit hacked cheap RC car without burning receiver board? The board runs two AAs 3V. I'm replacing stock motor slightly larger one (12V, taken printer) remounting chassis homebrew robotics project... messing around learn more. I imagine I could go safely 4.5V even 6V receiver I don't want go much higher since half stuff epoxied I can't really tell what's there. What I'd like able add additional two AA batteries behind receiver run receiver system 6V add another two 3V 123A batteries motor 12V ability run higher current draw due heavier load motor handle fancy new chassis... without pulling current receiver circuit. My first thought simply connect 123As negative motor positive common ground... I'm really sure I want careful damage circuit batteries. My next thought simply build single power supply 123As use current divider I've read never actually tried so. I've kiddie ""electronic playgrounds,"" books probably cost Google extra bucks energy costs I'm still kinda loss.",motor power
1327,How I interpret specs motor motor driver?,"I ran confusion reading motors. Consider motor specs: Maximum motor voltage - 6VDC No load current - 250mA max. Stall current - around 1A I considering using Texas Instruments L293D, specs: Output Current - 600 mA Per Channel Peak Output Current - 1.2 A Per Channel If I use L293D run 1 motor (back forth), safe? What would happen motor requires 600mA? Does simply mean I need different driver IC? Also, specs say I want drive 2 motors i'll need compensate current. Is current power supply motor driver?",mobile-robot motor
1329,Battery pack discharged,"I used Turnigy 2200mAh 3S 25C Lipo battery pack Turnigy balancer & Charger 2S-3S month. Yesterday I left battery plugged four ESCs quadrocopter. Today I've found battery totally discharged. When I tried charge it, charger showed faulty. After replugging charger showed fully charged. How I charge now? P.S. I've got multimeter, I know measure... The battery pack two plugs: one connected charger ESCs...",battery
1332,Multicopter odd even,I would like ask better design multicopter odd even number propellers? why?,quadcopter
1334,Arduino Controlled RC Car. What now?,"I bought RC car year ago. A days later I integrated arduino nano vehicle. The thing arduino receive RC signal pass esc/servo. So, basically big amount NOTHING :) Right wiring looks like this: [Remote] -> [rc receiver] -> [arduino] -> [servo/esc/lights] I added lights I experiments distance sensors I try integrate car control via xbee + processing. This works via serial already. What else could possible setup like that? Here ideas: perhaps sort autonomic driving? The car built offroad suspension bad pretty fast (40 km/h) crash would fatal. FPV (first person view) driving? I could add another servo move small camera. ""swarm intelligence""? I built two vehicles. Both feature arduino nano, zigbee LED front lights. steering correction? I could integrate gyro sensor check car driving straight should. telemetry another arduino? I could build sort arduino-zigbee-handheld shows information cars like motor temperature, current speed, uptime, battery voltage, sensor values etc. Any ideas, anyone? Right driving like normally would. I integrated arduino RC toy awesome amount NOTHING. Makes feel pretty stupid.",arduino sensors radio-control automatic
1336,Association multiple measurements multiple objects,"I matrix M measurements N objects. Each cell contains cost assignment particular measurement object. I want assign optimally. As condition, one measurement go one object, one measurement go one object. I want set cost threshold, effect may measurement object, assigned all. How I it? I recently thinking auction algorithm, however never leave unassigned measurement object. If false, correct please. Or help alternative solution. Thanks time!",artificial-intelligence sensor-fusion
1339,Permission fly UAVs,"Okay, might sound like stupid question but, sort permission US I might require fly quadcopter UAV matter? I couldn't find much help anywhere else.",quadcopter
1342,"Open source ""sci-fi""-like robot projects IRL","I'm looking robot capable moving around arms get objects one place drop another. Something akin see sci-fi movies, though much simpler. It may run legs, wheels tracks; may claws hands. I'm looking open-sourced design, schematics, specifications parts, coding - whole package. It may specific cases projects/initiatives growing collection robots. As long take trash, it's perfect. ;D",mobile-robot
1344,Aluminum vs Carbon Fiber,"So building quadrocopter scratch HAS lot decision making, I need input material choice. I short listed Aluminum Carbon Fiber Arms support Quadrocopter. I little short cash experiment them. So considering I enough money buy either those, assuming I access general tools like Table Saw, Horizontal Band Saw, CNC Router Water jet. What would better material work EDIT: I deciding specs around frame allow design liberty. So right now, goal assemble durable, as-light-as possible frame, withstand lot experimentation electrical side.",design quadcopter
1346,"Upgrading motors SeaPerch ROV - torque, RPMs?","I looking upgrade motors SeaPerch underwater ROVs carry heavier payloads equipment. My question is, I look motors higher RPM lower torque, lower RPM higher torque gain substantial power increase? If latter, threshold RPMs I stay maintain speed? We currently running Jameco motors ~1 1/2"" props (same setup here). They mainly run max power ESC currently consists fuse toggle switch.",motor underwater
1348,Single camera vision mapping system,"Some time ago I saw demo small 'toy tank' single camera mounted it. This tank able drive around floor detect objects move/steer avoid them. The interesting part used single camera vision system far I remember taking advantage floor flat. using rate feature moving scene relative motors directions travel evaluate hence map scene. Can anyone send pointers search get information this, pointers codebases this. The reason I ask single camera system number years ago (5+) therefore (from I remember) relatively low compute load. I intending try Raspberry PI build car/tank maps room set rooms.",raspberry-pi computer-vision
1349,Working Autonomous Lawn mower(ALM) unbounded area without perimeter wire,"I Autonomous Lawn mower(ALM) mow certain lawn area area bounded perimeter wire. Even perimeter wire removed, mow mentioned area accurately without slipping neighboring area. Constraints problems: The ALM open loop system. Differential GPS tried, yield proper results. Any iterative pattern area coverage used provided error iteration added cumulatively result unpredictable error end. I expect full fledged solution. But I need starting point understand motion planning particularly unbounded robotics solve problem. I searched internet know knowledge sources motion planning could get good results. Can anyone guide know sources preferably books articles internet help solve problem? EDIT: Addition information: The picture shows irregular lawn area enclosures perimeter wire 1.The red mark shows center point lawn . 2.The grey area initial scaled area resembles shape larger area .I could draw grey area exactly resembles larger green area . 3.The grey lines contours tracks followed lawn mower Idea description: 1.Using planimeter app onetime , shape dimension lawn area (green area) known Link: 2.Center polygon found using method following link 3.Calculation area grey shape figure . 4 . Grey shape least possible area grazed ALM . Grey shape similar green area shape formed Green area scaled To determine scale factor numerical value ‘ n’ (n<1) Where Grey area = n * Green area Once Grey area known , number contours tracks grazed ALM determined manually . The width contour equal distance blades either end i.e. width grazed ALM single stroke . Green area = Grey area + area track 1 + area track 2 + area track3 + . . . . . . + area track n 5.Once lawn mower switched ,it reach center lawn (red mark showed figure) 6.Then, ALM graze least possible area grey area . 7.After ALM Switch contour circumscribing grey area . It continue circumscribing track till tracks completed( decision made validating calculated preset value ' No.of tracks' ALM) In way entire lawn mowed without need perimeter wire also ALM would mow neighbor’s lawn Challenges : a. Enable ALM reach center point lawn a. To make ALM mow grey area accurately b. To make ALM switch one track track . c. To bypass obstacle track return track . When mentioned idea colleague ,he mentioned possible cumulative addition error iteration resulting unpredictable error end . I intend minimize error fix boundary correct possible. In fact deviation predictable corrected .",motion-planning
1350,Building Autonomous pesticide spraying system using swarm robotics based odor (volatile Organic Compounds) detection,"Visible worms, pests, diseased parts plants emit unique odor (Volatile Organic compounds different concentrations). I understand sensors quantitatively detect compounds development developed. My idea build swarm robots spray pesticides detecting VOCs three targets present plants across fields. Target 1: Visible worms, pests, larvae. May mechanically eliminated Target 2: Invisible pathogens certain areas plant Target 3: Areas pesticides sprayed prevent disease For targets, pesticide administered correct concentration This idea optimize use pesticides treat plant properly Questions: Is swarm robotics still sci-fi Did one implement it? Are specific scenarios implemented swarm robotic systems coming help establish ease? Which implemented system idea conception help formation solution problem? How much time required approximately realize idea? Hope question sound sci-fi practical intention solve definite problem How work following steps make idea concrete",sensors research
1356,Can I use Ziegler-Nichols's rules find PID parameters non linear system,"I'm trying use PID stabilize system described following difference equation: $$y_{k+1} = y_k \sqrt{(1-y_k)}~~~ + b y_{k-1} ~+ c u_k$$ Can I use Ziegler-Nichols's rules find PID parameters situation? To precise. My system Apache Http Server, particular I'm trying model CPU load change function KeepAlive parameter. When KeepAlive grows cpu load decrease. So: $$cpu_{k+1} = \cdot cpu_k \sqrt{(1-cpu_k)}~~~ + b \cdot cpu_{k-1} ~+ c \cdot keepAlive_k$$ Obviously Cpu load scalar $\in [0,1]$ , $keepAlive$ time $a,b,c$ parameters known experimental data multiple regression them.",pid
1367,Prop Orientation Multirotor,"While looking information right propellers quadcopter, I realized different orientations i.e. Clockwise Counterclockwise. On research I found multi-rotors different combinations orientations. So question WHY? How matter propeller turning clockwise anti-clockwise?",quadcopter multi-rotor
1369,Instantaneous Center Rotation differential Drive Robot,"I want find instantaneous center rotation differential drive robot. Assuming I know robot travel particular linear angular velocity $(v,w)$ I use equations (given A Path Following Circular Arc To Point Specified Range Bearing) come be: $$x_c = x_0 - |\frac{v}{w}| \cdot sin(\theta_0)$$ $$y_c = y_0 - |\frac{v}{w}| \cdot cos(\theta_0) $$ I'm using webots simulator I dumped gps points robot moving circle (constant v,w (1,1)) instead single $x_c$ $y_c$ I get center point every point. If I plot matlab look nice: The red points image perceived centers, seem trace curve itself. Is detail I missing? I'm really really confused what's happening. I'm trying figure center I check whether obstacle circle whether collision occur.",mobile-robot motion
1370,Prop orientation tricopters,"This question stems previous question, I asked prop orientation matter much multirotor. But research† I found reasons need apply tri copter. again. Why? Are reasons general multi rotors odd number motors? even rotors? † This forum talks lot tricopters prop orientations nothing really answers question.",multi-rotor
1378,How tell ArduPilot finished initialising gyros (without referencing telemetry)?,"Using ArduPilot software (fixed wing, ArduPlane), I know I boot I need keep system sit still gyros initialise. When I ground station field it's easy know it's safe launch telemetry message tells me. But I don't always fly ground station. In situations I currently sit wait arming, launching. Is reliable rule thumb? information blinking arming switch buzzing I haven't worked yet? This UAV PX4 autopilot hardware (with Px4FMU PX4IOBoard), including buzzer illuminated arming switch. The LEDs board obscured (but I could make light channels required). (Note: I'm asking question test theory robotics stack exchange night appropriate forum sorts questions, suggested couple times response Area51 drones proposal.)",uav
1383,Software robot parts interaction modeling,"I'm robotic engineer, using OpenSCAD model robotic components (gears, pulleys, parts, etc). But I need application model physics interaction components (for i.e. robot move I rotate given gear). So, software I use modelling interactions Linux? Google SketchUp good, I can't use Linux.",software
1388,programming pan-tilt unit C,"I trying write C code pan-tilt unit model ptu-d46 using visual studio 2010 Windows 7, I can't find tutorial reference so. All user's manual mentions C programmer's interface (model ptu-cpi) available, doesn't say find use. I looked google couldn't find anything. There command reference manual along user's manual, shows different commands control tilt explain make C program connects tilt controller sends queries it. Does anyone please idea I look open source programs that. I'm trying make complicated program. I need connect tilt controller (the computer connected via USB cable host RS232 tilt controller) makes nod say ""Yes"" ""No"" !",c
1391,creating robot ez-b regular arduino,"Does anyone experience ez-b, sold ez-robot.com comes SDK Visual Studio It direct scripting runtime usb bluetooth, wifi, irc, https My question is, I get regular arduino board, able same? ive read, arduino needs hold instructions memory, I rather brain computer, feed signals back forth microcontroller Also, arduino alone, step website niceley puts Thanks help advance",arduino microcontroller
1392,Why LSM303 magnetometer reading change loop?,"I using LSM303 sensor compute heading I want turn robot heading. I simple code here: In function called speed angle (heading), trex part tells motor controller turn point loop test desired heading reached. However, testing using couple instances Serial.println(mag); I determined inside loop, mag never changes means robot turns indefinitely. I idea would happen. Perhaps someone does? Thanks.",arduino
1393,What cheapest / easiest way detecting person?,"I'd like know anyone success detecting warm-bodied mammal (ie. Human) using standard shelf, inexpensive sensors? Ideally, I'd like use inexpensive sensor combination sensors detect person within room localize person. I would like robot enter room, detect human(s) is/are present move detected human. The accuracy need 100%, cost factor. I'd like computational requirements sensor run Arduino, although it's impossible, I'd willing utilize something horespower, Raspberry Pi BeagleBone Black. I thoughts; however, none ideal: PIR Sensor - Can detect movement within large field vision (ie. usually 120 degrees more). Might closest thing ""human"" detector I'm aware of; however, requires movement localizing/triangulating person would difficult (impossible?) large field vision. Ultrasound - Can detect objects good precision. Has much narrower field view; however, unable differentiate static non-living object human. IR detectors - (ie. Sharp range sensors) Can detect objects great precision, narrow field view; however, unable differentiate objects. Webcam + OpenCV - Possibly use face detection detect human(s) room. This may best option; however, OpenCV computationally expensive would require much arduino run. Even Raspberry Pi, slow. Kinect - Using feature detection capabilities Kinect, would relatively easy identify humans area; however, Kinect expensive I would consider ""cheap"" solution. Perhaps someone aware inexpensive ""heat-detector"" tuned body heat and/or success combination (#1-4) would like share results?",sensors sensor-fusion
1394,qt ros tutorial issue,I working robotic application R.O.S. groovy Galapagos. I would like make tutorial create template app catkin_create_qt_pkg. I'm unable call script catkin workspace. I found root : _/opt/ros/groovy/qt_ros/qt_create/script_ But even I try execute sudoer I got error. ImportError: No module named qt_create I'm unable determine I make work. Why?,c++ ros
1399,Wearable Accelerometor,"I've worked wiimote accelerometer, I think I want move past that. Mostly I want wider range available gestures I think using one accelerometer many limitations I want do. I'm looking something compatible arduino RPi. Does anyone recommendations I this?",control sensors accelerometer
1400,Stream Real-time Video Environmental Data Overlaid,I want embed environmental data collected sensors live video stream camera. Has anyone done know I would go something like this? Is library available arduino RPi?,sensors cameras
1408,Pushing Buttons Remotely Ethernet,"So I want program something simply push button, controllable ethernet. I'm new robotics I don't know start. What's best way control actuator network connection?",arduino actuator
1413,Is Raspberry Pi processor powerful enough mobile chatbot?,"In general, Raspberry Pi processor powerful enough mobile chatbot? I want make small mobile robot like chatbot. Is Raspberry Pi processor powerful enough type AI robotics? As far mobile robot, I want make wheeled robot one foot every dimension. The chatbot abilities ProgramPY-SH, new chatbot program uses Xaiml databases. The chatbot works looking database match user's input (vocal text-based). It acts according instructions given XML-like database.",mobile-robot raspberry-pi artificial-intelligence
1414,PID Conundrums Legged Robots,"I currently working legged hexapod moves around using tripod gait. I two sets code control tripod. Set 1: Time based control In code set, I set tripod motor set move rated rpm required amount time shifting tripod motor set. PID control would based counting number transitions using optical speed encoder, Calculating error based difference actual speed required speed adjusting error fixed Kd Ki values. Set 2: Transitions based control In code set I count number transitions required complete one rotation leg(tripod motor set) starting leg(tripod motor set). PID control would time based. Calculation error would difference time taken individual motors motor set. Query: The set 2 shows promising results even without PID control, first set not.Why so? The motors basically set move 1 rotation set moves. Would speed differences motors cause destabilize? How often I update PID loop? My robot seems drag little bit. How I solve this?",mobile-robot pid legged walking-robot hexapod
1416,"Building robots high reliability, durability, battery life","I'm involved research psychologically plausible models reinforcement learning, I thought it'd nice try see well models perform real world (i.e. sensory-motor learning mobile robot). This already done robotics labs, Sutton's implementation Horde Architecture ""Critterbot"". However, implementations involve robots custom-build robotics experts order deal trials tribulations learning long time-scale: ""The robot designed withstand rigors reinforcement learning experiments; drive walls hours without damage burning motors, dock autonomously charging station, run continuously twelve hours without recharging."" Unfortunately I'm expert comes designing robots, don't access high quality machine shop even I did; I'm stuck whatever I buy off-the-self assemble hand. Are constraints common enough amateur robotics suppliers cater to, I expect start scratch?",mobile-robot battery reinforcement-learning
1417,"What best way go building robot hand type keyboard, move &click mouse, swipe touchscreens?","How would go building robot use computer? Type keyboard, move & click mouse? I talking physically manipulating hardware inputs, robot would able see screen. Not connected anything. It's purely autonomous. My hope replace human QA testers.",wheeled-robot artificial-intelligence robotic-arm
1419,How I improve map Mobile Autonomous Robot using KINECT,"A little background aim I process building mobile autonomous robot must navigate around unknown area, must avoid obstacles receive speech input various tasks. It also must recognize faces, objects etc. I using Kinect Sensor wheel odometry data sensors. I chose C# primary language official drivers sdk readily available. I completed Vision NLP module working Navigation part. My robot currently uses Arduino module communication Intel i7 x64 bit processor laptop CPU. This overview robot electronics: The Problem I implemented simple SLAM algorithm gets robot position encoders adds whatever sees using kinect (as 2D slice 3D point cloud) map. This maps room currently look like: This rough representation actual room: As see, different really bad maps. Is expected using dead reckoning? I aware particle filters refine ready implement, ways I improve result? Update I forgot mention current approach (which I earlier forgot). My program roughly this: (I using hashtable store dynamic map) Grab point cloud Kinect Wait incoming serial odometry data Synchronize using time-stamp based method Estimate robot pose (x,y,theta) using equations Wikipedia encoder data Obtain ""slice"" point cloud My slice basically array X Z parameters Then plot points based robot pose X Z params Repeat",arduino slam kinect odometry
1427,Controlling Quadrotor PC,"I need control quadrotor PC, without using joystick. I got mini-beetle quad V929 Beetle 4-Axis also NRF24L01+ Wireless Transceiver Module Chip (2.4ghz transceiver) Is possible write arduino program make speak other? I research found quad v929 model uses flysky protocol works A7105 NRF24L01 2.4ghz transmitter chip one mentioned Are better ways controlling quad PC arduino board?",arduino quadcopter radio-control
1429,Pan tilt bracket stepper motor,"Currently, I'm using pan tilt bracket works servos I (spark fun product 9065), generic servos. However, servos aren't accurate enough. I'm looking options, limited knowledge them. What would recommend? An important consideration I need motor tilt two dimensions, random $x, y$ coordinate accurately. To this, I think I'll need sort attachment motor shaft, like pan tilt bracket. What motor bracket would recommend I use go random $(x,y)$ coordinate?",servos stepper-motor motion
1435,laser scanner distance,I'm looking laser scanners I see huge range detection distances. The furthest I've see 30m exclude expensive ones claim 150m. My question reason huge difference range/price. I would think laser wouldn't difficult detect something distances greater 30m. What's physical limitation makes much expensive go 30m laser scanner one?,localization
1437,Most material efficient quadcopter frame,"I haven't made flown quadcopter, I fascinated them. But looking frame lot designs, whachting video I wondered lot frames X shape. Since efficient shape would according video something like >-<, corner 120°. I also quick search internet found blog stated (however mention exact angle) said: ""Even though entirely new idea, yet widely accepted community.""",design quadcopter
1440,trapezoidal vs sinusoidal commutation,"How know commercial driver working trapezoidal sinusoidal commutation? If measure 3-phase voltage applied PMSM means oscilloscope, see difference?",brushless-motor
1443,Learning embedded systems,"The last robotics project I worked involved autonomous outdoor navigation, using microcontroller lower-level control computer image processing decision making. I worked higher-level software another guy team electrical embedded systems. I would like capable everything, including stuff embedded, I'm sure look information. If I done project scratch own, I'd need know: What microcontroller use What motors required What motor controllers get, interface controllers What encoders use motor feedback, write drivers What batteries use safely power everything If I trying learn higher-level software, I'd probably take courses Udacity. Are good resources like kind low-level stuff?",microcontroller power embedded-systems
1445,How get data ArduPilot Serial Port,"I'm project related telemetry, I want make ArduPilot (programmed ArduPlane 2.73) send serial port sensors informations height, GPS position, etc.. I tried use ArduStation, I could change firmware I want. The idea would read Ardupilot's serial port using Arduino Uno, saving SD card real-time. So ArduPilot needs send data without user input something like that. I've already tried manipulate ArduPlane source code that, I couldn't either. Has someone something like before? I need advice!",arduino ardupilot
1448,Maze Solving Algorithm For Mazes With Loops,"I trying implement line following robot solve mazes similar Pololu robots watch youtube. My problem maze I trying solve looped therefore simple Left/Right hand rule solve maze. I done research think either Flood-Fill Breadth-First-Search algorithm able solve looped mazes. Solving maze reaching large black area sensors read black. When robot following line sensors read white central ones black. Is algorithms solve looped mazes? I understand Flood-Fill algorithm works unsure could implemented situation. My robot 3 sensors bottom. The one centre expected always read black (the black line follows) sensors right left expected read white (while following straight line) black junction turn reached. My robot problem following line, turning etc. I need find algorithm solve looped mazes (that is, find path entrance exit).",mobile-robot motion-planning line-following routing
1449,How units noise measurement related units sensor's data measurement?,"I'm trying understand noise represented accelerometers, gyroscopes, magnetometers I match requirements project standard specs sensors. I want output 3 axis inertial sensor values meters/sec/sec, gauss, radians/sec axis, noise represented range around true value (so X +/- X m/s/s, gauss, radians/sec) accelerometers, magnetometers, gyroscopes respectively. Switching gauss teslas, meters feet, radians degrees, etc. would fine. After looking datasheets, I'm surprised find that... Accelerometer noise measured ""LSB rms"" ""μg/√Hz""(, ) Gyroscope noise measured ""º/s-rms"" ""º/s/√Hz"" () Magnetometer noise measured ""µT rms"" ""Gauss/√Hz"" (, ) What units mean, (or they) translate I want?",imu accelerometer gyroscope noise magnetometer
1450,How would I go interfacing raspberry pi arduino?,"I want project I control motors, arduino seems ideal that. However, I'm going need quite bit processing back end first. Connecting arduino computer isn't option, quite mobile. Does anyone experience controlling arduino raspberry pi?",arduino raspberry-pi
1454,Motor Ethernet shields together,"I wondering possible plug motor shield top Ethernet shield, even though direction pins motor shield would connected pins spi bus. I thinking would work if, coding, I disabled chip selects Ethernet shield I used motors.",arduino
1455,Help adaptive fill algorithm Water Color Painting Robot,"TL;DR: Can anyone point good adaptive path fill algorithm? Hey there, name James, daughter built awesome painting robot friends Evil Mad Scientist labs, even brought white house, fun stuff! Anyways, I'm web programmer day, though might fun try write software get robot cool stuff, crazy reason I decided using standard web technologies like SVG JavaScript, and.. actually works! [see project ] But there's problem: fill colors given shapes, requires kind path filling algorithm using given size shape cover every part shape internally, mention take account overlapping paths occlusions. I successfully created ""fake"" fills, following known paths like spirals back forth hatch lines paths, detecting occlusion using browser internal functions detecting object lies given x/y coordinate, fill functions fall incredibly short anything simply following paths, incredibly inefficient filling certain paths (like filling borders, letters, U shaped areas). The question: I need adaptive path filling algorithm. I know they're currently used similar CNC setups milling, similar algorithms used Roomba 3D printers figure coverage efficient way possible. The issue comes I don't think ever done JavaScript, using native SVG paths. Anyone know I look? I'm afraid attempt port something JS, possibly even use native Node.JS module. All work sure go back community become open source well. Thanks help!",algorithm motion-planning motion cnc
1457,Is good quadcopter build?,"3D CAD: After editing: I'm building frame aluminum polycarbonate. EDIT: frame polycarbonate except arms (and screws & nuts & washers)), form aluminum covered polycarbonate. total length (from one motor another) exactly 60cm Approximate Mass: 1.736 kg What I thought put in: Battery: ZIPPY Flightmax 4000mAh 3S1P 20C (changed 1500mAh battery) Motors: Turnigy Aerodrive SK3 - 2822-1090kv PDB: Hobby King Quadcopter Power Distribution Board ESC: Hobbyking SS Series 18-20A ESC Core: Arduino Nano IMU: Invensense MPU-6050 Propellers: 10x4.5 SF Props 2pc Standa## Heading ##rd Rotation/2 pc RH Rotation (changed 8x4.5 ones) I'm gonna program (or atleast try to). I WANT TO USE IT AS A UAV (self controlled) Questions: Is good setup? It costs much me, way keep frame change parts cheaper yet good quadcopter? Does propeller fit motor? Any place buy cheaper? Is good frame? Am I missing parts? Thanks alot, Dan EDIT: I checked using site gave errors (guess good sign). The camera image picture (no camera intended there).",arduino motor quadcopter
1463,"Does ""Power"" (W) means better motor?",If motor Power (W) another means better?,motor quadcopter power
1466,Quadcopter application underwater,"Just curiosity, concept Quadcopter applied ROV? Would work way underwater would Air? If kind modifications would take implement idea, underwater?",quadcopter
1475,"Pros/Cons common robotics ""kits"" high school level","I interested starting robotics club high school next year, since don't one, I want know pros/cons common kits. I already Vex kit since uncle one regional suppliers Indiana, I'm sure Vex best choice. What pros/cons kits there? Note: I looked Lego Mindstorms, used I learning robotics, want this. Also, Raspberry Pi.",raspberry-pi mindstorms beginner children
1483,Optimal-time trajectory 2D 3D simple constraints,"I'm trying find optimal-time trajectory object (point mass) point initial velocity v0 point p1 velocity v1. I'm considering simple environment without obstacles move around. The constraint maximum acceleration direction a_max optionally maximum speed s_max. This easy work 1D I struggle solution 2D 3D. I could apply 1D solution separately dimension, would limit acceleration speed single dimension. The actual acceleration might larger multiple dimensions. Are textbook, closed-form solutions problem? If not, I solve discrete-event simulation?",control motion-planning
1489,automatic sorting barcode identification inside refrigerator,"I'm endeavoring prototype challenging sorting mechanism inside fridge would appreciate constructive tips get specs plausible design. Problem The aim game identify sort food items limited space fridge - user would push unsorted shopping chamber top enclosure - machine inside would try identify contents help bar-codes (first big problem) - sort move items according identities different chambers (second big problem). Solution? Are existing devices already serve functions (automatic bar-coding sorting), designs could perhaps inform mechanics device I'm planning construct? I'm thinking maybe manufacturing plants packing factories conveyor belts etc may use systems already solve problems? Or filtering mechanisms candy dispensers, mechanized lifting forks? Textbook engineering mechanisms?",arduino motor sensors cameras
1492,Single power source electronics actuators,"It seems popular build robotic systems separate supplies electronics motors/servos, would involved circuit powers one source? If helps, particular situation. I want use single 7.4V Li-Po pack power embedded system (2.5-6V operating voltage input, max 1A current draw) 18 standard-sized servos (HS-645, 4.8-6V operating voltage). This would hexapod, unlikely servos would stalling normal gait patterns.",electronics servos power legged
1494,How build liquid filling machine using piston?,"My team developed filling machine liquids uses piston measure deliver volumes 0.1 1 liters bottles. It built mostly mechanical parts we'd like replace electronic ones. How I build machine pull liquid reservoir fills bottle using piston, electronic parts stepper motor, linear actuators sensors? I understand somewhat vague. Any aligned response appreciated. Update: This machine should, max speed, fill 1 litter bottle water 2 seconds (to deliver 30 bottles per minute). Higher viscosity liquids may take longer. It spill liquid needs filling acceleration control. You may assume two operation modes: bubbles without bubbles. The first plus. I'd like able change volume electronically (via LCD menu). I thought single main valve switches reservoir bottle. That controlled electronically too. I could use two valves too.",sensors stepper-motor mechanism
1496,"On ardupilot board, difference A10 / A11 ground pins PWM ground pins?","I'm looking electrical explanation statement here: Warning: Do connect power (red + & black -) RC10 (A10) & RC11 (A11) connectors servos, use signal lines. Power servos via PWM Outputs connectors. These solutions avoid scenario possibly happen Pan/Tilt servo draw much current cause APM brownout (reset) I examined APM2.5 board drawing schematic grounding little unclear. On schematic, go GND, board drawing ground pins appear unconnected traces. I checked continuity, continuity PWM grounds A10/A11 ground pins. By way, power setup I J1 enabled I using ESC power board. Can anyone figure out, electrically, two sets ground pins? Ground pins appear unconnected traces: PWM ground connected GND: analog output ground also connected GND:",power ardupilot
1500,lithium thionyl chloride batteries generate 20A @ 14.4V,"I building robot power density critical, looking using lithium thionyl chloride (SOCl2) batteries. I drawing around 20A constantly need 12 17V. The batteries I found far AA-sized designed deliver 100mA, 3.6v, 2.4Ah, weigh 19g each. I could picture pack 4 blocks batteries series, block 20 batteries parallel. That would mean 48Ah, way ~10Ah I need, 1.52kg, I would like robot carrying. So, question is, way achieve 10Ah 20A 14.4V (i.e. 5 hours) using SOCl2, carrying much less weight 1.52kg?",power
1503,Python3 Modules motor movement,Are Python3 modules used program robotic movement declaring device component providing instructions? I looking modules test components.,python
1514,Reducing motor speed without jamming,"So I built three little bots far. One raspberry-pi, (6V motors), one arduino (12V motors), another arduino hacked remote car (7ish, volt motors): The problem I motors spin fast car bumps something seconds. (I small house) I tried use PWM control speed, little less full throttle (255) jam can't take weight I put them. Should I buy one chassis slow motor give torque gearbox, anything else I do?",motor pwm
1515,Building non rotating persistence vision device,I'm looking way create non-rotating persistence vision device. I electronics set I'm stumped mechanical design. I tried two designs: But didn't work well. Everything shakes violently doesn't go nearly fast I need (about 20 swipes per second) Any ideas I build this?,motor mechanism
1517,Light pattern flashing intermittently using RVIZ/OpenNI two Kinects,"I two Kinects (each USB card) whose cameras I'm watching RVIZ OpenNI, structured light pattern one flashing intermittently - it's short flash every two seconds. Obviously, structured light depth calculations work pattern always projected camera looking it. What causes this, I fix it? EDIT: I also issue single Kinect, I discovered issue, detailed answer. However, problem persists two Kinects plugged in, one Kinect flashing functioning normally.",ros kinect openni
1518,How visual obstructions impact ability localize using LIDAR?,"If street extremely crowded extent terrain visible point view LIDAR (e.g. google's self driving car), still manage localize continue operate? I recall Sebastian Thrun saying Google's car cannot navigate snow filled roads since onboard LIDAR cannot map terrain beneath snow (e.g. here). [Edit : Based comments] Clarifying context, ""not visible"" means obstacle LIDAR terrain",ugv lidar
1519,PX4 Communication,"Does anyone know PX4 software? I'm using Eclipse program I want Open new UART door write this, I'm following commands... But working! Anyone idea why?",microcontroller communication
1524,Line Follower optimization,"I'm working building line follower robot want optimize performance. It suggested I use PID algorithm. I read lot PID confused bit regarding following: I've calculated error_value using $k_p * proportional + ...$ But regarding change motor speed I'm confused use comparison difference (i.e. currentposition - setpoint) errorvalue. That I use (error_value > 0) { //code changing appropriate motor's speed using error_value } Also specified range values constants $k_p$, $k_i$ $k_d$? I'm using differential wheeled robot line follower. Also I would happy someone suggests advanced optimization algorithm improving line follower robot.",arduino pid line-following
1525,How implement Bounded Angle Vision Particle Filter?,"I built Particles Filter simulator I wanted add following functionalities. Limited Range Vision (Robot see 50 meters) Limited Angle Vision (Robot see within certain angle w.r.t current orientation. e.g. If current orientation 30 degree see range 0 60 degree.) I managed add Limited Range Vision functionality unable add Limited Angle Vision. Method Sense landmarks distance within range Method calculate probability particle @Override public double measurement_prob(double[] measurements) { double prob = 1.0; int c = 0; double[] myMeasurements = sense(false); (int j = 0; j < measurements.length; j++) { (measurements[j] != 0) { prob *= Util.gaussian(myMeasurements[j], sense_noise, measurements[j]); c++; } } (isBoundedVision()) { (c > 0) { // increase probability particle see landmarks prob = Math.pow(prob, 1.0 / c); } else { prob = 0.0; } } return prob; } Coordinates relative robot distance calculation I using Euclidean Distance method Robot gets localized correctly.",localization particle-filter visualization
1530,How dim 12 volt LEDs?,"I considering using Raspberry Pi controlling USB Relay dim 12V LED lights, I'm trouble finding solution isn't simple ON/OFF. What type device would I need dimming?",raspberry-pi
1538,How convert vertical motion horizontal,"I interested using miniature motor (Squiggle Micro Motor) create tiny horizontal movements. However, due limited space, I place vertically within project. Assuming motor placed follows, one adapt simultaneous movement right angle? (Ideally X-axis movement matched Y-axis movement well possible.)",motor motion movement driver linear-bearing
1544,Arduino C/C++ progamming tutorials,"I problem reading circuit schemes, connecting wires, resistors etc. (basing example instructables.com), I've tried learn Java (a ago) it's difficult find what's going C-code-stuff. Are tutorials focused programming part? thanks",arduino
1547,How I simulate changing environment non-rigid objects?,"Many robot applications (actually - practical appealing ones) include robot's reaction (and impact on) evironment, e.g. due stochastic nature environment (e.g. robot handle non-rigid objects like clothes) due variability environment (e.g. harvesting robots prepared pick fruits different sizes shapes). The question - robotics simulator simulate robot also environment well? E.g. simulate response robots action cloth folding fruit picking on. I guess simulator really non-trivial maybe ongoing project it?",simulator industrial-robot
1552,Use automated tricopters instead quadcopters?,"Hy, I found useful post idea here. I've seen videos automated quadcopters: . I surfed pages companies presenting research information internet, I haven't found use quadcopters specifically. I understand, accelerating, rotating rolling works quadcopters - it's simple, claim quadcopters minimum number working parts fulfill needs, I don't agree I think tricopters better (duocopters can't rotate horizontally, tricopters inclining powering remaining left right propeller). I rode forums, calculated draw drafts tri quad found, tri much efficient everything quad props battery taken account best properties smallest copter largest props so: 3:4 moving parts (no vectored yaw tri), 9.5:16 size, building Y instead X construction take far less material 1.5:2.82, lesser maximum power input 3:4, better power efficiency makes longer flight time tricopters also improved agility quadcopters. The disadvantage I see bit complicated horizontal rotating tricopter without vectored yaw, problem man controlled machines easily solved simple algorithms automated machines -> it's real disadvantage, small work done. I thinking bachelor thesis, I looking opinions, thanks! EDIT: Maybe torque problem, tricopters 3 props 1 direction 2 1 direction 1 opposite it's symmetrical neither way, I'm sure main problem...",quadcopter multi-rotor
1554,Track moving object,"If already answered, means please point it. I process building quadcopter I eventually plan run autonomously allowing track object take video feed moving. GPS one options I've considered, basically: GPS antena moving object (person, car, bike, surfer) GPS antena quadcopter Radio transmit coordinates moving object quad copter Some challenges I foresee Line sight camera. How camera know exactly point? Angle, I pre-program quad always record, say... 10m right moving object, even better, program set angles record whilst keeping object GPS accuracy, happens GPS lock weak? What options? I saw TED Talk quads following ball shaped sensor? I believe uses Kinect cameras lots really option challenge. So I'm open hearing ideas I start research development features.",arduino quadcopter gps
1562,If create pure yaw motion quadcoptor won't work tricoptor?,"An answer question Why quadcopters four propellers? (Besides name) said: You need 4 degrees freedom control yaw, pitch, roll thrust. Four props therefore minimum number actuators required. Tricoptors require servo tilt one rotors mechanically complicated. In comment, I asked: How get pure yaw motion quadcoptor that's possible won't work tricoptor? I don't understand get yaw motion system rotors plane without first tilting moving. I would thought main difference quadcopters tricoptors would kinematic calculations would complex. Another answer explained: get pure yaw following way: North South motors rotating speed collectively higher (or lower) speed East West Motors also speed. This explains works quadcopter, doesn't explain won't work tricopter. Is simply fact asymmetry means can't imbalance torque effects provide yaw movement still keeping thrusts balanced keep pitch roll constant?",design quadcopter uav
1564,Roslaunch include file remotely,"I trying launch file remote computer I could success. Actually I connect remote computer I think problem including file remote computer. In words, I looking machine tag include. Here code:",ros
1567,H-bridges stall current,"For DC motor stall current 950 mA, H-bridge's current rating be? What happen use H-bridge L293D whose max. output current 600 mA?",motor electronics h-bridge
1570,Accelerometer bias removal,"I found good explanation remove accelerometer bias (when flat table one axis show values, two 0). I've calculated S B factors (page 3): Record $B_x^{0g}$, $B_y^{0g}$, $B_z^{0g}$, $S_{xx}$, $S_{yy}$, $S_{zz}$ EEPROM flash memory use values subsequent calculations acceleration get corrected outputs. I don't know incorporate final calculation accelerations. I guess bias substracted sensor reading. What sensitivities (S)?",accelerometer calibration errors
1571,How raise/drop spider,"For Halloween, I'd like build spider drops ceiling detects motion, rewinds back scare next kids. I already lightweight foamish spider Hobby Lobby I'd like use, I need help adding smarts scare kids. Ideally it'd able detect tall/far away kid drop custom height time, I'd settle standard dropping height that's much. I even idea motion sensor shoot Silly String webs front people. I technical background, I'm total n00b comes robotics, ideas components considerations I'd need would greatly appreciated!",motor rcservo
1579,Accelerometer calibration - get cross-axis sensitivities,"I've already asked related question (accelerometer bias removal) robotics got bit better results corrected accelerometer output. To get even better results I found calibration equations (7th & 8th paragraph) Vectornav bit enhanced solution linked question: However, six variables needed: Sensitivity sensor X-axis Y-axis inputs ($M_{xy}$) Sensitivity sensor X-axis Z-axis inputs ($M_{xz}$) Sensitivity sensor Y-axis X-axis inputs ($M_{yx}$) Sensitivity sensor Y-axis Z-axis inputs ($M_{yz}$) Sensitivity sensor Z-axis X-axis inputs ($M_{zx}$) Sensitivity sensor Z-axis Y-axis inputs ($M_{zy}$) Below also stated: IEEE-STD-1293-1998 [...] provides detailed test procedure determining calibration parameters However, searching 1293-1998 standard (especially page 201 Google Docs) I didn't find clue calculate $M$ values. Also, $B_{d}$ $V_x$ values Vectornav equations explained anywhere. Can someone point further?",sensors accelerometer calibration errors
1581,Choosing motor battery robot,"I project requires robot move around room flat surface (concrete floor). The robot must carry laptop. I estimated total weight would 6-7kg (including motors, battery, laptop, motor controller board mics items). I would like move speed Roomba moves. The robot two motors castor. I tried calculation determine type motor use, I'm confused. Can someone advise type motor type battery (Lipo/SLA) use?",motor wheeled-robot battery
1582,Interference 900 MHz video transmitter 2.4 GHz control radio,"I'm starting attempt fly FPV quadrotor. I using FrSky D8R-II 2.4 GHz frequency hopping diversity receiver (two antennas) control recently added no-name 910 MHz 1.5 watt analog video transmitter FPV flying: When video transmitter powered up, control range drops 1.5km 50m. I'm surprised 910 MHz video channel affects 2.4 GHz control channel way. Is sort interference expected? Is transmitter low quality? What changes recommended — I switch UHF control radio? Or different frequency (eg 5.8 GHz?) video radio? Or try moving inches (they already 5in apart)?",multi-rotor
1584,How deal sonar crosstalk,"Our robot circular array 12 sonar sensors looks like this: The sonar sensors pretty good. We use low-pass filter deal noise, readings seem pretty accurate. However, robot comes across flat surface like wall, something weird happens. The sonars don't show readings would indicate wall, instead, appears like curved surface. The plot made robot facing wall. See curve blue lines, compared straight red line. The red line produced using camera detect wall, blue lines show filtered sonar readings. We believe error due crosstalk, one sonar sensor's pulse bounces wall angle received another sensor. This systematic error, can't really deal like would noise. Are solutions correct it?",sonar sensor-error
1589,existence probability object fusion,"I want compute existence probability object sensor fusion high level (having sensor list objects already filtered e.g. Kalman Filter). There formulae: $$LR(G)_{old} = \frac{p(Ex_{out})_{old}}{1 - p(Ex_{out})_{old}}$$ $$\alpha = \frac{p(Ex_{in})_{old}}{p(Ex_{in})_{old}*(1 - p(Ex_{in})_{new})}$$ $$LR(G)_{new} = LR(G)_{old} * \alpha$$ $$p(Ex_{out})_{new} = \frac{LR(G)_{new}}{1 + LR(G)_{new}}$$ Where $p(Ex)$ probability existence $LR$ Likelihood Ratio. The idea $p(Ex)_{in}$ probability existence local object, fused global $p(Ex_{out})$, probability influences global one. $old$ would mean values previous cycle. How condition computation avoid situations dividing zero, obtaining , Inf? Also, $p(Ex_{in})_{new}$ almost 1, $\alpha$ huge, increasing output, increasing enormously later cycle, object live forever. How prevent it?",sensors kalman-filter sensor-fusion
1590,"What name transfer function, GH","What name transfer function, GH, simple feedback control system like $$y=\frac{G}{1+GH}u$$ What call G? What (G/(1+GH))? I confused fact ""open-loop transfer function"" ""Loop transfer function"" used mean GH different people. Which academically correct widely accepted? There several terms: ""closed-loop transfer function"" ""open-loop transfer function"" ""overall transfer function"" ""Loop transfer function"" ""loop gain"" ""loop ratio"" Thanks",control
1595,measuring gears servo motors,"I'm quite new mechanical engineering familiar gears motors. A days ago, I bought second-hand GWS servo motor project, didn't include gears. Can someone help understand correct measurement motor I buy correct gear fit servo motor. Specifically, measurement gear hole:",rcservo
1598,Making robotic arm draw circle,"I software engineering student don't know much hardware. I recently started project AI course. The project playing 3x3 tic-tac-toe game computer human. In tic-tac-toe board, suppose play first put cross mark certain place.(in tic-tac-toe board position (3,1)). Now computer take picture webcam analyse picture help Opencv(It open source c++ library image processing. details opencv.org). After finding position cross mark find optimal position help algorithm put circle. For output speak position. Now, I want make robotic hand draw circle output. Would anybody please help find hardware materials needed make robotic hand? It helpful anybody suggest tutorials. I Googled found many many suggestions, I confused choose.",robotic-arm
1602,How design differential steering mechanism?,"I want give robot differential mechanism system turning steering. Considering case turning right-angled corner, robot achieve following gradual circular arc intersection maintaining steady speed. To accomplish end, increase speed outer wheel slowing inner. But supposing want turn within definite radius, calculate ratio 2 speeds in? Can someone give insight this? What Ive done this, although I doubts. If speed right wheel $V_r$ speed left wheel $V_l$, ratio speeds turning equal ratio circumferences corresponding quadrants. Therefore $$V_r :V_l =\frac{r+A}{r}$$ Is right? I sinister feeling Im missing something out..",kinematics
1603,How implement Wavefront algorithm,"I thinking creating robot navigate using map. It controlled PC. An 8-bit controller performs low level tasks PC image processing. I plan implement single room robot placed robot environment tracked camera height ceiling room. First, robot needs mapped, like To do: Track robot height using camera Following wavefont algorithim locate robot obstacles. Procedure:(just idea) The camera give image robot surrounded obstacles random places. using opencv technique draw grind image. Locating grid contain robot(by colored symbol robot) locating grids containing obstacle. Now grids obstacle thought wall remaining free space robot navigate. robot going get goal place reached given pc(may like point place reach image mouse click). Unknowns : Mapping room locating robot How that? The robot know map image. We cannot believe camera enough locate robot. So I thought adding triangulation mapping like placing two IRs room receiver robot. The doubt I IR receiver know direction receiving IR signal (from left right ). I think knows receives IR direction. Then triangulation going happen I don't know angle direction? coming image processing, I implement Wavefront algorithm(that capture live vedio draw grids find robot obstacles)? I HC-05 Bluetooth module, Arduino, Bluetooth dongle, chassis dc motors driver, dc supply.",algorithm mapping
1607,Do servos stop limits automatically?,I'm moving controlling robot arm basic time based motors controlled using raspberry pi python advanced robotic arm servos (e.g HS-425BB). With time based motors I must constantly keep track arms position (guess work) make sure doesn't turn. Do servos automatically stop give position outside boundaries rather grinding gears?,rcservo
1610,"How make motion sensor circuit, communicate LAN?","I'm newbie Electronics/ Robotics, I love hobby. So I want build circuit (a really small size would much better) motion sensor communicate data (Basically sense motion send signal) computer Wifi. Is something possible? If I it, may schematics diagram, someway start project would grate help. Thank you!!",sensors wifi communication circuit
1613,Motor driver selection,I building 2 wheel robot carry 7KG load. I used link get torque required motor 11Kg-cm. So I choose 2 motor 36Kg-cm(2x more) torque. I noticed stall current 14A. Can I use Adafruit Motor Shield Arduino rated 3A peak current capability? If current rating driver look into? Thanks!!,motor driver current
1614,ArduIMU noisy output Quadrotor,"We using ArduIMU (V3) Quadrotor's inertial measurement unit. (we separate board control motors, ArduIMU itself). Now problem ArduIMU's sensors output. When put quadrotor steady ground motors on, instead getting 0 degree roll pitch noisy output something like image below( -6 6 degree error ): delta_t = 0.2s We sure isn't mechanical problem, checked mechanical joints everything. I mention motors everything going well. Also checked vibrate device slowly yaw axis axis, still shows noisy output. We using DCM filter inside ArduIMU, also tested Kalman filter difference. We also tested FRI low-pass filter, results good 3 seconds delay output. We also checked separate ArduImu's power circuit, still difference. What's problem ArduIMU get rid noisy output ? Update: We think problem PID controller noises ... Is true assumption ? We can't tune PID parameters ( using Ziegler–Nichols method ) noisy data. We tested Ziegler–Nichols method low rate noises successfully tuned PID noise appears unable tune PIDs. Is anyway us tuning PID situation ? Is problem noises PID get rid ?",arduino quadcopter noise ardupilot
1615,Why Humans single audio crowd? What would take robot same?,"I Robotics conference earlier today one speakers mentioned robots able function well crowd can't single audio like person can. Why people single audio well? And would take robot same? I'm aware Active Noise Reduction (ANR) like Bose Aviation headset, I'm talking about. I thinking ability take everything process feel important.",artificial-intelligence
1618,Beaglebone Black power draw,"What minimum amount power beaglebone needs start up? This would peripherals attached besides host usb. The getting started guide claims run computer's usb power, makes mention many amps actually needed. I saw mention older kernels limiting current draw .5 amps working usb, although I could find. Could one start BeagleBone Black .3 amps? If not, many?",microcontroller
1622,How I motorize elbow socket joints powered exo-skeleton?,"How would motorize joints Iron Man suit? You need something fairly shallow, I would think, probably dual servos sitting either side elbow knee joint either side hips, get motorized action without dramatically adding thickness joint? Bicycle-style chain drives wouldn't work, I would think, since length chain would need vary depending position you're least lot joints. How would motorize joints?",design mechanism
1627,Why quadcopters use brushless motors,"I've thinking starting quadcopter project, maybe building scratch. One main barriers-to-entry motors: seems like quadcopters use brushless motors. I experience DC motors using PWM signals regulate speed, experience brushless motors. As I understand it, brushless motors expensive typical DC motor I would use land robot, also require electronic speed controllers (ESCs), seem make (from perspective) even expensive complicated use. So, question: brushless motors make useful quadcopter? Is torque, less weight, something efficiency? And would significantly harder (or even possible) achieve lift using DC motors instead?",quadcopter brushless-motor
1630,Controlling conveyor belt time based motor,"I crude time based motors taken robot arm upgraded proper servos. I want able power conveyor belt one I wondering I would go following setup: A ball drops hole onto conveyer belt hitting lever switch way through. This switch triggers motor start. When ball gets top belt falls hits another lever switch turns motor off. I could handle logic hooking raspberry pi using python start stop motor depending GPIO pin received input (top bottom lever). Or I could use single lever set constant time interval stop motor. I would prefer use handle change scale/construction. I wondering however could done breadboard alone, using logic gates similar?",motor raspberry-pi
1633,How I get data kinect?,"Whenever I try using , works normally, however, I try viewing image using kinect's rgb depth camera, even recording simple bagfile data kinect, I unable see picture rosbag record data, seconds running image_view rosbag record, I got error: terminate called throwing instance 'openni_wrapper::OpenNIException' what(): virtual void openni_wrapper::OpenNIDevice::startImageStream() @ /tmp/buildd/ros-groovy-openni-camera-1.8.8-0precise-20130418-2203/src/openni_device.cpp @ 224 : starting image stream failed. Reason: Xiron OS got event timeout! [camera_nodelet_manager-2] process died [pid 3788, exit code -6, cmd /opt/ros/groovy/lib/nodelet/nodelet manager __name:=camera_nodelet_manager __log:=/home/rosbotics/.ros/log/16b63744-e043-11e2-ac16-080027486aa8/camera_nodelet_manager-2.log]. log file: /home/rosbotics/.ros/log/16b63744-e043-11e2-ac16-080027486aa8/camera_nodelet_manager-2*.log After searching around trying various fixes, I figured might problem openni started using freenect, however I encountered problems, I could record data using bagfiles see images kinect (using rviz image_view) Then someone asked use something completely unrelated, freenect-glview, however gave black screen. lsusb shows 3 parts kinect connected I've able control kinect's motor ubuntu I know least connection established both. Additional Info: I run ROS Ubuntu using VirtualBox V.4.2.14 Windows 7 USB 2 ports I using ubuntu 12.04 ROS-Groovy (all date) I've exact errors Mac OSX Lion When I try using Rviz kinect, VirtualBox crashes together I would appreciate anyone's help matter.",ros kinect
1634,How control velocity ratio turning angle θ?,Im designing differential steering mechanism robot. Supposing robot going straight line I want change direction certain angle( $θ$ diagram). What velocity ratio 2 wheels gradually turns starts moving along line $θ$ degrees initial line movement? If there's ambiguity question please take look earlier question similar. How design differential steering mechanism?,kinematics
1637,Paper work I make Line follower Robot,"I graduate student trying make Line follower Robot minor assessment, I've hardware parts data-sheets me, I've attended workshops Robotics studied lot Line follower robot. I good knowledge C Programming Embedded systems, problem I've limited amount time(2 days). Please help suggest good paper work Project - Line follower robot, I start ? I getting confused I start Programming I first circuit simulations I know It better approach use directly hardware. Please suggest fine Paper work links/videos I make Robotics projects fast. Any help would really appreciated, Thanks.",mobile-robot
1638,WHY operating torque specifications steppers?,"I looking online while, I cannot seem find steppers without torque ratings. (Operating torque, holding torque.) I even looked hobby sites usually ratings, including Adafruit Sparkfun. I found one ever said operating torque, however, didn't seem reputable didn't holding torque, might likely it's mistake. I might contact ask. Am I missing something? Can I calculate run certain factors? (How long step, etc.) The reason I say I found tutorial saying much torque (didn't specify kind, I kinda assume isn't holding) need CNC machine (what I'm building). Equation (From site): Also page: By way, talking torque continual turning motion, holding position. That seems like operating torque, makes confusing sell steppers list holding. What I missing?",stepper-motor cnc
1642,How speed robotic arm?,I need robotic arm ring desk bell. I one maplins site usb robotic arm. It seem slow. What I hack boost downwards upwards speed. I need hit bell tip/platform quickly twice. This purely LOL project work. Ever time get order want arm ring bell. :) -EDIT This gearbox assembly - And much much slow - What change speed one gearbox least 4 times? The grabber gearbox different though. The gear marker P7 white seems move grabbers faster speed.,robotic-arm
1644,What rotor torque?,"On stepper's datasheet, category ""rotor torque"" (labeled N-CM). What mean? Is torque supply turning? (Hopefully)",torque stepper-motor
1649,How I manipulate real-time sonar data Arducopter Arduino?,"I APM 3DR Quad 3DR radio telemetry kit. I would like send real-time sonar data laptop (running Windows 7) order manipulate additional Arduino Sketch. The sonar sensor connected Analog In channel Arduino. That data processed altitude calculations, I would like send altitude data sort ground station computer use telemetry kit (2 3DR Radios: 1 quadcopter 1 computer). I quite sure go task. Is way I modify source code (GCS.h GCS_Mavlink.pde) conjunction Mission Planner Mav 1.0 ground station this? Or would I need write python module accomplish this?",quadcopter python sonar
1653,Calculate position differential drive robot,"How calculate update position differential drive robot incremental sensors? There one incremental sensor attatched two differential wheels. Both sensors determine distance $\Delta left$ resp. $\Delta right$ wheel rolled known time $\Delta t$. First, let's assume center wheels marks position robot. In case, one could calculate position as: $$ x = \frac{x_{left}+x_{right}}{2} \\ = \frac{y_{left}+y_{right}}{2} $$ ""Deriving"" equations assumption wheels rolled straight line (which approximately correct small distances) I get: $$ \frac{\Delta x}{\Delta t} = \frac{1}{2}\left( \frac{\Delta left}{\Delta t} + \frac{\Delta right}{\Delta t}\right)cos(\theta) \\ \frac{\Delta y}{\Delta t} = \frac{1}{2}\left( \frac{\Delta left}{\Delta t} + \frac{\Delta right}{\Delta t}\right)sin(\theta) $$ Where $\theta$ angle orientation robot. For change angle I found equation $$ \frac{\Delta \theta}{\Delta t} = \frac{1}{w} \left( \frac{\Delta left}{\Delta t} - \frac{\Delta right}{\Delta t}\right) $$ Where $w$ distance wheels. Because $\Delta x$ $\Delta y$ depend $\theta$, I wonder whether I first calculate new $\theta$ adding $\Delta \theta$ I rather use ""old"" $\theta$ ? Is reason use one other? Then, let's assume center wheels mark position robot. Instead I want use point marks geometric center robot's bounding box. Then $x$ $y$ change to: $$ x = \frac{x_{left}+x_{right}}{2} + l\, cos(\theta)\\ = \frac{y_{left}+y_{right}}{2} + l\, sin(\theta) $$ ""Deriving"" first gives: $$ \frac{\Delta x}{\Delta t} = \frac{1}{2}\left( \frac{\Delta left}{\Delta t} + \frac{\Delta right}{\Delta t}\right)cos(\theta) - l\,sin(\theta)\,\frac{\Delta \theta}{\Delta t} $$ Now dependance $\Delta \theta$. Is reason use ""new"" $\theta$ ? Is better method simulatenous update position orientation? May using complex numbers (same approach quaternions 3D?) homogeneous coordinates?",mobile-robot kinematics motion two-wheeled forward-kinematics
1654,What difference Robot Machine?,"What difference Robot Machine? At point machine begin called robot? Is certain level complexity? Is software etc?. For instance: A desktop printer mechanics, electronics firmware considered robot (or it). A Roomba stuff call robot. So difference. I always believed robot robot takes input it's environment uses make decisions affect it's environment; i.e. robot feedback loop.",industrial-robot
1658,Implementing Slip Compensation Half-Size Micromouse,"I would like know solutions implement slip compensation Half-Size Micromouse conventional method. I spoken Japanese competitors, told solution problem creating table predetermined values using values increase decrease turn/after turn distances. The values used determined Mouse's intelligence. Due fact method many limitations, I would like hear suggestions people familiar matter.",micromouse
1660,How protect milk homemade vending machine?,"I working homemade vending machine project serves milk cookies, using arduino basic servos stuff. The problem is: I really clue protect milk last long, even know milk still ok drink.. All I really know air bad milk (and cookies), I came with: Two solenoids activates time, allow air in, milk out. All inside ""slightly"" colder place. I'm sure design might sound stupid you, I need help please, think design work ? (Would solenoid top make difference protect milk?) How improve make milk last long possible ? I'v heard big guys making machines keep milk fresh weeks even months, i'm probably sure milk won't stand couple hours.. Any idea information, link, clue would greatly appreciated. Thank you.",arduino
1666,classify two adjacent surfaces belong object,"I box (cuboid) lying floor table. So 6 surfaces box 1 surface floor. If I take pair surface surfaces ""adjacent"" other, I get two kind pairings: 1) two surfaces box: surface normals surfaces diverge other. 2) 1 surface box + surface floor : surface normals converge intersect angle 90 degrees. ( 8o 100 degrees, want add tolerance). I want distinguish two cases representing function? What function distinguish two situations? In cases, normalized dot product surface normals 0, since angle b/w 90 degrees. So right solution...",kinect computer-vision machine-learning
1670,"Moldable rubber ""feet""","I’m trying inject kind rubber around aluminum strut form “feet” robot. I’ve already milled mold, I’m trouble finding inexpensive readily available rubber compound cure without exposure air. Ideally cure consistency silicone O-ring. I’ve tried silicone gasket-maker (the automotive stuff), however week later hasn’t cured mold, exposure air. Is anything similar consistency silicone, doesn’t require air cure? Or way get I’m currently using set without waiting millennium? There aren’t real mechanical requirements, I’m trying clean look robot prevent legs scratching table.",cnc
1676,funny behaviour - dc motor control,"I'm trying control speed motor, motor driver pic16f690. pwm program Starting 50% duty cycle motor doesn't run. But moving say, 80% 50% (i.e. program PIC 80% duty cycle, re-program 50%), motor run 50% (of course lower speed). I consider funny. Anyone explain this? motor powered 5V.",motor
1678,Smooth servo movement crawling robot,"I made small crawler robot little ago two legs two degrees freedom each, 4 RC servos total. While I programming movement legs I noticed moved rather stiffly. It makes sense RC servo's internal controller would quick response position commands, I wanted crawler move way seems little smooth life-like. My solution create cubic function time describes path servos, set position small time increments, resulting smooth motion. Essentially I solve $a_i$ coefficients cubic equation using time interval, starting ending position servo, starting ending rates servo move (which derivative position): Solve $a_0$, $a_1$, $a_2$, $a_3$: $$ position(t) = a_0 + a_1t + a_2t^2 + a_3t^3 $$ $$ rate(t) = position'(t) = a_1 + 2a_2t + 3a_3t^2 $$ Given: $position(0)$, $position(t_f)$, $rate(0)$, $rate(t_f)$ I set rate servo pair movements zero movements opposite directions, positive negative movements positive negative direction, respectively. This worked pretty well, solution limited ways. For one, it's difficult decide exactly rates movements go direction be. I used average slopes ahead behind particular position movements, isn't clear optimal. Second all, cubic curves could take servo position outside range positions beginning end movement, may undesirable. For example, point time interval, curve could cause servo go beyond second position, first position. Thirdly, curve generation consider maximum rate servo turn, curve may servo move speed unrealistic. With that, minor concern maximum turning rate depends response servo's internal controller, may change depending size position interval. Neglecting last concern, issues may solved increasing degree polynomial adding constraints solve coefficients, I'm starting wonder... Is better way make servo movement smooth seem life-like?",servos kinematics
1680,Management asynchronous commands,"I working robotics project C++ (drawing signs board), CRS CataLyst5 arm. I faced problem: I many methods move different directions, goToLocalizations, etc, problem I run many main without Sleep() function function run properly. I think first one needs time (the time robot movement) I put Sleep(10000) (I guessed 10 seconds enough movement) ok. This ineffective slow solution. Would like give solutions avoid use Sleep ?",activerobot
1682,Does vehicle defferential gear still move straight?,"I concept phase driving robot. The two wheels front axle powered, rear dragged along. The rear also responsible steering noting question. Since robot required make relatively sharp turns high speed. Therefore I two options compensate different speeds sides. On one hand, differential gear front axle could used. It would powered one motor then. On hand, I could simply use two motors directly powering front wheel. This way I could simulate differentiation software. I'd like go first approach, using hardware differential. But I one concern it. Would robot vehicle differential gear still move straight, without explicit steering applied? My imagination that, wheels solidly connected, robot would move random curves I'd compensate lot steering then. I know real cars, differential gears standard work, I talking small robot measuring 6 inches.",motor wheeled-robot motion wheel
1684,Wind force impact torque mechanical arm,"I've got arm attached shaft. The arms dimensions 40x5 inches arm weights 10 lbs. If I wind acting side arm, would I translate wind force torque shaft? To give information, I'm rotating arm using stepper motor, I would like know size motor depending environmental conditions. What formula look like order arrive required oz-in torque given requirements being: I need able accelerate arm 0 12 rpm 1.5 seconds The wind speed high 30 mph Using formula P = .00256 x 30^2 find wind pressure per square foot 2.304 Using formula F = A x P x Cd calculating force, I get 1.389 x 2.304 x 2 = 6.4 So I know wind force arm 6.4 lbs. But I translate torque arm? Source:",force torque
1687,Can GPS modules work inside plastic enclosures?,"I'm going embarking autonomous robot project I going using GPS navigate waypoints (I'm aware margin error comes localization GPD I live lovely area many open fields). I going use Adafruit's Ultimate GPS Breakout board RaspberryPi, I wondering I protect mount GPS protect elements. Do GPS units need face unobstructed (ex. wood plastic) order work? If so, I still protect GPS unit outdoors?",gps protection coverage
1693,Do 6 motors require 6 individually-assigned batteries?,"For Dagu Wild Thumper 6 Wheeled platform, multiple motor system, I really need 1 battery motor? Or I buy 2 either side platform. In addition, larger motors like ones platform, I deal power generated coasting motor? I want jump deep end robotics, I already hold programming skills, I realize platform magnitude may difficult endeavor. Recommended motor voltage 2 – 7.5 Volts, one use two 22 Volt batteries left right side, six 7.5 volt batteries?",motor battery
1695,"Help PID ""units"" quadcopter control system","I'm process writing simple quadcopter controller experimental use, I'm trouble getting head around convert degrees PID controller demands appropriate 1k-2k range PWM output. For example, take roll axis '+' configured 'copter (pseudo-code): How I take roll demanded PID controller convert value useful motors, say, rollPWM come from? My first instinct use simple linear relationship, i.e.: rollPWM = scaleToRange(demandedRoll, MinValue=receiver.throttle/2, MaxValue=2000-receiver.throttle); //don't let go beyond 50% throttle low end, ESC's max high end. However seems far simplistic work. Or I calculations everything goes PID control? Any help would great.",pid motion multi-rotor
1697,MPU-6050 + Arduino nano - Logic converter not?,"I bought MPU-6050: link According manufacture site, sensor logic level 3.3V (though ebay page says ) Should I use 4 channel Bi-Directional Logic Level Converter (like one) SDA, SCL, INT channels? I connect directly arduino nano? I saw places says I use logic level converter say it's ok without it. (I guess depends sensor board, please take look, link above) Current Setup: SDA <-> LLC <-> A4 SCL <-> LLC <-> A5 INT <-> LLC <-> D2 VCC <- LLC <- 5V (arduino) GND <- LLC <- GND (arduino) I still don't parts I can't test it, I'm probably going use Jeff Rowberg library communicate sensor (I2C)",arduino sensors quadcopter logic-control
1707,Build WiFi IP camera webcam,I USB webcam WiFi module convert Serial data WiFi vice versa. The question I simply convert data coming webcam serial USB Serial IC (like FT232R ) hand WiFi Module? Update: The WiFi module DataSheet,cameras wifi usb
1711,Approach using PID get differential robot driving straight,"Consider differential drive robot two motorized wheels encoder attached feedback. Supposed function DC motor takes float -1 1 sets PWM signals provide proportional amount power motor. Unfortunately, motors created equal, sending motor PWM signal makes robot veer left right. I'm trying think drive robot straight using encoders attached motor input PID loop. Here's I would it: I would take difference left right encoders, bound error range, normalize [-1, 1], map motor powers 0 1. So I D zero, get error 1 (so left motor turned much right motor), left motor would set 0, right motor set 1 (causing hard left). Are issues this? What better approach?",pid differential-drive
1712,What difference RC motors cars helicopters?,"I working robot focus speed. At moment I looking suitable motor world help I understood difference various options. To provide background, I worked RC model components before, I think place find components needed robot, motor. I already figured much power motor needs accelerate robot desired, taking energy conversion efficiency tractional resistance account. It's 170 watts, depending final weight. To limit search further, I need decide either using RC car motor RC helicopter motor now, I don't understand difference options. Focussing brushless motors (if matters), differences RC car RC helicopter motors might need taken account choosing them?",motor brushless-motor
1717,How determine parameter Complementary Filter?,"I know Complementary Filter functions LPF HPF. But I think understanding principal behind still unclear. I quite new digital signal processing, maybe fundamental explanations help lot. Say I Complementary Filter follows: $$y =a\cdot y+(1-a)\cdot x$$ Then parameter $a$ may calculated $$a=\frac{\text{time constant}}{\text{time constant}+\text{sample period}}$$ $\text{sample period}$ simply reciprocal $\text{sampling frequency}$. The $\text{time constant}$ seems choice. My Questions: What theory behind calculation? How choose $\text{time constant}$ properly? Note: I also posted question Stack Overflow, answers likely slightly different emphasis.",gyroscope magnetometer
1724,Off-the-shelf micro fluid dispenser,"Need way dispense micro liter amounts water (lets say 1-10ul). Only thing I've found piezoelectric dispensers >$100. Any suggestions? I build, preferably would off-the-shelf component.",electronics
1728,What effective distribution grayscale sensors robot,"I'm working robotics project, I using grayscale sensors automatically follow black line: turning 90 degrees, going round circle, passing gaps lines etc. I wondering effective way detect colours move lines, five six grayscale sensors. Thank much.",mobile-robot sensors automatic line-following
1729,How SLAM algorithms handle changing environment?,"I'm groundwork project, I question current state SLAM techniques. When SLAM-equipped device detects object, object's position stored. If look point cloud device generating, you'll see points object, models generated include geometry here. If object placed previously-empty space, detected, points added. Subsequent models feature geometry describing new object. How device react object removed? As far I've seen, SLAM systems tend leave points place, resulting ""ghost"" geometry. There algorithms disregard lone points caused transient contacts, objects remained long enough build solid model remain device's memory. Are systems capable detecting previously-occupied space empty?",slam
1730,How correctly compute direct kinematics delta robot?,"I'm trying put together simple simulation delta robot I'd like use forward kinematics (direct kinematics) compute end effector's position space passing 3 angles. I've started Trossen Robotics Forum Delta Robot Tutorial I understand math, all. I'm lost last part forward kinematics, trying compute point 3 sphere's intersect. I've looked spherical coordinates general couldn't work two angles used find rotate towards (to E(x,y,z)). I see they're solving equation sphere, that's I get lost. Can someone please 'dumb down' ? Also, I've used example code quick visualization using Processing, last part seems wrong. The lower leg changes length shouldn't:",kinematics forward-kinematics
1737,H-Bridge using atmega8 microcontroller,"I want use atmega8 uC h-bridge. Can anybody give source code using C, microcontroller acts H-Bridge.",microcontroller c h-bridge avr
1743,AT command SIM900A GSM/GPRS module find originating address SMS,"I using SIM900A purpose want know number sender message comes. I unable find specific AT command related receiving message give number latest message comes. I used AT+CNMI (it corresponds notification regarding latest received message), unable find sender number. I seen AT+CMGL=<stat>[,<mode>] give string oa i.e. originating address stored string I easily parse out, I data format string. Need help suggestion somebody help possible solution.",arduino microcontroller
1745,What modelling tools available design robot,I planning build robot. 1) What free low cost robot modelling tools exist.,design
1750,Design Calculations & Mathematical Modeling Tricopters,I studying building tricopter. But I couldn't find design calculations mathematical modeling tricopter internet. What mathematical relationships equations motion forces tricopter? How I calculate requirements structural design energy requirements motors?,design
1753,Assigning Serial number GUID microcontroller,"This might league question may seems odd.I using multiple Arduino UNO boards network want assign GUID Serial number board ever send data central server, server able find Device assign name device. first way assign GUID serial number device message send central server manually programming burn hex arduino. Now way burn program always give output string (GUID+Serial number device) like program EEPROM burn main code Arduino pick GUID+Serial ID combo EEPROM write every message arduino pushing central server. Or another way asking program EEPROM different program Arduino separately like 2 files running parallel possible? Is way this?",arduino microcontroller communication
1755,"Any globally unique signature Ardupilot hardware, Arduino general?","I several APM 2.5 boards need identify based globally unique hardware signature change programming. Arduinos atmel AVR chips general (also thread) accessible serial number. However, seems Ardupilot many integrated sensors ICs one must something unique I use ( see schematic )! I checking datasheets MPU-6000, HMC5883L-TR MS5611, meantime, someone already figured one out, please answer.",arduino ardupilot
1757,Laser / photosensor pair similar,"I'm looking laser / photosensor pair (or product similar function) detecting beam interrupted (no 3ft apart, probably like 1ft). I'd like run 5V, since I'm using Arduino. My main requirement, however, parts nice housings, ideally mounting screw holes something along lines. This going project sturdiness durability important. I don't know search parts like I looking for. Could please point either good product sources, give better keywords searching, link directly potentially useful products?",arduino sensors
1758,Polling Timer interrupt?,"We hope build simple line follower robot got problem discussing PIC programming. We planed write endless loop, check sensor panel reading relevant stuff reading. But one friends told us use timer interrupt generate interrupts definite time periods interrupt check sensor panel reading relevant stuff reading. But can't figure best: endless loop main method OR timer interrupt method. What best way, why?",sensors microcontroller interrupts
1765,Place GPS antenna autonomous vehicle,"I used think higher GPS antenna position better I read following GPSd FAQ: One common error place GPS antenna high possible. This increase multipath effects due signal bounce ground water, cause GPS mistake position time signal. The correct location boat GPS antenna gunwale rail pushpit rail, close water far mast possible (to reduce signal bounce mast). If you're outside fixed location, put GPS antenna far buildings possible, ground. If you're car, don't put GPS antenna roof, put towbar similar location. If you're driving heavily built area, you're going get signal bounce buildings reduced accuracy. That's physics works. Note, however, velocity goes becomes easier convergence filters GPS spot discard delayed signal, multipath effects proportionally less important fast-moving vehicles. Does anyone experience placing GPS antenna towbar car suggested? Does give reasonable effect? My concern placing antenna reduce error much, expose device (antenna) possible mechanical damage. So, better positions apart roof towbar? Thanks",gps ugv
1766,How model unpredictable noise Kalman Filter?,"Background: I implementing simple Kalman Filter estimates heading direction robot. The robot equipped compass gyroscope. My Understanding: I thinking representing state 2D vector $(x, \dot{x})$, $x$ current heading direction $\dot{x}$ rotation rate reported gyroscope. Questions: If understanding correct, control term, $u$ filter. Is true? What I take state 1D vector $(x)$? Then $\dot{x}$becomes control term $u$? Will two methods yield different results? As know, main noise source comes compass compass distorted magnetic field. Here, I suppose Gaussian noise less significant. But magnetic distortion totally unpredictable. How model Kalman Filter? In Kalman Filter, assumption ""all noises white"" necessary? Say, noise distribution actually Laplacian distribution, I still use Kalman Filter? Or I switch another filter, like Extended Kalman Filter?",localization kalman-filter gyroscope compass
1767,What control input Kalman filter unknown?,"I implementing simple Kalman Filter estimates heading direction robot. The robot equipped compass gyroscope. Say time $t-dt$, compass reports reading $\theta_{t-dt}$, gyroscope reports reading $\omega_{t-dt}$. Then I assume time $t-dt$ $t$, rotation rate regarded constant. Thus, current heading direction $$\theta_{t}=\theta_{t-dt}+\omega_{t-dt}\cdot dt$$ As seen, $\theta$ easily time-updated. But $\omega$? The robot control. So rotation rate next moment unpredictable. How I time update case?",kalman-filter gyroscope compass
1774,"In SLAM, laser range finder produce pseudo-segments dynamic objects?","In paper, author says SLAM process, pseudo segments appear momentary pause dynamic objects laser data would make map unsatisfied. How caused? If dynamic object moved, won't laser data update eliminate segment dynamic objects?",sensors slam
1775,How control position pneumatic piston?,"How I control position pneumatic piston? The way I know using magnetic reed switch (magnetic sensor) matching piston use type control algorithm, like PID instance, keep piston sensor is. The problem gives limited control position, adds another ""state"" (open, closed, sensor position) full control. example I want 43% 70% time, without using sensor position I would like ""options"" available (I mean percentages aren't pre-defined) This example pistons I use: This good example I want:",sensors control pid movement
1776,running UWSim commands ROS,"Where I find good documentation UWSim ROS. Actually source files enough actually hard follow functions. example, I use command correctly : & rosrun UWSim gotoAbsolutePosition 0 0 0 0 0 0 I know node 'gotoAbsolutePosition' Package 'UWSim' I knwo variables, I cannot set two topics properly.",ros
1777,Tracking accelerometer gyro versus multiple accelerometers,I'm building quadcopter control systems use one accelerometer gyro. I've read papers usually accelerometer used reference ground gyro slowly drifts away time. But quadcopter crazy maneuvering force direction accelerometer point ground accelerometer data useless. As well problem centripetal force accelerometer directly centor mass. I thinking using multiple accelerometers. To fully determine position motion quadcopter one would need three accelerometers(If I done math right). This would kind solve problem centripetal force So I would like know anyone tried use multiple accelerometers better orientation estimation.,quadcopter imu accelerometer gyroscope
1782,Actuator design. plausible?,"So got idea waay back highschool kind electromagnetic analogue biological muscle. basically long stack thin electromagnets connected parallel. . current applied gaps electromagnets shrink thus providing contraction whole chain. I pretty sure work. It can't offer great contraction range (up 50% would guess) potential provide good speed compact multiple chains combined form stong fast linear actuators. The thing is, never heard type actuator used. catch? better alternative? design flaw? much heat generated making unpractical?",actuator
1787,How I send text Torobot USB device?,"I'm trying get ""Torobot"" USB servo controller work Angstrom Linux Beagle Board XM. The servo controller registers USB device. The device takes simple text commands, TTY associated it. So I'm sure send commands it. Can I send data like (assuming 002/005 device): Or I need associate generic USB device? If so, I that?",control microcontroller rcservo usb embedded-systems
1790,Motor Controller micro USB interface,I Robotics enthusiast planning make small simple four wheel car whose motors supposed controlled Android device housed inside car means micro USB port device. The car move forward backward directed signals Android device. So assumption circuit board accepts signals microUSB/USB Android device controls power electric DC motor. Also power motor supplied battery pack inside car. Could anyone suggest cheap motor driver circuit supports micro USB USB? And I get parts online? I lot research confused technical terms I familiar with.,mobile-robot motor wheeled-robot
1791,How control brushless motor?,"I consider using brushless outrunner motor, designed helicopters, driving roboter. How I control brushless motor micro controller? Of course I'll separate power source. The roboter able move forwards backwards, I need control motor way determine direction rotation, too. I think isn't related question, I need ensure high acceleration. Specially, I talking motor listed German shop.",motor control microcontroller power brushless-motor
1795,Localizing swarm robots,"I 300cm x 300cm room 25cm high ceiling (yes twenty five centimeters). It contains 50 small wheeled robots (about 20cm x 20cm). A central computer orchestrate movements robots, using wireless network send position commands them. The robots perform closed loop position control save wireless bandwidth. The robots 32-bit ARM microcontrollers. They wheel position sensors, ability accurate wheel control. Problem: The robots can't actually yet way measure position room. Question: How robots given ability measure position orientation accuracy better ±5mm? I looking accurate robust solution, affected occlusions, doesn't require high power PC robot. Whatever sensors necessary localisation easily added robots. The microcontrollers easily changed powerful ones localisation solution demands it.",localization wireless swarm
1797,How I Calibrate Analog Thumb stick?,"Outline: I'm trying work Arduino Analog thumb stick get values simple differential drive robot I'm working on. The Keyes_Sjoys Arduino Joystick Module I possession giving strange numbers. Following axises Data I have: X-axis range 0 shaky 470-520 center value 40. Y-axis range solid 4 solid 1023 center value 605. Problem I haven't used analog sensors seems pretty obvious X-axis ranges feel somewhat similar Y-axis don't. In addition, X-axis hits zero way way even coming close edge operating range. Is sensor broken (it's new), way I recalibrate potentiometer? Note, I also asked Electrical Engineering Stack Exchange.",microcontroller
1806,Gears modeling Google SketchUp SketchyPhisics,I'm trying make differential Google SketchUp using tutorial gears modeling. But I problem: gears don't collide objects (and gears). What's wrong? How fix this? How make bevel gear placed 90 degrees relative conical cylindrical gears joints? P.S. Is something like SketchUp SketchyPhisics Linux?,design mechanism 3d-printing
1808,Tiny high torque actuator/sensor design,"I need assemble small (about 8cm x 5cm x 5cm maximum), actuator much torque I get size. It driving small reel pulley (reel ~1.25cm^3, 5mm center diameter), needs respond load (eg. stop load increases beyond certain threshold). Power actuator provided via common bus line, space limit isn't limited size battery. My thought use worm drive (for torque) watch change current/voltage (for load), I'm sure mechanically sound. It seems like mechanical advantage provided worm would make hard detect change load. Plan B I could add another sensor would gauge force exerted. I'd prefer avoid adding many points failure system, I sort sensor would I use? How I approach this?",sensors control actuator
1811,Localising robot swarm non-optically,"This question Localizing swarm robots. In summary: I want create swarm robots measure position 3x2m room 25cm high ceiling, accuracy ±5mm. There good answers, optical methods. I would interested hear non-optical localisation ideas, I impose following constraints: Localisation method cannot use optical means, either visible invisible. Nothing added floor ceiling. There's appreciable gap top robots ceiling. There walls, equipment added around perimeter room. I look forward hearing creative ideas.",wireless swarm
1813,Software designing mechanical systems/robotic parts,"Which software used prototype/design robot parts (mechanical parts, body, gears, etc)> I crazy idea I would like try (quadripedal walking robot, animal-like), I'd like design mechanism test (to degree) mechanism kind simulator I start wasting money parts/materials. What tool could I use that? I'm interested mechanical design (chassis + servo/motor placement + cogs/gears), electronic design. I'm interesting robot control software, I'll probably able slap something like arduino onto program behavior I want (experienced programmer) Details (what I'd like see): Should work 3d. I.e. finished system viewable 3d. I able cut materials like plywood/metal, drill holes, place gears it, etc. It would nice kind part catalog place gear/cog I wouldn't need design scratch. It would nice I could test parts actually move. I don't need full-blown simulation, see gears turn they'll get stuck. Not interested electronic circuitry, need mechanical parts, able place servos. It would nice could produce blueprints. cheap/inexpensive, possible. Basically, I able construct robot mechanism (by placing/connecting parts like gears,cogs, motors, springs), kind clock, test (to degree) actually works. I know I could use blender3d that, wasn't exactly designed purpose. I also heard solidworks could used designing mechanical parts, expensive, especially one-time-project. Any recommendations?",software
1815,Roller Screw drive - axial movement instead friction,"I need equation hints solve following problem. Imagine roller screw drive. I apply torque translative move load mass M. I assume screw efficiency 90%. Now additional axial force affects mass opposite moving direction. Is force completely transformed torque (of course considering efficiency) possible, whole roller screw moving, fixed? I found papers/books/articles movable slides/loads, fixed shafts. But case motor shaft part osciallation system. I'm mechanical engineer, I'm sorry answer may trivial. I made little sketch The process force Fp pushing mass, force transformed load torque Tp acts drive torque TD. Some energy lost friction. The question is, also partial force Tp? affecting bearing therefore exciting chassis.",movement torque differential-drive
1826,Why 1000 rpm 10 rpm DC motors cost same?,"Today I going buy motor online, saw 10 rpm 1000 rpm DC motors cost same. How possible change rpm without requiring additional parts cost?",motor
1831,quadcopter parameters calculations simulink model,"I want make mathematical model quadcopter simulink. I studied quadcopter, although I new build flying robot before. I studied far I use four brushless DC motors PID speed control, two motors rotate clock wise two anti clock wise. I want make simple mathematical model. The input model xyz locations 3d space, copter always fly 0,0,0 path. So far I decided I increment coordinates step step example I want next location x=10, y=10, z=10; I increment locations input flight control block. My question I decide speed motors according x,y,z next location convert speed Yaw Pitch Roll finnally convert Yaw, Pitch Roll X,Y,Z coordinates. I need convertion formulas easily implemented simulink. Please provide help thanks",quadcopter simulator
1835,Effective motor type robotic arm?,I trying build arm 5 5 maybe 7 centimeters room rotary motor capable lifting it. The joint basically allow arm rotate single degree freedom circle perpendicular ground.The rest arm probably around 64 centimeters long weigh around minimum 9 kilograms lifts anything. What kind motor type would give best chance lifting arm quickly† reasonably accurately&ddagger;? † Raising straight 90 degrees around 1 .5 seconds maximum. &ddagger; At least centimeter end arm means probably least 300 positions motor.,motor robotic-arm
1837,Choosing platform start,"I'd like start robotics, unfortunately I know little HW engineering. Moreover I used use languages Python, C# Java, much experience C. Still I want much able program robot, I big interest Computer Vision AI. Are platforms/kits buy, little time spent already program them, preferably high-order languages? I'd prefer something wheeled (something flying would also nice, may hard case first robot), camera additional sensors. Would also nice something, could help avoid obstacles, like laser distance sensor ultra-sonic sensor. Ideally I would like build robot navigate room without help operator. I'd like look SLAM time future, I need something get familiar robotics. Also probably expensive, least I sure I ready go deeper robotics. Something 300-500$ would awesome. Can somebody suggest kits/platforms/tutorials/any info?",beginner
1838,"How Yaw, Pitch Roll effect flight Quadcopter?","I simulation Quadcopter simulink. I want know Yaw, Pitch Roll effect flight Quadcopter? How different single rotor helicopter? Mainly change RPM change x,y,z coordinates Quadcopter? Is Differential Equation convert rpm yaw pitch roll? Please help.",quadcopter
1839,What frame reference used Visual Servoing?,"I'm new whole visual servoing area. I'm reading tutorial Visual Servo Control Part I: Basic Approaches"" I don't understand something fundamental - information available robot? Is 3D location tracked features current frame known? Is known desired frame? Is known both? If it's known - would best thing do? Would compute current desired 3D location orientation robot, plan optimal path accordingly, essentially knowing everything advance? Also, sense could control law (i.e translation + rotation path) optimal visual servo?",localization research visual-servoing
1844,Stabilizing quadcopter optical flow,"My quad copter balance air using data collected mpu6050. With sonar sensor, hover specific height, moves horizontal plane random direction. If put object it, ascend keep distance sonar senor object. Now want make ability hover stably. Is possible add downward-facing camera calculate speed optical flow order keep hovering point horizontal plane? Could I use forward-facing camera stabilize vertical speed?",sensors quadcopter cameras visual-servoing
1853,Digital servo shaking,need advice someone experienced something similar. I try using digital servo tried connect board tutorial servo motor shakes first ten cycles turns normally. I idea every article read controlling digital servo analog need program unboxing. Thanks idea,raspberry-pi servos
1856,Need suggestions object recognition,"I tasked creating system recognize fish pulled lake. The system able identify type species fish. Typically, I turn Arduino projects like this. However, based I've read image processing, it's sounding like Arduino doesn't processing power. Does anyone suggestions development boards cameras easily interface board? I've look option, . It seems like would nice one type thing. Has anyone used anything like this? Thanks!",arduino microcontroller raspberry-pi cameras
1857,Transducer underwater applications (passive sonar),"I'm kicking around idea building small passive sonar autonomous submarine. I've looked net parts finding good transducer converting sound underwater electrical impulse. After looking parts I got piezoelectric materials used barium titanate Lead zirconate titanate. From I've read web, materials toxic. My question is, piezoelectric materials one could build sensor scratch possess toxic qualities? Something could preferably thrown pool w/ kids give defects.",sensors
1858,Why 3-axis accelerometers seemingly left-handed coordinate system?,"Careful inspection page 35 (figure 58) ADXL345 datasheet shows gravitational loading only, chip uses left-handed coordinate system. My experiments chip confirm this. I typically use chip indicate gravity vector. So using chip, I simply negate values get right handed coordinate system. But doesn't seem right. I assume logical mathematical explanation left-handed coordinate system can't figure might be.",sensors imu accelerometer calibration
1861,question car-like robot localization based dead-reckoning,I question car-like robot localization using dead-reckoning. Given: robot position (at current time step) form $\begin{bmatrix}x & & \theta\end{bmatrix}$ (theta heading) steering angle distance traveled two time steps How I estimate position robot next time step?,mobile-robot localization
1863,May I suggestion inexpensive robotic arm?,"I want build simple application. I need 5 6 degrees freedom robotic arm. The arm must feedback, I control preciously. The arm must able handle least 5 lbs. And arm would able work 10 hours day. My budget USD$300 . Any suggestion?",robotic-arm
1864,Razor IMU Arduino interfacing,"I looking Razor IMU Sparkfun, realized example code sparkfun's website meant hooking computer (the AHRS head tracker used serial usb chip). I looked google saw nothing stories work. Is good way hook Razor IMU arduino uno (or arduino without hardware support one serial port), example code exist?",arduino imu
1874,Where I learn algorithms find examples code controlling rover?,"I programmer profession new Robotics. I studied ECE, know electronics, familiar mechanical aspects robotics. I working learning project Dagu Rover 5 platform. I trying control 4 DC motors PWM want use optical encoders feedback. I looking algorithms, example code C effectively control rover. I know control GPIO, PWM interrupts processor. I interested learning algorithm controls motors based this. For now, working manual robot, controlled up/down/left/right keys. In future, I would like add sensors, camera etc work autonomous aspects. Any pointers would helpful. For reference, I working Raspberry Pi platform control rover.",mobile-robot algorithm pwm c
1876,Depth map Raspberry Pi,Is possible get two images Raspberry Pi camera mounted remote controlled bot sent computer Wi-Fi process images computer generate depth map? All done short time robot helped locomotion without making completely autonomous.,raspberry-pi
1877,Controlling bot using video image processing,"I going start project controlling robots using hand gestures. Though I used MATLAB purpose earlier, I realized extremely slow practical real-time system. I currently planning use OpenCV purpose. I want suggestions on, OpenCV best alternative, alternatives I use OpenCV, language I go for, C, C++ Python?",real-time
1881,Should learn assembly language robotics?,"I ask since assembly language really close micro-controller hardware, micro-controller would reccomend. The bot search object I show I 'lose' object. Note, I know anything micro-controllers.",microcontroller software programming-languages
1884,Blender good robotic simulator quadcopters / swarm simulations?,"I'm interested simulating Quadcopter control Swarm co-ordinations. Was wondering Blender specifically MORSE going good enough? According limitations MORSE, states: MORSE never meant physically accurate simulator: rely state-of-the-art physics engine (Bullet), expect accurately simulate robot arm dynamics fine grasping. Other projects much better (like OpenGrasp grasping). While on-going efforts try tackle issue, consider MORSE good enough temporal accuracy time synchronization capabilities application like hybrid simulation (where robots simulated others physically operated). Was wondering anyone experience using blender types applications.",simulator
1895,Arduino simple Data-Glove. Should I go Mega Due?,"First, I'm beginner MCU/Robotic world (been working ATMega+CVavr, that's all). please bear me. I'm making prototype data glove (Like KeyGlove, much simpler), consist of: IMU sensors (MPU 9150 9DOF, reading fused built DMP) -> Reads hand position orientations Minimum 2 flex sensors -> Reads Figer flexion MCU (well, Arduino specific) The sensors plugged Arduino reading filtered (e.g Low pass, Kalmann) Arduino transferred serial PC. The PC translates data virtual gripper move object (VR) Initially I planned use UNO + Pansenti’s MPU9150 Library code, I realised flash memory size left would tiny (i.e MPU9150 lib code size ~29k, Uno 32k). My project still early stage, lot things expected changed added, little flash memory left. I much. I immediately looking Mega replacement (256k flash) I realised also newer Due faster processor. They cost effectively now. . My main concern robustness compatibility when: Designing HW interface Arduino (making circuits, addding shield) Code development (available library) Streaming filtering sensor readings (would 32 bit MCus helps, it's overkill?) I know question might sound localized, I believe lot projects utilize multiple sensor reading + filtering similarly also benefits discussion. I'll revise question it's needed. The main question probably Would 32 bit MCUs perform significantly better multiple sensor reading signal filtering compared 8 bit MCUs? Or case.. I go Mega Due?",arduino imu
1897,Mechanism changing gears bicycle,"I'm looking make automatically shifting bicycle senior design project (along additional features TBD). However, I come electrical/software background; mechanical one. So I need figure decent way shift gears. I thinking leaving gear system place using sort motor (servo stepper motor worm gears) pull release wire cable needed. However, I concerns this; namely amount torque needed pull wire finding something enough holding torque. Perhaps best option use trigger shifters well perhaps use solenoid. My concern (namely worm gear) it'll slow. So I would like pick brains moment. Thanks",motor automatic
1899,Making brushless servo using Hall sensors,"I'd like assemble prototype brushless servo system using RC brushless motor (heavily geared down), sensored Electronic Speed Controller RC motors, microcontroller PID control. I'd add three Hall sensors around motor, feed signals ESC microcontroller. The MCU run PID controller, output RC servo compatible PWM signal ESC. Question: Is likely work, I find ESC trying clever? I one RC car switches reverse double pulse reverse signal. (Note, reason I'm trying get working using off-the-shelf ESC, rather designing proper one development time much expensive parts cost moment).",servos brushless-motor esc
1901,Does Monte Carlo Localization need predefined map?,"So I'm reading Monte Carlo Localization, sounds like approach based using predefined map, I need make sure (because I haven't read anywhere absolutely needs predefined map). I want make 100% sure understanding correct: Does absolutely need predefined map? [maybe I need add stuff another question, goes nothing] And localization approaches don't need predefined map? So far I've read SLAM (which sounds like general approach instead specific implementation). Thanks advance!",localization slam mapping
1903,Is finished plywood comparable prototyping substitute polyoxymethylene?,"I'm working robot team, we're building robot acetal polyoxymethylene (POM) (specifically, delrin) plastic. However, we'd like prototype robot build POM, POM somewhat expensive. There several critical areas plywood would used place POM: Over sliding surfaces Around gearboxes Under weight stress We'd like take account friction coefficients, smoothness, rigidity materials deciding whether plywood valid prototype substitute. The material 1/4"" thick. What differentiates plywood acetal POM respect relevant points?",design
1904,Strafing Mecanum wheels,I part college robotics team. We participating Robocon 2014 thinking using mecanum wheels. We done research one thing id like clarify is: Does number rollers mecanum wheel effect strafing? yes how?,wheeled-robot
1909,Arduino isp bootloader burning,"In earlier versions Arduino IDE option burn bootloader using Arduino programmer. As current burn bootloader option. Was burn using Arduino isp integrated still existing one, disappear?",arduino
1910,Use computer throw small switch,"Would like product enables use computer throw small DC ON / OFF switch. Seems like stupidly simple thing do, life I can't seem find device I search online. Is device floating around I order? Or kind term I searching for? Thanks much!",control
1911,How optical encoders used platforms like Rover 5?,"I got rover 5 chassis 4 motors 4 quadrature encoders I trying utilize optical encoders. I know encoders generate pulse signals used measure speed direction motor. I want know 4 separate optical encoders add value controller rover 5 like platform. The controller normally uses PWM control speed motor. If two motors running speed encoder output same. So, controller monitor 4 encoders?",mobile-robot motor control
1918,Installing MORSE simulator Ubuntu 12.04,"I've trouble installing MORSE. I trying install Ubuntu 12.04 VirtualBox Ubuntu 13.04 (I don't need VirtualBox, I'm trying make something work). On Ubuntu 12.04 I get following errors cmake stage: On fresh VMBox Ubuntu 13.04, 'morse check' succeeds, I try ""morse create mysim"" get: adminuser@adminuser-VirtualBox:~$ morse create mysim usage: morse [-h] [-b BASE] [--name NAME] [-c] [--reverse-color] [-g GEOM] [-v] {check,edit,run} [scene] ... morse: error: argument mode: invalid choice: 'create' (choose 'check', 'edit', 'run') Any suggestions? UPDATE: I've managed install MORSE Ubuntu 12.04. Make sure Blender compiled version python (i.e python 3.2.2) MORSE compiled in. I used Blender:",simulator
1919,How manage stepper motor cables?,"I need actuate 3 4 Cnc-like Nema 23 (~1N.m torque) stepper motors, I would like cable solution connect easily motor motor driver. I yet bought anything, I searched various robotic stores ebay, yet found triple (motor, cables, driver) would ""plug play"". As stepper motors usually 4 6 cables, multiple motors, manual soldering everything would time consuming, error prone messy. Is standard way deal cables stepper motors ?",stepper-motor wiring
1924,Any ideas robot?,"I FLL (First Lego League), waiting competitions, want work robot. Anyone ideas?",sensors
1925,Performing proper coordinate system transformation,"I could use guidance regarding coordinate system transform problem. My situation this: system begins unknown location, I initialize location (x y) orientation (roll, pitch, yaw) zero. I establish frame reference point, I call ""local"" coordinate frame. It fixed world move. At system startup, body frame perfectly aligned local frame, body +x points forward, +y right +z down. The body frame fixed system, travels system moves. I estimation routine provides x position, well roll, pitch, yaw system. Yaw rotation z axis local frame. Pitch roll respect body frame (I.e.,if robot pitches up, I always get positive value. If rolls right, I get positive value.) How I take known roll pitch values transform respect local (fixed) frame?",mobile-robot kinematics
1927,DC motor direct loading,"I found many tutorials online calculators selection dc motor drive wheel, I understood torque affect driving wheel. But happen I change orientation motor load? What main criteria dc motor work I want rotate plate vertically mounted motor's shaft, motor placed vertically also (as shown picture)? I engineering student please provide answer simple possible.",motor torque
1931,Is thrift store good place get servo motor?,"I'm trying learn basic motor, servo motor. Can found thrift stores like Goodwill old toys? Are ""robotic"" quality? What toys kinds things would I scavenge? All I want get motor. After I want Arduino make ""work."" Nothing complex.",servomotor
1934,Field oriented control brushless motors,"If I controlling normal brushed motor servo, I would measure motor's position, adjust PWM signal control voltage. This way I could achieve precise velocity/position profile control good enough. When Field Oriented Control (FOC) brushless motor, two parameters I control: The voltage angle, voltage magnitude. There three things I measure, current angle magnitude, rotor position. I want achieve precise velocity/position profile including good control zero speed reverse. Question: I calculate correct voltage field angle (or phase lead) magnitude? Do I need two PID algorithms? phase_lead = CalcPID_1( ... ); voltage_mag = CalcPID_2( ... ); Assume I take reasonable measurements motor state, including rotor position winding current.",servos pid brushless-motor
1935,How open sliding window?,"I live apartment sliding windows it. The apartment naturally warm live mechanical room, either opened windows ran air conditioning winter. I want create device open close windows apartment depending temperature. The software electronics already figured out, I need figure move windows. This sample window. It takes 4 lbs force pull open, open 6 inches(since I'm 16 stories high). Ultimately, I want make cheap enough I could replicate 6 windows. My first thought linear actuator, ones I seen designed moving 100+lbs cost several hundred dollars. Pneumatic actuators cheaper, I'd run network air lines solenoids, would compressor would randomly kick in. A double winch system would complicated set prone failure. Lastly, I thinking cheap metal gear servo(dealextreme 15kg/cm servos $15.00), would somewhat difficult use series turnbuckles arms translate 6 inches linear movement. Any help would appreciated.",design actuator
1944,Arc welder 3d printing,"Has anybody experimented GMAW additive manufacturing? The thing is, welding wire much cheaper ABS PLA filaments and, well, steel printing in, flimsy plastic! I imagine arc deposition printhead would constructed similarly one used plastic filament printers, except need heating element (so, even simpler). Welding often requires fast Z speed (to finely control arc) think Delta (DeltaMaker) chassis would work best. GMAW calls sort inert gas insulate heated metal oxygen. It would make sense seal interior printer fill heavier air inert gas printing. I would highly appreciate pointers existing 3d printer designs employing deposition method well flaws design outlined here.",3d-printing
1946,What appropriate SLAM algorithm quadrotors RGB-D camera?,"I researching SLAM. I came across EKF SLAM uses odometry measure robot's initial position map well landmarks helps robot's position accurate. Based SLAM dummies, problem loop closure. In another journal, compared fastSLAM EKF big-O function $O(K^2)$ $K$ number landmarks fastSLAM $O(M\log(K))$. It also said promising SLAM algorithm journal ""The vSLAM Algorithm Navigation Natural Environments"" FastSLAM However, vSLAM used experiment done University Pennsylvania occupancy grid SLAM. I want ask would approriate SLAM algorithm vSLAM given unmanned aerial vehicle like quadrotor RGB-D camera + IMU? Also algorithm extended support co-operation?",localization slam quadcopter mapping
1947,I want stepper motor switch speed traveling (not acceleration wise),"I project I'm working I'll need speed stepper motor change set speed certain distance, I can't figure way it. I'm using arduino stepper motor, current code. What I want basically first moveTo(2500) current speed 200 2500 I want increase speed 400. After moved 5000 turns moves back position that's implemented already.",arduino control stepper-motor
1949,"In EKF-SLAM, even need odometry reliable sensor?Also, SLAM algorithms feature-based?","In book SLAM dummies, even need odometry robot would use data retrieved laser scanner accurate odometry? Why rerly laser scanner away odometry? Is contribution odometry laser scanner have? Also, SLAM algorithms feature-based?",localization slam mapping
1954,Is possible use HC-SR04 ultrasonic range sensor indicate thickness material,"The HC-SR04 directly connected Arduino board receiver end(echo) connected analog pin 2 transmitter (trigger) connected digital pin 4. I wondering I use sensor sense change saturation object block path. The receiver transmitter positioned like The line middle supposed paper. I'll using see difference one paper two paper travel trough two. Now I'm sure possible way I see working kind similar IR LED Arduino program connected LED, one paper passes trough light gets little bit weaker two takes heavier hit. Is possible?",arduino sensors
1955,Choosing path planning obstacle avoidance algorithm 2D space,"I working 2D space robot needs follow trajectory avoiding obstacles. I've read recently methods path planning ""Vector Field Histogram"" ""Dynamic window approach"". Is worth use kind algorithms 2D space I go something Potential Fields Rapidly-Exploring Random Trees?",mobile-robot motion-planning
1959,Will wiring unipolar stepper bipolar stepper driver decrease holding torque?,"I read wire unipolar stepper bipolar driver, I have, ignoring two extra wires. One concern I whether connecting unipolar stepper bipolar driver cause lose torque (holding operating)? Will same? Increase? I've read bipolars bang buck energy-wise, since ""transform"" unipolar stepper bipolar good enough driver still work right, I would think might run efficiently. Is true?",torque stepper-driver stepper-motor
1965,What telemetry used for?,I'm pretty new world UAS ten year holiday RC flying. I'm looking Ardupilot wondering purpose telemetry serves? Is get flight data back ground station also used program system flight? Are capabilities I missing?,uav ardupilot
1966,Public training data vehicle detectors computer vision?,"This question anyone familiar object (specifically vehicle) detection research. I'm new computer vision confused training object detection classifiers. Specifically, objective vehicle detection. I've reading vehicle detection literature weeks now, I'm still bit confused. What I'm confused evaluation. For evaluation system, research community usually benchmarked dataset used testing data. But performance system also depends much data used train it, no? So aren't training datasets there, too? That would make far uniform method comparisons. I seem keep finding papers using benchmarked datasets evaluation, making mention got training data from.",computer-vision
1974,Autonomous car steering using IR sensors,"I want steer RC car straight line.The car 4 sharp IR sensors corner car help steer corridor.The corridor irregular looks something similar picture below. The car needs stay exactly middle(shown lighter line) take help IR sensors correct path. The car servo front wheel steer another controls speed. I tried running using algorithm summed values side car took difference.THe difference fed pid control output went steer car.The greater value pid (on either sides), greater value steering angle till reaches middle. It works part walls similar distance center even oscillates lot around center fails miserably around bumps corridor. I need make changes algorithm need help steering right direction. The IR sensors finicky way filter noise make readings stable? Any help regarding changes needs implemented much appreciated. Currently car uses 4 IR sensors guide.I also use 2 ultrasonic sensors.",mobile-robot sensors
1976,"Usage Multibeam 2D Imaging Sonar AUVs, testing pool environment","I belong AUV team university. We planning Multibeam 2D Imaging Sonar (the Blueview P900) AUV detect obstacles underwater. I following questions ask feasibility testing/implementing sonars AUVs. As know multibeam sonars multiple reflections arriving different times various surfaces testing pool, recommended way filter noises image obtained sonar pings? Are sonars use/test team/organization anywhere else pool testing ocean/reservoir testing multiple reflections almost zero except reflections obstacle(s)? Also would like know recommended image processing algorithms implemented/used detect obstacles sonar images.",sonar
1978,Accelerometers error (BMA020 BMA180),"Recently I working two accelerometers: BMA020 BMA180. I try explain problem using BMA020 example less accurate therefore problem visible. When I hold Acc neutral position I get correct average result: -1G. Now I turn Acc upside time average result +0,91G. The problem occurs axis. For BMA180 problem less visible (-1G normal position +0.98G upside down). Do know accelerometer behaves like ?",accelerometer
1979,How retrieve parameters mavlink .tlog using pymavlink?,"I've able use pymavlink.mavutil read telemetry .tlog created MissionPlanner. To this, I create like this: mlog = mavutil.mavlink_connection('mylogfile.tlog') Now I want read flight parameters (settings) .tlog . The method mavlogfile.param_fetch_all() appears designed work live telemetry link rather log. It sends parameter request command, obviously result linked log rather actual aircraft. I know parameters .tlog... I get out?",python ardupilot
1981,1 cm accuracy radio rangefinder?,"I need track point space. The point less 2 away, passive, batteries, charging. I don't always line sight. I need pinpoint centimeter. I need sample frequency 10 Hz more. Can done all? Does solution exist?",sensors
1983,Can career robotics hate mechanics?,"I'm first year electronics engineering student. I love almost aspects robotics - electronics, algorithms, control theory etc. I can't stand mechanical aspect robotics though. Can I fulfilling career Robotics I hate mechanics love parts robotics? I'm ready learn mechanics I absolutely to, would strongly prefer learn anymore absolute basics. Thanks.",software electronics mechanism
1985,SLAM without landmarks?,"First, possible build map without landmarks robot 2D? Let's say aisle surrounded two walls. The robot moves environment. Now feasible build SLAM problem? Or landmarks must available so?",mobile-robot slam
1991,Are time-of-flight cameras like swissranger affected outdoor fog?,"I'm looking build outdoor robot I need know time-of-flight cameras like SwissRanger™ SR4500 work fog, anybody experiences that?",mobile-robot cameras
1992,Jacobian observation model?,"The state vector $$ \textbf{X} = \begin{bmatrix} x \\ \\ v_{x} \\ v_{y} \end{bmatrix}$$ transition function $$ \textbf{X}_{k} = f(\textbf{X}_{k-1}, \Delta t) = \begin{cases} x_{k-1} + v_{xk} \Delta \\ y_{k-1} + v_{yk} \Delta \end{cases} $$ $z_{b} = atan2(y, x)$ $z_{r} = \sqrt{ x^{2} + y^{2}}$ Jacobian observation model: $$ \frac{\partial h}{\partial x} = \begin{bmatrix} \frac{-y}{x^{2}+y^{2}} & \frac{1}{x(1+(\frac{y}{x})^{2})} & 0 & 0 \\ \frac{x}{\sqrt{ x^{2} + y^{2}}} & \frac{y}{\sqrt{ x^{2} + y^{2}}} & 0 & 0 \end{bmatrix} $$ My question Jacobian observation model obtained? 2X4? model Kalman filter.",kalman-filter
1995,Pre-built PID motor controller,"I lead university robotics team needs PID controllers four drive motors two additional motors used secondary system. I would strongly prefer buy pre-built PID controllers provide reasonable interface setting PID constants, motor velocity direction, controllers remotely central difficult, interesting problems we're trying solve. To astonishment, Internet doesn't seem saturated controllers (talk reinventing wheel - hundreds tutorials almost pre-built solutions! Did Willow Garage build PID controller PR2?!). Does anyone recommendations/experience, preferably pointers controllers? I've Googled around quite bit, far best option I've found. It's cape BeagleBone Black (which board we're using). The problem Python library finished - resets PID constants every call, doesn't support changing direction motor, seems support setting motor power, velocity, gives impression it's actually using PID controller all. Additional details: The stall current drive motors 6A. They brushless DC motors quadrature encoders. The secondary motors much smaller, we're building encoders them. Our code base Python, we're running BeagleBone Black using latest Debian image Robert Nelson (that guy's awesome!). Our batteries provide 14.8V, already 3.3V 5V rails. Our robot fairly small, 1x1x2 feet, weighs 9 pounds. This info meant give perspective regard scale. $350 comfortable top range could spend get 6 motors PID-controlled. Any help would greatly appreciated!",motor pid brushless-motor
1997,Is way determine degrees freedom lost robot singularity position looking jacobian?,"For 6DoF robot revolute joints Jacobian given by: $$ \mathbf{J} = \begin{bmatrix} \hat{z_0} \times (\vec{o_6}-\vec{o_0}) & \ldots & \hat{z_5} \times (\vec{o_6}-\vec{o_5})\\ \hat{z_0} & \ldots & \hat{z_5} \end{bmatrix} $$ $z_i$ unit z axis joint $i+1$(using DH params), $o_i$ origin coordinate frame connected joint $i+1$, $o_6$ origin end effector. The jacobian matrix relationship Cartesian velocity vector joint velocity vector: $$ \dot{\mathbf{X}}= \begin{bmatrix} \dot{x}\\ \dot{y}\\ \dot{z}\\ \dot{r_x}\\ \dot{r_y}\\ \dot{r_z} \end{bmatrix} = \mathbf{J} \begin{bmatrix} \dot{\theta_1}\\ \dot{\theta_2}\\ \dot{\theta_3}\\ \dot{\theta_4}\\ \dot{\theta_5}\\ \dot{\theta_6}\\ \end{bmatrix} = \mathbf{J}\dot{\mathbf{\Theta}} $$ Here singularity position Staubli TX90XL 6DoF robot: $$ \mathbf{J} = \begin{bmatrix} -50 & -425 & -750 & 0 & -100 & 0\\ 612.92 & 0 & 0 & 0 & 0 & 0\\ 0 & -562.92 & 0 & 0 & 0 & 0\\ 0 & 0 & 0 & 0 & 0 & 0\\ 0 & 1 & 1 & 0 & 1 & 0\\ 1 & 0 & 0 & -1 & 0 & -1 \end{bmatrix} $$ You easily see 4th row corresponding $\dot{r_x}$ zeros, exactly lost degree freedom position. However, cases straightforward. $$ \mathbf{J} = \begin{bmatrix} -50 & -324.52 & -649.52 & 0 & -86.603 & 0\\ 987.92 & 0 & 0 & 0 & 0 & 0\\ 0 & -937.92 & -375 & 0 & -50 & 0\\ 0 & 0 & 0 & 0.5 & 0 & 0.5\\ 0 & 1 & 1 & 0 & 1 & 0\\ 1 & 0 & 0 & -0.866 & 0 & -0.866 \end{bmatrix} $$ Here clearly see joint 4 joint 6 aligned 4th 6th columns same. But it's clear Cartesian degree freedom lost (it rotation end effector's x axis red). Even less straightforward singularities workspace limits. $$ \mathbf{J} = \begin{bmatrix} -50 & 650 & 325 & 0 & 0 & 0\\ 1275.8 & 0 & 0 & 50 & 0 & 0\\ 0 & -1225.8 & -662.92 & 0 & -100 & 0\\ 0 & 0 & 0 & 0.86603 & 0 & 1\\ 0 & 1 & 1 & 0 & 1 & 0\\ 1 & 0 & 0 & 0.5 & 0 & 0 \end{bmatrix} $$ In case, robot able rotate $\dot{-r_y}$ $\dot{+r_y}$. There rows full zeros, equal columns, clear linearly dependent columns/rows. Is way determine degrees freedom lost looking jacobian?",robotic-arm inverse-kinematics industrial-robot
2000,Maintaining positive-definite property covariance unscented Kalman filter update,"I unscented Kalman filter (UKF) tracks state robot. The state vector 12 variables. Each time I carry prediction step, transfer function (naturally) acts entire state. However, sensors provide measurements different parts robot's state, I may get roll, pitch, yaw respective velocities one measurement, linear velocity another. My approach handling far simply create sub-matrices covariance, carry standard UKF update equations, stick resulting values back full covariance matrix. However, updates, UKF yells trying pass matrix isn't positive-definite Cholesky Decomposition function. Clearly covariance losing positive-definite properties, I'm guessing attempts update subsets full covariance matrix. As example taken actual log file, following matrix (after UKF prediction step) positive-definite: However, processing correction one variable (in case, linear X velocity), matrix becomes: 1.1969 0 0 0 0 0 0.11567 0 0 0 0 0 0 1.9682 0 0 0 0 0 0.98395 0 0 0 0 0 0 1.9682 0 0 0 0 0 0.98395 0 0 0 0 0 0 1.9682 0 0 0 0 0 0.98395 0 0 0 0 0 0 1.9682 0 0 0 0 0 0.98395 0 0 0 0 0 0 1.9682 0 0 0 0 0 0.98395 0.11567 0 0 0 0 0 0.01 0 0 0 0 0 0 0.98395 0 0 0 0 0 1 0 0 0 0 0 0 0.98395 0 0 0 0 0 1 0 0 0 0 0 0 0.98395 0 0 0 0 0 1 0 0 0 0 0 0 0.98395 0 0 0 0 0 1 0 0 0 0 0 0 0.98395 0 0 0 0 0 1 The difference two matrices 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 -0.00468 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 As see, difference two value location variance linear X velocity, measurement I processed. This difference enough ""break"" covariance matrix. I two questions: Updating subset filter doesn't appear right way go things. Is better solution? Alternatively, I missing step would keep covariance matrix positive-definite? Thanks! EDIT: It looks like I'm properly placing values back original covariance matrix. Simply copying values back isn't sufficient. I need track correlation coefficients covariance matrix, make sure I update variance value, I update values row/column maintain correlation coefficient value. I testing verify issue, initial analysis Matlab suggests is. If I'm correct, I'll answer question. EDIT 2: Given response trying it, I see original edit idea won't fly. However, I one question: As UKF, I don't actually Jacobian matrices. I think I see I would make work within UKF update equations, even EKF - I ask I one well - state-to-measurement function $h$ going end identity matrix, I directly measuring state variables. In case, I take ""Jacobian"" would $m \times n$ matrix ones $(i, i)$ location, $i$ index measured values measurement vector?",kalman-filter
2009,EKF partial state update question,"This follow Maintaining positive-definite property covariance unscented Kalman filter update ...but it's deserving question, I think. I processing measurements EKF subset variables state. My state vector cardinality 12. I directly measuring state variables, means state-to-measurement function $h$ identity. I trying update first two variables state vector, x position robot. My Kalman update matrices currently look like this: State $x$ (just test values): $$ \left(\begin{array}{ccc} 0.4018 & 0.0760 \end{array} \right) $$ Covariance matrix $P$ (pulled log file): $$ \left(\begin{array}{ccc} 0.1015 & -0.0137 & -0.2900 & 0 & 0 & 0 & 0.0195 & 0.0233 & 0.1004 & 0 & 0 & 0 \\ -0.0137 & 0.5825 & -0.0107 & 0 & 0 & 0 & 0.0002 & -0.7626 & -0.0165 & 0 & 0 & 0 \\ -0.2900 & -0.0107 & 9.6257 & 0 & 0 & 0 & 0.0015 & 0.0778 & -2.9359 & 0 & 0 & 0 \\ 0 & 0 & 0 & 0.0100 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\ 0 & 0 & 0 & 0 & 0.0100 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\ 0 & 0 & 0 & 0 & 0 & 0.0100 & 0 & 0 & 0 & 0 & 0 & 0 \\ 0.0195 & 0.0002 & 0.0015 & 0 & 0 & 0 & 0.0100 & 0 & 0 & 0 & 0 & 0 \\ 0.0233 & -0.7626 & 0.0778 & 0 & 0 & 0 & 0 & 1.0000 & 0 & 0 & 0 & 0 \\ 0.1004 & -0.0165 & -2.9359 & 0 & 0 & 0 & 0 & 0 & 1.0000 & 0 & 0 & 0 \\ 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0.0100 & 0 & 0 \\ 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0.0100 & 0 \\ 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0.0100 \\ \end{array} \right) $$ Measurement $z$ (just test values): $$ \left(\begin{array}{ccc} 2 & 2 \end{array} \right) $$ ""Jacobean"" $J$: $$ \left(\begin{array}{ccc} 1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\ 0 & 1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\ \end{array} \right) $$ Measurement covariance $R$ (just test values): $$ \left(\begin{array}{ccc} 5 & 0 \\ 0 & 5 \\ \end{array} \right) $$ Kalman gain $K = PJ^T(JPJ^T + R)^{-1}$: $$ \left(\begin{array}{ccc} 0.0199 & -0.0024 \\ -0.0024 & 0.1043 \\ -0.0569 & -0.0021 \\ 0 & 0 \\ 0 & 0 \\ 0 & 0 \\ 0.0038 & 0.0000 \\ 0.0042 & -0.1366 \\ 0.0197 & -0.0029 \\ 0 & 0 \\ 0 & 0 \\ 0 & 0 \\ \end{array} \right) $$ $K$ 12x2, meaning innovation - therefore measurement current state - would need 2x1 order 12x1 result add current full state: $x' = x + K(z - h(x_s))$ $x_s$ vector containing parts full state vector I measuring. Here's question: $K(z - h(x_s))$ yields $$ \left(\begin{array}{ccc} 0.0272 \\ 0.1969 \\ -0.0948 \\ 0 \\ 0 \\ 0 \\ 0.0062 \\ -0.2561 \\ 0.0258 \\ 0 \\ 0 \\ 0 \\ \end{array} \right) $$ Does make sense vector, I add current state, non-zero values positions 1 2 (the x positions robot)? The non-zero locations correspond robot's z location, x, y, z velocities. It seems strange measurement x yield changes variables state vector. Am I incorrect assumption? Incidentally, covariance update works well Jacobean form, maintains positive-definite property.",kalman-filter
2011,How calculate right left speed tank-like rover?,"I trying control Rover 5 robot using Android app touch-based joystick control app UI. I want calculate speed left right motors rover joystick moved. From joystick, I get two values, pan tilt. I convert polar coordinate system theta. Where r ranges 0 100 theta 0 360. I want derive equation convert (r, theta) (left_speed, right_speed) rover. The speed values also [0;100] range. Now, I figured till now. For value r, If theta = 0 left_speed = r, right_speed = -r (turning right spot) If theta = 90 left_speed = r, right_speed = r (moving forward speed r) If theta = 180 left_speed = -r, right_speed = r (turning left spot) If theta = 270 left_speed = -r, right_speed = -r (moving backwards speed r) For values, I want moving turning simultaneously. For example, If theta = 45 left_speed = alpha*r, right_speed = beta*r (moving forward turning right) So, basically (r, theta), I set speeds as, (left_speed, right_speed) = (alpha*r, beta*r) I need formulate equation I generalize cases finding alpha beta based theta. How I this? Is existing work I refer to?",control kinematics movement
2018,Arduino Uno R3 Roboduino ATMega168 Arduino Mega 2560 R3 board better small robots,"I new robotics. May question looks like naive want know better board among Arduino Uno R3 Roboduino ATMega168 Arduino Mega 2560 R3 purpose mention - A simple robot wheels, move around. Can IR sensors camera. Is powerful enough deal computer vision computations. Arduino Mega 2560 R3 looks powerful too, I want know purpose solved two boards too? Thanks",arduino
2021,Telemetry Ardupilot 2.6,"I'm using telemetry kit 3DR robotics (433MHz) interface Ardupilot Mega 2.6, controlling quadcopter. The Mission Planner (v1.2.84) Michael Oborne works well telemetry kit, transmitting flight data (IMU, compass, GPS etc.) quadcopter GCS displaying GUI. However, I would like see data hyperterminal (windows system). The radio receiver GCS connects PC USB drive. I tried calling remote radio station using possible Baud rates, starting 110 921600 (including 57600). I've set data bits 8 stop bits 1. 'None' parity flow control. However, I ever get terminal either gibberish data all. I also tried burning software radio receiver tried using AT commands radio. It connects OK '+++', keeps returning error AT1, ATT etc. Please give idea get flight data hyperterminal. Thanks.",quadcopter ardupilot
2022,How currently evaluated computer technology influence robotics embedded systems forseeable future?,"This first question site, might little subjective :) There ongoing process many cool cyclonic changes technology electronics software industry. Concurrency Parallelism What implications GPGPU, Multi-core ""programming large"" model specific case embedded software, influence styles conventions community? Single board multicore hardware like soon released Parallela example? Programming language research The results excellent. Functional Programming supposedly started reaching masses. It late night previous weekend I briefly skimmed example functional reactive programming solve real time problems. AI people also suggesting programming robots Declarative Domain Specific languages soon. It would nice know implications robotics community. There tremendous growth frameworks like ROS Urbi too!! That region look upon.. Most robotics, embedded high performance AI codebase directly depends C/C++ , though languages like Rust D bubbling up, wouldn't take massive amount time adopt new languages, ever adaptation begins? AI Correct me, seems like lot time passed many major production results AI community. I've heard cognitive architectures old like ACT-R 4CAPS. They seem hibernation mode! There seems lot work lately otherwise intelligent systems (solved problems) like Computer vision Data mining, problems cater supercomputing industrial crowd more. Could possible shift towards low powered systems soon? Thanks",software artificial-intelligence programming-languages beginner embedded-systems
2024,Roboticize old netbook?,"I old beat-up netbook currently collecting dust. I've also taken stuff apart, without worry putting back together, please bear possibly stupid questions. a) I imagine it's possible wire baby servos, breadboards, good stuff. Am I correct? b) I'd like start simple Raspberry Pi-like projects (think automating irrigation system, feeding dog work, etc). Obviously barring energy expenditure, wouldn't netbook apt Raspberry Pi handling type thing? c) I basic Python experience, I wouldn't mind picking I go. Would sufficient? Cheers!",raspberry-pi python
2027,ROS AMCL need odometry data?,"I'm reading amcl document ROS Wiki. In subscribed topics odometry topic, why? It works laser? Subscribed Topics: (From ROS Wiki) scan (sensor_msgs/LaserScan) tf (tf/tfMessage) initialpose (geometry_msgs/PoseWithCovarianceStamped) map (nav_msgs/OccupancyGrid) And next question I use Gazebo simulator turtlebot? Any tutorial available?",slam ros navigation
2028,Is possible run multiple loops time? (Arduino),"I've got code I motor running back forth buttons connected scanner, I press buttons causes motor stop rides it. I would like run parallel codes don't interrupt other. Here code",arduino stepper-motor c
2031,"Calculate covariance matrix x,y,z data","In ROS I've recorded bag file custom robot (in real world) provide covariance matrix I want use feed EKF, covariance matrix 0. How I calculate it? Note: Covariance matrix needed EKF estimate position. It's sample /odom: pose: pose: position: x: 0.082 y: 0.507 z: 0.0 orientation: x: 0.0 y: 0.0 z: -0.789272088731 w: 0.614043622188 covariance: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0] twist: twist: linear: x: 0.104 y: 0.0 z: 0.0 angular: x: 0.0 y: 0.0 z: 0.0663225115758 covariance: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]",localization ros odometry
2032,Rocker bogie suspension stability,"From designs usually shown rocker bogie systems, whole weight platform seems supported one rod, differential bar gear. Isn't bit unstable system arms rover one end high torque rod? Is understanding rocker bogie systems correct? If so, solutions problem don't sacrificing functionality rover? To clarify, I want know rovers like curiosity designed balance heavy platform differential bar mechanism. I trying make small rocker bogie I want avoid anticipated problem.",mobile-robot design wheeled-robot
2034,Cheapest 3D printer gears?,"It would incredibly useful I could print gearing solutions, even I print gears one time. However, I know market's cheapest printers accommodate task. --The gears need 2-3 inches diameter, bear light load (much less 1 foot pound), material need strong machinable. --The tolerances need sufficient teeth mate robustly, preventing hang. Unfortunately, I sense tolerances allow gears mate properly. --(If machine precise enough print hole statically mate shaft specified dimensions due friction, excellent. If not, I probably improvise tiny shaft hole adhesive.) --Because may used close proximity pavement, melting temperature excess 100F desirable required. --Because given element interact kinetically elements also 3D printed (except metallic shaft), compatibility external resources required. I would grateful anyone could shed light issue!",wheeled-robot
2036,Making high CAN baud rates work,"I'm dealing board matter I I can't seem make CAN work 125 kbit/s. I'll give detail board bottom, I'm going keep question generic. First all, regarding hardware. From I've gathered, isn't need pull-up resistor TX CAN. Is correct? It may perhaps chip-specific, wherever I see, seems TX/RX lines directly connected transceiver. Second, regarding bit-timing: Using different calculators, example, Kvaser one Microchip, I see following configuration (for 64 kHz input clock): I've seen one source. Furthermore, numbers fit formula datasheet microcontroller. However, configuration 125 kbit/s works me. I'm using CANreal monitor messages. I've tried different configurations CAN, example 16 time quanta instead 8 well changing microcontroller's clock 16 MHz using different values. Regardless that, speeds higher 125 kbit/s result errors warnings CANreal (which taken CAN driver). Note CAN board, driver software works 1 Mbit/s hardware I have. This made harder since, soon I put probe oscillator TX line, becomes continuous 0-1 alteration like following: __------ __------ __------ __------ __------ / | / | / | / | / | / | / | / | / | / | / | / | / | / | / | | | | | | | | | | | | |_| |_| |_| |_| | Which something I would outputting software. In fact, soon I remove probe, messages start arriving (again, 125 Mbit/s). So basically, I don't seem able oscillator debugging available. Back ""first all, regarding hardware"", shape signal suggests pull-up resistor may necessary, I haven't seen need datasheet I found. Furthermore, microcontroller configures pin used CAN, I don't control making push-pull (since looks like it's open-drain). Not mention microcontroller doesn't even configuration make pin push-pull. Is hidden parameter somewhere also set? Is pull-up resistor necessary all? Why would oscillator probe cause behavior? Details board: MCU: P18F45K80. CAN connected default RB2 RB3. CAN transceiver: ISO1050 Compiler: mikroC",microcontroller can
2039,quadrotor experimental identification,"want model quadrotor using experimental method ""i built yet"" want is: turn one motor specific speed ,then plot x,y,z angles identify transfert functions plots,x/w1,y/w1,... on, don't know it's possible graphs have,so know subject maybe tried something like that, feel free add anything think might helpfull",control quadcopter brushless-motor uav
2042,Choosing correct power supply Stepper Motors,"I building machine need 2 Stepper Motor that. The motors driven using 3.3v arm device. I made following selections regarding stepper motor, stepper motor driver power supply. Power Supply 12 Volt Power Supply - 3.5 Amp Single Output Stepper Motors Stepper Motor: Unipolar/Bipolar, 200 Steps/Rev, 42×48mm, 4V, 1.2 A/Phase Stepper Motor Driver DRV8825 Stepper Motor Driver Carrier, High Current I tried best research compatibility came these. Is good selection considering fact Power Supply driving 2 motors. I running motors 1/16 step high resolution.As far speed concerned,it's going pretty slow running continuously hours end.Basically I trying make V-Plotter.As far I tell, loads start stop motion motors though.",stepper-motor power stepper-driver
2045,Questions Irobot Create,"I'm interested getting Create project I'll working on, wanted information somebody already one: How much weight safely carry? I talked Irobot's tech support told maximum 5lb, searching internet seems like limit actually strict appears be. I'm asking I'd need put 3kg laptop top it, would mean ~3.5-4kg also consider kinect eventual supports both. I guess I could use netbook send data I need another computer, I wanted avoid additional overhead wireless link. For long run using AA batteries? I'm inclined getting battery pack, since I'd using robot europe, I'd also need transformer I went battery pack option. Thanks!",mobile-robot irobot-create
2048,Encoder based speed control Rover 5,"I trying get precise control speed rover 5 based robot. It four PWM controlled motors 4 Optical Quadrature Encoders. I using 4-channel motor controller rover 5 chassis. I using arduino Nano control. I able read encoder INT output change PWM based pulse width control speed. But, result, I getting heavy oscillations control output. That makes, robot move steps, PWM changing constantly. I need algorithm minimize ringing smooth moving robot. Here arduino code snippet. Here req_speed -100 100, sign indicates direction. Please consider undefined variables globals. I experimentally measured that, motor running full speed, pulse width around 3200us. Encoders' INT outputs (XOR A B) connected A0 thru A3. Motor PWM connected D3, D5, D6, D9. Please let suggest improvements code advice I missing here.",arduino motor pwm
2053,Odd L293D behavior: Pin 16 seems act enable,"I chip labeled L293D small 'ST' logo, behave like I believe L239D should: I chip breadboard pins 4,5,12 13 connected ground rail. The positive rail gets 6V battery pack. A motor connected pins 3 6. Pin 2 connected positive rail. Now, I connect pin 1 (enable 1) positive rail, motor spins, expected. The weird thing I connect pin 16 instead pin 1 positive, motor spins, well. Also, motor connected 11 14, 15 connected positive, motor spins I connect pin 1 pin 16 positive, I connect pin 9 (which enable pin side). Does make sense? Am I missing something here? Thanks!",motor h-bridge
2056,Bluetooth module HC-05 giving ERROR :(0),"I working right Arduino UNO HC-05 bluetooth module.I followed instruction given link wiring. So 2 mode working HC-05 module Simple serial communication Working AT command mode change parameters HC-05 module As long I work simple serial communication mode, everything works fine I tried change parameters module, didn't work out. For working At command mode, PIN NO 34 HC-05 module needs high I taken care of. Lately I found mu module knowingly connected Berg strip PIN 34, I connected PIN directly, even though I able change parameters module I write command COM port arduino IDE, I get response I think garbage due code Here code: #include <SoftwareSerial.h> SoftwareSerial BTSerial(10, 11); // RX | TX void setup() { pinMode(9, OUTPUT); digitalWrite(9, HIGH); Serial.begin(9600); Serial.println(""Enter AT commands:""); BTSerial.begin(38400); } void loop() { uint8_t x; char CommandFromSerial[50]="" ""; char ResponseFromBluetooth[50]= "" ""; ((Serial.available())){ if(Serial.available()>0){ for(x=0;x<50;x++) CommandFromSerial[x]=Serial.read(); BTSerial.println(CommandFromSerial); } } ((BTSerial.available())){ if(BTSerial.available()>0) for(x=0;x<50;x++) ResponseFromBluetooth[x]=BTSerial.read(); Serial.println(ResponseFromBluetooth); } } I able figure I wrong. I used command COM port AT\r\n many commands every time I get response. Did I mess bluetooth module unknowingly?",arduino c communication serial
2062,Guidance compensating internal forces closed loop chain,"I'm working legged robot generating joint torques. Basically robot seems statically stable extend. The robot goes instable center pressure moves border feet. I'm looking method move away center pressure feet edges calculated joint torques. In Sentis thesis ( ) , mentioned somehow manages cancel internal forces keep feet flat supporting surfaces. Does anyone got experience dealing internal forces? As far I understood literature one modify nullspace calculated torques achieve COP remains geometrical center considered foot. I'm looking methods apart virtual linkage model seem work someone I could discuss virtual linkage model described ( ) I might understood correctly.",stability legged
2063,Unable read pushbutton press properly Arduino,"I trying use push button order know print number time push button pressed using counter.But everytime press button , counter get incremented sometime 3 sometime 5 time counter start >100 continue. I preferred link wiring PUSH button arduino. code I dont know count coming absurdly unevenly.",arduino c serial
2068,My Raspberry Pi losing power surge,"I RC car. The battery provides power ESC ESC provides 6 V back receiver. Instead receiver I Raspberry Pi, uses 6 V, steps 5 V provides power Raspberry Pi. The problem Every time go full power*, lack voltage Raspberry Pi seems hard reset. * By full power mean direct 100% ranging 0-100 I expert electrical circuits, suggestions use capacitor provide missing 5 V interim. How I prevent Raspberry Pi dying event full power?",raspberry-pi electronics esc
2074,Omron G5V-2 relay NO pins working,"I could swear working while. I got back desk, tried again, it's longer working. Could I fried NO pins sides? This DPDT relay. Everything works normally NC pins. I never applied 5V. I hear relay click I apply 5V coil. But I measure voltage NO pins, I get 0V. Has anyone else seen this? I two relays I can't seem get voltage NO pins either relay. I clarify I'm expecting 5V power source power coil common pins. If NC pins work I don't see NO pins shouldn't. In cases 5V shared coil load attached NC/NO pins. I try driving entire circuit 9V power supply, change results (and contradict earlier statement I've never applied 5V relay). My circuit based Charles Platt's ""Make: Electronics"", p. 59. Here's pic schematic I following, except I using 5V relay 5V power supply (USB port) I using piezo buzzers without resistors instead LEDs.",electronics
2075,Particle filter implementation ROS,"I'm looking particle filter implementation ROS use mobile robot localization, seems available package amcl (Adaptive Monte Carlo), I'm sure possible use particle filter not, it's feasible, how? Note: The robot (wheeled robot) provides odometry data another data source , provides visual odometry data using fovis.",mobile-robot localization ros particle-filter
2077,Recommendations system repeatedly force contact head desk,"I frequently bang head desk performing task poorly. I would like eliminate unnecessary middle step actually performing task poorly. As such, I would like design system hold head repeatedly strike desk. Alternatively, system holds desk repeatedly strikes head would acceptable. Requirements least 2 strikes per second maximum ~50cm travel. Can anybody make recommendations system base device of? Denso products, small affordable, required load capacity (some users may rather large head, involuntary resistance expected -- least near start cycle). I thinking something industrial, perhaps:",robotic-arm
2081,Soft LED Protection Material,"I looking material build soft clear protective covering RGB LEDs. The material needs close transparent allow light shine through, soft compliant sturdy enough withstand someone standing it. The ultimate goal floor LEDs someone jump barefoot change led colors. I tried Gel Candle Wax Silicone neither worked well. I looking material ideas relevant StackExchanges I could find.",arduino
2083,"Arduino Uno getting type ""HANGED"" runing samll code switc debounce Serial print","I using Arduino UNO read push button every time pressed.Earlier simply reading Digital IO pin read count faced condition switch debounce regarding asked question get know must use Interrupt instead reading digital IO pin even using interrupt, facing problem Switch Debouncing. So used link code given link change long debounceDelay = 50; 10(means read thing ina time gap 10 mili second) code says.Now happening, code running board time board get hang LED stop toggling press push button manually reset board.I also want add upon thing also using serial port LED toggles switch pressed. I totally confused happening.There beone possibility happening reduced time gap two consecutive events 10 50 miliseconds might making AVR get hanged thus require manual reset.",arduino c serial communication
2084,Fake localization using bag file ROS,"I bag file contains couple topics needed localization, odometry data, kinect data . What I want watching robot's movement path rviz initializing robot position (even I don't know initial it). Any help? All topics: /scan /tf /clock /map /odom",localization ros
2087,Which Kinect movement base?,"I making mobile base robot wheels. I want use Kinect like movement sensor (to avoid obstacles, recognition people, etc...) I read 2 models, 360 Developer. Which Kinect works well job? And another thins, another thing I use like movement sensor? To see diferent posibilities,",mobile-robot wheeled-robot kinect
2088,Powering servos completely RobotC+Tetrix,"For certain robotic application (actually FTC challenge year) team performing operation servo-driven arm could potentially forced unknown position. We using NXT+Tetrix. Since could damage powered servo working forced position (servo holding arm weight fixed base trying move heavy base relative fixed arm), thinking somehow de-powering servos (or servo controller), order get servos ""relax"" accept mechanically-forced position. Originally, thinking RobotC code determine physical position given servo set desired position every loop, limiting much servo would try fight movement, dismay, actually gives us setpoint, physical location (due servo unable provide information). We also considered setting ServoChangeRate[fooServo] 1(the minimal value) changes rate target location changing relative previous target. So, we're concluding way really fully depower servos. Is possible NXT/Tetrix RobotC? A notes: I realized well one could suggest rig encoder(associated Tetrix motor need encoder) onto rotating area. That actually would work mechanical constraints. I looked setting PWM enable shown sure send i2c commands needed. If someone could clue commands would sent terms c code, would helpful.",power rcservo nxt robotc
2089,Compiling Code EY-80,"I recently purchased EY-80 electrodragon: EY-80 All one 9-Axis Motion Sensor (Gyro + Acceler + Magneto + Baro) I hard time compiling example code arduino: This happening. So far, I copy pasting code. Any help? (I somewhat new programming, don't fully understand code)",arduino sensors gyroscope
2090,Wifi pass aluminium,"I make rc car uses wifi connection. The body car would made aluminium wifi receiver placed inside aluminium casing. How I make sure work? Would I forced change material I make extension receiver make sure casing? If , would really help me?",wifi
2091,How use Arduino ESC control?,"I using Arduino Uno control ESC (in progress) quadrocopter. I currently using servo library control ESC, works great. Except.. A count 100 max speed, meaning I 10 speeds 90 (stopped) 100 (motor full power) correctly run quadrocopter, I would like many speed options. Any ideas? I'm hard time using PWM signal, I might right though. My current code here:",arduino control quadcopter esc servomotor
2096,Using Armatures Morse Robotic Simulator,I'm trying add robot Morse 1.1 (using Ubuntu 12.04). I struggling add armature actuator armature pose sensor existing robot. Can someone please explain done (preferably sample code using socket interface). Thanks.,mobile-robot sensors robotic-arm simulator python
2098,Are GPS sensors provide data 1Hz faster?,"I searched GPS devices provide 1 sec updates server, I found any. I found T=30s.Module sent monitoring data packet. After 12 seconds server sends acknowledgement. In 18 seconds later (T = 30s) module sends next monitoring data packet Are products take less time? Why gps devices take much time send data?",sensors gps
2101,Do I need accurate flight model UAV?,"As I understand it, Kalman filter uses mathematical model robot predict robot's state t+1. It combines prediction information sensors get better sense state. If robot aeroplane, accurate/realistic model need be? Can I get away simple position velocity, I therefore need accurate flight model computational fluid dynamics?",kalman-filter uav
2104,How calculate probability particle survival particle filter?,"I'm trying figure way I calculate probability particle survive re-sampling step particle filter algorithm. For simple case multinomial re-sampling, I assume model process like Binomial distribution care one sample/particle. So particle weight w also probability get selected step re-sampling. So use 1 - P(k, p, n) P Binomial distribution, k 0 (we select particle tries), p equal w n equal M, number particles. What case though systematic re-sampling, probability particle selected proportional equal weight?",particle-filter
2105,360 degree ultrasonic beacon sensor,"Basically, I want detect ultrasonic beacon radius around robot. The beacon would separate ultrasonic emitter robot would spinning receiver. Are existing ultrasonic sensors would meet use case I stuck hacking one together myself? Is ultrasonic even best choice? I hoping beacon would kept pocket, I figured optical sensors out. Edit: The beacon robot mobile fixed base stations option.",sensors
2106,What happened Butler's car?,"Having read article ""This Car Has Electric Brains"" Popular Mechanics, August 1958 I questions. How practical methods? Was work acquired car manufacturer company? Were methods developed further? How corner navigation work? I don't think needed know distances road segments; I think could used sonar radar detect corner cars entering corner him, could misinterpret cars wall absence corner. Additionally I think he'd need two sonar/radar systems sides cars aren't mentioned; that's mentioned set relays. What compensator mentioned (it's said function gyroscope)? I cannot find information device (that I'm sure relevant).",design navigation
2109,POMDPs robotics,"POMDPs used cannot observe states. However, I cannot figure POMDPs useful robotics. What good example use POMDPs? (I read one paper used them, I didn't find obvious pomdps used) What would good projects ideas based POMDPs?",algorithm artificial-intelligence
2110,RC Transmitter Quadcopter Arduino,"I WL v262 quadcopter I want control using Arduino instead joysticks transmitter. I opened transmitter saw joystick 2 potentiometers PCB voltage pot goes 0-3.3V. I used arduino's PWM low pass filter connected output filtered output potentiometer's analog pin connected PCB (I cannot desolder take pots PCB) even $V_{out}$ going onto analog pin, transmitter's display gave ???? Now I really confused frustrated I don't know else control transmitter attaching stepper motors joysticks manually controlling transmitter really last resort. Can someone help this? I spent hours hours trial error I getting nowhere. Here PCB transmitter:",arduino sensors radio-control wireless
2111,Have bloodstream nanobots approved countries?,"A Google search ""bloodstream nanobots"" yields thousands results first page, many results blog posts date back 2009. It nearly 4 years later. I've luck finding information actual APPROVAL bots. Are countries approved this? People seem talked like crazy 4 years ago, yet, we're still seeing anything.",microcontroller
2114,sending receiving parameters ardupilot,"I interested getting arducopter ardupilot(APM). I read documentation I understand, ardupilot low level hardware firmware directly controls motors arducoptor. I would like know higher level programmatic interface ardupilot? The mission planner provides user interface control ardupilot. But programmatic interface control it? In words, would possible user written 'linux process' receive send sensory data ardupilot respectively?",quadcopter ardupilot
2117,Defining frames 5DOF robotics arm,"For examples robotic arm: Example, base rotation (5th DOF clip 0:58), know Z axis joint Z axis base frame{0}, I don't know Y Z axises base rotation respects base frame, ? And one thing, defining frame base rotation (at 0:58 clip), vertical arm pitch (at 0.47 clip) horizontal arm pitch (at 0:46 clip), it's pretty easy, I don't know continue defining frame wrist roll (at o.12 clip) wrist pitch (0.23 clip) since angle Z axis wrist roll wrist pitch 90o. Thank much.",localization kinematics robotic-arm
2119,Deburring Robot (Plastic Box),"For university course I asked design rough ""specification"" system deburr plastic box appears workspace. Due irregularities boxes edges I cannot use simple position control must use force control. I far decided on; Using IR sensor detect box appeared workspace. Use Epson 2 axis robot move around work piece Use ATI 6 axis force sensor maintain constant force edge box deburrer/robot moves around it. Is simple means detecting end side box ? A 0N force value would indicate reaching edge box could also mean breakage box also specified. How I distinguish two ? Also work far sound sensible ? Thanks help",control
2121,"Resampling attitude states (quaternions, rotation matrix) Particle Filter","Suppose I particle filter contains attitude state (we'll use unit quaternion body earth frame discussion) $\mathbf{q}_b^e$. What methods used resampling? Many resampling schemes (e.g. paper) seem require variance calculated stage, trivial $SO\{3\}$. Or, variance required performing roughening. Are good papers resampling attitude states? Especially re-sample complete poses (e.g. position attitude)?",particle-filter pose
2124,Image retrieval multibeam imaging sonar,"I would like know anyone used Blueview SDK (Linux) retrieval images pings obtained multibeam sonar (P450, P900, etc.) ? If so, I'd like know would anyone get null head I trying retrieve head (eventually pings converted image) using method. My snippet retrieving image .son file (some_son_data.son) given below: int main() { BVTSonar son = BVTSonar_Create(); BVTSonar_Open(son, ""FILE"", ""some_son_data.son""); (NULL != son) cout << ""son null"" << endl; BVTHead head = NULL ; BVTSonar_GetHead(son, 0, &head); return 0; }",auv sonar
2127,learn electronics intro advance digital,"I'd like well put video series like 30 videos. Or anything needs thorough easy English...less mundane. So far resources found either go upto resistors code projects tell tada got this. Is really online resource people learn electronics. I want master analog move digital cause it's better spend 0.40 cents.... spend $95 components get whole thing tiny chip. Please bare like six months searching legit source, material meant teach you. I like pictures colors.",electronics
2130,Transform Image Using Roll-Pitch-Yaw Angles (image rectification),"UPDATE: This exact problem solved StackOverflow. Please read post explanation working solution. Thanks! I working application I need rectify image taken mobile camera platform. The platform measures roll, pitch yaw angles, I want make look like image taken directly above, sort transform information. In words, I want perfect square lying flat ground, photographed afar camera orientation, transformed, square perfectly symmetrical afterwards. I trying OpenCV(C++) Matlab, I seem missing something fundamental done. In Matlab, I tried following: Where R_z/y/x standard rotational matrices (implemented degrees). For yaw-rotation, works fine: R = R_z(10)*R_y(0)*R_x(0); Which gives result: If I try rotate image amount X- Y- axes, I get results like this: R = R_z(10)*R_y(0)*R_x(10); However, I rotate 10 degrees, divided huge number, starts look OK. But again, result research value ever: R = R_z(10)*R_y(0)*R_x(10/1000); Can someone please help understand rotating X- Y-axes makes transformation go wild? Is way solving without dividing random number magic tricks? Is maybe something solved using Euler parameters sort? Any help highly appreciated!",computer-vision cameras
2131,Line following robot EV3 Colour Sensor,I trying build advanced coloured lines following robot ability differentiate many different coloured lines follow them. I looking right sensor help robot achieve objective. As I researching I came across EV3 Colour Sensor detect 7 colours. Is sensor suitable project? What sensors I use how? Thank You,mobile-robot sensors line-following
2132,What dependencies I need USB programing python pyUSB?,"I trying get command work properly python script I'm writing Angstrom Beagleboard. Here code: #!/usr/bin/env python import usb.core import usb.util import usb.backend.libusb01 libusb PYUSB_DEBUG_LEVEL = 'debug' # find device # Bus 002 Device 006: ID 1208:0815 # idVendor 0x1208 # idProduct 0x0815 # dev = usb.core.find(idVendor=0xfffe, idProduct=0x0001) # iManufacturer 1 TOROBOT.com dev = usb.core.find(idVendor=0x1208, idProduct=0x0815, backend=libusb.get_backend() ) I don't know what's missing, I know. When I don't specify backend, backend found. When I specify backend usb.backend.libusb01 I get following error: root@beagleboard:~/servo# ./pyServo.py Traceback (most recent call last): File ""./pyServo.py"", line 17, <module> dev = usb.core.find(idVendor=0x1208, idProduct=0x0815, backend=libusb.get_backend() ) File ""/usr/lib/python2.6/site-packages/usb/core.py"", line 854, find return _interop._next(device_iter(k, v)) File ""/usr/lib/python2.6/site-packages/usb/_interop.py"", line 60, _next return next(iter) File ""/usr/lib/python2.6/site-packages/usb/core.py"", line 821, device_iter dev backend.enumerate_devices(): File ""/usr/lib/python2.6/site-packages/usb/backend/libusb01.py"", line 390, enumerate_devices _check(_lib.usb_find_busses()) File ""/usr/lib/python2.6/ctypes/__init__.py"", line 366, __getattr__ func = self.__getitem__(name) File ""/usr/lib/python2.6/ctypes/__init__.py"", line 371, __getitem__ func = self._FuncPtr((name_or_ordinal, self)) AttributeError: python: undefined symbol: usb_find_busses What I missing work properly? Thank you.",rcservo python usb
2133,Turning differential drive robot specific angle,"Given robot 2 wheels radius r one axle length D, I want set wheel speed turns angle phi fast possible. The timestep 64 milliseconds. I thought wheel speed could set v = ((desired_heading-actual_heading) * circumference_wheel_trajectory)/(2*pi * * wheel_radius). This converge somewhat right angle, eventually, slow becomes slower I approach angle I want at. Is alternative/better way this?",kinematics
2135,Algebraic geometric inverse kinematic,"I'm wondering case algebraic way can't solve problem geometric ? Cause I'm working 2DOF robotics arm This one, I know length L1 L2, location I want end effector, I tried calculating angles using algebraic gave cos(alpha) > 1, I tried solving geometric, I find solution, I use wrong way algebraic ? Thank much.",localization kinematics robotic-arm inverse-kinematics
2138,Move ATRV robot specific distance using ROS,"Is node package send commands move ATRV-Jr like 2 meters forward turn 90 degree right/left? I don't want tell robot move specified speed. For example I use command rostopic pub /cmd_vel geometry_msgs/Twist '[1.0,0.0,0.0]' '[0.0,0.0,0.0]' robot starts moving forward I send another command send break command.",mobile-robot ros navigation
2145,Another SDK like OpenNI,"I taking information project I need see libraries ans SDKs. Searching web I found OpenNI lot functions I try found another SDK, I dont find other. I working Kinect XTION I need SDK works both. Is SDK set libraries works well both? Thanks!",kinect openni
2146,APM Accelerometer Calibration,"I trying manually calibrate on-board accelerometer APM 2.6 controller. I using following code (I found somewhere, don't remember where) Arduino 1.0.5 (in Windows environment) fetch accelerometer gyro data: My objective use calibrate accelerometers (and gyro), I use without depend Mission Planner. I'm reading values like: Acc X 288 Acc Y -640 Acc Z 16884 Gyro X -322 Gyro Y 26 Gyro Z 74 Acc X 292 Acc Y -622 Acc Z 16854 Gyro X -320 Gyro Y 24 Gyro Z 79 Acc X 280 Acc Y -626 Acc Z 16830 Gyro X -328 Gyro Y 23 Gyro Z 71 Acc X 258 Acc Y -652 Acc Z 16882 Gyro X -314 Gyro Y 22 Gyro Z 78 Acc X 236 Acc Y -608 Acc Z 16866 Gyro X -321 Gyro Y 17 Gyro Z 77 Acc X 238 Acc Y -642 Acc Z 16900 Gyro X -312 Gyro Y 26 Gyro Z 74 Acc X 226 Acc Y -608 Acc Z 16850 Gyro X -321 Gyro Y 26 Gyro Z 68 Acc X 242 Acc Y -608 Acc Z 16874 Gyro X -325 Gyro Y 27 Gyro Z 69 Acc X 236 Acc Y -576 Acc Z 16836 Gyro X -319 Gyro Y 19 Gyro Z 78 Acc X 232 Acc Y -546 Acc Z 16856 Gyro X -321 Gyro Y 24 Gyro Z 68 Acc X 220 Acc Y -624 Acc Z 16840 Gyro X -316 Gyro Y 30 Gyro Z 77 Acc X 252 Acc Y -594 Acc Z 16874 Gyro X -320 Gyro Y 19 Gyro Z 59 Acc X 276 Acc Y -622 Acc Z 16934 Gyro X -317 Gyro Y 34 Gyro Z 69 Acc X 180 Acc Y -564 Acc Z 16836 Gyro X -320 Gyro Y 28 Gyro Z 68 Acc X 250 Acc Y -596 Acc Z 16854 Gyro X -329 Gyro Y 33 Gyro Z 70 Acc X 220 Acc Y -666 Acc Z 16888 Gyro X -316 Gyro Y 19 Gyro Z 71 Acc X 278 Acc Y -596 Acc Z 16872 Gyro X -307 Gyro Y 26 Gyro Z 78 Acc X 270 Acc Y -642 Acc Z 16898 Gyro X -327 Gyro Y 28 Gyro Z 72 Acc X 260 Acc Y -606 Acc Z 16804 Gyro X -308 Gyro Y 31 Gyro Z 64 Acc X 242 Acc Y -650 Acc Z 16906 Gyro X -313 Gyro Y 31 Gyro Z 78 Acc X 278 Acc Y -628 Acc Z 16898 Gyro X -309 Gyro Y 22 Gyro Z 67 Acc X 250 Acc Y -608 Acc Z 16854 Gyro X -310 Gyro Y 23 Gyro Z 75 Acc X 216 Acc Y -634 Acc Z 16814 Gyro X -307 Gyro Y 27 Gyro Z 83 Acc X 228 Acc Y -604 Acc Z 16904 Gyro X -326 Gyro Y 17 Gyro Z 75 Acc X 270 Acc Y -634 Acc Z 16898 Gyro X -320 Gyro Y 31 Gyro Z 77 From I understand, SPIread(...,...) returns analog voltage value data pins sensor, happens proportional acceleration values. Right? My question is: How I go calibrating accelerometer? What I've tried till date: I've tried ""place horizontal... place nose down... left side, right side"" technique used mission planner. Basically, placed horizontal position, sensor experiencing +1g it's Z axis 0g X Y axis. Left/right side provides ±1g Y axis nose down/up provides ±1g X axis. Now every orientation, I've passed raw sensor data LPF computed mean, median SD sensor data 100 iterations. I store mean, median SD value EEPROM axis (one +1g one 0g). Now, I use sensor, I load stats EEPROM, match mean/median standard deviation current reading 4/5 iterations. Here I'm working assumption values 0g +1g (and anything 1g) interpolated/extrapolated data using linear plot. Is correct approach calibration? Can suggest better way? I noticed maxima/minima axis different. Is expected outcome something wrong code? What I gyro? How calibrate angular acceleration?",arduino accelerometer ardupilot
2147,How I interface CMOS camera module Arduino?,"I totally new camera interface usage Embedded project, would like use CMOS vision sensor like this.This project used power small robot on-board video processing power using processors like ARM 9. I limitation I worked 8-bit micro-controllers like atmega 8, 16, 32 Arduino platform. I think better processing use Arduino Due. With data sheet CMOS camera above, build breakout board. But next? I haven't I found useful resources searching. All I need capture small video store SD card. I seen links haven't proved useful don't provide required form factor. I looking interface module customized board. So I need understand commands accept proper functioning like starting take video posting output pin. If get video output pin, pin I take output controller, i.e. UART I2C SPI?",arduino microcontroller computer-vision cameras c
2148,Continuous Discrete,"I new robotics control I thinking deal problems real life. I passed course control, I idea control discrete/digital systems. There lot robots general dynamic systems controlled microcontrollers computers software, i.e. simulink. Usually sensors send feedback microcontroller computer controller sends signal w.r.t input signal sensors. I wondering decide system discrete continuous? How one decide use discrete continuous blocks simulink control dynamic system. Does really matter one use? After computers digital I think easier work digital signals also really continuous signal? I passed signals course, questions might really easy. I find place question.",control microcontroller
2149,Extended Kalman Filter Laser Scan + Known Map,"I currently working project school I need implement extended Kalman Filter point robot laser scanner. The Robot rotate 0 degree turn radius drive forward. All motions piecewise linear (drive,rotate,drive). The simulator using support acceleration, motion instantaneous. We also known map (png image) need localize in. We ray trace image order simulate laser scans. My partner I little confused motion sensor models we'll need use. So far modelling state vector $(x,y,\theta)$. We using update equations follows We thought everything working noticed forgot initialize P zero, meaning correction happening. Apparently propagation accurate haven't yet introduced noise system. For motion model using following matrix F: $F = \begin{bmatrix}1 & 0 & -v*\Delta t*sin(\theta) \\ 0 & 1 & v*\Delta t*cos(\theta) \\ 0 & 0 & 1 \end{bmatrix}$ As Jacobian update formulas. Is correct? For sensor model approximating Jacobian (H) taking finite differences robots $x$, $y$ $\theta$ positions ray tracing map. We talked TA said would work I'm still unsure will. Our prof away can't ask unfortunately. We using 3 laser measurements per correction step H 3x3. The issue initialize P. We tried 1,10,100 place robot outside map (-90,-70) map 50x50. The code project found here: Any advice greatly appreciated. EDIT: At point I've gotten filter stabilize basic movement noise actual movement. As soon robot starts move filter diverges quite quickly exits map.",mobile-robot ros kalman-filter ekf
2151,What micro controller I use?,"I planning building robot wheels (later legs, possible), move around room analyze certain things, using couple sensors. In later steps functions grabbing things I want add. Could recommend micro controller? My concern Arduino aren't enough slots, Raspberry Pi seems like constantly needs screen user. I complete amateur comes robotics. However, I quite familiar computer languages Java Python. Since I wrote fun app Android I would love robot compatible Android, too.",arduino raspberry-pi beginner
2156,How calibrate industrial Robot?,"I testing industrial robot (ABB IRB 1410) using three simple Micron Dial gauges get x,y,z values particular point varying Speed, Load distance home position. My questions are, Whether three parameters influencing repeatability accuracy? Using dial gauges, without relation Base frame, possible measure accuracy? Is cost effective method measure repeatability accuracy like method?",industrial-robot calibration
2158,Making tiny robot using remote brain,"I'd like build robot small possible ""delicate"" parts possible (the bots bashing other). I wondering possible use small chip could receive bluetooth/IR/wifi commands move motors, turn, send back feedback based sensors accelerometer (to detect impact). I probably achieve something like PiCy however slightly bigger I'd like (due size Pi) I'm sure long Pi would last taking continuous impacts. I'd therefore like try offset brain (the Pi) side arena use small chip receive move commands, send back data accelerometer. Do recommendations chip? Wifi would choice impacts size I could try BT Edit: After research seems Arduino nano WiFi RedBack shield might job along something like motors:",raspberry-pi rcservo accelerometer
2159,computer aided RC airplane combat,"2011 SWARM shows RC aircraft combat wings trying hit air. Scoring hit pretty rare, I'd like increase pilot's chances using computer targeting system. It would offline system gets data sensors airplane. What sensor(s) would work application?",mobile-robot sensors
2165,SPP Bluetooth profile compatibility phone,"I'm building project uses cell phone control microcontroller via Bluetooth. I've decided use HC-05 Bluetooth module. HC-05 Manual: And phone I'm using Nokia C3-00 (series 40). The HC-05 module uses SPP Bluetooth profile phone supports DUN, FTP, GAP, GOEP, HFP, HSP, OPP, PAN, SAP, SDAP profiles. But knowledge phone API utilizes RFCOMM. Question is, I use Bluetooth module phone? Thanks advance apologies question trivial I'm quite new Bluetooth. -Shaun",microcontroller
2167,Quadcopter instability simple takeoff autonomous mode,"I'm trying get quad rotor fly. The board controller Ardupilot Mega 2.6, programmed Arduino 1.0.5. I'm trying fly simple autonomous mode, Radio controller involved. I've done thorough static weight balancing assembly (somewhat like this: ) propellers balanced correctly. I'm trying get quadcopter lift using code: But issue is, soon quadcopter takes off, tilts heavily one direction topples over. It looks like one motor/propeller generating enough thrust arm take-off. I've even tried offsetting weight balance direction fails lift, doesn't work (and I snapped propellers process); Is something wrong way ESCs fired using Servo library? If everything else fails, I assume something wrong motors? Do I need implement PID controller self-balancing roll pitch get quadrotor take off? Edit 1: Thanks replies. I got PID place. Actually, still PD controller integral gain set zero. Here's I'm writing angles servo: motor1.write((int)(val + (kP * pError1) +(kI * iError1) +(kD * dError1))); //front left motor2.write((int)(val + (kP * pError2) +(kI * iError2) +(kD * dError2))); //rear right motor3.write((int)(val + (kP * pError3) +(kI * iError3) +(kD * dError3))); //front right motor4.write((int)(val + (kP * pError4) +(kI * iError4) +(kD * dError4))); //rear left kI zero, I'll ignore that. With value kP set somewhere 0.00051 0.00070, I'm getting oscillation steady amplitude around supposed mean value. But problem is, amplitude oscillation way high. It somewhere around +/- 160 degrees, looks crazy even tightly constrained test rig. [ Edit 2: How I calculate term 'pError' - Simple linear thresholding. I've precomputed data average readings (mean SD) coming gyro IMU steady. Based gyro reading, I classify motion setup left, right, forward backward. For motion, I increase pError term two motors, i.e, right tilt, I add pError terms motors 2 & 3, left tilt, I add pError term motors 1 & 4 etc. (check comment lines code snippet given above). The magnitude error I assign pError term = abs(current gyro reading) - abs(mean steady-state gyro reading). This value always positive, therefore side dipping downwards always positive increment RPM. ] As I crank derivative gain around 0.0010 0.0015, oscillation dampens rapidly drone comes relatively stable attitude hold, horizontal plane. The oscillation dies (considerably, completely) give stable quadrotor tilted 90 - 100 degrees horizontal. I'm using gyros calculating error. The gyros self calibrated, hence I expect fair amount noise inaccuracy associated error values. Do think primary reason high amplitude oscillation? One probable reason might low update frequency errors. I'm updating errors 6 times second. Could probable reason taking longer stabilise error? And, steady state error wild oscillations dampen, necessary fine tune integral gain get rid that? Please help. Edit 3: I cranked frequency operation 150+ Hz I get controlled oscillation (within +/- 10 degrees). I'm yet tune derivative gain, following I plan recompute errors integral gain using combination gyro accelerometer data. Edit 4: I've tuned P D gain, resulting +/- 5 degrees oscillation(approx). I can't get lower this, matter much I try. There two challenges I'm deeply concerned: After 5 8 seconds flight, quadcopter leaning one side, albeit slowly. A) Can drift controlled tuning integral gain? B) Can drift controlled using accelerometer + gyro fused data? C) Given drone still shows +/- 5 degrees oscillation, I consider optimal set point proportional derivative gains? Or I need search more? (In case, I'm really wits end here!)",arduino quadcopter pid ardupilot
2173,Visualizing kinect data rviz,"I beginner ROS, Kinect Ubuntu. What I want visualize Kinect's data rviz environment run object recognition it. I've tried tutorials luck. All I got empty rviz world. Since I beginner I would appreciate step-by-step instructions (preferably hydro groovy). I would also like note I've managed get visual Kinect device working fine.",ros kinect
2180,Lawn mower robot (type cutter),"If all, major types lawn mower robots rotary mowers. I presume1 reel mower efficient, said leave better lawn health cut. So, industry go option? 1 - I'm assuming efficiency, electrical rotary mowers least 900W universal-motors induction motors, manual reel mower capable nearly cutting speed.",motor mechanism
2182,What I use speech recognition?,"I wondering, team working robot communication-oriented wanted add speech recognition it. What technology I use ?",software
2186,Understanding Arduino bootloader,"That I came understand reading flashing new bootloader/understanding bootloader etc etc The bootloader supposed first thing runs I power Arduino Duemilanove (or micro controllers general). It setup runs app. It also listens usb cable I upload code erases old one run new one. There 2 sections memory, one bootloader (S1) one app (S2). Code S1 write S2 S1 (or strongly discouraged I don't remember). There things I don't understand though : If I upload new code app running, upload works. What happened ? I thought bootloader gave hand app How flash new bootloader ? If bootloader thing runs section 1 (S1) write S2 bootloader thing listens new code uploads, ... Can help correct thoughts answer questions ? Many thanks !",arduino microcontroller
2189,What autopilot purchase APM 2.6 PixHawk?,"I'm newbie UAV stuff, advice would helpful, want start mapping using fixed wing UAV, main choice APM 2.6, researches, found APM 2.6 won't actively maintained future future releases PixHawk. wonder choose APM 2.6 stability, side don't see benefits Pixhawk apart long time support. newbie start something experimental like APM 2.5.2 (cheap chinese version APM). Thanks advance",uav
2192,How I build 10cm-200cm IR range sensor?,"Everybody probably aware Sharp distance sensors (GP2Y0 series, e.g. GP2Y0A02YK0F). They use diode emit infrared light measure angle reflected light PSD (i.e. triangulation). They seem producers technology. I aware similar incomparable devices (sensors ambient light distance proximity like Si114x). Which comparable products there? Another way ask question: ""What different ways build 10cm - 200cm range low-cost IR range sensor, example ways?""",sensors manufacturing
2195,Re-Calibration articulated industrial robot,"We planning recalibrate ABB IRB 1410 robot conduct series accuracy & repeatability tests using FaroArm. My questions i) Is physical identification marker robot used identify location base co-ordinate frame? ii) If locating base frame possible, accuracy measured fixed arbitrary point space?",industrial-robot calibration
2196,Robots without microcontrolers (beam robots). Are technologically limited?,"BEAM robotics seem good approach teach learners electronics robotics. But robots like regular programmed ""cognitive"" robots? Can robots, analog circuits, take us level robotic assistants, worker robots kinds self sufficient autonomous robots? I specifically want know that, creating mission critical robots -> 1) What areas robotics practically impossible without real time software system? 2) What areas field done without programming? If yes, areas feasible without onboard software system? 3) Could intelligent space rover, work without cpu future?",control software electronics artificial-intelligence embedded-systems
2197,How make boat,I'm event boat race.Simple boat made.All 5 days.The restriction 24V motor 1000 rpm.What best material shape suggest make boat.I know basic circuits.We make boat wired circuit.That circuiting ideal shape boat maximum speed achieve?,activerobot
2205,Low speed control bldc motors,"I'm problem controlling BLDC motor starting running low rpm. I custom board measure rotation motor using optical sensor send servo pwm commands esc. The problem is, I can't start motor smoothly. When I slowly increase control signal, starts stuttering jumps directly 1500rpm. Is way improve situation without using sensored motor/esc combo?",motor control brushless-motor
2209,What different types electric motors?,"I beginning learn hardware aspect robotics, order lot new information useful (whether site elsewhere) I need basic understanding terminology. One thing comes repeatedly different electric motors: servo, DC motor, brushless motor, step motor, gear motor... etc Is comprehensive list? Or least list common ones, descriptions / differences?",motor
2215,How robotics startups work?,"In software engineering startups, generally go room computer bring laptop, write code. I'm interested robotics startups work: Is separate location designing robots? Take example, Anki. Do separate research labs designing robots? How robot get single design manufactured? I couldn't find better place SE post (the startups business section defunct): Please link another SE site better place ask question.",manufacturing
2216,method I use putting rubber bands wheels?,"I BOE bot PBasic2 stamp based robot came rubberband ""tires"" wheel. however, tight I can't figure get onto plastic hubs. furthest I've gotton mostly covering outside, trying make less crooked came again. trick getting pesky tires stay on?",wheeled-robot
2217,Access denied PIC Programming Windows XP,"I'm programming PIC16F77 ProPic 2 communicates via serial port. As I don't port PC, I used serial USB adapter. I'm using ICProg Windows 8. I've proggrammed Windows XP using driver specifies worked perfectly. But OS difference adapter, program gives errors loading driver: ""Error occured (Access denied) loading driver!"" ""Privileged instruction""",microcontroller
2218,What purpose electronic braking motors?,"I Micro Magician v2 micro controller. It A3906 Dual FET “H” bridge motor driver built in. In manual states ""Electronic braking possible driving inputs high."" My first question is, purpose brakes? If I set left/right motor speed 0, robot stops immediately anyway. What advantage using brakes, I taking word ""brake"" literally? My second question is, driver ""motor stall flags normally held high pullup resistors go low motor draws 910mA current limit. Connect spare digital inputs program know robot gets stuck."" But robot hits wall, wheels keep spinning (slipping will), I take stall flags used rough surface wheels friction?",motor h-bridge
2222,"I entrepreneur I want start building robots businesses, I start?","Over last couple years I've good success technology startups looking enter robotics. I interested robotics automation ever since I kid (yes, sounds nerdy). So question is: Where get started, build? sell? And lastly, difficult sell industry?",industrial-robot
2224,Udoo board + Kinect sensor?,I wondering would possible get Kinect work Udoo board (Quad). I found support ROS + Udoo. Also saw question asked Xtion + Udoo shows interest. It would really great could possible Kinect+Udoo. Was hoping implement perhaps miniature version TurtleBot. I wish someone could give insights matter. Thanks.,ros kinect arm embedded-systems
2227,Quadcopter configuration,"I'm building quadcopter. It controlled Beaglebone black several Sensors cam. I new quadcopter stuff, therefore would nice someone could look setup I buy parts. Frame: X650F - 550mm Battery: Turnigy nano-tech 5000mah 4S 25~50C Lipo Pack Motor: NTM Prop Drive 28-30S 800KV / 300W Brushless Motor ESC: Skywalker 4x 25A Brushless This sums ~ 2kg. Giving still room 700g payload. What think? Did I miss something important? Better ideas parts?",quadcopter
2228,Zero crossing events brushless DC motors,"I would like ask question zero crossing event trapezoidal commutation brush-less DC motor. Here waveform shows zero crossing event occurs every 180 electrical degrees sinusoidal commutation: But trapezoidal commutation. Here waveform I found trapezoidal commutation: So see, zero crossing occurs 30 electrical degrees previous commutation 30 electrical degrees next commutation. In motor one pole pair, would 30 electrical degrees = 30 mechanical degrees, would waveform: You see zero crossing phase A occurs magnet faces phase C, words, 30 electrical degrees last commutation. My question zero crossing happen moment, 60 electrical degrees, 15 electrical degrees? Is related law's induction? What law law's appear motor? Can someone explain pics?",brushless-motor
2234,Zero crossing events trapezoidal commutation,"I would like ask question zero crossing event trapezoidal commutation brush-less DC motor. Here waveform shows zero crossing event occurs every 180 electrical degrees sinusoidal commutation: But trapezoidal commutation. Here waveform I found trapezoidal commutation: So see, zero crossing occurs 30 electrical degrees previous commutation 30 electrical degrees next commutation. In motor one pole pair, would 30 electrical degrees = 30 mechanical degrees, would waveform: You see zero crossing phase A occurs magnet faces phase C, words, 30 electrical degrees last commutation. My question zero crossing happen moment, 60 electrical degrees, 15 electrical degrees? Is related law's induction? What law law's appear motor? Can someone explain pics?",brushless-motor
2236,ComputerCraft (Minecraft mod) navigation: Collision avoidance path planning/finding 2D/3D space,"I'm programming Lua controlling computers robots in-game Minecraft mod ComputerCraft. ComputerCraft robots called Turtles, able move around grid based(?) world Minecraft. They also equipped sensors making able detect blocks (obstacles) adjacent them. Turtles execute Lua programs written player. As hobby project I would like program function Turtles. Some Turtles actually equipment remove obstacles, I would like make avoid obstacles thus prevent destruction in-game environment. I prior experience robotics, I B.Sc. Computer Science lead web developer. I research found basic strategies, namely grid based quadtree based. As I experience area, strategies might old school. Note Turtles able move three dimensions (even hover height). I could share obstacles well obstacle free coordinates common database discovered would help out, obstacles stationary placed. What best options matter? Are easy fixes? Where I look additional resources? Thank much advance! :-) EDIT: Thank feedback! I started reading book Artificial Intelligence: A Modern Approach, 3rd Edition get speed basic theory suggested Ian. Pointers educational resources appreciated. Also, I started developing basic navigation algorithm moving unexplored areas, similar Cube suggested. The priority moves possible, costs time fuel cells additional move (approx. 0.8 seconds 1 fuel cell per move either direction). I plan using Euclidean heuristics function Greedy Best-First Search computing path expected quite optimal reducing number moves reach goal, enough data available shared database previous exploration. Each time obstacle reached, I plan use following basic algorithm, exploiting fact Turtles able move vertically: 1. Calculate direct horizontal path goal. 2. Turn direction next step path. 3. If obstacle detected front Turtle go 5. If 4th time obstacle detected front Turtle moving up, go 6. 4. Move forward, go 2. 5. If obstacle detected Turtle, move go 3, else go 7. 6. Backtrack coordinates Turtle moving upwards. 7. Turn left, go 3. When using algorithm, records kept explored coordinates uploaded shared database. However, cases, I consider: - When move down? - What goal reachable coordinate directly it? - If horizontal move direction possible, long backtrack? - How detect unreachable goals (obstacles removed requested) Maybe enough exploration data area available, Jump Point Search performed calculate optimal path. However assumes 2D map. How I take 3rd dimension account? Also, would good data structure store exploration data?",mobile-robot navigation
2244,How know desired orientation quadcopter?,"I trying simulate quadcopter model Simulink. I want implement PID controller X,Y,Z phi,theta, psi angles. PID gets error, input, minimized. For X,Y Z, desired values entered user actual values calculated accelerometer data, hence, error desired set value - actual value. For phi,theta psi, actual values may obtained gyroscope accelerometer (sensor fusion) I don't actually know calculate desired values one since user usually interested giving position values X,Y Z desired angle values! The absence desired values prevents form calculating angular error needed PID controller.",design pid quadcopter
2245,Kalman Filter state noise vector?,"I'm reading Probabilistic Robotics Thrun. In Kalman filter section, state $$ x_{t} =A_{t}x_{t-1} + B_{t}u_{t} + \epsilon_{t} $$ $\epsilon_{t}$ state noise vector. And $$ z_{t} = C_{t}x_{t} + \delta_{t} $$ $\delta_{t}$ measurement noise. Now, I want simulate system Matlab. Everything straightforward except state noise vector $\epsilon_{t}$. Unfortunately, majority authors don't care much technical details. My question state noise vector? sources it? I need know I want simulation rather sensible. About measurement noise, evident given specifications sheet sensor uncertainty ${\pm} e$.",kalman-filter noise
2250,Finding inverse kinematics algorithm specific manipulator,I need find way solve invrese kinematics Comau SMART-3 robot. Could give hints start looking? I idea robotics I couldn't find algorithm specific robot.,inverse-kinematics
2251,Difference Rao-Blackwellized particle filters regular ones,"From I've read far, seems Rao-Blackwellized particle filter normal particle filter used marginalizing variable from: $$p(r_t,s_t | y^t)$$ I'm really sure conclusion, I would like know precise differences two types filters. Thanks advance.",slam particle-filter
2256,Flipping old manual switch (physical one),I Have old audio amplifier switches turn on. I'm looking simplest motor/robotic arm (or relevant component) control switch - eventually via Raspberry Pi . Are options ?,motor raspberry-pi robotic-arm
2261,How gyroscopically measure number rotations one axis concurrent random motion another axis,"Can gyroscopic sensor (comparable type typically used smartphones) embedded black object rotating around X axis measure number rotations around X axis object may may also rotating time random ways (number partial full rotations, speeds, directions) around Z axis? If so, Z axis rotation irrelevant, special mathematics involved filtering affects Z rotation measurement X axis rotation? Or another measurement acceleration magnetism need used solve problem? Is impact using 2-axis vs. 3-axis gyroscopic sensor measurement scenario?",sensors gyroscope
2262,How choose WiFi signal strength detecting sensors,We want create robot localize signals wifi routers. Which sensors buy detect strength 3 WiFi signal? Which following necessary us? suitable variants? We using arduino platform.,arduino sensors localization wifi
2263,"Quadcopter Position Measurement (Accelerometer, GPS Both)?","I previously thought accelerometer quadcopter used find position integrating data got it. After I read lot watched Youtube video (specifically time 23:20) Sensor Fusion Android Devices, I seem get use little correct. I realized it's hard filter considerable noise, generated error integration, get useful information position. I also realized used along gyroscope magnetometer fused information orientation linear translation. For outdoor flight, I thought GPS data get relative position, accurate away enables position measurement (with good precision)? How commercial quadcopters measure positions (X,Y Z)? Is GPS data fused accelerometer data?",quadcopter accelerometer navigation sensor-fusion
2264,Are Artificial Intelligence Robotics Different?,I need help differentiating AI Robotics. Are AI Robotics two different fields robotics subject AI? I want pursue career AI Robotics. So I need valuable suggestion. I searched web also universities I want apply I cannot find thing I searching for.,artificial-intelligence
2273,Unwanted Arduino reconnect: Servo + Arduino + Python (Raspberry Pi),"I difficulty sustaining connection Raspberry Pi (Model B running Raspbian) Arduino (Uno) sending signals Raspberry Pi continuously rotating servo (PowerHD AR- 3606HB Robot Servo) via Python. I'm sure efficent way sending servo instructions via Python Arduino rotate servo. I'm attempting communicate signals Raspberry Pi Arduino via USB using I believe considered ""digital Serial connection"". My current connection: Servo connection Arduino: Signal (Orange) - pin 9 Power (Red) - +5 V Ground (Black) - GND On Raspberry Pi I installed following (although needed addressing problem): xboxdrv pyserial Python-Arduino-Command-API PyGame lego-pi Arduino The sketch I've uploaded Arduino Uno corresponding sketch provided Python-Arduino-Command-API. *Again, I'm positive best method means driving servo Python Arduino (to servo). From Raspberry Pi, I see Arduino initially correctly connected via USB: pi@raspberrypi ~/Python-Arduino-Command-API $ dir /dev/ttyA* /dev/ttyACM0 /dev/ttyAMA0 pi@raspberrypi ~/Python-Arduino-Command-API $ lsusb Bus 001 Device 002: ID 0424:9512 Standard Microsystems Corp. Bus 001 Device 001: ID 1d6b:0002 Linux Foundation 2.0 root hub Bus 001 Device 003: ID 0424:ec00 Standard Microsystems Corp. Bus 001 Device 004: ID 045e:0719 Microsoft Corp. Xbox 360 Wireless Adapter Bus 001 Device 005: ID 1a40:0201 Terminus Technology Inc. FE 2.1 7-port Hub Bus 001 Device 006: ID 0bda:8176 Realtek Semiconductor Corp. RTL8188CUS 802.11n WLAN Adapter Bus 001 Device 007: ID 046d:c52b Logitech, Inc. Unifying Receiver Bus 001 Device 008: ID 2341:0043 Arduino SA Uno R3 (CDC ACM) From Raspberry Pi, I'm able rotate servo test clockwise one second, counter-clockwise one second, stop servo, following Python script: #!/usr/bin/env python Arduino import Arduino import time board = Arduino(9600, port='/dev/ttyACM0') board.Servos.attach(9) # Declare servo pin 9 board.Servos.write(9, 0) # Move servo full speed, clockwise time.sleep(1) # Sleep 1 second print board.Servos.read(9) # Speed check (should read ""0"") board.Servos.write(9, 180) time.sleep(1) print board.Servos.read(9) # (Should read ""180"") board.Servos.write(9, 90) print board.Servos.read(9) board.Servos.detach(9) The output via Raspberry Pi terminal reads: 0 180 90 Although performs full-speed direction (as well calibrated ""stop"" speed 90), I successfully alternated full-speed slower speeds, example, going 0 90 increments 10. From Raspberry Pi, I'm able send input Xbox controller drive servo small custom Python script I've created along xboxdrv (which works flawlessly projects I'm doing): #!/usr/bin/python legopi.lib import xbox_read Arduino import Arduino # To catch Ctrl+C import signal import sys # The deadzone within ignore inputs, approximately 1/3 total possible input DEADZONE = 12000 def signal_handler(signal, frame): print ""Stopping Wrapper"" sys.exit(0) # Capture Ctrl+C shut nicely signal.signal(signal.SIGINT, signal_handler) print ""Starting Wrapper"" print ""Press Ctrl+C time quit"" board = Arduino(9600, port='/dev/ttyACM0') board.Servos.attach(9) board.Servos.write(9, 90) event xbox_read.event_stream(deadzone=DEADZONE): print ""Xbox event: %s"" % (event) # If RB button it's held, rotate servo counter-clockwise full-speed. # When RB button released, stop servo. if(event.key=='RB'): if(event.value>0): board.Servos.write(9, 180) print board.Servos.read(9) else: board.Servos.write(9, 90) print board.Servos.read(9) continue This script runs, I'm able control servo using RB button controller. However, eventually fails - sometimes minutes, sometimes seconds (rapid intermittent input seemingly influence expediting crash). Input longer read script, terminal comes halt, servo freezes whatever last command given (either spinning endlessly stopped), I'm forced Ctrl + C script. If I check see Arduino still connected Raspberry Pi, shows reconnected Raspberry Pi ""ttyACM1"" (from /dev/ttyACM0 /dev/ttyACM1): pi@raspberrypi ~/robotarm $ dir /dev/ttyA* /dev/ttyACM1 /dev/ttyAMA0 Why Arduino reconnect itself? Is way I processing information? Distance wireless Xbox receiver factor pieces adjacent one another testing purposes. It prove impossible use servo wheel robot I'm constantly tending issue.",arduino raspberry-pi servos python
2274,Workable low-resolution object/target recognition pattern library?,"I've spent quite time researching this, Google search results turned academic research papers interesting practical. I'm working target/pattern recognition project** robot small camera attached attempt locate targets using small wireless camera moves around room. The targets ideally small possible (something like size business card smaller), could (less ideally) large 8x10 inches. The targets form something easily printable. The pattern recognition software needs able recognize target (only one time) field vision, needs able accurately differentiate least 12 different target patterns, hopefully maybe 50x50 pixel portion 640x480 image. Before playing camera, I envisioned using somewhat small printed barcodes excellent zxing library recognize barcodes. As turns out, camera's resolution terrible - 640x480, grainy well-focused. Here example still image. It's well-suited capturing barcodes, especially moving. I think could work 8x10 barcodes, that's really larger I'm looking for. (I'm using particular camera tiny, light, cheap, includes battery wi-fi.) I'm looking two things: suggestion pointer optimal pattern I could use targets, software library and/or algorithm help identify patterns images. I NO idea start right type pattern suggestions would really help, especially project something resembling this. I've found OpenCV OpenSIFT seem like potential candidates software libraries, neither seemed examples type recognition I'm talking about. I'm thinking picking right type pattern big hurdle overcome here, pointers optimal type pattern would great. Being able recognize pattern different angles must. So far, idea use patterns perhaps look something like this, three concentric color rings simply either red, green, blue - allowing 27 unique targets, 81 I use 4 rings. From 2 feet, capture 3x3 inch target (from computer screen) looks like seems like would suitable analysis I feel like better type pattern would compact easier recognize - maybe plain black white pattern sort shapes it? Pointers optimal approach greatly appreciated.",software computer-vision artificial-intelligence
2277,"Once understand motors, what's next step?","I've gone tutorials build circuits control dc, stepper, servo motors. I may understand everything internally, good basic foundation. Now i'm loss go here. I'm interested learning make mechanical devices electronics behind devices. While know go hand hand, want learn mechanical aspects using motors. I mind several ultimate goal projects want work toward, like home automation, model rc vehicles, autonomous robots, etc... But i'm sure mechanics need learn jump project like that. He learn fly one day must first learn stand walk. Are hobbyist mechanical starter kits starter projects learn make effective use electric motors? I don't necessarily need specific product endorsement, rather general idea important concepts learn materials / projects help learn them. My apologies question broad. I refine deemed necessary.",motor mechanism
2279,"2D path following robot, converting XY axis path input wheels","moment I creating android program, steer simple, 3 wheel (2 motors, 1 balance) robot move online following path drawn user screen. The robot operated WiFi 2 motors react input signals. Imagine user drawing path robot smartphone screen. It aquired points XY axis, every time beginning (0,0). Still I idea, somehow ""convert"" points, voltage input motors. Signals sent approx. 60Hz connection, quite fast. Maybe every single axis point taken consideration, surely skips, irrelevant, since path done perfectly robot, reasonable error scale. Do idea make robot follow defined axis points overall create path? Edit 10.01: The voltage computed robot, input -255 255 velocity increase decrease lineary borders. Additionaly, I would like solve perfect conditions, I don't need feedback crazy models. Let's assume data true, sensors additional devices. Just XY axis path required input (ommit wheel slide too).",wheeled-robot wifi two-wheeled
2283,Emulation Orrery,"Orrery clockwork model solar system. I trying emulate one 2D. Now, emulate, I need know goes inside. Can someone please explain basic principle behind clockwork? Or direct resource explain machinery inside simple Orrery.",motor design
2289,Dynamics parallel manipulator,"My task apply forces control 3-dof parallel manipulator. Forces applied linear actuators, friction neglected. End-effector robot supposed follow generated path; example, let simple circle. So far I made simplified 3d model robot calculated inverse kinematics. Promoter engineering work don't really know this, said calculating forward dynamics complex shouldn't go way. Could tell easiest way go?",force dynamics manipulator
2290,KK2.0 Quad Stablility,"I'm running kk2.0 + 4 20A Multistar ESCs + 4 EMax GF 2215-20 motors + 4 Slow Fly Props After foot ground, entire quadcopter starts wobbling like crazy (no auto-level). Any ideas? I'll add video needed.",quadcopter stability
2295,Power Model humanoids,"I process creating Power Prediction Model Hubo Robot. The Robot 38 Degrees Freedom computer sensors motor boards. The motors powered Motor Boards. All boards powered main power board exists robots chest. My model able predict power trajectory robot. Say instance robot raises hand 0 degrees 180 degrees model able predict power. Heres idea I came across. My idea equate electrical torque mechanical torque joint. For instance Right arm pitch moves 0 180 degrees I follows ? $mgsin(\theta)= Kt*I$ However, I getting proper prediction current value way read software installed robot. I know losses even off. I wondering approaches fault approach. And I I add joint currents specific trajectory give estimate total power consumption.",brushless-motor power inverse-kinematics motion-planning torque
2297,Quadcopter PID tuning,"In continuation question I asked here: Quadcopter instability simple takeoff autonomous mode ...I'd like ask questions implementing basic PID quadrotor controlled APM 2.6 module. (I'm using frame 3DRobotics) I've stripped entire control system two PID blocks, one controlling roll another controlling pitch (yaw everything else... I'd think later). I'm testing setup rig consists freely rotating beam, wherein I've tied two arms quadrotor. The two free move. So, I'm actually testing one degree freedom (roll pitch) time. Check image below: A, B marks freely rotating beam setup mounted. With careful tuning P D parameters, I've managed attain sustained flight 30 seconds. But 'sustained', I simple mean test drone ain't toppling one side. Rock steady flight still sight, 30 secs flight also looks quite difficult. It wobbles beginning. By time reaches 20 - 25 seconds, starts tilting one side. Within 30 secs, tilted one side unacceptable margin. Soon enough, I find resting upside As PID code itself, I'm calculating proportional error 'complimentary filter' gyro + accelerometer data. The integral term set zero. The P term comes 0.39 D term 0.0012. (I'm using Arduino PID library purpose, want get one PIDs implemented here.) Check video, want see works. [Yeh, setup pretty ancient! I agree. :)] Please let know could I possibly improve stability stage. @Ian: Of many tests I setup, I plot graphs tests using reading serial monitor. Here sample reading Roll vs 'Motor1 & Motor2 - PWM input' (the two motors controlling roll): As input/output: Input: Roll pitch values (in degrees), obtained combination accelerometer + gyro Output: PWM values motors, delivered using Servo library's motor.write() function Resolution I resolved problem. Here's how: The crux issue lied way I implemented Arduino program. I using write() function update servo angles, happens accept integer steps argument (or somehow responds integer input, 100 100.2 produces result). I changed writeMicroseconds() made copter considerably steadier. I adding RPM one motor keeping steady value. I changed increase RPM one motor decreasing opposing motor. That kinda keeps total horizontal thrust unchanged, might help I'm trying get vertical altitude hold thing. I pushing RPM max limit, quadcopter kept losing control full throttle. There room RPM increase sensed tilt. I observed one motor inherently weaker one, I know why. I hardcoded offset motors PWM input. Thanks support. Source Code: If you're interested, here's source code bare-bones PID implementation: PID Source Code Please feel free test hardware. Any contributions project would welcome.",arduino pid quadcopter stability
2298,"How much accuracy could I get position tracking 3-axis accelerometer gyro sensor, compass, would I it?","Given 12' x 12' field (4m x 4m), reasonably cheap 3-axis gyro sensor accelerometer, compass, I plan design device capable tracking position sub-centimeter accuracy minute motion so. The device holonomic drive system, capable moving direction maximum 8mph (3.6m/s), maximum acceleration 2g's. However, simplifying constraints. For one, field nearly flat. The floor made tough foam, slight sinking, floor flat except ramp known angle (to degrees). The device will, excepting collisions, rising floor. Accuracy preferred simplicity, mathematics required software side improve system would welcomed. Before I definitively choose accelerometers method position tracking, though, I would like idea much accuracy I could get, best ways it.",kinematics accelerometer machine-learning
2299,Where start software side Robotics?,"I Computer Science student entering last year college. I'm pretty sure Robotics I want eventually based interests AI embedded systems. I've seen lot topics covers Robotics as: control theory, signal processing, kinematics, dynamics, 3D simulators, physics engines, AI, Big Data machine learning. I'm hoping someone point right direction I attempting study interests Robotics. I sure topics I mentioned would relevant. I would like deal software side Robotics, AI none AI. My question machine learning. I've seen researchers applying machine learning (deep learning/unsupervised learning specifically) robotics this? Is information data transferred internals robot external computer data processing? Machine learning requires lot data predict. Is way machine learning used robotics (through external computer)? I hope someone touch things I've mentioned, Thank you.",mobile-robot software artificial-intelligence programming-languages
2304,System determining occupied seats auditorium,"I need app live monitoring whether seat auditorium occupied, visitors load app see sit. The auditorium relatively flat ceiling 4m high, seats .5m wide. The hardware cost per seat needs $5. I'm looking solutions. Web cams, preasure sensors, sonars, lasers, arduino, pi, intel edison, anything. Obviously cannot wires people could trip over. Sensors ceiling could wired networking. Sensors seat floor would need wireless communication. sensors ceiling would need consider occlusion people sitting seats (think, empty spot 2 people, sensor see empty) In end, data needs collected simple list chairs occupied/open Possible solutions: rasberry pi's ceiling every 8 seats camera. pressure sensors chair legs wired pi's gpio Drones flying around auditorium :) Any ideas? Update (more constraints): auditorium size 400 seats Installation costs average 10 chairs per hour(400/10 = 40 hours) picture shows, chairs cushioned regular maintenance take longer 30 min. per 2-hour event(eg, batteries) hardware last 100 sessions auditorium cleaning, possible ""disconnect"" ""reconnect"" chairs 4 hours labor.",arduino sensors raspberry-pi computer-vision
2315,Overcorrecting Kalman Filter,"I'm trying get extended Kalman Filter work. My System Model is: $ x = \begin{bmatrix} lat \\ long \\ \theta \end{bmatrix}$ lat long latitude longitude (in degree) $\theta$ current orientation vehicle (also degree). In Prediction Step I get reading current speed v, yaw rate $\omega$ inclination angle $\alpha$: $z = \begin{bmatrix} v \\ \alpha\\ \omega \end{bmatrix}$ I use standard prediction EKF $f()$ being: $ \vec{f}(\vec{x}_{u,t}, \vec{z}_t) = \vec{x}_{u,t} + \begin{bmatrix} \frac{v}{f} * \cos(\theta) * \cos(\alpha) * \frac{180 °}{\pi * R_0} \\ \frac{v}{f} * \sin(\theta) * \cos(\alpha) * \frac{180 °}{\pi * R_0} * \frac{1}{\cos(lat)} \\ \frac{\omega}{f} \end{bmatrix} $ $f$ prediction frequency, $R_0$ radius earth (modelling earth sphere) My Jacobian Matrix looks like this: $ C = v \cdot \Delta \cdot cos(\alpha) \cdot \frac{180}{\pi R_0} $ $ F_J = \begin{pmatrix} 1 & 0 & -C \cdot sin(\phi) \cdot \frac{1}{cos(lat)} \\ -C \cdot sin(\phi) \cdot \frac{sin(lat)}{{cos(lat)}^2} & 1 & C \cdot cos(\phi) \cdot \frac{1}{cos(lat)}\\ 0 & 0 & 1 \end{pmatrix} $ As I far higher frequency sensors prediction step, I 10 predictions followed one update. In update step I get reading current GPS position calculate orientation current GPS position previous one. Thus update step standard EKF Update $h(x) = x$ thus Jacobian Matrix $h()$, $H$ Identity. Trying implementation testdata GPS Track constant northern direction yaw rate constantly turns west, I expect filter correct position close track orientation 355 degrees so. What actually happens seen image attached (Red: GPS Position Measurements, Green/blue: predicted positions): I Idea this. I'm experienced Kalman filter, might misunderstanding something, nothing I tried seemed work… What I think: I poked around bit: If I set Jacobian Matrix prediction identity, works really good. The Problem seems $P$ (the covariance Matrix system model) zero $P(3,1)$ $P(3,2)$. My interpretation would prediction step Orientation depends Position, seem make sense. This due $F_J(2,1)$ zero, turn makes sense. Can anyone give hint overcorrection may come from, I look / google for?",kalman-filter gps sensor-fusion
2321,Tracking 2D positioning IMU Sensor,"I using miniature car I want estimate position. We use GPS modules tracking systems I saw, using IMU senson GPS module. In car able find exact correct location image processing parts dont enough markings this. So want use IMU backup positioning. long positioning close good us. And interested 2D position since car flat ground. I using IMU 9DOF sensor I want calculate movement. I seen amazing works IMU tracking body movements code simple explanation anywhere it. So basically I reading accelerometer, gyro magnetometer. I also orientation quarternions. From device I getting also linear acceleration even I moving direction values 0 really confusing. Can please help approach this? Thanks advance",sensors accelerometer gyroscope
2322,What rating specifications dc motor used making quadcopter?,I want make quadcopter final year project I willing use DC motors four rotors quadcopter. Can one guide ratings proper motor selection job.,quadcopter
2324,Kinematics 4 wheeled differential drive robots,"I 4 wheeled differential drive robot, like Pioneer 3-AT. There two motors, one left wheels one right wheels. I want send velocity commands robot, I'm using ROS standard commands are: [linear_velocity, angular_velocity]. I need convert left right velocities, literature I 2 wheels I this: $v_l = linear_v - \omega * |r|$ $v_r = linear_v + \omega * |r|$ |r| absolute value distance wheels robot ""center"". How I take account I 4 wheels?",wheeled-robot inverse-kinematics wheel
2326,problem simulated sensor Matlab?,"I'm simulating sensor 3D. The sensor determine ($p, \theta, \phi$) origin $\theta$ rotation z-axis $\phi$ rotation x-axis. The sensor given position point($x, y, z$). This I Now I need get Cartesian coordinates ($x',y',z'$). This I [p theta phi] = getmeasurement(x, y, z); x' = p*cos(theta)*sin(phi); y' = p*sin(theta)*sin(phi); z' = p*cos(phi); The sensor working fine beginning particular point behaves strangely. I state vector compare measurement. I'm guessing $\theta$ might problem. Edit: I'm sorry mistake. The aforementioned calculations based following picture So, point rotate first z-axis ($\theta$) rotate x-axis ($\phi$)",sensors sensor-error
2330,Is possible achieve fully autonomous route following using PX4FMU module?,I quadcopter equipped PX4FMU board. You may download datasheet HERE. I wonder whether possible program quadcopter autonomously follow path like circular motion without human interference. Are built-in sensors enough task? I also wonder accurate built-in GPS is? I read gives coordinates radius 5m error.,quadcopter
2331,What Kalman Filter basics aspects?,"My question broad. However I would like complete description last detail way foreign exchange student would understand. I want try best master way Kalman Filter works. Please possibly can, more.",kalman-filter
2336,learning (embedded) electronics,"I aerospace engineer (currently grad school) I really want get (embedded) electronics. But I problem: I understand theory fairly well, I took edX course circuits problem. I build projects internet. However, I hard hard time connecting theory practical part, understanding projects done way done I hard time design projects! Please help! I'd appreciate following: -General tips: learn it? How workflow? What I do? Which steps I take? -Books: hands books websites recommend? I looking books website practical also explain -Kits: What kits recommend combine theory practical? -Anything think important Thank time!",electronics
2337,Monte-Carlo Localization,"I'm implementing Monte-Carlo localization robot given map enviroment starting location orientation. Mine approach follows: Uniformly create 500 particles around given position Then step: motion update particles odometry (my current approach newX=oldX+ odometryX(1+standardGaussianRandom), etc.) assign weight particle using sonar data (formula sensor probability*=gaussianPDF(realReading) gaussian mean predictedReading) return particle biggest probability location step 9/10 new particles resampled old ones according weights 1/10 uniformly sampled around predicted position Now, I wrote simulator robot's enviroment localization behaves: I'm afraid longer period time robot may get lost. If add particles wider area, robot gets lost even easier. I expect better performance. Any advice?",localization motion-planning sonar
2341,How ultrasonic range finders detect objects angle?,"As far I tell, ultrasonic rangefinder works reflecting inaudible soundwaves objects timing return. But object flat surface angled respect line rangefinder, detect object? Under circumstances might give false distance otherwise fail detect object?",sensors sonar
2345,Simple web interface beaglebone black,"This actually simple question, I'm lost moment. I using beaglebone black school project. It controls bunch motors actuators,etc. We wrote everything C++, made libraries functions. When main program calls them, functions run fine. Recently told demo progress far. The main program nowhere near done, thinking sort web interface execute complied C++ program command. We hoping get server hosted board, access via LAN PCs. But I've never done idea start. Does node.js (with 'bonescript') going help? Or simpler way basic HTML? I days figure out, I didn't want waste time looking wrong methods.",embedded-systems
2347,The costs using existing 6 axis kuka/abb robots existing vision systems picking placing tasks,"I would like use Kuka/abb 6 axis robot machine vision system pick place variety metal drill bits size ranges 0.5mm (ascending 0.5mm per cylinde) 13mm metric 1/16 inch ascending 9/64 inch. The machine would differentiate bits, niether drill bit would weight 1kg. Crucially beginning end picking placing I would like inspect tip cylinders inspected 118 degree chamfer one end bit present regardless drill diameter length. I lead believe drill bits placed end conveyor belt always place relatively low cost crucially kuka 6 axis robot find drill bits cost increases dramatically, true?",industrial-robot
2348,What motor use reciprocating (reversive) movement,I want make copy machine Fisher Price Soothing Motions™ Glider I'm wondering motor use? Simple DC motor appropriate gearbox (slow rpm) stepper motor? Here another instance idea.,motor stepper-motor mechanism
2350,Electronic noses detecting dog urine,"I limited experience sensors robotic components all, I hope excuse lack detail Question. I want set posts around yard electronic noses detect dog urine. I want use information make map yard dogs perspective. Is possible todays technology? What would cost? There may information relevant me, I'm requesting. This lacking insight. If something think I consider research, please say so.",sensors electronics
2356,Line follower robot program,"I working line follower robot part Microelectronics project, confused sort code use program ""pic18f"" microcontroller I'm using. Can someone give source code layout code there?",c line-following
2357,Cons pros wireless technologies rescue robot,"robotics enthusiasts! I'm member team develop mobile rescue robot cooperate firemen (e.g. earthquake sites). The problem connection commander post robot. The robot enter buildings, desirable connection go several decimeters walls reach 50-100 meters. On hand, need send lot data (camera images, point clouds, maps) easily eat 10 Mbps more. At time use 2.4 GHz WiFi connection. As speed, direct visibility seems sufficient, single robot operating (we use 3 non-overlapping channels, theory 3 robots work together; usually environment messed home routers). We need least 5 robots operating simultaneousely. We tried 5 GHz WiFi, problems penetrating walls, used UAVs. My idea use mobile connection technology like LTE. I found LTE run 800 MHz, could great wall penetration performance. I also found LTE's theoretical upload speeds (for clients) 70 Mbps, nobody says 2.6 GHz would changed running LTE 800 MHz. Moreover, cannot rely provider's coverage. I found build LTE transmitter €2000, seems interesting us. Maybe possible build even cheaper. But think 2.6 GHz 800 MHz regulated frequencies. However, cooperation firefighters could persuade local regulators give exception us setup small LTE base station. And question: think setup would give better results using WiFi? Or know technologies would help us either increase bandwidth wall penetration performance? What cons pros?",wireless
2361,Explanation Kalman Filter,"I beginner robotics, I learning Kalman filter. I seem get it, though. I mathematician, would helpful Kalman filter could explained mathematical method.",kalman-filter
2362,Actuator control steam valve,I steam radiator home valve similar picture below. Please note valve doesn't grooves top attach things to. I want build something turn depending temperature certain points room. I taken care cannot find way attach actuator(actuator right word context I guess?) turn valve directions. Also It rented apartment I would like avoid making modifications radiator itself.,actuator valve
2363,Building mobile camera platform,"I zero experience robotics, I need build mobile platform streaming camera. The idea I'll plug Android phone pan/tilt unit wheeled robot drive look around via WiFi. I already solved software, interface controller issues, I would appreciate advice build wheeled platform. My initial idea buy cheap RC car, remove electronics replace own. This approach almost worked. I purchased New Bright F-150 Truck. The size good plenty storage space: However, I quickly ran problem thing. I assumed front wheel would turned kind servo. Instead I found nonsense: That small gear shaft driven servo - it's conventional motor, spins jammed extremes travel. The wheels straightened power removed small spring side. This means one angle wheels turned, angle way small I need. So using RC car work. Before I start buying things, I would like hear opinions experienced people. Am I right track? Do I simply need get better RC car, designed like this? Perhaps options would suitable I doing?",mobile-robot
2365,covariance matrix EKF?,"I'm struggling concept covariance matrix. $$ \Sigma = \begin{bmatrix} \sigma_{xx} & \sigma_{xy} & \sigma_{x \theta} \\ \sigma_{yx} & \sigma_{yy} & \sigma_{y \theta} \\ \sigma_{\theta x} & \sigma_{\theta y} & \sigma_{\theta \theta} \\ \end{bmatrix} $$ Now, understanding $\sigma_{xx}$, $\sigma_{yy}$, $\sigma_{\theta \theta}$ describe uncertainty. For example, $\sigma_{xx}$, describes uncertainty value x. Now, question rest sigmas, represent? What mean zeros? I interpret $\sigma_{xx}$ zero, means I don't uncertainty value x. Note, I'm reading Principles Robot Motion - Theory, Algorithms, Implementations Howie Choset et. al., states By definition $\sigma_{ii}$ $\sigma_{i}^{2}$ variance $X_{i}$. For $i ≠ j$, $\sigma_{ij} = 0$, $X_{i}$ $X_{j}$ independent other. This may answer question rest sigmas zeros however, I'm still confused relationship variables example $x$ $y$. When happen? I mean correlation them. Or words, I assume zeros? Another book namely FastSLAM: A Scalable Method ... Michael Sebastian states The off-diagonal elements covariance matrix multivariate Gaussian encode correlations pairs state variables. They don't mention correlation might happen mean?",kalman-filter noise
2371,Compensating Yaw Lateral Quadcopter Movement,I'm trying make quadcopter move laterally certain angle. I've able find proper roll pitch angles (that work yaw 0°); would I adjust values compensate different yaw?,quadcopter gyroscope movement dynamics
2373,Using vision Monte-Carlo localization,"From step vision code I able get around 400 coordinates robot thinks walls I want integrate Monte-Carlo observation step. I'm storing map maze set Line segments. What would nice way implement sensor update, i.e. given position (x,y) robot probability found given described coordinates walls. The main idea I currently have: Transform points polar coordinates. Then point (from vision output) compute ray angle find first intersection maze. Now predicted distance real distance compute probability measurement right. The main drawback slow. For point vision output I iterate line segments find one closest intersection. The line segments number around 50. So gets O(400*50*Particle number).",mobile-robot localization computer-vision
2374,Maximum angle camera pose correctly estimate homography,"I want capture two views scene. The scene consists set objects kept table. From two views, I wish calculate homography image matching. I want know maximum angle two views homography accurately calculated. Right now, I capturing images around 60 degrees angle, unable construct homography accurately.",kinect computer-vision stereo-vision
2376,Kinect Xbox: SDK selection,"My application basically sound source localization visual servoing. I selected Kinect main hardware. I already know basic differences Kinect Windows Kinect Xbox. I cannot access windows version country (no reseller Turkey), xbox version stores. I sure problem specific software selection. I found latest Kinect SDK supports sound source localization (and beamforming) using built-in microphone array. Can I use SDK within xbox version? Or another SDK xbox, support? I sure I also read OpenNI provide best audio API. I also apply processing image & depth outputs, I using OpenCV. I also want use Qt threading, GUI etc. So, another question: Is possible use microsoft official kinect SDK within another IDE, Visual Studio?",kinect
2379,Water depth arduino sonar sensor,"Just like fish finder finds depth water directly beneath it, Im trying find sensor I purchase Arduino same. would like check 20 ft least, high accuracy, +/- 10 15 cm. All threads info I've finding water level sensors water depth. So anyone know sensor like I find one?",arduino microcontroller underwater
2382,Motion Model Holonomic Robot,We working holonomic robot equipped three (120 degree shifted) omnidirectional wheels. The relative movement estimated dead reckoning using wheel encoders. To improve estimation installed gyroscope measure change orientation. Furthermore robot 270 degree laser range finder. In order solve kidnapped robot problem implemented particle filter. In every step particle updated according odometry gyroscope readings. Since readings distorted noise need motion model include errors. As described Probabilistic Robotics Thrun (Page 118 - 143) two commonly used motion models (velocity motion model odometry motion model). However models seem describe behavior differential drive robots omnidirectional robots. I base thesis fact error relative y-direction proportional error orientation far motion models Thrun concerned. This appropriate differential drive robots orientation heading robot identical. For omnidirectional robots assumption made since heading orientation completely independent. Even assume perfect information robots orientation still obtain error relative y-direction. I would like discuss assumption - velocity/odometry motion model fails omnididrectional robots - correct sure that. Furthermore curious motion models omnidirectional robots might fit better.,mobile-robot localization motion particle-filter
2387,How I start programming proto X quad,I bought really small proto X quad (it joystick navigates device) I looking way send signal thing computer. So anyone point I turn one propellers quad using laptop (I decent knowledge python/matlab/C# hardware completely new world me).,quadcopter programming-languages
2394,LIDAR solutions,"I surprised price range Lidar applications considering simplicity design. I try make simple project requires lidar object recognitions etc. I wouldn't like use Visual Recognition OpenCV. Regardless I trying understand Lidar solutions expensive see Small lidar sensor goes 20,000$. I strongly believe Lidar next step robotic applications I sure EXCLUSIVE. I seen projects go around 200$ performance bad. I hope answer makes Lidar expensive cheap systems hobbyist afford.",arduino computer-vision lidar
2396,Generic name two-motor wheeled/tracked robots?,Is generic name category robots move using two opposing wheels tank-like treads?,mobile-robot differential-drive
2402,How to: Attach wheel encoder motor?,"I couple DC motors Which extended motor shaft sticks back 1mm diameter. I'm trouble trying think best way attach encoder disk shaft. I thought getting custom wheel 3d printed make opening 0.9mm tight fit. But I don't know small? I also though taking encoder disks PC mouse drilling 1mm / 0.9mm problem added difficultly trying drill small hole small thing. So I wondered anyone knows better way, made disk attach. As I can't find anything 1mm shaft",motor
2409,Connections Baby Orangutang B-328 board,"I new robotics planning first purchase. I'm looking Baby Orangutang B-328. Here information microcontroller: . The pin headers come unmounted, soldering yourself. My problem I don't know pin connections for. Here picture board: . Could someone briefly tell different connections for, link website does?",microcontroller
2411,Robotic part dispense candy,"I'm complete newbie trying build simple robot dispenses candy (M&M, skittles, etc). However, since I'm familiar field, I'm hard time googling I don't know correct terms search for. I'm looking piece build robotic 'trap door' sorts open specified amount time release candy. What parts I use called? I've tried robotic lever, robotic door, etc luck.",design
2413,Why analysis required study robotics?,I studying Informatics I interested Masters Robotics I checking unis courses I saw Robotics contains analysis lot math. Why that?,software
2416,Low Amp FPV Quadcopter Motors,Why FPV Quadcopter Motors (usually expensive ones) draw lower amps regular motors? And squat(disk shaped) opposed normal motors diameter height?,motor quadcopter
2418,Quadcopter Props? Wood vs Plastic vs Carbon Fiber,All pro FPV builds expensive quads don't seem using plastic props. Any reason this?,quadcopter
2421,"Just run program NXT, download?","Is way I simply run program NXT, download it? I programs already downloaded, I connecting USB cable MacBook Pro using NXT-G interface. Is way I run programs existing NXT computer, download them? It's really increasing robot's run time. I competing Robocross Science Olympiad, event noon. Thank you.",nxt usb
2422,Is configuration space joint space?,For robotic manipulator like one picture: configuration space joint space equivalent? I trying understand difference two...,kinematics motion-planning forward-kinematics
2423,What quadcopter propeller specifications mean?,"I'm trying figure diameter tri-blade propellers. I found 7x3x4.5 blade, I'm trying understand measurements. Is '7' length blade giving prop 10.5"" diameter? 7 total diameter?",quadcopter design
2424,Android phone + ADK + Arducopter APM 2.5 autonomous quadcopter,"project robotic lab, i'd like build automous quadcopter able follow path land own. I'd like use onboard android phone image processing recognition part, I avoid send video stream control station, process send back commands. As I need use indoor environment (so GPS coordinate), I need phone guide quadcopter giving relative directions like FORWARD 1 sec STOP. This something normal pilot would via RC radio. I already arducopter APM 2.5 arduino mega ADK I thinking connect phone ADK ADK APM guide copter. I think I 2 options: either ADK generate PPM/PWM signals RC receiver would use mavlink protocol. Which best/easiest solution? Other info: -I already read checked UAV related websites, I couldn't find something close I want. In them, try build new type controller, use ab Android phone + ADK. I'd like stick something already tested known work (as APM & arducopter software) I don't want use phone IMU don't trust sensors -I already built quad (a hexa actually) -I already set connection protocol phone adk i'm able send commands like, i.e. forward, turn, hover etc... -I already checked andro-copter project similar ones. -I might consider platforms APM 2.5 there's something easier use -It'd nice keep RC receiver loop regain control quad something goes wrong.",arduino control quadcopter ardupilot
2426,How programatically calibrate Turningy esc?,"I Turnigy ESC I controlling AVR. Now I need calibrate set range input. With servo tester I managed calibrate without problems, less following user guide, I try procedure code, ESC starts beeping confused pattern enters programming mode. My code looks like this: +SERVO_RANGE_TICKS 2.2ms pulse length, -SERVO_RANGE_TICKS 0.8ms pulse length 0 1.5ms. The timeouts 10s measured manual calibration stopwatch. I checked oscilloscope output servo signal looks way I would expect -- 10 seconds 2.2ms pulses, 10 seconds 0.8ms pulses 1.5ms pulses. Edit: I made mistake here, see answer. Do idea change calibrate ESC?",c calibration esc avr
2433,What minimum torque required CNC stepper motors spindle aluminium milling?,"I planning buy CNC mechanical skeleton without motors, spindle controller. I using CNC mainly aluminium milling. Are specifications minimum torque requirement stepper motors spindle perform aluminium milling ?",stepper-motor cnc
2434,Is possible make DIY clone MakerBeam,"Is possible make clone easy accessible material like: wood plywood OSB MDF HDF others Using type CNC machine mill holes rails materials may give sufficient results e.g. make prototype 3D printer ""beams"". Of course won't rigid durable making prototypes may good idea. Just reference: reading I've found , , .",mechanism
2435,JSP container embedded systems,"There project I working using BeagleBone need JSP container run it. I thinking Tomcat wanted know Tomcat suitable embedded systems. Is resource-heavy? If yes, lighter JSP containers? I know Tomcat Jetty.",beagle-bone
2443,How link ends timing belt loop,When I buy length timing belt I don't know link ends timing belt loop. So far I've found one way (thanks ): Any ideas?,mechanism
2445,Transformation robot 2D?,"I'm watching video 36.00 min. The guy gave example I'm sure problem. He stated want move robot following inhomogeneous case, $$ x' = Rx + \\ R = \begin{bmatrix} cos\theta & -sin\theta \\ sin\theta & cos\theta \end{bmatrix} $$ $t$ translation vector $x$ previous position. homogeneous case, $$ x' = \begin{bmatrix} R & \bf{t} \\ \bf{0}^{T} & 1 \end{bmatrix} x $$ Now, gave example $$ = \begin{bmatrix} 1 \\ 0 \end{bmatrix} , x = \begin{bmatrix} 0.7 \\ 0.5 \end{bmatrix} $$ My solution following Matlab For homogeneous case >> xn = [R t; 0 0 1]*[x ; 1] xn = 1.1414 0.8485 1.0000 Both result, guy got another result. What exactly >> xf = [R x; 0 0 1]*[t ; 1] xf = 1.4071 1.2071 1.0000 Why switch $t$ $x$? I'm aware issue trying calculate velocity fact computing position. This mistake notation won't affect final result. Second question, assumed forward movement robot example $$ = \begin{bmatrix}1\\0\end{bmatrix} $$ ? He said robot always forward movement move +x axis. Why case? The movement robot's frame determined based direction robot distance robot travels specified hypotenuse length.",mobile-robot
2446,RC Helicopter Connect computer,I planing control RC helicopter computer. I experience programming .Net. Could use .Net control RC helicopter? From I start project?,control radio-control
2453,Quadrocopter first build: tell components play well together?,"I'm building first quadrocopter, I'm trying come parts list suitable first build. I use learn fly quadrocopter manually (lots crashes!), experiments running AI piloting it. A couple questions list parts: Is good choice first build? Are missing crucial parts? Do components work together? Is battery strong enough fuel components need power? Here's current list parts: Frame - 450 mm Propellers - 10x4.5"", two pairs Motor (4x) - 900kv brushless outrunner motor; max current: 18A; ESC: 25-30A; cell count:3s-4s lipoly Electronic speed controllers (4x) - 20A constant current, 25A burst current; battery: 2-4S lipoly Battery - 3300mAh lipoly, 11.1v, 3 cell; constant discharge: 30C, peak discharge: 40C. charge plug: JST-XH. 3300 mAh x 30C = 99 amps? Charger - lipoly, 50W, 6A, 12v power supply Power supply - input: AC 100-240v 50/60Hz; output: DC15v 5A Arduino board Gyroscope arduino Accelerometer arduino GPS sensor arduino? RC transmitter arduino RC controller",arduino motor sensors quadcopter
2456,How Interference Avoidance Collision Avoidance different?,Someone told explaining controller module named checks self-interference moves accordingly without detecting collision. To sounds same. How different? Thanks.,untagged
2458,What I study I want get robotics?,"I understand broad question I'm taking risk ask anyway. Robotics, I tell far, detailed, diverse, thorough field. However, better areas research invest time into, would areas be?",research
2462,Connecting Raspberry Pi roomba via FTDI cable,"I Raspberry Pi FTDI cable Roomba 560. The Roomba SCI port allow control roomba via serial. I installed PySerial library pi send valid commands Roomba, roomba doesn't respond. I TXD cable attached TXD roomba, RXD cable wired RXD roomba, ground cable wired ground roomba (everything it's respective port). I power going cable roomba vice-versa. What I can't figure commands aren't working. There's error message upon running python code. This information sheet Roomba's SCI port. Code:",mobile-robot software wheeled-robot
2465,Alternatives Primesense depth cameras?,"I'm looking low-cost depth cameras (less 1000 USD) range 3 meters. Currently, I found SoftKinetic DS-311 meets requirements. Here low-cost cameras I found, short range: pmd[vision] camboard nano SoftKinetic DS-325 others long range high cost Panasonic D-Imager pmd[vision] CamCube 3.0 SwissRanger SR4500 Odos Imaging Real.iZ-1K",sensors kinect computer-vision
2470,GPS Amplifier - Is reliable?,"I'm multimedia developer searching way get GPS signal inside buildings/structures. Is amplification reliable way fix GPS signal issue? Will ""GPS Amplifier"" work perfectly using GPS outside?",wireless gps
2476,Benefits Number Propellers,"I planning creating quad-copter Arduino I have. I created land robots aerial vehicles, new me. I looking Internet different models, I see robots 4 propellers. I also seen hexacopters (?) octocopters many propellers can't get hand. Does 4 propellers best efficient thrust weight ratio, 3 propellers/arms work better?",quadcopter
2478,Ros ~ Android sensor driver,"I try connect android device computer ROS. tutorial explains good. I download application android device set ROS_MASTER_URI.. When I run application, phone shut node seen 'rosnode list' Is anyone experience similar error?",ros
2480,looking circular track bearing spindle,"I've really tried find something online that's suitable I'm I've two concentric circular rings, one diameter 10mm smaller larger . The rings region 300mm diameter. I'm trying find way connect two together allow smaller 'slide' circular rotational way within larger one. I'm also trying let 2 rings pivot vertically relation - intention producing gyroscopic-esque motion. What type bearings/tracks/spindles would suffice?",tracks linear-bearing
2481,writing simple program processing RGBD video OpenNI,"I would like write simple program processes depth feed Asus xtion depth sensor using OpenNI. The sensor fixed like CCTV camera count multiple targets moving around. The processing would involve simple functions frame (background subtraction, level sets, connected components filter), multi-target tracking across frames. I searched web, hard see best get started (and I'm also quite new programming C). Can anyone recommend existing code help get started / libraries would suitable real-time application? Or perhaps opensource code already thing? Would really appreciate pointers anyone experience. Thanks!",openni
2486,VAL language velocity control industrial robot,"In bachelor, I programmed CNC machines. Now, working Industrial robot arm, I learn programming languages mostly similar. VAL typical example, instance: Most cases, control robot arm similar example. Cleary, move end-effector point given pose. But... way I control end-effector (EE) speed? An example ""Move EE P1 time duration T1"", ""Move EE P1 velocity V1"" (I could seen defining joint rotational velocity) In way speaking, I command EE move P0 P1 cannot control duration traverse necessary cases EE velocity control This programming manual robot . The velocity control I'm talking joint velocity end-effector velocity. But EE_screw = robot_Jacobian*joint_vel means control EE velocity, resolves control joint velocity. About inverse kinematic, I've already programmed module solve robot experienced robotics programming VAL please help! I've stuck problem months",control manipulator
2488,Can motion model noise zero?,"Can I assume noise motion model zero? If so, consequences so?",kalman-filter noise ekf
2489,VeX - Keeping arm angle,"So team made Vex robot toss-up competition, need arm autonomous. The problem it's heavy stay own. I going use encoders count angle arm at. I going use code, I'm sure there's better way. Would anyone recommend better solution best way? This untested way.",arm
2491,How color sensors used line following?,I build line following robot able detect selected colored line floor start following it. How color sensors detecting specific colored line?,mobile-robot sensors
2494,SLAM Autonomous car,I working SLAM autonomous car like vehicles 2D lasers IMU (deriving odometry). I would like know efficient using existing SLAM algorithms (for example: gmapping ROS based rao blackwellized particle filter). till find MAP high volume speed vehicle high importantly computational time compared Mobile robots. Are important factors consider car like vehicles using SLAM algorithm. thank you.,mobile-robot localization slam
2498,Forward Kinematics Two fixed standard wheels,What would equations robot's angular linear velocity P also P2? I think I'm wrong... WL = left wheels angular velocity WR = right wheels angular velocity For P I example linear velocity = (1/3)*r*WL + (2/3)*2r*WR Am I right track?,kinematics wheel
2499,Can inverse dynamics control regarded function?,"I know inverse kinematics ($p \rightarrow q$, p: desired pose end-effector, q: joint angles) function might multiple joint angle vectors q result pose p. By inverse dynamics control I mean mapping $(q, \dot{q}, \ddot{q}) \rightarrow u$ (u: required torques. I experienced kind problems. Is mapping function, i.e. triple $(q, \dot{q}, \ddot{q})$ unique solution u? My intuition says is. But I sure. If not, would always possible obtain solution averaging two solutions?",dynamics
2504,Jacobian method inverse kinematics,"I big problem. I solve inverse kinematics manipulator 6-DOF using jacobian method. From I know I need matrix transformation Denavit–Hartenberg parameters, I have. But I mathematician, descriptions I find web even bit understandable me. So I would love could give example solve problem. The Denavit-Hartenberg parameters are: $$ \begin{matrix} \alpha & l & \lambda & \theta\\ 90 & 150 & 0 & var(-69) \\ 0 & 610 & 0 & var(85) \\ 90 & 110 & 0 & var(-52) \\ -90 & 0 & 610 & var(62) \\ 90 & 0 & 113 & var(-60) \\ 0 & 0 & 78 & var(-108) \\ \end{matrix} $$ The values theta values get following matrix transformation, values I want get jacobian method. And values degrees. Matrix transformation: $$ \begin{matrix} 0.7225 & 0.0533 & 0.6893 & 199.1777\\ -0.2557 & -0.9057 & 0.3381 & -500.4789\\ 0.6423 & -0.4206 & -0.6408 & 51.6795\\ 0 & 0 & 0 & 1 \\ \end{matrix} $$ I would greatful, someone could walk solve simple language.",inverse-kinematics
2507,robotics beginner,I want begin robotics.So beginner micro-controller would convenient?Arduino PIC?what type robots built arduino PIC? Should I start line-following vehicle?,arduino microcontroller beginner
2508,Looking way scan cylindrical objects,"Can anyone recommend commercial solid, reliable DIY solution scanning cylindrical objects? I've seen couple simple hacks flatbed scanners, I'm looking something I could make buy commercial project work reliably. Many thanks",stepper-motor
2510,Slam Vision (good resources)?,"I would like know good source combines Slam problem vision. From mathematical perspective, numerous resources handle SLAM ,however, I didn't find good source focuses slam vision.",kalman-filter slam ekf
2511,Find difference two consecutive sensor readings real-time C,"I working Micromouse three sensors. Call S1,S2 S3. For now, I use S1. The idea S1 controls left motor S3, right motor. S2 detect wall front. Anyways, I trying write code C dsPIC30F4011 MCU would continuously read Sensor values reading two consecutive values, compare two values. Read happens every 0.1ms. The Flow Code follows: So look line *, I compare two sensor values real-time every 0.1ms ? Let know one wants info!!",c micromouse
2519,"How measure displacement, cheaply without using accelerometer?","Motion known confined sphere radius 0.5m, resolution doesn't high (5cm enough). The device actually incorporated toy designed kids. I tried implementing accelerometer estimated displacement drifted away 100s meters per minute. Is solution, maybe involving electrical magnetic fields? It's important sensor costs bucks. Edit: The device attached anything mechanical movement 3d (a kid moves toy freely).",sensors imu
2524,How calculate power required drive fan,"I need specify fan motor combination wondered formulas work out? The fan using crossflow fan: So I'm assuming power required drive derived number blades, dimensions blades (including angle attack), dimension barrel/wheel speed RPM. Is possible need worked practically experimental measurements etc? Hopefully correct stack question, mods please feel free edit/close.",motor power
2526,Neuromorphic Engineering Robotics,"I boggling paper research neuromorphic engineering implications robotics applications, lately. It relatively less applied field full academic papers difficult skim easily :) There many ongoing projects applying analog digital circuitry design implement neurosynaptic simulations brain. Consumer oriented products like IBM Synapse Qualcomm's Zeroth focus digital hardware whereas academic research like Standford's neurogrid ETC Zurich's Human Brain Project focus actual brain study using analog hardware. If anybody following engineering field, he/she spread light explain it's implications, methodologies toolsets community, detail? PS : Regarding toolsets, I'm talking feasible engineering methodologies commit field.",mobile-robot artificial-intelligence research machine-learning
2530,Help sending serial command Roomba,"I Raspberry Pi hooked Roomba 560's serial port. While going spec, I noticed movement controls weren't simple I expected. I can't send bytes larger 255, but, according spec, go straight I send 8000. How work? EDIT: My solution following three functions:",mobile-robot raspberry-pi serial irobot-create roomba
2531,Why ROS real-time operating system?,"ROS real-time OS. After reading architecture ROS, I unable realize ROS real-time? What part architecture design decision causing that?",ros
2542,What call coupling infinite range rotation,"In situations, range motion limited fact need carry power information past joint. So, past certain point either cables way, cables would stretch much would either prevent movement break. However, situate conductors concentric rings around within rotor shaft, joint rotate forever keeping contact modules side. What call mechanism? Does even name?",motor motion joint
2545,arduino serial mixing incoming commands,In project i'm aiming control quadruped robot android phone using raspberry pi middle device (web server). In order make sure server RPi working fine googled got app sends specific character whenever button clicked arduino job simply receive serial port blink led! (so easy huh?) problem noticed leds blinking click button assigned them! disaster controlling robot! Does anybody know reason solution?,arduino serial
2552,Best Way Sense Rubiks Cube Movements,"I wondering was, opinion, best way study different motions Rubiks Cube. I want able recognize face moved direction. Would I able get direction face accelerometers/gyro yes many would I need? If ever used Leapmotion Kinect, possible achieve using those?",accelerometer motion
2553,Capacitive touch input robot remote access iPad,I'd like buy capacitive touch input robot order remote access iPad I'm trouble describing correct kind robot. I would like keep lag additional 60ms still high quality interface. I would like robotic arm equipped capacitive pen moves places ipad screen based mouse I'd like array capacitive pens emulate touch user. I guess I'd use Squires software reflect mirror function I'm open using SHD camera robotic arm pixel sensor array array capacitive pens. Does make sense? How could I improve design? What materials would I need build myself. Assuming ready built arm? How could I build array capacitive touch micro pens?,robotic-arm
2555,Any image transfer protocol wireless serial transfer?,I want send image wireless serial communication. I planning capture images using either raspberry pi stm32 mcu using DCMI transfer image using wireless serial communication module Xbee 3DR radio provide air data rate upto 250Kbps baud rate 115200 I would like know protocol send jpeg compressed image wireless serial data.,raspberry-pi serial communication wireless
2556,How rotate covariance?,"I working EKF question regarding coordinate frame conversion covariance matrices. Let's say I get measurement $(x, y, z, roll, pitch, yaw)$ corresponding 6x6 covariance matrix $C$. This measurement $C$ given coordinate frame $G_1$. I need transform measurement another coordinate frame, $G_2$. Transforming measurement trivial, I would also need transform covariance, correct? The translation $G_1$ $G_2$ irrelevant, I would still need rotate it. If I correct, would I this? For covariances $x$, $y$, $z$, first thought simply apply 3D rotation matrix, works 3x3 submatrix within full 6x6 covariance matrix. Do I need apply rotation four blocks?",kalman-filter
2559,Are propellers dangerous?,Aren't propellers super dangerous? How startups like Hex Pocket Drone selling drones 'kid-friendly' consumers? What happens kid puts finger propeller's movement space flying?,quadcopter
2563,Connecting Wifi bee Xbee USB adapter,"I started follow ""Get started Wifi Bee"" tutorial Wifi bee v1.0 wiki page. I using Xbee USB adapter v2.0,Wifi Bee-RN-XV,mini USB cable listed Tools needed. When conneted Xbee USB adapter v2 computer via mini USB cable Wifi bee didn't light (but USB adapter light up). Then followed steps till number 4, "" Send AT command $$$ wifi Bee reply ""CMD"" indicate enter command mode properly"". When sent command, didn't reply anything. I typed commands like show net scan, didn't reply either. When tried Arduino Server example wiki page, Wifi bee lighted up. But gave strange ip address port 200, entered ip address browser address, browser couldn't find page. So question Xbee Usb adapter need extra power sources? Or doesn't fit Wifi Bee? I don't think problem usb cable, 'cause computer found device.",wifi usb
2564,How use TOA (Time Of Arrival) measure 3-axis location wireless device?,"I need read location device within 1m radius sphere, accuracy 5-10cm. The device handheld wireless, currently communicates using Bluetooth v4 chip. I could add RF transmitter moving part stationary receivers base. What components I look into? What would cheapest way triangulate it?",sensors imu
2570,Do servo motor specifications take account gear ratio inside?,I looking buying servo motor application must able lift 4-5 lb rotational speed approximately 1rpm. The servo motor listed states stalling torque 200 oz-in. Is torque rating horn servo motor torque rating actual motor gear reduction done? Is motor sufficiently strong application?,motor servos servomotor
2571,Sensor tracking relative position human,"I making robot needs continuously track relative position human, 15 meters away least 300 degrees coverage. Currently I using Hitechnic IRSeeker v2 sensor made beacon wristband 6 TV remote IR LEDs. But maximum distance I get around 3 meters. I ordered 3 watts IR LEDs boost power, size wristband problem run CR2032 battery. I also bought IR remote receivers. But I sure reflection wall give false results. Is I trying possible? Is beacon 15m away feasible using technology? If is, I need modify current implementation? If not, technologies I considering track relative position direction human, 15 meters away least 300 degrees coverage?",sensors
2575,PID control sine wave error,"I'm writing PID control toy car follows black line circuit. I've tuned PID works high speed circuit except winding section. For that, error signal looks like sine wave, toy car steers much. I would like go close straight, possible? Edit: My car sees 100 grey points line ahead, difference darkest point middle visual range error signal. My output angle servo front wheels car, speed back motors constant. The desired performance would oscillate amplitude less amplitude winding road, actual performance car steers close sine line one period, next max amplitude steers. Sorry, I can't provide graphs right I'll try add next days. Is formula adjusting PID constants desired PID bandwidth?",pid
2580,Fit robot simulator robot,"I odometry data $(x, y, angle)$ real two-wheeled robot, received control commands $(forward speed, angular speed)$. Now I want code motion model (in C++ (/ROS)) follow trajectory, given control commands. Normally, kinematics look something like this: $$ \begin{align} v_{fwd} &= control_{fwd} \\ v_{ang} &= control_{ang} \\ x &= x_{old} + 0.5(control_{fwd} + v_{fwd,old}) * \cos(angle) * dt \\ &= y_{old} + 0.5(control_{fwd} + v_{fwd,old}) * \sin(angle) * dt \\ angle &= angle_{old} + 0.5(control_{ang} + v_{ang,old}) * dt \end{align} $$ And I thought setting $$ \begin{align} v_{fwd} &= control_{fwd} + k_1 v_{fwd,old} + k_2 v_{fwd,old}^2 + k_3 v_{ang,old} + k_4 v_{ang,old}^2 \\ v_{ang} &= \text{ ...analog...} \\ x, y, angle &\text{ unchanged} \end{align} $$ search minimum squared distance computed trajetory real one - depending values $k_i$. This would mean either good optimization algorithm brute-forcing / randomly testing lot values. Is way go here? I tried 2nd approach, results far good. So, might guess now, I'm pretty new this, help appreciated.",wheeled-robot kinematics algorithm
2587,Reading data D+ D- pins USB,"So I optical mouse me, PAN3504DL-TJ optical sensor. It USB interface I looked internet, I could find tutorials using A2501 sensors lines pins like SCLK SDI I don't instead I D+ D-. I understand data pins I take two wires plug Analog Pins dsPIC30F4011 read data it. After setting UART communication transmitting data, I get numbers running continuously. What I want read coordinates analog pins mouse aka sensor moves surface. I would use position control robot. So question I read coordinates Optical Sensor D+ D- lines Analog Pins ?",sensors
2588,Robotics StackExchange vs ROS Answer,Robotics Stackexchange vs. ROS Answer: What better purpose?,ros robotc
2591,Denavit–Hartenberg parameters robot spherical wrist,"What valid values Denavit-Hartenberg parameters $d$ $a$ (sometimes called $r$) last 3 links robot spherical wrist? From reference, ""A spherical joint represented three consecutive rotary joints intersecting rotation axes."" So retrictions be: $L_{n-2}$ ($d$ arbitrary, $a=0$) $L_{n-1}$ ($d = 0$, $a=0$) $L_{n}$ ($d = 0$, $a=0$) But exam I found internet, It says KUKA robot spherical wrist, $d$ last joint different $0$. Would $d\neq0$ last link still yield spherical wrist?",kinematics joint
2593,Sourcing Motors larger robots,"I wanting build larger robots r/c cars time now, one issue I trying find larger motors, range electric wheelchair motor size. I found one set ebay I trying find reliable source these. To make question clear, I looking reliable source(s) medium size electric motors around size power rating typical electric wheelchair motor",motor
2594,24v dc 12vdc converter,"I built r/c car runs 2 30AH 12V DC deep cycle batteries. The motors 24v motors draw around 15A full power. My motor controller handle this, well reclaiming braking energy. This way saying 24v power system. Now issue I want run 12v device 24v service. I want hassle another battery maintain would like power main batteries. All BECs converters found supply around 1 amp device looking powering take around 4-5A 12v DC. Does anyone know device this.",bec
2595,Control Arduino firmata HC-05,"I'm using johnny-five library control Arduino Uno running StandardFirmata. I HC-05 bluetooth module I want use wirelessly control firmata, yet get working. I used configure board 57600 baud rate: . I'm able send various AT commands read back results serial monitor. I followed wire voltage divider, make Arduino's TX operate 3.3 going HC-05's RX. I've tried running HC-05 master, slave, slave-loop. It makes BT connection slave, default. When I run johnny-five script, here's output: ± node jf-simple.js 1394412173445 Board Connecting... 1394412173447 Board -> Serialport connected waiting board ready 1394412273448 StandardFirmata A timeout occurred connecting Board. Please check you've properly loaded StandardFirmata onto Arduino 1394412273448 Board Closing: firmata, serialport I've more-than-triple-checked everything. Uploaded firmata many times. Firmata works fine USB. Also, I able get working past HC-06. Am I missing something? What good debugging techniques figure won't connect Firmata?",arduino troubleshooting
2596,Atlas Robot Reference,"Boston Dynamics keeps making great robots, however, I dont see papers publish. Although I find papers people using ATLAS robot, I find original paper detailing robot mechanics designs. Is reference robot, I use youtube videos?",design mechanism humanoid
2597,Software libraries parsing sensor data,"What software libraries assisting general problem parsing stream sensor data? We use various sensors like LIDARs GPSINS units provide messages proprietary binary formats, write drivers one. Even though there's lot similar concepts used sensor (like general purpose datagram messages, consisting e.g. start/end sentinels, length specifications checksum, variety well-defined message formats payload), ends lot tedious work develop driver time. I'd love solution I write packet/message specifications format, library finds & extracts valid messages stream, provides simple data structure format. I'm fussed language, basically want general purpose datagram parsing library. There's lot customisation sensors, maybe odd format parsing, probably initial configuration start data stream, really something I want library processing data real-time used part driver/application. Everything I find either basic (the low level tools interpreting individual elements, still lots time spent extracting individual elements explicitly), specific (i.e. parsers written specifically one particular protocol). As concrete example, consider NMEA messages: There's basic outer datagram (starts followed message name, comma separated data, ends *, checksum line terminating character) Data ASCII needs parsed binary computational use Outer datagram allows validation removal incomplete/corrupted messages Message name & content would parsed consumption Field names specified ease use A 'GPGLL' message might turned $GPGLL,4533.21,N,17739.11,W,113215.22,A*31 programmatic data structure containing latitude, longitude, UTC timestamp validity.",sensors software driver
2600,Need Troubleshooting help regarding Arduino Uno & HC-06 Bluetooth connection problem,"I bought Arduino Uno HC-06, I hooked connections: 5V Bluetooth → 5V Arduino GND Bluetooth → GND Arduino TDX Bluetooth → RX →1 RDX bluetooth → TX → 0 Here pictures: My problem I cannot seem search Bluetooth connection Laptop phone. Is something wrong I here?",arduino
2604,Differential drive trajectory following control,"I robot platform differential drive knows it's position orientation. Lets say space robot moves known static obstacles. The task move robot point A heading alpha (on currently stands) point B heading beta map. Lets also say I obtain reasonable trajectory (in relation turning abilities robot). As robot sensors inert, general approaches controlling robot follow path? It course kept mind final task reach point B without colliding obstacles perfect trajectory following. I hope question general.",control pid navigation differential-drive
2606,Where ask NXP LPC1343 / ARM Cortex M3 related questions,I beginner robotics embedded systems. Consequently I lot questions related toolchain things going together like debug connect bluetooth module. I already tried work me. Any ideas I get help LPC1343 related questions?,microcontroller arm embedded-systems
2609,Arduino Operational Frequency,"Just wanted clarify pretty basic Arduino concept: If I put code arduino board: ...I see >38000 value serial monitor (for 'counter' variable). However, moment I put heavy calculation 'Point A', value drops 150 - 170. This expected, I guess. My question is: Is way push operational frequency lies optimising code/calculation? Or, way I get faster execution?",arduino
2610,function PIDControl #pragma config() directive robotC,"I trying sync motors VEX Cortex based robot mixed success using encoders position control. I noticed motor setup directive parameter ""PIDControl"" I cannot find documentation actually does. I see encoder documentation page encoder provides velocity output, apparently built API. So question two fold: 1) What ""PIDControl"" directive actually do? 2) How I use encoder control speed motors?",robotc
2613,What suitable model four-wheeled differential drive rigid-body robots?,I found model 2-wheeled robots here: What suitable model two-wheeled robots? How I adapt 4-wheeled setting?,wheeled-robot kinematics
2619,Building A Servo Tester To Measure Peak/Stalled Amp Draw,"Since finding data stalled use load (not free) amp draw servos seems impossible, I want build/create servo tester. All I really want know much amps servo drawing idle, movement load, stalled/full position. I think cover bases relative amp usage servo not, please let know I missing. Here questions: I going need power supply exact 4.8V 6.0V since seems standard measurement voltages. I'll need way accurately measure amp draw. I'll need way control servo movement. Is it? What I missing anyone suggestions please let know thanks help. This seems uncharted waters RC hobby area someone robotics field may path.",rcservo
2620,How explain bandwidth measurement noob?,I working system measuring force. The specification 500Hz bandwidth measurement. Now I trying explain 500Hz bandwith mom I could really explain easily. What easy way explain term bandwidth measurement someone without control engineering background?,control
2628,Project Idea AI related project,"I Computer Science final year undergraduate student.Until now,I used shirk away robotics I believed related electrical mechanical aspects.But interest robotics grew seeing demos I seriously want make robot involves AI teaming interbranch students college.So best project I pick beginner robotics AI experience Computer Science I apply AI Machine learning concepts learns something.How start something?",artificial-intelligence machine-learning
2631,Quadrocopter build - Do parts look fine?,I completely brand new quadrocopter building. I currently start building Quad. I done little bit research thinking buying following parts: KK2.1 Hobbyking Flight Controller Turnigy H.A.L Quadcopter Frame 4 x NTM Prop Drive 35-30 1100kv / 380w Turnigy 9X 9CH Turnigy Plush 40A ESC Slow Fly Prop Left Slow Fly Prop Right Quad Power Dist Board Turnigy 5Ah 3S25C LiPo What think parts/Do complete builds instructions would recommend instead? Thanks,motor sensors quadcopter multi-rotor
2635,How much realistically drawn 25C max 50C battery?,"I using 8 brushless motors octocopter. Each motor run maximum 30A. I use 4 batteries parallel. How high C number needed? $$\frac{30*8}{4*2} = 30C$$ When running motors 100% load, draw 30C battery. Can 25C max 50C used, run hot? Additionaly, many ampere hours drawn 5000mAh battery it's empty? Many 12V car batteries drawn 60% stated capacity need charged.",battery
2637,What meant speed profile?,"When researching robots, micro mouses etc I've often come across people taking generating ""speed profiles"" calculate them. Also profiles acceleration , deceleration , turning etc. Also trapezoidal profile? But I can't seem find exactly meant this. The also. So ""profile"" sense would need one?",control
2639,Raspberry Pi two wheel robot?,"I want create two wheel remote controlled robot. I worked lot logic regards balancing. I started read motor control arduino vs beagleboard black vs raspberry pi. Is multitasking nature full linux OS problem I need concerned application? I expect I adjust motors least 20 times per second, I don't think slight variation update loop interval problem. Possibly, I face problems I need PWM myself? Basically, way I plan make robot work using accelerometer reference is. The robot autonomously work keep direction accelerometer down. The remote control simply adjust readings accelerometer, balancing loop react robot falling accelerate wheels.",arduino control raspberry-pi real-time
2641,What response time Arduino Nano?,I want make circuit powers transistor sound set threshold reached. (Trigger flash high speed photography.) How long response time be?,arduino
2642,"What best way fuse measurements IMU, LIDAR, Encoder information recursive bayesian filter?","I SLAM four wheeled (2-wheel drive) differential drive robot driving hall way. The hallway flat everywhere. And robot turns spinning place, traveling resulting direction. The SLAM algorithm need run online. The robot takes measurements strap IMU/gyro measuring , ax refers acceleration x direction wx measures angular acceleration x-axis. The LIDAR scans hall way 270-degree arc measures ranges angles. However, far I know hall way discernable features except corners I need find best way fuse proposed action measured encoder IMU LIDAR data. It makes sense I could fuse yaw IMU encoder data get better sense heading, I incorporate LIDAR data? In essence, appropriate measurement model I incorporate noise motion model? Beside adding gaussian noise (0,σ)? Addendum This somewhat orthogonal question confusing me. Currently I using particle filter SLAM, I little confused whether represent uncertainty angular acceleration particles themselves. I see two options: A separate navigation filter using EKF (or anything really) find vector ""best-estimate"" angular acceleration matrix first, use matrix absolute truth particle filter. So drift particles uncertainty angular acceleration. Incorporate uncertainty particle drift themselves. This option appears sensible I sure principled way is.",kalman-filter slam particle-filter
2643,Can rigid-prop quadcopter hover upside-down?,"Most small quadcopters use rigid rotors fixed pitch. In principle, I imagine might possible rigid-prop quadcopter hover upside-down, apparently requires reversing direction rotation 4 motors. (This different way ""standard"" single-rotor model helicopters hover upside-down continuing spin rotor ""the direction"", moving swash plate give negative blade pitch). Is possible rigid-prop quadcopter hover upside-down? When I build quadcopter switch flying upright flying upside-down back mid-flight, I differently normal quadcopter designed always fly right-side-up? (Related: ""Can run BLDC motor backwards without damage?"" )",motor quadcopter multi-rotor
2644,DC motor encoder,"Can anyone help DC motor, especially encoder part? I tried searching around datasheet short 1 page spec I get are: Encoder: 1 pulse/revolution It 2 connection bottom, I guess driving motor, say nothing 3 connections wires below.",motor quadrature-encoder
2649,Kinect point cloud + Pcduino. Will work?,"I'm newbie Mircroprocessors (PcDuino, example) I wanted know Kinect integrated pcduino, I go buy board. I know terms connectors etc might required. My concern regarding hardware required run Kinect. To elaborate more, I'll explain current system: I system working laptop uses Kinect extract unorganized point cloud data using ""Processing"" IDE interacts Kinect using openni drivers. My Matlab code processes information detect obstacles specific objects (can also done using C++). I want build system robot, using pcduino processing module. This means Kinect connect pcduino using one usb ports. I'll power Kinect using battery converted power adapter. Since pcduino run Linux (Ubuntu) I (think I) easily convert laptop code whatever Ubuntu requires. The concern I problems associated using depth sensors mini pc boards terms hardware capabilities mini pc boards? I know mini pc boards fast PC, processing would slower, I'm concerned speed, atleast time being. One problem I encountered using kinect, even PC point cloud drivers openni won't initiate point cloud data stream, unless GPU PC; exact code runs perfectly PC dedicated GPU. However, I know pcduino GPU chip (OpenGl ES2.0). Would kinect work this? I searched online closest thing I could find elaborate integration Raspi Asus Xtion works. I'm picky boards, anything would work kinect fine me, although I like pcduino since arduino headers built wi-fi etc. Any additional pointers also helpful. Please let know I need elaborate anything more. Thanks advance",microcontroller kinect
2652,A questions first quadcopter build,"I'm planning order parts first quadcopter build I questions. Here parts list. I'm crossing fingers compatible, I'm pretty sure are. I two questions: Do I need Power Distribution Board so, do? Where flight controller I attach radio receiver?",quadcopter microcontroller radio-control
2657,Could piezoelectric sensors crushed?,"I found load sensors (piezoelectric) measure relatively small weights (on order ~ grams). That's I need! However... Around robot, occasionally bursts extremely high pressure. These bursts need measured... wash over. The pressure appears, sensor, ~ 2,000+ kg Question: Are sensors likely break fatigue? I realize piezos measure via deformation, still... that's big load! Maybe I order try...",sensors
2661,Kalman Filter states observable time?,"I system I make strong kinematic model for, sensors send readings unpredictable times. When I say unpredictable, I saying order readings arrive, I also mean sensors able sleep see significant change. When input arrives given sensor, information used infer states many sensors based model. At first, seemed like Kalman Filter exactly I needed I could make prediction states system update states one piece information comes repeat process good estimate system whole determined. However, reading Kalman filters, looks like assume every state updated regular basis. Is way Kalman filter modified unsure input come next also unsure much time elasped next input arrives? Please note case, information arrives, I know source input well time elapsed since last update, I won't able predict two things beforehand.",kalman-filter
2667,Wine yard robotics?,"My friend acquired (small) wine yard discover much work tending harvesting grapes. Now musing enlist robotic help. The vine stocks usually connected stiff wire, dangling machine might feasible. We looking references/inspirations agricultural robotic vine assistant. Any ideas?",mobile-robot robotic-arm
2668,Removing quadcopter drift side,"I wrote quadcopter firmware based older code. This code shall stabilize copter always equilibrium. The model behaving relatively nice. I control laptop. However I noticed, copter hovering side (if manually controlled), likely wind, well balanced turbulence. My idea maybe fuse GPS accelerometer data implement function shall help hold position. But likely work I hold altitude function, changes pitch roll change height, thrust changed slightly. This I recently added routine shall allow hold altitude. Is someone experiences this? I mean avoiding side drifts model whatever software? The problem opinion, I don't know whether position change wanted (by remote control) not. Additionally hard localize correct position calculate distance caused drift (just GPS, precise). Copter control: // Stabilise PIDS float pit_stab_output = constrain_float(_HAL_BOARD.m_rgPIDS[PID_PIT_STAB].get_pid((float)rcpit - vAtti.x, 1), -250, 250); float rol_stab_output = constrain_float(_HAL_BOARD.m_rgPIDS[PID_ROL_STAB].get_pid((float)rcrol - vAtti.y, 1), -250, 250); float yaw_stab_output = constrain_float(_HAL_BOARD.m_rgPIDS[PID_YAW_STAB].get_pid(wrap180_f(targ_yaw - vAtti.z), 1), -360, 360); // pilot asking yaw change - feed directly rate pid (overwriting yaw stab output) if(abs(rcyaw ) > 5.f) { yaw_stab_output = rcyaw; targ_yaw = vAtti.z; // remember yaw pilot stops } // rate PIDS int_fast16_t pit_output = (int_fast16_t)constrain_float(_HAL_BOARD.m_rgPIDS[PID_PIT_RATE].get_pid(pit_stab_output - vGyro.x, 1), -500, 500); int_fast16_t rol_output = (int_fast16_t)constrain_float(_HAL_BOARD.m_rgPIDS[PID_ROL_RATE].get_pid(rol_stab_output - vGyro.y, 1), -500, 500); int_fast16_t yaw_output = (int_fast16_t)constrain_float(_HAL_BOARD.m_rgPIDS[PID_YAW_RATE].get_pid(yaw_stab_output - vGyro.z, 1), -500, 500); int_fast16_t iFL = rcthr + rol_output + pit_output - yaw_output; int_fast16_t iBL = rcthr + rol_output - pit_output + yaw_output; int_fast16_t iFR = rcthr - rol_output + pit_output + yaw_output; int_fast16_t iBR = rcthr - rol_output - pit_output - yaw_output; // Hold altitude hold_altitude(iFL, iBL, iFR, iBR, rcalt); hal.rcout->write(MOTOR_FL, iFL); hal.rcout->write(MOTOR_BL, iBL); hal.rcout->write(MOTOR_FR, iFR); hal.rcout->write(MOTOR_BR, iBR);",arduino quadcopter
2671,Compliance control single link robot matlab,"What exactly active compliance control robotics joint? Why Is used ? How I write program simulate compliance control matlab single robotic link single robotic joint ? I develop algorithm torque control. I sense torque give feedback BLDC motor supposed apply controlled torque. I also unclear understanding things: Lets say I single joint two link systems, How would system behave I applied compliance control algorithm joint? How I test it? I mean I apply external torque I understand compliance control mode. Here related paper.",control robotic-arm
2672,MCBL Controller RS232,I'm trying use MCBL Controller Faulhaber control motor. I'm trying program sort driver linux using serial connection libserial. But seem working now. I'm using usb RS232 converter like one: I'm wondering it's well supported libserial. I've read yes anyone experience it?,serial communication
2673,Passive ego-motion estimation vs active,"I research ego-motion estimation positioning 6DoF space. And I found apparently systems based active RGB-D sensors, like Kinect. I understand, sensors provide greater accuracy, requires less computational resources. But systems used, example, augmented reality robot navigation, going solve problem interference signals different systems, operating space? If many people wear AR glasses active sensors - interfere other, aren't they? Are big commercial projects, use passive visual odometry multiple camera units IMU sensors? I found good papers topic, I found commercial application technology. I going make research passive odometry method AR, actually problem active depth sensors, described earlier? UPD: The main question: Is passive odometry, based video flow analysis IMU, worth make deep research topic, active sensors - future, signal mix big deal, passive odometry dead end kind technology? Because useful make research useless technology...",kinect sensor-fusion odometry
2676,How Can I Measure Torque Value Servo?,"I know must ""tool"" measure oz-in torque. I want trust servo manufacturers state site torque values I want test myself. Anyone know tool I use this? I used fishing scales before, I need something sensitive units pretty small around 20 oz-in. Thanks.",servos
2677,Autonmous surveillance vehicle,"I planning build autonomous terrain surveillance robot using raspi, better option Computer vision ultrasonic sensing avoid obstacles? And want transmit video recording base station.",raspberry-pi computer-vision ultrasonic-sensors
2680,"How decide length robotic arm, base torque?","I designing remote controlled robot base three wheels, two simple wheels back base third ball wheel front. It robotic arm gripper hold objects 1kg. I designed arm like What I want ask calculate length arm, base robot, torque also motor use. Please suggest better solution designing robot.I robot enthusiast I designing robot first time.",motor control design robotic-arm
2683,Altitude hold quadcopter Accelerometer Barometer,"I wonder currently implement altitude control quadcopter. I atm barometer/GPS accelerometer. Barometer GPS relatively straight forward implemented, precise slow. For accelerometer readout, I remove constant 9.81 m/s² acceleration low pass filter. Then I take data calculate climb-rate(in cm per s). I know speed approximation way great. However I don't know better approach far. For calculation motor speeds I use atm two PIDs (STAB RATE). I coded example shown below, without much testing far. I believe work smooth nice way. E. g. instead speed calculated accelerometer I could use climb-rate barometer. However low altitudes small changes I need likely accelerometer. ArduPilot seems use somehow different way third PID acceleration. I believe calculate height difference like me. Then use maybe STAB-Pid barometer climb rate (not like accelerometer) calculate acceleration data another output. Unfortunately I don't know exactly, whether methods. Does someone know exact layout implement barometer accelerometer altitude hold function. I mean I really sure whether ideas would correct. Maybe I post options later. My PIDs: Code altitude hold: // Stabilizing code done float fCurAlti_cm = _HAL_BOARD.get_alti_m() * 100.f; // Barometer GPS data float fAcclClimb_cms = _HAL_BOARD.get_accel_mg_ms().z * 100; // Accelerometer output cm per (gravitational const. corrected) // calculate difference current altitude altitude wanted float fAltStabOut = _HAL_BOARD.m_rgPIDS[PID_THR_STAB].get_pid(fCurAlti_cm - (float)(rcalt_m*100), 1); // Rate climb rate (here accelerometer) int_fast16_t iAltOutput = _HAL_BOARD.m_rgPIDS[PID_THR_RATE].get_pid(fAltStabOut - fAcclClimb_cms, 1); // Modify speed motors iFL += iAltOutput; iBL += iAltOutput; iFR += iAltOutput; iBR += iAltOutput;",sensors quadcopter accelerometer ardupilot
2687,Need help calculating thrust quadcopter motors,"I'm trying calculate lifting capability four quadcopter motors. I tried using eCalc doesn't battery I'm using. Are equations keep mind calculations? Here relevant details: Battery: 2200mAh 3S 25~50C LiPo ESC: 25A Motor: 1240kV Brushless Propeller: 8x4 Any help would much appreciated, thanks!",quadcopter
2692,Using 3DR Radio communicate ArduPilot Data,"I trying send data PC Arduipilot, I used Normal USB connection send recurring string like this:- I receive string fine I open serial monitor baud 38400 bits/sec. But, I remove USB port plug 3DR radio module ardupilot PC, gives garbage. I know 3DR radios use MAVLink communication protocol, I wondering it's possible change protocol use normal SPI I receive data format I receive connected via USB. If possible, way convert garbled data radio module useful string. It would greatly appreciated someone help this.",ardupilot radio-control
2694,Set CANopen Node ID Ingenia Pluto DC Servo Drive,"Does anybody know configure node ID Ingenia Pluto DC Servo Drive? I've got request support team, perhaps somebody already familiar drive boards. I Ingenia MotionLab 2.7.2, ship documentation MotionLab user manual site date (I previously looking hardware documentation, turns info MotionLab documentation; although instructions previous versions longer seem apply 2.7.2).",control can
2695,What options thin light source (e.g. LED)?,"I'm looking make buy something resembling LED, would thin (about 0.5mm less) cheap (<0.1$ mass production). Any suggestions?",arduino electronics
2696,An architecture testing autonomous flight sensors,"I'm designing simple autopilot software top Ardupilot, goal possibly interface Raspi top ArduPilot Mega (APM). I stuck setting simulation environment using either V-Rep Gazebo. The quadcopter basic sensors plus advanced sensors. basic sensors talks directly ArduPilot, advanced sensors talks autopilot software. I trying wrap head around feasible setup test software using ArduPilot Mega Hardware-In-The-Loop. I planning three stages Simulation: Stage 1. Simulate quadcopter physics Gazebo/V-Rep, run ArduPilot software autopilot software VM (not sure it's even do-able) Stage 2. Simulate quadcopter physics computer, run autopilot software VM, run APM hardware-in-the-loop fashion. Stage 3. deploy autopilot onto Raspi interface APM run hardwares Hardware-in-the-loop fashion.",quadcopter simulator
2698,Random number generation Particle Filter,I implemented bootstrap Particle filter C++ reading Papers I first implemented 1D mouse tracker performed really well. I used normal Gaussian weighting exam. I extended algorithm track face using 2 features Local motion HSV 32 bin Histogram. In example weighing function becomes probability Motion x probability Histogram. (Is correct). Incase correct I confused resampling function. At moment resampling function follows: For Particle N = 50; Compute CDF Generate random number (via Gaussian) X Update particle index X Repeat N particles. This re-sampling function moment. Note: second step I using Random Number via Gaussian distribution get index weighting function Probability Motion Histogram. My question is: Should I generate random number using probability Motion Histogram random number via Gaussian ok.,mobile-robot localization particle-filter tracks
2700,Battery system without mains voltage attached,"I'm working project mains voltage sometimes disconnected, system run battery long possible (safe) shutdown. The desired behavior exactly like laptop battery system: When mains voltage connected, charge battery power system mains When mains voltage disconnected, power system battery Prevent battery system supplying current batteries discharged certain voltage (to prevent damage). Is name type system, name feature(s) I looking I look chargers? (If matters, system 12V, I'm looking 14.8V Lithium battery options.)",power battery
2701,2D Map representation GPS coordinates degrees,"I want implement GPS navigation quad-copter. I calculate filter GPS coordinates (latitude longitude degrees). I believe easiest approach would be, calculate change heading quad-copter current attitude destination point let fly straight turning. However I sure 2D representation latitude/longitude-GPS coordinates (for round earth 2D map system calculating heading change). How big expected error? Or none?",navigation gps
2702,How one calculate angular motion node robotic arm,"A robotic usually consists joints sections possibly varying width connected together. Considering know much bent length section, location 3D space (not local coordinates) time zero; determine much joint rotate goto position B position A. Both A B defined world cartesian coordinates. Now joint move terms once, joints move simultaneously turns?",kinematics robotic-arm
2704,Quadcopter forward speed,"I trying better understand dynamics forward flight multirotors. Assuming I quadcopter 4 motor/propeller combinations capable (each) propeller pitch speed of, say, SpeedMax= 100 mph. In forward horizontal flight, quadcopter pitch certain angle, let's say AlphaP, horizontal. If AlphaP is, say, 45 degrees, drag neglected, wouldn't quadcopter capable max theoretical speed sin (45)* SpeedMax ~ 70Mph? Also, seems AlphaP cannot go way 90 degree (quadcopter flying like plane), point propellers would produce upward thrust maintain copter aloft given wing loading available plane. If drag neglected, factors would optimum AlphaP depended on, would angle be, maximum speed?",quadcopter
2706,How I get started Computer Vision?,"I want know write run correct code. I understand I need download OpenCV (which I have), I try compile sample code - example, Blob Detection - doesn't compile. I confused process need get something show screen. I know question really vague, I bad understanding Computer Vision I don't really know describe problem. Hopefully discussing able help me. Please help me! I searching Internet 2 hours I lost sea information...",computer-vision
2708,Multiple position estimates fusion,"I system I two separate subsystems estimating robot positions. First subsystem composed 3 cameras used detecting markers robot carrying outputs 3 estimates robot's position orientation. The second subsystem system located robot measuring speed two points robot. By numerically integrating two I get estimate robot's position orientation (because I tracking two points once). The first system less accurate second system drifts. First system gives output second second one gives output much frequently (100-200 times per second). I assume must better approach reset position first system's estimate (as 100% accurate), also use accumulated position second sensor system fuse new data first system. Also, question fuse 3 estimates first system? There must better way pure average might happen two estimates exactly third one completely different (meaning probably wrong)? Do fusion algorithms recommend use system? I know Kalman filter, I trouble figuring use two systems output data different frequencies. I hope question clear enough, best approach fuse estimates correct accurate estimate? Thanks",sensors localization kalman-filter sensor-fusion
2712,Power issues involving Raspberry Pi,"I Raspberry Pi (Model B) attached Roomba. I'm using part bring unregulated 17V+ power Roomba 5V/1A Pi. The problem Pi randomly reboot cause peripherals (such bluetooth adapter) freak work. We sometimes drive around little reboots, times happens almost immediately.",mobile-robot raspberry-pi
2713,"How connect Arduino Uno3, L293D motor driver 3 colour sensors together?","I trying build autonomous multi coloured lines following robot. The parts I bought far include: Arduino Uno 3. 3 Colour Sensors (taos tcs 230). L293DNE motor driver. Robot chassis including 2 dc motors, 2 wheels 1 caster wheel. I trying figure connect components together (for example: arduino colour sensor, l293d motor). How I connect order motor rotate directions? Do I need solder anything?",mobile-robot
2714,Precision expect ultrasound-based localisation system,"I'm considering building absolute, indoor robot-positioning system based ultrasound Time Of Flight. Transducers ordinary, narrow-band, 40 kHz ones. Based experience, best exactitude precision achieve system? I'm aware answer question depend many factors, hardware software (if applicable), I'm asking performance one solution another, intrinsic limitations ultrasound technology.",localization ultrasonic-sensors
2715,How implement distance proximity sensor wider range,"More line robotics observing environment, I'm trying implement proximity sensor sense objects front least $-30^ \circ \space$ $\space+30^ \circ $ it's direction propagation. There two ways I think Multiple Infrareds. Con: spacious Fast-Motor. Con: expensive money time-complexity wise I'm currently using Proximity Sensor 10ft distance capability",sensors
2719,H bridge rover,"I building 6 wheeled rover, one set 3 wheels work together set 3 wheels run together, current side may vary 3A-15A(blocked rotor) 6V want make H-bridge(for controlling direction speed(i use PWM) require two H-bridges. copper track thickness use proteus making design else shall go manual soldering replacing tracks wires. Can anybody suggest design relatively easy design protection circuit (for MCU pins isolation) suggest suitable motor controllers TI company apt problem",motor control
2720,What pros cons fictitious play,I've looking articles topics Fictitious Play learning algorithms presentation I haven't found it's pros cons Is book something I benefit from? Thanks,algorithm
2723,SCARA Arm Lead Screw Choices,"I'm thinking building SCARA Arm lift moderate loads(5lbs) high degree accuracy. I want relatively quick inexpensive Z axis gantry, I thinking using lead screw dual linear rail. Trouble I'm certain linear velocity fast enough. What's best method choosing lead screws associated nut, given desired linear velocity 10inches/second NEMA stepper motor driving it?",robotic-arm mechanism
2724,What's good pose estimation method high precision (<5mm per-axis) solutions short range (<50cm)?,"I'm trying get 6DOF pose solution object that'll 10 50 cm fixed point. I want avoid putting much special hardware object, extra hardware fixed side fine. I've looking two general methods: fiducial markers There several software packages different types markers, I haven't able find information regarding precision accuracy short-range pose sensing. ultrasonics I've found commercial systems 6DOF pose sensing (e.g. hexamite), they're expensive require put transmitters object.",sensors ultrasonic-sensors pose
2726,What's difference CAN's Motor Max Velocity vs. Profile Max Velocity?,"CAN301/402 provides Max Motor Speed (0x6080,0x00) Max Profile Velocity (0x607F,0x00). In profiled motions, maximum speed limited lower two values. In non-profiled motions, maximum speed limited Max Motor Speed. What intended purpose Max Profile Velocity, rather providing Max Motor Speed using everywhere instead?",motor control can
2729,Is analytical solution inverse kinematics 6 DOF serial chain?,"Let's take 6 DOF robotic structure. It's consisting 3 DOF global structure position - 3 DOF local structure orientation endeffector. If last 3 axis (of local structure) coincident one point, inverse kinematics solved analytically decomposing position- orientation-problem. But possible solve inverse kinematics analytically last 3 axis NOT coincident one point? I've read several papers claim due high non-linearity trigonometric functions motion complexity 3D-space, 6 DOF serial chain cannot solved analytically. Does anybody know right?",inverse-kinematics
2730,How use scan command Arduino WifiBee,"We want find available WiFi networks near. So tutorial command scan, send CoolTerm program PC. Now want write program Arduino operation, done?",arduino wifi
2731,Using robotic simulator prediction step probabilistic localization approaches,"Probabilistic localization approaches like Kalman Monte Carlo benefit accurate prediction step. The accurate prediction step, accurate belief robots pose. In approaches probabilistic motion models applied, mainly robot dynamics difficult model. Still approaches rely dynamic models order increase accuracy. Therefore, I wondering it’s reasonable utilize robotic simulator like V-REP Gazebo prediction step. The advantages I see following: robots kinematic solved default, simply modeling robotic simulator robots dynamics taken account nonlinear behaviors like slippage collision modelled certain extend robots workspace taken account, modeling environment (if robot drives wall previous models would predict behind wall, won’t happen robotic simulator) With shown advantages I hope achieve accurate prediction. However might problems using robotic simulator. For start ensure real time behavior delay prediction due communication simulator. I looking papers pick idea couldn’t find any. Are approaches similar idea? If not, reasons nobody using robotic simulator prediction? What opinions proposal?",mobile-robot localization motion simulator
2744,What different sensing approaches used current batch indoor 3D cameras?,"I'm aware PrimeSense camera powering Kinect. Are advanced sensor types available < $500 range? For example, sort game-changer structured light techniques? Do decent flash lidar cameras exist now?",sensors kinect cameras lidar
2747,Robot start-up movement problems,"I created robot using robot chassis kit hobbyking. At first testing robot connected USB power source wheels lifted ground everything seemed OK. Then, I tried power robot batteries I encountered problem starting movement. The robot hardly starts move even I power 100% power - sometimes I push little bit order start driving. As newbie I don't know whether power source (battery) motors problem. There 4 motors torque 800gf.cm min chassis. The gear ratio 48:1 power motors I used two serially connected Li-ion batteries dc-dc regulator limits voltage output 5V. The power regulated dual H-bridge motor driver. According specifications, maximum free running current single motor 250mA I read stall current 3-8x running current. Anyway, problem robot problems starting-up driving I don't know whether motors even powerful enough move robot power source problem perhaps obstacle could solved appropriate power regulation (ramp). How I solve problem?",motor battery movement
2748,Maximum Distance using Ultrasonic sensor Arduino,"What maximum distance (of say , car ) could measure using ultrasonic sensor would compatible arduino? Is sensor(ultrasonic not) could measure distance car , say upto 50 meters used arduino?",arduino ultrasonic-sensors
2754,What Name part I'm describing,"I'm looking part particular function. It able move along one axis tell force exerted it. Kind like piston moves inside engine (one axis movement) except something pushing top piston I need know hard pushing. Another difference piston won't constantly moving back forth, needs able receive commands like. remain stationary new position. I know make would involved sensor something exert force name described machine? Edit #1 - Response Matthew Gordon The piston would move 0-6 centimeters. The form factor would small, ideally smaller palm hand. (Smaller=better) The forces would deal comparable forces exerted bicycle chain. I'm math/cs person engineering I don't know technical terms kinds things top head. It would real time sensor reading, volume data could processed phone. Would working conjunction wireless communication, probably Bluetooth, I'd look latency requirements sure.",sensors mechanism force-sensor
2758,What advantages using Denavit-Hartenberg representation?,"When one wants model kinematic chain particular define frames attached body, common use Denavit-Hartenberg parameters. What advantages representation? I understand interest normalized representation impact algorithms performance? The algorithm trivial implement, gain expect instead of, instance, fixing reference frames hands (i.e. arbitrarily) like done many robotics formats URDF.",kinematics
2760,Computing inverse kinematic jacobian matrices 6 dof manipulator,"I'm trying calculate inverse kinematic 6 dof manipulator. Task: A target point $p_{target} = (x,y,z)^T$ orientation $o_{target} = (a, b, c)^T$ given I want get angle configuration $q = (q_1, q_2, q_3, q_4, q_5, q_6)^T$ robot. Method: For I try implement Jacobian method (with transposed jacobian matrix) guide followed pseudocode slide 26. But instead using pseudoinverse Jacobian matrix I used transposed one. I'll try compute Jacobian matrix numerically analytically, didn't get solution (endless loop) them. Here's I retrieve Jacobian: Numerically: Analytically: private void calculateMatrixAnalytically() { var peMatrix = calculateJointPositions(); var zMatrix = calculateZ(); (var column = 0; column < this.Columns; column++) { double[] p_p = new double[3]; for(var row = 0; row < zMatrix.Rows; row++) { p_p[row] = peMatrix.M[row, this.Columns-1] - peMatrix.M[row, column]; } this.M[0, column] = zMatrix.M[1, column] * p_p[2] - zMatrix.M[2, column] * p_p[1]; this.M[1, column] = zMatrix.M[2, column] * p_p[0] - zMatrix.M[0, column] * p_p[2]; this.M[2, column] = zMatrix.M[0, column] * p_p[1] - zMatrix.M[1, column] * p_p[0]; this.M[3, column] = zMatrix.M[0, column]; this.M[4, column] = zMatrix.M[1, column]; this.M[5, column] = zMatrix.M[2, column]; } } /// <summary> /// Calculate positions every joint. /// </summary> /// <returns>The Matrix joint coordinate joint.</returns> private Matrix calculateJointPositions() { Matrix jointPositions = new Matrix(3,6); Position pos; (var joint= 0; joint< this.currentAxisConfiguration.joints.Count(); joint++) { pos = this.kinematic.CalculateDirectKinematic(this.currentAxisConfiguration, joint); jointPositions.M[0, joint] = pos.Point.X; jointPositions.M[1, joint] = pos.Point.Y; jointPositions.M[2, joint] = pos.Point.Z; } return jointPositions; } private Matrix calculateZ() { // (z0^T-z1^T-z2^T-...-z6^T) var ksEnd = Kinematics.TranslateRobotToWorld(); var zMatrix = new Matrix(3, 6); (var column = 0; column < this.currentAxisConfiguration.joints.Count(); column++) { (var row = 0; row < zMatrix.Rows; row++) zMatrix.M[row, column] = Math.Round(ksEnd.M[row, 2], 7); ksEnd = ksEnd.Multiply( Kinematics.TranslateCoordinateSystem( Robo.theta[column] + this.currentAxisConfiguration.joints[column], Robo.d[column], Robo.alpha[column], Robo.a[column]) ); } return zMatrix; } Here implementation Pseudocode: { jacob = JacobiMatrix.GetJacobi(currentPosition, currentAxisConfiguration); jacobiTranspose = jacob.getTransposeMatrix(); // deltaE = (x2-x1, y2-y1, z2-z1, a2-a1, b2-b1, c2-c1) deltaE = Position .GetDistanceVector(currentPosition, targetPosition); deltaThetas = jacobiTranspose.Multiply(deltaE). Scale(beta); (var axis = 0; axis < deltaThetas.Rows; axis++ ) currentAxisConfiguration.joints[axis] += deltaThetas.M[axis, 0]; currentPosition = this.CalculateDirectKinematic(currentAxisConfiguration); } (Math.Abs(Position.Distance(currentPosition, targetPosition)) > epsilon); $beta = 0.5$ $epsilon = 0.0001$ Problems: The transformation matrice fine, behaves good forward kinematic. In opinion Jacobian matrix must somehow wrong. I'm sure correct I put orientation data numerical calculation. For analytical computation I didn't clue could wrong. I would thankful advice. An explicit example calculating Jacobian would also helpful.",inverse-kinematics manipulator
2761,Is possible record incoming data realterm?,"I trying test sensor circuit I'm working on. Essentially, I using RealTerm send commands microcontroller returning value read sensor. When logging file RealTerm, I noticed commands sent showing well data returned. I wondering anyone knew way record incoming data using RealTerm, outgoing commands. Any suggestions would greatly appreciated. Unfortunately, way around using RealTerm specifically company policy.",serial
2767,NXT Segway problem. Need advice/help,"I'm attempting build segway robot using gyrosensor accelerometer. I'm trouble getting robot remain standing, reason, I can't identify problem. Here's I know: The gyroscope API lejos NXT platform here: By using timestamps angular velocity, project attempts infer angle robot. The API suggests order accurate, must polled 100 times per second (or every 10ms average). The problem simply polling gyrosensor takes 4ms. Polling accelerometer takes 10ms. The dimensions robot: Height: 28cm wheel circumference : 13.25cm Radius wheel, given circumference: 2.1cm The accelerometer mounted top robot (at approximately 28cm ground, 26cm axis rotation) In order keep correction amount linear (as opposed trying correct arbitrary angle) , I translate angle robot distance travel along ground ""right"" robot. This might bit naive, I'm open suggestion here. Basically it's horizontal distance calculated using right-angle triangle angle robot top hypotenuse 28cm. If that's clear, it's essentially horizontal distance top robot bottom robot. Right main concern amount drift gyroscope seems experiencing. Given fact NXT java software package, it's nearly impossible poll 100 times per second, amount error accumulated gyroscope fairly large. Finally, I've implemented PID control system. The thing I'm clear respect system integral derivative error must calculated given set values. Say, last 20 error measurements recorded. If amount past errors recorded variable, PID constants variable, speed wheels variable, seems problem begs kind automated optimization. But it? If I set speed 120 RPM (roughly max NXT servos) take past 20 errors calculating integral derivative error, possible optimize PID constants successfully? Or must 5 variables tuned together? Thanks ahead insight problem.",accelerometer gyroscope nxt
2768,differential drive PID controller,"I differential drive robot works fine (good PD parameters) driving say 1 m/s. Now, speeds (to 1.2 m/s) starts wobbling again. What would good strategy controller able cope whole speed range 0 - 4 m/s? edit 14th April: The robot line follow robot I see would related question since robot following trajectory would problem. I recently talked developers differential drive robots facing similar issues e.g. told need adjust PID parameters battery fully charged hence robot drives different speed. I know guys youtube, really interested robot link would helpful: PID parameters are: P 0.31, D 0.59, I 0.00 PID controller programmed using C:",pid differential-drive
2769,How turn rover 90 degrees using wheel encoders?,"I four wheel DC rover two optical wheel encoders. I'm executing rover turns controlling direction wheel motion either side rover. To turn left, wheels left rotate backwards right wheels rotate forward. This allows rover remain relatively position turning. The directions reversed right turn. How I use two sensors execute close 90 degree turn possible without fusing additional sensor data?",sensors motion
2771,Point tracking mobile robot,"How I track fixed point $P=(x_P, y_P)$ moving robot? Coordinates $P$ relative state/pose robot (x axis looks forward robot axis positive right robot). Suppose initial robot state/pose $S_{R}=(x_R, y_R, \theta_R)$. The next frame (namely $\Delta t$) applied control $(v, \omega)$ robot state $S_{R'}=(x_{R'}, y_{R'}, \theta_{R'})$. Where (I set axes OpenCV): $x_{R'} = x_R + v cos(\theta_R) \Delta $ $y_{R'} = y_R + v sin(\theta_R) \Delta $ $\theta_{R'} = \theta_{R} + \omega\Delta t$ The question is: coordinates $(x_P', y_P')$ point $P$ relative $S_{R'}$? As visible picture, I know transformation initial state next state robot coordinate P reference initial state $$ = \begin{pmatrix} cos(\theta_{R'}) & -sin(\theta_{R'}) & x_{R'}\\ sin(\theta_{R'}) & cos(\theta_{R'}) & y_{R'}\\ 0 & 0 & 1\\ \end{pmatrix} $$ Please correct I made mistakes! Thank you, help appreciated.",mobile-robot kalman-filter tracks
2772,Quadcopter Throttle PID mixing Motor Speed,I've writing quad copter software I sure best way map throttle PID inputs ESC power. My throttle range 0-1 PID outputs 0-1. My ESC's range 1060us 1860us. I mapped motor speeds like this: This works quad perfectly level (i.e. PID outputs 0) I apply full throttle (1.0) map ESC power I get quarter power (1260us). How I throttle max I get max power? If throttle half (0.5) I get half power plus PID values etc. Can anyone help this? Thanks Joe,motor quadcopter pid pwm esc
2774,Datasheet Taos TCS3200 GY-31,Can someone please post datasheet colour sensor mentioned above. All find TCS3200,sensors
2781,How know motor/ESC/propeller combination work quadcopter?,"I preparing first quadcopter build need know tell motors/ESC's/propellers work other. I also would like know tell motors would capable carrying/how much thrust have. I would like put camera copter. I cannot find anywhere straight answer question. The ones I currently think ones I want are: ESC: Motor: Propeller: 11inch This copter needs able carry camera (~go pro) TLDR: How one match ESC's/Motors/Propellers, tell get job done? (ESC - Electronic Speed Control)",quadcopter brushless-motor esc multi-rotor
2782,Wire gauge hobby robot question,"So, i'm making second ever hobby robot(I'm 15) planning soldering connectors battery, sensors, Arduino, etc. It small mobile robot. Anyways, I wondering good gauge stranded hookup wire would good purpose. Thanks!!",mobile-robot
2787,Position Object Data Tracking,"For class project, I'm working weight stack: I'm trying simultaneously measure: position moving weight stack value weight based calibrated/preloaded position stack, via load sensor. (e.g. think stack plate weights sensor knows advance 1 plate = 10lbs, 2 plates = 20lbs, etc.) The weight stack base camp chip/sensor/laser would within two feet weight stack, I don't need anything overly strong. My requirement small/unobtrusive cost effective. I've looked options, I'm engineer I'm sure I right track. How would this? Is research I could check out?",sensors
2794,Crimp Solder LiPo Battery?,"So, I'm planning second hobby robot(I'm 15). I planning using 7.4V LiPo battery idea solder 3-pin header connect electronics. Anyways, I solder crimp terminals attach pack? Or I solder directly battery leads Keep mind I decent background hobby electronics starting robotics. My soldering skills also decent! Thanks!!",battery
2798,Why iRobot sell Create Europe?,"I'm trying find good beginners platform use ROS with, I came across iRobot Create. To surprise, sell Europe. Why that?",mobile-robot ros irobot-create
2800,PID output reach setpoint precisely enough,"I'm developing/tuning software PID quadcopter. For I'm trying stabilise pitch angle using front back motors, I'm looking Kp. The motors control resolution: input variations need reach threeshold effect all. The process output reach setpoint, precisely enough requirements. There steady-state error (aka droop), hunting range centered setpoint, wide requirements. Also instability oscillation, random drift needs large enough PID attempts correct it. With lower Kp output needs diverge setpoint significantly error big enough PID attempt correct it. With higher Kp PID oscillates. I could find reasonable compromise. I'm thinking applying cuberoot function (or similar) error feeding PID: way small errors significant enough PID attempt correct them, large errors would reduced might trigger oscillations. I suppose someone must before: good solution? Are better alternatives? This steady-state error (aka droop) oscillation issue far I tell: please don't suggest using Ki Kd EDIT: I clarified problem description suggested using cuberoot rather logarithm bad idea indeed. Thanks, Marc.",pid
2801,minimum number RC channels required control Quad Copter?,"Most blogs/website say need minimum Four channels quadcopter (pitch, roll, throttle, yaw): One channel throttle second channel turning right left. third channel pitching forward backward. fourth one rolling left right. But looking RC transmitter , see time change maximum two sets data ( left right joy stick) . Even want send Rudder Throttle information , sent packet ? My understanding two channels sufficient control quad copter. Please provide clarity this.",quadcopter radio-control
2802,Radio-control dozens kilometers mountains,I wondering technology I use transmit data (enough controlling robot receiving video) dozens kilometers mountains ?,radio-control
2807,robot control law - control theory vs optimal control,"For robot, say path planning particular, pros cons choosing classical control theory optimal control (LQR example) ?",control motion-planning
2812,Role Neuromorphic Computing Quantum Computing field Robotics AI,"I asked similar kind question time ago (Neuromorphic Engineering Robotics) Since then, many things come point revelation. A road-map neuromorphic computing revealed recently; It proposes analog way computation, solve advanced computer vision problems. IBM Qualcomm also working similar project though digital side. Memristor technology slated come soon. The question I asking How Robotics community working adopt technology? This question opens domain pressing questions answered cryptically since 1980s. Are neuromorphic computers good mission critical precise robots, like Mars? Can use neuromorphic systems Avionics systems? How neuromorphic processing going help us solve problems NLP, knowledge processing? Aren't quantum computers similar neuromorphic computers ideology? If neuromorphic robots gain traction, digital hardware still required? It would really nice someone could explain points, answers various sparsely related research papers cryptic.",microcontroller computer-vision machine-learning research
2822,Robot kit suggestions,"I want develop toy project allow move object around house. Because I interested programming robot actually build it, I would like use sort programmable ""starter kits"" (like lego mindstorm) get started. While I everything figured yet, list specs I expect ideal kit have: The ability lift object (Object big 4'' 10 centimeters) The ability distinguish objects colors. It stort color sensors. Obviously able move smooth surface. Obstacle detection. Should sensors obstacle detection Extra: Maybe remotely controllable. Can someone please suggests cheapest kit I use this? Thanks",mobile-robot kit
2826,How much I expect Kalman filter converge?,"I learning Kalman filters, implementing examples paper Kalman Filter Applications - Cornell University. I implemented example 2, models simple water tank, filling constant rate. We measure tank level, Kalman filter supposed infer fill rate. According model, fill rate constant, I assumed time, Kalman filter would converge accurately (and less less noise) correct fill rate. However, amount noise fill rate never seems reduce first iterations: This graph shows fill rate part state vector changes course 1000 iterations simulation. Adjusting Measurement Variance Matrix seems little effect fill rate noise. Also, Kalman gain vector State Variance matrix seem constant throughout simulation. I assumed State Variance would reduce filter became confident state estimate. Questions: - Is graph I expect see? - Should Kalman Gain vector State Variance matrix change time situation?",kalman-filter
2828,Click button short vs long button presses Arduino,"I using clickbutton library Arduous problems implementing it. As stand code runs servo clockwise I'm sure I wrong. Basically I want servo pressed short period time move according exponential function, pressed according long period time move regular pace.",arduino
2829,Differential Drive Robot uneven surfaces,"So I building differential drive robot I want autonomously drive straight line uneven surface. I know I need position velocity PID. As now, I deciding sensors buy. Should I use optical encoders, accelerometers, something else? I wanted go accelerometers due error encoders would face due slippage, I sure. Some enlightenment would help!",sensors control pid differential-drive
2832,Servos power supply Quadruped Robot,I'm facing problem building quadruped robot figuring efficient power supply needed 12 servos. I'm using 12 MG995 tower pro servos powered 2 lithium batteries 2x3.7v (about 8 volts) 2200 mA . I really don't know enough servos something else needed added(i hardly fitted 2 batteries robot's body) suggestions please?,power battery servomotor walking-robot
2834,Dead reckoning car-like robot gyro one encoder,Recently I began build car-like robot I stumbled upon dead reckoning. I use one motor steering one traction. I want able get position robot. From I read 2 encoders used. But I curious use one encoder motor shaft get distance gyro + accelerometer get orientation robot.,mobile-robot motor gyroscope encoding
2837,What kind motor control I implement I cannot use Encoder?,"Every time I see PID control motor, involves Encoder, algorithm knows real position motor wheel. But robot I have, I cannot use encoder. I ONE optocoupler per wheel count many degrees wheel moved. I use increment counter, counter ALWAYS increment (if wheel moves forward wheel moves backward). The first moment I saw inconvenient I studied Arduino PID Autotune Library. In first figure, I would see decrements INPUT. My objective move little two-wheels robot small segments driven simple trajectories separated time complete stop (straight 10 cm, stop, move right 90 degrees, stop, straight detect obstacle...) Could suggest kind ideas? The first idea I transform PID position control speed control (which convenient feedback loop I have) keep counter traveled distance inform speed control stop.",arduino motor control pid
2841,What approaches I consider create rotating turret,"First bit background, I planning make highly maneuverable airship controlled four thrust vectored propellers. I don't want rely rudder forward momentum turns instead able maneuver direct prop thrust. I want able point prop anywhere within half sphere/dome. So two axis, 360 degrees traversal forward/back/up/down 180 degrees left/right. The nearest thing I think ball turret similar ball turret instead gun, motor propeller. The turret rotate infinitely 360 degrees, gun rotates 90 degrees. My first thought servo axis, limited range I would like 360 axis able rotate continuously. This would allow turret rotate desired angle using shortest path. My question is, What I need able rotate turret still know angles turret currently pointing?",sensors servos
2847,"Accelerometer, gyro, magnetometer sensor fusion 2d","I yet build basically theoretical question. I still wrestling C code manage i2c communication etc. When I originally said ""I build this"" I meant robot could called ""design phase"". For sake question lets assume moment whole robot consists one IMU sensor. It moves magically (no motors create lot noise sensor measurements). With theoretical I mean I interested mathematics algorithms involved solving problem. What I call IMU sensor provides raw accelerometer, gyro, magnetometer measurements. Lets say tiny robot travels snooker table (3569 mm x 1778 mm). I believe sufficiently small call 2d. Now, sensor fusion much easier (faster, consume less resources) 3d, right? I would like measure velocity possible position. With velocity I mean given point time I need know current velocity robot moving snooker table. Velocity range 0 - 5 m/s. With position I mean given point time I need know current position robot snooker table (x, y, heading). I hope possible since robot able identify landmarks use information reduce position errors. When I originally said ""I hope possible"" I meant express I already aware fact real sensor data noisy errors accumulate quickly. Using landmarks I / able manage reduce error position estimates. But NOT part question. I improve linear algebra knowledge. So I confident manage matrix multiplications, inversions such. My question ideas, references measuring velocity position 2d using IMU sensor like one. A little side question: I figured question probably theoretical robotics.SE. If know forum focused mathematical / algorithmic side robotics please let know.",localization imu sensor-fusion
2848,CTL port motor controller,"When I look 160A motor controller, port called ""CTL."" What CTL stand for? Is sort protocol like RS232?",motor
2849,Our quadcopter goes forward instead hovering place. How correct it?,"I'm trying quadcopter friends problem. It goes forward instead hovering place. We made video explain it, see here. As see, quadcopter flight go forward I don't touch controller. I need correct go backward goes forward again. We use kk2.1.5. The HobbyKing KK2.1.5 Multi-Rotor controller flight control board multi-rotor aircraft (Tricopters, Quadcopters, Hexcopters etc). Its purpose stabilize aircraft flight. To takes signal 6050MPU gyro/acc (roll, pitch yaw) passes signal Atmega644PA IC. The Atmega644PA IC unit processes signals according users selected firmware passes control signals installed Electronic Speed Controllers (ESCs). These signals instruct ESCs make fine adjustments motors rotational speed turn stabilizes multi-rotor craft. We made test. As see video, placed battery backward sure weight against. When check values debug mode, values 0 nothing pressed.",quadcopter uav multi-rotor
2850,Need specifications operate stepper motor RPi Arduino,"Here disassembled stepper motor I'm working with: Contains photo motor, label that's bottom motor. I need identify stepper motor retrieved scrap project. Budget constraints force us use scrap motor. I tried drive using L298 H Bridge, I couldn't find right bit sequences get running smoothly. I also tried search specifications sheet internet label, unsuccessfully. I'm using either RPi Arduino board run this. I need pin diagram specifications motor, guys seen type before.",arduino raspberry-pi stepper-motor
2852,How get prevent twisting cables,"I planning create motor turret described question. But simplify problem, I'm thinking wind turbine generator main head rotate freely 360 degrees face wind. How would I prevent power sensor wires coming head shaft twisting?",sensors wiring
2854,Create set drones fly patterns,How would one go making number drones fly preset pattern formation. example rotating around point. something like this.,quadcopter
2860,How long VEX pneumatic arm be?,How long vex pneumatic piston be?,robotic-arm arm
2865,Simplest way object tracking 2D range finder sensor?,"My current class assignment program robot course includes two moving obstacles – robots moving constant speed around region one robot must get to. Since robots moving constant pace alongside predictable path, robot stop border region, wait others pass proceed. The robot use 2D laser range scanner sense surroundings. Given restrictions, simplest object tracking algorithm I could use? I thinking something along lines: Collect two laser readings (2D point clouds) B suitable time gap them; Apply DBSCAN A B, producing cluster lists A' B'; Generate list P pair-wise matches clusters A' B', maybe using Hungarian algorithm; Discard P pairings whose difference falls within threshold; Calculate direction magnitude movements distance centers mass cluster pair. The reason choosing DBSCAN Hungarian algorithm I already implemented use elsewhere; difference clusters could measured distance centers mass. Do think solution would work problem? Do suggestions better and/or simpler ways solve it?",mobile-robot sensors algorithm rangefinder
2868,Differential Drive Robot Control,"Edited: I differential drive robot needs drive hall stay center. I 4 ultra sonic sensors, 2 side. Currently, I thought implementing pure pursuit lookahead distance etc. I sure correct approach. I lower level PIDs motor control working, I need help choosing path planning algorithm? Will pure pursuit work needs? OR people suggestions.",control pid differential-drive
2870,Find right actuator control flow flour,"I'm building circuit control flow flour. The basic idea open actuator (Possibly valve?) let specific amount go close it. The tube diameter 1cm max. I wonder right actuator use? Maybe valve right one? Any solution? Also, would great pointed suitable actuators I buy online.",actuator
2871,SLAM without data association?,"I would like build 2D EKF-SLAM openGL. I've implemented entire virtual environment robot moves 2D landmarks(feature-based map). I motion observation models. Also, I've implemented sensors Gaussian noise. Now, I would like use MRPT build SLAM. At point, I don't want use data association robot moves detects pose landmarks discard previous data means I concern current state vector. My question Is possible build SLAM without data association? Please suggest articles I enrich background issue.",slam ekf
2873,How calibrate differential drive?,"I'm building robot differential drive. I've reached point I drive around remote control I'm trying get localization working. Now I would like exactly measure parameters robot. Model robot I'm using two wheels spaced $b$ meters, wheel distance per encoder tick $s_L$ $s_R$ variance standard deviation driven distance $\sigma_L$ $\sigma_R$. When moving, distances random variables following distributions: $d_L \sim t_{L}s_{L}N(1, \sigma_L^2)$ $d_R \sim t_{R}s_{R}N(1, \sigma_R^2)$. Later model might expand little bit. What good way measure parameters? I found way measure $b$, $d_L$ $d_R$ (added answer), I idea measure standard deviations. The model used prediction input MCL, I don't need covariance matrix localization.",localization calibration differential-drive
2875,Connect sensors beaglebone/arduino complex robot,"I'm building biggest robot I've ever done. The hardware I far follows: HCR-Platform DFRobot base x2 12V 146Rpm DC motor two phase hall encoder x7 Sharp 2Y0A21 IR sensors x6 URM37 ultrasonic sensor x4 IR ground sensor Microsoft Kinect Right I'm using RoMeo board (arduino 328 compatible) drive motors process PIDs wheels + steering also access sensors (except kinect). I BeagleBone Black running linux intended main brain connected RoMeo using RS232 port processing Kinect + wifi access. I started thinking connecting sensors Beagle board directly I don't need waste time sending commands arduino board read sensors yielded first issue, beagle board works 3.3V instead 5V used sensors. After I thought create board voltage divisors connect sensors using ribbon cable connect new board beaglebone. I couldn't find 2x23 IDC male connector create ""interface cable"" two boards beaglebone option I don't want tons jumper cables place. This morning I thought I researched GPIO boards USB found three Numato, one works TTL 5V 8 pins I would need use sensors unless I design board option too. At point I'm quite confused terms what's best hardware I could use drive beast. Right I think I use Intel NUC linux Kinect, wifi usb link custom made sensor board. This custom made board work TTL 5V, provide power bus sensors interface ""low level"" sensors using USB link. I also thought FPGA custom board I'm sure would help it's worth effort learning use it. What thoughts this? Any idea issues solved ""complex"" robots?",arduino mobile-robot sensors computer-vision beagle-bone
2876,Why linkage-based haptic devices much common cable (tension)-based ones?,"According link, humble opinion common sense well, cable-based haptic devices got lower inertia less complicated mechanically. I also believe controlling big deal - inverse kinematics quite straightforward. Moreover, play easy compensate - occurs all, since cables tensioned. Cables also easy - ? guess - equipped strain gauges become strain gauges themselves, allowing enhance control capabilities device. Where I wrong? Why links-based systems (e.g. PhaNTom Falcon, although latter got cable transmission), especially impedance control, I seem able buy? Is cable elongation (creep)? Or constrained workspace (esp. angles)?",sensors mechanism
2879,What use electrovalve?,I want make following installation (blowing bottle tops music instrument): And I want use rc servo electro valve (throttle) control air flow bottle. Is way that?,rcservo mechanism valve
2882,How I add external library Rock Framework?,"The Rock framework already includes lot software libraries. However, I would like add existing external library I use component development. What preferred way that?",software rock
2885,Can identify construction material/system used pic?,"What's name ""big meccano"" used photo construct cabinets racks? It appears aluminium cut-to-length system 4-way rails. I've seen used many times assume well-known brand-name know. Photo taken theverge.com feature Audi building new car.",frame
2889,Static equilibrium 7 dof manipulator,"I 7 dof manipulator (Kuka LBR4+) would like calculate joint torques needed keep arm static equilibrium. In books transposed jacobian used map forces applying end effector joint torques. $\tau = J^T\cdot F$ That however doesn't take mass links account. Is way calculate needed torques given configuration that, assuming ideal case, setting torques arm static equilibrium? cheers EDIT: For everybody interested, found solution problem Introduction Robotics - Third Edition John J. Craig Page 175-176. It done aid iterative Newton-Euler dynamics algorithm. The actual trick is, set velocities accelerations zero except base acceleration. The base acceleration $^0 \dot v_0 = G$, G magnitude gravity vector points opposite direction. This equivalent saying base robot accelerating upwards 1 g upward acceleration causes exactly effect link gravity would.",torque manipulator
2890,Filling 30mL bottles food-grade liquid,"A project given work, schematics idea going. I need fill 5 30ml bottles time food-grade liquid. Based parts I have, I think design going use air agitated pressure pot tank used spraying paint, would work weren't using food grade liquid, right bat I cant use that. The main parts I use Allen Bradley micrologix plc, 2 pneumatic cylinders, couple solenoids, start stop buttons. My question is: fill 30ml bottle liquid, would positive displacement pump vfd best way slowing pdp enough fill 5 30ml bottle time? I little experience particular plc ladder logic issue, figuring specs pump motor. Any input would helpful also links would great. At point im trying determine huge waste time money I go buy filling machine $3-5000.",electronics
2891,Outputting precise voltage millivolts Arduino Mega,"So I need output varying voltage Arduino Mega range 17 32 millivolts, I've attempted sending PWM signal board low-pass filter steps voltage. This works, problem Arduino's analogWrite function accepts value 0 - 255 represent duty cycle PWM isn't precise enough. A value 1 yields around 20 millivolts value 2 yields around 40 millivolts. Is way duty cycle precise 0 - 255 range like 0 - 1023 (I think even isn't really precise enough)? Or better way get precise voltage output? The mega running outputting max voltage 5 volts, low pass filter contains 11 kiloohm resistor 1 microfarad capacitor.",arduino pwm
2894,"What good cheap, silent, motors mannequin robots kind controller I use?","What good cheap, silent, motors mannequin robots kind controller I use? I'm creating mannequin robots require 24 motors: 2 neck, 4 shoulder, 2 elbow, 4 wrist, 2 waist, 4 hip, 2 knee 4 ankle motors. The mannequins bolted via horizontal post lower back wall. This means run, dance, pose. I may also something horizontal beam robots side flips, moves like twist, jumps crouches. They stand up, bolted I've described wall. They could even spin around completely face wall. I've tried using 6v hobby servos joins. These weak lifting fibreglass mannequin body parts. They loud. They also make noise poses held, drop smash power shut off. I using handheld remote control testing 5 channels. The robot must programmable though. Lets say objective make mannequin dance 'Thriller' like Michael Jackson. I open using kinnect technology controller (so dancer simply dance front robot, copy remember) I'm also open controllers allow force mannequin pose specific time codes song. If necessary, I also willing program poses using kind lighting desk type controller (such tech crews use rock concerts sync everything go music). I noticed power drill winch loud whereas fan quiet. I live apartment neighbours hear footsteps apartments. I would dare turn drill 4am would wake everyone whole building, I would guilt turning fan. I need robot quiet fan. The voltage really matter project. I'm happy use 240v wall socket. Please let know motors controllers best mannequin robots, taking cost account. Thanks much help :)",microcontroller robotic-arm motion humanoid
2897,How read data i2c using i2cget?,"I'm new embedded devices trying understand use i2cget (or entire I2C protocol really). I'm using accelerometer MMA8452, datasheet says Slave Address 0x1D (if SAO=1, I believe referring I2C bus channel 1 raspberrypi v2). From command line, I enter It returns 0X00 I think means I'm attached correct device. So now, I'm trying figure I get actual data back accelerometer? The i2c spec says i2cget [-y] i2cbus chip-address [data-address [mode]] So I tried sudo i2cget -y 1 0x1D 0x01 0x01 OUT_X_MSB. I'm sure entirely I'm expecting get back, I figured I saw data 0x00, I might able figure out. Am I using ic2get wrong? Is better way learn get data i2c? The datasheet accelerometer chip",raspberry-pi i2c
2899,Salvaging bunch laptop battery packs,"I'm working first robot project. I previously used 12V 6Ah sealed lead acid battery, recently I aquired 15 ASUS Li-Ion battery packs, 14.8V either 2200 mAh 4400 mAh. The laptops discarded, battery packs seem dead. The battery packs 8 pin connector. Inside, I assume there's bunch 18650-cells electronics. My robot handle 14.8 V directly. How I use batteries? How I charge without laptops? I'm little put idea taking 18650-cells packs rebuilding battery pack charging system, that's what's needed I it. The packs marked ASUS A41-A3 2200 mAh ones, ASUS A42-A3 4400 mAh ones.",battery
2902,Solutions Finding Position Heading Multi-Level House,"I wondering could reccomend possible solutions locating robot within multilevel house. What seems obvious need altitude sensor derive story robot, compass sensor derive heading. However I wondering I could use locate robots xy position house. If requirement unclear, imagine I map dot representing robot position image current floor top. My original idea use GPS, however I need submeter accuracy would incredibly expensive. I also considered Monti-Carlo localization, however requires obstruction sonar sensors walls. It also significant task programically. I idea place 3 wireless beacons sort vertexes equilateral triangle surrounding house, triangulate position using distance beacon. However, I idea I would go hardware-wise. Do ideas seem viable, suggestions implement them? Otherwise, reccomend easier cheaper alternative? My platform essentially arduino hooked sensors motor drivers connected java laptop serial. Thanks.",arduino sensors localization gps
2904,Using pic webserver?,I want show information temperature Internet using sensor PIC. How I using PIC? Is way PIC 16f628A 18F it? Does anyone hame literature it? Schematics?,microcontroller
2905,Grasshopper effect quadcopter kk2.1.5,"We builded quadcopter use flight manager kk2.1.5 latest firmware. When increase throttle, flight. When keep hand stick able maintain don't touch throttle, goes down. You see example video. We tried different values PID don't know best us. We large quadcopter medium propellers (may small). Does weight quadpcoter width propellers factor? What problem?",quadcopter multi-rotor
2908,Simon K firmware IMU outputs 50HZ,"I building Quadcopter using Sparkfun Razor IMU outputs Roll, Pitch Yaw axes values 50 Hz, limits operations controller(implemented Arduino IMU), 50 Hz mx itslef. Please tell flashing ESCs(EMax 40A) Simon K firmware good. I'll grateful. :)",arduino quadcopter imu
2915,Effect adding Pole Zero PID,"I confused adding D (which adds zero complete system) decreases speed system. But normally add zero system, causes system overshoot. The goes I part PID. Normally add pole system, less overshoot, time integrator increases overshoot! How I make sense inverse relation?",control pid
2918,Suggestions stepper motor controllers,"I working project dslr camera rotated tripod 2 axes. I'm definitely using nema 17 motors I have. The motors rotate 30 degrees every 5 seconds normal usage speed requirement. The weight camera 1170g I'm using 3d printed parts remainder mount. I tried running nema 17 stepper motors Adafruit Motor Shield V2 whole thing overheats (battery, driver, motor). By way, motor controlled Arduino. I need find another motor controller use. I looked ebay things like came 20 dollars seems good true. My question motor driver I use project I little experience outside Arduino shields",arduino motor cameras stepper-driver
2919,How use Nicolas ziegel approach system never becomes unstable?,"How use Nicolas Ziegel approach root locus plot system never becomes marginally stable , gain (unless negative).. ?? How estimate ultimate gain value????",control pid
2920,understanding PID controller,"I trying understand effects P, I D constants PID controller system. As far I've understood, P I make system 'faster', D makes 'slower'(which I read books), I don't actually understand makes go 'fast' 'slow'. How integrator causes overshoot things like that. It makes sense P part causes overshoot, since adds gain. But integrator doing? I want kind mathematical understanding parameters affect system. I know work individually, I'm hard time understanding, affects system whole. For example, Zero added system lead decrease overshoot, normally adding zero system would create overshoot.",pid
2921,Controlling digital servos,"Many websites say analog servo motors work 50Hz digital servo motors work 300Hz. My question is, difference apply inner control loop servo user digital servo actually provide 300Hz PWM signal? To rephrase, (most) servos including digital ones controlled 50Hz PWM, digital ones specifically controlled 300Hz PWM? Thanks",rcservo pwm servomotor
2925,Why ID controller exist?,Why doesn't PID consisting ID exist?,control pid
2930,Is important good PI settings running self-level kk2?,"I kk2.1.5 I fly self-level on. In kk2, two menus. One set PI-settings another selflevel-settings. Both enable set P-Gain I-Gain. Is important good PI-settings self-level on, setting good values selflevel-settings sufficient?",multi-rotor
2931,Quad copter attitude control,"I built quad copter completely scratch (electronics, mechanics software). I point sensor data looks correct I tilt quad copter correct motors increase decrease. I trying tune PIDs couple days now, rate mode stays level rotates roughly correct degrees per second I give command. In stability mode lot time spins around axis I get stable kept rotating upright upside maintaining upside flat position. I come conclusion I either something completely wrong I + - signs mixed around somewhere. Would anyone knowledgeable quad copter control code able take look I done works I'm really struggling work needs change I try next. My flight control code posted below, relevant classes hardware.h main.cpp The whole program seen mBed page If need info something explaining let know. If anyone point right direction idea I try next would much appreciated. Thanks Joe",quadcopter pid imu
2933,Does RoboRIO support Java 8?,My FRC team recently upgrade CompactRIO RoboRIO. CompactRIO supports Java 1.4. What version Java RoboRIO?,microcontroller
2935,How PID affect Root locus close loop transfer function,"I trying understand PID controller moves poles zeros transfer function. I've playing bit it, aren't able see kind connection. I mean P I rises Overshoot would mean damping ratio gets smaller, thereby away real axis. D opposite, doesn't seem true examples i've used.. something wrong?? Well kind want general knowlegde affect second order systems.",control
2936,Best strategy area scanning using little sensing bots,"I'm currently working school project simulating robots scanning area, struggle find strategy robots use. Here details: I given certain amount robots, sensing range $r$. They spawn one another. Their task scan rectangular area. They communicate within communication range. I looking best strategy, (i.e. time efficient solution) this. Any reply clue strategy appreciated.",mobile-robot sensors coverage
2937,poles zeroes affect step response transfer function?,"I close loop transfer function: It overshoots, why? The poles placed damping = 1, overshoot?",control
2939,"What ""inverse"" peak mean? (step function)","I identified system I trying tune PI regulator since I think I need D. I came across graph Matlabing I know mean. I using pidtune() get P I values. (I think computation correct, I made model simulink confirm). Anyway see picture arrow pointing I understand. Why system going zero first? It supposed water flow regulator. Transfer function: $$ \frac{-0.311s + 0.05548}{s^2 + 0.06882s + 0.0007626}$$ Continuous-time PI controller parallel form: $$K_p + K_i * \frac{1}{s}$$ With $K_p = 0.256$, $K_i = 0.000342$",pid
2940,LQR design low effort,"I trying implement controller inverted pendulum using LQR (with MATLAB command lqr(A,B,Q,R)). The problem motors relatively weak, I tried increase R, simulations show effort still high. How I reduce effort?",control design
2945,How robot efficiently store map makes?,"From I understand, create map using sensors storing values array. For example, array 0's places visited, 1's places visited, 0's open spaces 1's occupied spaces, etc. The map I'm thinking making 1000 x 2000 members. This means I need array 2 million members. That seems like lot. If I eight attributes member (like temperature, light level, sound level, etc.), I 16 million pieces information capture. Is correct, better way create map robot using software?",software mapping
2948,PID tuning method based Pole placement,"Is possible determine PID parameter using pole placement. I mean solving ch. eq. close loop transfer functions consists either P,PI,PD PID controllers?? Because i've tried it, eventhough getting poles locations I want systems act I assumed. example. I want system overdamped settling time less 1 sec. means want poles lie real axis, less -4. $$G(s) =\frac{10.95 + 0.9574}{s^2 + 0.09149 + 6.263*10^{-6}}$$ With P = 0.1, I= 0.617746, = 0.0147173 I get close loop system $$G_cl(s) = \frac{0.1612 s^4 + 1.109 s^3 + 6.86 s^2 + 0.5914 s}{ 0.1612 s^4 + 2.109 s^3 + 6.952 s^2 + 0.5914s}$$ But looking it's step response I see creates overshoot, cannot justify due step input...",control pid tuning
2949,Actuation three reciprocating blades via conversion rotary linear,"Sorry robotics, seemed closest. A motor used rotate three cranks. They plane, run time. Only one occupies central position, corresponding motor, rotate. The discs mounted rectangular frame slid bring required disc central position. Can anyone suggest method achieve this? (Basically coupling uncoupling motor shaft whatever disc centre.)",motor mechanism
2961,McKibben artificial muscles 400:1 ratio,"I recently reading artificial muscles highest power/weight ratio electric motors ratio less 100:1. As electrical engineer I never worked pneumatics big idea air pumps. My question is, much ratio change consider autonomous system. On one side, McKibben actuators + air pumps valves + energy source side, electric motors + energy source. As example, let suppose somebody found way model control artificial muscles good electric motors make two autonomous walking leg models, one would higher resulting power/weight ratio ?",control power actuator torque battery
2963,How I learn Arduino/raspberry-pi based robotics own?,"I interested learning build dynamic quadcopter, hope fairly proficient Arduino/raspberry-pi. What resources and/or practices might recommend?",arduino raspberry-pi beginner
2964,Quadcopter PID output,"I'm trying develop control system quadcopter one options use PID controller (which I think used method). From I've read, commom strategy run PID algorithm axis. My question is: PID output converted PWM signals? I'm asking three axes four rotors depend other. I mean, I slow couple rotors opposite quadcopter move vertical axis. But I speed one slow other, quadcopter rotate different axis. So cannot isolate axis associate single rotor pair those. And that, PID output (which associated axis) converted PWM signals rotors? Is MIMO system?",quadcopter pid
2966,What parts I need strong robotic arm?,"I found robotic arm internet, I wondering someone tell parts I need build similar. The video says lift small cat. I need able program it, I'll need controller. Please recommend specific motor, controller links recommend. Thanks :)",robotic-arm
2968,proper tuning method cascade controller?,"Would control system consisting 2 PID controller one plant would considered cascade controller?? And come would proper tuning method be? As far i've googled seems best method manually it, one one. system looks like",control
2970,How I dynamically control amount torque necessary rotate something test rig?,"I'm looking build test rig robot rotates 1"" diameter pipe 180º (roll yaw pitch). I currently testing motor's performance subjected various kinds PWM (high duty cycle, low duty cycle, etc). I would like characterize performs various loads. Is simple mechanical mechanism I attach fixture insert around pipe lets control easy difficult rotate? I thinking something like drill bit chuck fits inside pipe expands circular clutch clamps around pipe add resistance one tightens thumbscrew. I would like go resistance full stop 4N•m motor. I would like able test 'sticky' pipe using torque wrench. I imagine would simple I can't think something would this!",motor torque
2972,Transfer function DC motor unstable due controller?,"I hard time grasping concept DC motor load unstable, stable due controller My confusions appears I trying design controller one using Z-N method, transfer function i've identified using matlab tells DC-motor always stable. Which makes sense, since feeding constant voltages, lead constant veloicty. But use z-n approach system able become unstable, since isn't possible getting confused motor able become motor design controller for. The question simplicity, come controller make motor, (if motor cannot (due pole zero plot)) unstable.",motor control
2976,Selecting Precise High Torque Motor Motor Controller use Arduino Mega 2560 R3,"My current project calls 6 motors (50 mechanical watts), assortment sensors. I selected Arduino Mega 2560 R3 use basis project. I trouble determining best motors motor controllers project. The motors need precise controllable, meaning I need make small changes speed motor several times second. The motors follow position vs. time curve. I broke position vs time graph 100 hundred sections. I found acceleration(degrees per second^2) section, I want put array format such: float arr[] = {position 1, acceleration position 1 2, position 2, acceleration position 2 3, position 3, etc...} Here idea I plan program motor: I planning run motors PID loop cut dry loop above. I saw spark fun AutoDriver stepper motor controller, I thought accompanying library would save lot work. I quickly noticed major limitations. First allow acceleration motor running, example: I call: kneeMotorDriver.run(FWD, 2000); I call softStop() hardStop() otherwise AutoDriver keep telling busy, interpretation (please correct I wrong) I cannot change drive commands (i.e.) I cannot vary acceleration. The AutoDriver functions require target step, I want give target step I don't want limited steps (1.8 degrees stepper I have) I may want stop 34.6 degrees, Auto Driver I cannot. The auto driver also limited 3A per phase current limit. Just summarize: I need Mega control 6 motors minimum output 50 mechanical watts, I need precise control, I planning using potentiometer rotary encoder. The motors run PID loop several sensors. I need able vary speed several times second. All 6 motors executing different motions need able run consistent time, (i.e) motor 1 2 degrees motor 2 must 18 degrees. I still open idea stepper motor I live stop step I would really prefer too. Any help would greatly appreciated. Thanks, Joel",motor
2980,Definition (or determine whether something is) robust controller?,"I bit uncertain I interpret definition robust controller. As far I've understood, closed loop system including controller high gain frequencies disturbance appears, decay frequencies higher work area, noise. Both determined using bode plot, thereby determining robustness closed-loop system.",control
2981,Acrylic/plastic cutting services,I want cut acrylic pieces assembled body robot. What recommendations acrylic/plastic cutting services? Does laser cutting produce best results?,manufacturing
2982,Performance/memory considerations pathfinding lookup tables RobotC small set paths,"I'm writing C code generator geared toward RobotC complex tasks FTC team, wondering performance storage concerns: How much memory available program's data? It'll mostly pre-defined lookup tables, generally form multidimensional arrays. How much NXT memory available program itself? As in, roughly much code I expect fit single RobotC compiled program? How quickly programs execute, generally? Looking disassembly generated lines correspond 2-4 opcodes. Based these, I'm trying make decision precomputation vs runtime pathfinding. I'm using NXT/Tetrix. My major interest point questions pathfinding. I plan 64x64 grid running Djisktra's A* algorithm heuristic function assigns penalty turns close consistent possible (not sure consistency/monotonicity doable turn penalty). Roughly 8 paths would cached I decide use pre-cached lookup tables. Instead set, I'll probably use boolean array set nodes visited. The fact I'm working square layout allow use 2D array map needed reconstruct path. I'd love feedback answers question anyone any. Thanks!",nxt robotc
2983,Securing disc/wheel shaft,"I situation I need secure 20"" wheel made 3/4"" thick MDF (of making) onto 1-1/4"" precision-ground steel shaft, joint needs strong enough convey rather large amount torque, 575-600 in-lbs, effectively 5hp motor driving shaft 500-600 rpm. I don't milling machine metalworking tools, preferred option 'milling flats onto shaft' out. My second option attempt increase surface area wheel's bore use appropriate adhesive JB Weld. Is JB weld suitable solution problem better method fastening doesn't involve modifying steel shaft all?",wheel
2987,Can I reuse hall sensors brushless motor encoder?,"I upgraded motors robotic arm sensored, brushless RC car motors. The hope reuse Hall sensors double rotary encoder, tapping 2 Hall sensors treating 2 bits quadrature signal (a crude quadrature since 2 4 states longer 2). This works none motor phases powered I rotate motor manually. But stator coils energized, encoder longer counts correctly: When running low power, counting correct, running high power, count monotonic (only increases decreases) matter I run reverse forward. I'm almost certain stator coils overpowering permanent magnets rotors. So still way use Hall sensors encoder? Sorry obvious question. I'd love research problem I time. Update: I've measured wave forms DSO quad see expected 120 degree separated signals (the measurement phase C gets inaccurate time I 2 probes, I measured phases A & B first, A & C, merged them. When ESC speed 0.1: When ESC speed 0.3: Previously, I using hardware quadrature counter (EQEP module BeagleBone). At speed=0.3, counting backwards matter I forward reverse! I implemented quadrature counting LPC1114FN28 uController. The result still bad high speeds (count didn't change all). The logic was: Then I got idea change code update prevState expected state happens (to deal glitches): int state = phaseA | (phaseB * 2) (prevState != -1) { (allowableTransitions[prevState][0] == state) { ++rotations; prevState = state; } else (allowableTransitions[prevState][1] == state) { --rotations; prevState = state; } else { // assume transition glitch } } else prevState = state; Now counting finally correct directions, even speeds higher 0.3! But really glitches causing this? I don't see waveforms?",brushless-motor encoding hall-sensor
2988,Voice control solution Linux robot?,"I wanted present voice-controlled robot lab's upcoming demo contest. My robot essentially x86 Ubuntu notebook resting top two-wheeled platform, principle solution available Linux would do. I looked Julius, seems comprehensive acoustic model available aimed Japanese language – coincidentally I speak little, apparently clearly enough produce anything beyond garbled text. I also tried Google Speech API, decent selection languages worked well, requires Internet access. Finally CMU Sphinx, I haven't yet tested, I'm afraid might problem accent (I'm nativa Brazilian Portuguese speaker, apparently acoustic model available it). Is it? Have I missed additional options? As may guessed, main requirement support native language (Brazilian Portuguese), failing that, good performance English spoken foreign accents. A C++ API highly desirable, I shell interface.",mobile-robot linux speech-processing digital-audio
2990,innovation step ekf localization?,"Let's say bunch observations $z^{i}$ sensor map get predicted measurements $\hat{z}^{i}$ landmarks. In EKF localization correction step, compare observation $z^{i}$ entire predicted measurement $\hat{z}^{i}$?, case two loops? Or compare observation predicted measurement?, case one loop. I assume sensor give observations landmarks every scan. The following picture depicts scenario. Now every time I execute EKF-Localization I get $z^{i} = \{ z^{1}, z^{2}, z^{3}, z^{4}\}$ I $m$, I get $\hat{z}^{i} = \{ \hat{z}^{1}, \hat{z}^{2}, \hat{z}^{3}, \hat{z}^{4}\}$. To get innovation step, I $$ Z^{1} = z^{1} - \hat{z}^{1} \\ Z^{2} = z^{2} - \hat{z}^{2} \\ Z^{3} = z^{3} - \hat{z}^{3} \\ Z^{4} = z^{4} - \hat{z}^{4} \\ $$ $Z$ innovation. For iteration I get four innovations. Is correct? I'm using EKF-Localization book Probabilistic Robotics page 204.",sensors localization ekf
2998,Why microstepping give less torque?,"I experimenting using stepper motor robotics project. I'd like use microstepping give better resolution smoother movement, I noticed finer microsteps, lower torque motor. Why this? For reference I'm using Allegro Micro A4988 motor driver, bipolar stepper motor.",stepper-motor torque stepper-driver
3006,"How I achieve long distance, high quality 3D Scans mobile robot?","Am going competing Robocup Rescue Thailand next year - I busy pull campaign Brazil year :( Will using CUDA powered GPUs, Kinect/Xtions, ROS primary navigation system, I need sensor long range scanning - least 25 meters. It probably overkill competition, I want used real world applications. It need robust, fairly light, high resolution, proven. The cheaper better, high quality must. Have read question, I need something available proven now: What different sensing approaches used current batch indoor 3D cameras? A similar question asked before, closed: LIDAR solutions. The suggestion good , I need something lot range: At moment probably going go RobotEye RE05 RE08 3D-LiDAR: Here paper descibes sensor used mobile robot: Does anyone alternative techniques, suggestions sensor achieve similar results?",mobile-robot ros slam kinect lidar
3007,Industrial Robotic Arm,I opportunity work factory/company domain space production want use robotic arm part production line. They want basically robotic arm payload 2 Kgs arm length 1600mm I researched companies like Kuka.com I sure I looking making suggestions researching it. Are suggestions give good points careful robotics arms? Any innovating companies I consider? How installation done I find supplier etc. Please enlighten me.,robotic-arm mechanism
3013,Does matter electronic speed controllers close brushless motors?,"I built several quadcopters, hexacopters, octacopters. This means flight controller (I use 3DR APM2.6 Pixhawk) motors heavy duty power wires well servo-style cable carrying PWM control signal ESC. Three short heavy-duty wires connect motor ESC, one phase. Several times I've heard read people saying electronic speed controllers (ESCs) mounted far away flight controller (FMU seems abbreviation en vogue) close motors. I think idea cuts interference (I'm sure sort) could emitted long ESC -> motor wires would required ESCs center aircraft. Another consideration ESCs cooled propellers right rotor wash, mine usually are. So, I've always mounted ESCs close motors, realized design could much simpler ESCs mounted centrally. So, question is: pros cons mounting ESCs close motor versus close FMU?",brushless-motor multi-rotor esc
3016,"Tried Normal Distributions Transform files (in correct PCD format) throws errors, why?","I've used program sample PCD's given came correctly. This confirmed experienced users here. Now I'm trying use pcd's. I didn't want bother changing program I changed names room_scan1 room_scan2. When I attempt use them, I get error: Loaded 307200 data points room_scan1.pcd Loaded 307200 data points room_scan2.pcd Filtered cloud contains 1186 data points room_scan2.pcd normal_distributions_transform: /build/buildd/pcl-1.7-1.7.1/kdtree/include/pcl/kdtree/impl/kdtree_flann.hpp:172: int pcl::KdTreeFLANN::radiusSearch(const PointT&, double, std::vector&, std::vector&, unsigned int) const [with PointT = pcl::PointXYZ, Dist = flann::L2_Simple]: Assertion `point_representation_->isValid (point) && ""Invalid (NaN, Inf) point coordinates given radiusSearch!""' failed. Aborted (core dumped) This program I compiled: Before suggest it, I let know I already changed PointXYZRGBA designations PointXYZ. It threw error this. The thing confuses I looked produced PCD files seem exactly samples given NDT. Mine: Sample NDT page: 2320 2e50 4344 2076 302e 3720 2d20 506f 696e 7420 436c 6f75 6420 4461 7461 2066 696c 6520 666f 726d 6174 0a56 4552 5349 4f4e 2030 2e37 0a46 4945 4c44 5320 7820 7920 7a0a 5349 5a45 2034 2034 2034 0a54 5950 4520 4620 4620 460a 434f 554e 5420 3120 3120 310a 5749 4454 4820 3131 3235 3836 0a48 4549 4748 5420 310a 5649 4557 504f 494e 5420 3020 3020 3020 3120 3020 3020 300a 504f 494e 5453 2031 3132 3538 Does anyone ideas?",kinect computer-vision openni
3017,Programming language?,"In general, good programming language robotics? I starting robo nerd don't know anyone would know things like this.",mobile-robot wheeled-robot programming-languages
3021,Directional hearing Linux robot?,"I want give Linux robot ability locate sound source drive towards it. I reading paper sound localization seems cover theory well enough, I'm loss I implement it. Specifically I would like know: How I connect two microphones Linux PC? How I record two microphones simultaneously? Is library sound processing algorithms (similar OpenCV library computer vision algorithms) available Linux?",mobile-robot digital-audio linux
3026,world files simulating roads tracks,"Hello I wanted simulate busy urban road,similar Darpa Urban Challenge autonomous self-driving-car. I'm search simulators that. I've seen gazebo since integration ROS easier editing world files indeed creating difficult. In torcs simulator I seen many world files many sensors. I don't want much physics simulation. I want light weight simulator(for checking path planning urban road) creating roads easier. I've even searched gazebo sdf files similar urban city vain.",simulator gazebo
3027,How frequently PID controller update?,"I developing quadcopter platform extended next year. The project found Github. Currently, using Arduino Uno R3 flight management module. At present, I tuning PID loops. The PID function implemented as: I trouble interpreting system response varying constants. I believe problem related questions below. How frequently PID controller update motor values? Currently, update time 100-110 milliseconds. What maximum change PID update make motor thrusts? Currently, maximum limit +-15% thrust range. At thrust range values, tuning performed? Minimum, lift off, mid-range irrelevant?",quadcopter pid
3029,Alternative way perform Pole zero cancellation?,I've read lot places making controller cancels unwanted pole zero good designing practice designing controller.. It make system uncontrollable course isn't wanted. But alternatives have.. ?? considering system poles zeros lies RHP.,control design
3032,jacobian Abb irb140 robot,Can someone please help jacobian matrix equations Abb irb140 robot. Or easy way I derive given DH parameters. I need implement form control working on. Thanks,control robotic-arm kinematics dh-parameters
3035,How make one robot follow parallel formation,"This quite basic question. I'm practising robot programming VRep. I 2 K3 robots scene. One robot follows predefined path. I want second robot move ""in parallel"" first one keep orientation distance time. When turn, I want follower slow/accelerate little keep parallel. In implementation, I use wireless communication. The first robot periodically ""tell"" second speed, orientation. The second use parameters calculate two speed two wheel. But I run it, doesn't work. The orientation follower wrong. The distance maintained. I totally confused. I think quite rudimentary task. There must practise follow. Can somebody help provide ideas, references? That highly appreciated!",kinematics
3040,"""Smooth"" inverse kinematics model 2-wheeled differential drive robot","I reading kinematic models nonholonomic mobile robots differential wheeled robots. The texts I've found far give reasonably decent solutions forward kinematics problem; comes inverse kinematics, weasel question arguing every possible destination pose either infinite solutions, cases $[0 \quad 1 \quad 0]^T$ (since robot can't move sideways) none all. Then advocate method driving robot based sequence straight forward motions alternated in-place turns. I find solution hardly satisfactory. It seems inefficient inelegant cause robot full-stop every turning point, smooth turning would feasible. Also assertion points ""unreachable"" seems misleading; maybe poses nonholonomic mobile robot can't reach maintaining single set parameters finite time, clearly, vary parameters time according procedure, absence obstacles, able reach possible pose. So question is: inverse kinematics model 2-wheeled differential drive robot shaft half-length $l$, two wheels equal radii $r$ adjustable velocities $v_L \ge 0$ $v_R \ge 0$ (i.e. in-place turns), given want minimize number changes velocities?",mobile-robot inverse-kinematics
3043,Are problems variable frequency PID?,"I working quadrotor trying solve problems described here. In attempts bring refresh rate 100 Hz, I analysis functions time 35+ ms taken RC receiver input function. To tackle this, I decided two solutions: Use interrupts ( library) instead pulseIn Reduce frequency pilot input The second solution much simpler simply read pilot input $(n+1)$ PID updates. So, $n$ times, update time $8\;ms$, $(n+1)^{th}$ time, update time T ms. $n$ around $10$. This create system run average $(n*8 + T)/(n+1)\; ms$. Now, dual/variable frequency affect PID system? Does system behave working effective frequency? I searching time I cannot find anything discusses situation.",pid
3049,How define conditions state-machines roby?,"I searching way allows wait conditions ports applying new state. My concrete Problem: I want make sure AUV aligns right pipeline. Therefore starting pipeline-tracking, I want check current system heading. My current state-machine looks like this: find_pipe_back = state target_move_def(:finish_when_reached => false , :heading => 1 ...) pipe_detector = state pipeline_detector_def pipe_detector.depends_on find_pipe_back, :role => ""detector"" start(pipe_detector) forward pipe_detector.align_auv_event, success_event roughly I looking way condition last-forward.",rock syskit
3052,Gears Autodesk Inventor looking weird,"I use Autodesk inventor professional 2014. I design gears using design accelerator. However, whenever I create gear trains, parts certain gears become transparent. This seems completely random sometimes I zoom I pan orbit, gears look normal again. I experienced problem using default material types. I also ensured gears enabled. Here example pictures Any help suggestions greatly appreciated.",design errors
3058,Why cannot find EtherCAT shields?,"I riddle EtherCAT mind I'd like point view it... With rise open platforms hardware, easily accessible embedded machines, rather straightforward install RT system Xenomai raspberry PI, beagleboard black, whatever cheap platform prefer... Now connect RT bus would really cool (e.g. EtherCAT...). Hence question: every hobbyist face problems RT communication, good reason exist open EtherCAT shield raspberry PI beagleboards? It would solve many problems... Any thoughts why? Any idea?",communication
3062,How connect servo motor crank shaft,"I standard 5v I using horn came it, I mean piece: Like long arm middle. Each holes 1mm diameter. Then I 3d printed crankshaft I did: Its holes also 1 mm. So servo horn attached servo, I attach crank horn order lift lower small scructure. What I sure hot connect 2 pieces (horn 3d printed crankshaft). So far I using paper clip, end I placed 2 blobs tin using soldering iron. This worked nearly year, today I failed, I wondering there's something specific problem, seems something common. I seen people use something called Dubro EZ connector, seems overkill, plus won't space 3D printed piece. Some people seems use clevis pin, I cannot find diameter less 1. So question is, I fix it? What I put ends stop slipping away? I already tried simple things like simply bending it.",arduino mechanism rcservo
3063,Why I still use EKF instead UKF?,"The Unscented Kalman Filter variant Extended Kalman Filter uses different linearization relying transforming set ""Sigma Points"" instead first-order Taylor series expansion. The UKF require computing Jacobians, used discontinuous transformation, is, importantly, accurate EKF highly nonlinear transformations. The disadvantage I found ""the EKF often slightly faster UKF"" (Probablistic Robotics). This seems negligible asymptotic complexity seems same. So everybody still seem prefer EKF UKF? Did I miss big disadvantage UKF?",mobile-robot localization kalman-filter ekf
3066,What generally accepted lift capacity guidelines multirotors?,"e.g. general multicopter configurations would generally accepted recommendations lift 0.5kg, 1kg, 2kg, 4kg, etc. Is general correlation number motors similar sized frame lift capacity?",quadcopter power
3069,Quadcopter degrees freedom,"It might kind stupid question many degrees freedom typical quadcopter? I say saying 4 saying 6. The difference stands translation throughout 2 axis (horizontal ones). Being strict directly tell quadcopter do, 4 movements possible since cannot apply pure lateral force. But tilt start lateral movement align body right let hover horizontal axis, theoretically. So, formally, many degrees freedom I consider exist?",quadcopter
3071,Mahalanobis distance 2 line features,"I implementing ATLAS SLAM framework ground robot, using EKF Slam local maps using line segment features. The line segment features abstracted respective lines α represent distance angle distance-angle representation lines. In given framework, local map matching step lines local maps matched, need distance metric 2 lines. The mahalanobis distance suggested literature, however strictly mahalanobis distance single measurement distribution 2 distributions. How I find mahalanobis distance line 1 [d1,α1] covariance matrix S1 line 2 [d2,α2] covariance matrix S2? In EKF Algorithm book Probabilistic Robotics Sebastian Thrun, computation feature update step, looks like covariances (of new measurement existing measurement) multiplied give resultant covariance matrix, inverse used Mahalanobis distance computation. That would similar Mahalanobis_Distance = [d2-d1,α2-α1] * Inverse(S1*S2) * [d2-d1,α2-α1]' Is correct?",ekf mapping
3073,Data association ekf?,"Given part following algorithm page 217 probabilistic robotics, algorithm EKF localization unknown correspondences 9. observed features $z^{i} = [r^{i} \ \phi^{2} \ s^{i}]^{T} $ 10. landmarks $k$ map $m$ 11. $q = (m_{x} - \bar{\mu}_{x})^{2} + (m_{y} - \bar{\mu}_{y})^{2}$ 12. $\hat{z}^{k} = \begin{bmatrix} \sqrt{q} \\ atan2(m_{y} - \bar{\mu}_{y}, m_{x} - \bar{\mu}_{x} ) - \bar{\mu}_{\theta} \\ m_{s} \\ \end{bmatrix}$ 13. $ \hat{H}^{k} = \begin{bmatrix} h_{11} & h_{12} & h_{13} \\ h_{21} & h_{22} & h_{23} \\ h_{31} & h_{32} & h_{33} \\ \end{bmatrix} $ 14. $\hat{S}^{k} = H^{k} \bar{\Sigma} [H^{k}]^{T} + Q $ 15. endfor 16. $ j(i) = \underset{k}{\operatorname{arg\,max}} \ \ det(2 \pi S^{k})^{-\frac{1}{2}} \exp\{-\frac{1}{2} (z^{i}-\hat{z}^{k})^{T}[S^{k}]^{-1} (z^{i}-\hat{z}^{k})\} $ 17. $K^{i} = \bar{\Sigma} [H^{j(i)}]^{T} [S^{j(i)}]^{-1}$ 18. $\bar{\mu} = \bar{\mu} + K^{i}(z^{i}-\hat{z}^{j(i)}) $ 19. $\bar{\Sigma} = (I - K^{i} H^{j(i)}) \bar{\Sigma} $ 20. endfor My question second loop ends line 15. Shouldn't end line 19. I've checked errata book nothing issue.",localization ekf data-association
3079,Typical method integrating neural net PLC,"How would one typically integrate neural network online automation system? As example, developed neural network predicts difficult measure variable within reactor using multiple sensors. We use predicted variable tell automation system to, example, increase/decrease stirrer speed. How would someone implement idea commercial system. Would develop function block simulate neural network? Would run software server reads writes PLC control tags?",sensors control
3080,Arduino Quadcopter using bluetooth shield android phone,"I need help go building quadcopter software scratch available tools I me. I don't transmitter radio therefore way I remote control using android phone itead studio bluetooth shield I recently given. How I use existing open source software, i.e aeroquad arducopter. The following parts I have:- Arduino Uno Bluetooth shield Four brushless motors Q450 frame Four ESC Turnigy MPU6050",arduino quadcopter
3088,Different Particle Filter min max particle numbers give almost result,"I'm using amcl package ROS localize mobile robot. I've changed max_particles several times calculated output difference odomotry evaluate parameters. The table demonstrate results; As see, notable change output ignore first row table, output variance small. And Particle Filter output map:",localization particle-filter
3090,How request specific Mavlink packet Ardupilot?,"I'm developing program communicating Ardupilot using Mavlink. I've generated code based Mavlink definition Ardupilot, I basic communication working. What I can't figure out, request Ardupilot send specific Mavlink message. I'd like Ardupilot send Mavlink message Attitude (#30) every second. How I this?",ardupilot
3091,How overwrite default git source autoproj?,"I want overwrite git source package autoproj. That package default gitorious I forked spacegit apply specific patches. According autoproj documentation (), I set new repo overrides.yml by: But I inspect remotes newly checked package, fetch url adapted spacegit whereas push url still points default gitorious repo: $ git remote -v autobuild git://spacegit.dfki.uni-bremen.de/<project>/orogen-<package>.git (fetch) autobuild git@gitorious.org:/rock-control/orogen-<package>.git (push) How I overwrite fetch push source package overrides.yml?",rock
3098,Controlling system delayed measurements,"Assume I rather simple system I want control, sensor measurements exhibit considerable time delay, i.e.: $z_t = h(x_{(t-d)}) \neq h(x_t)$ With limited knowledge control, I could imagine following setup: One observer estimates delayed state $x_{(t-d)}$ using control input (delayed) measurements. A second observer uses delayed observer's estimate predicts current state $x_t$ using last control inputs delayed measurement current time. The second observer's estimate used control system. Can I better that? What standard approch problem? And literature research topic?",sensors control sensor-fusion sensor-error
3101,Velocity Model Motion Matlab (Probabilistic Robotics),"I want implement velocity motion model Matlab. According Probabilistic Robotics page 124, model following \begin{align*} \hat{v} &= v + sample(\alpha_{1} v^{2} + \alpha_{2} w^{2}) \\ \hat{w} &= w + sample(\alpha_{3} v^{2} + \alpha_{4} w^{2}) \\ \hat{\gamma} &= sample(\alpha_{5} v^{2} + \alpha_{6} w^{2}) \\ x' &= x - \frac{\hat{v}}{\hat{w}} sin \theta + \frac{\hat{v}}{\hat{w}} sin(\theta + \hat{w} \Delta{t}) \\ y' &= + \frac{\hat{v}}{\hat{w}} cos \theta - \frac{\hat{v}}{\hat{w}} cos(\theta + \hat{w} \Delta{t}) \\ \theta' &= \theta + \hat{w} \Delta{t} + \hat{\gamma} \Delta{t} \end{align*} $sample(b^{2}) \Leftrightarrow \mathcal{N}(0, b^{2})$. With kind variance $\alpha_{1} v^{2} + \alpha_{2} w^{2}$, Kalman Gain approaching singularity. Why?",mobile-robot kinematics motion motion-planning noise
3102,6 DOF Robotic Arm,"We building 6 DOF robotic arm college project we've almost finished designs. The problem controls. We still havent thought control arm, , software gui interfaces , etc. Any suggestions ? Also, simulation software Simulating testing robotic arms ?",control arm
3104,EKF localization known correspondences,"I'm facing problems book book discusses localization depth. The results I'm getting makes sense. I've read lot papers, majority copy localization algorithm book. My question $\bar{\mu}$ $\bar{\Sigma}$ changed every iteration?? I'm using get predicted measurements lines 11- 13, fixed. 9. observed features $z^{i} = [r^{i} \ \phi^{i} \ s^{i}]^{T} $ 10. $j = c^{i}$ 11. $q = (m_{x} - \bar{\mu}_{x})^{2} + (m_{y} - \bar{\mu}_{y})^{2}$ 12. $\hat{z}^{i} = \begin{bmatrix} \sqrt{q} \\ atan2(m_{y} - \bar{\mu}_{y}, m_{x} - \bar{\mu}_{x} ) - \bar{\mu}_{\theta} \\ m_{s} \\ \end{bmatrix}$ 13. $ \hat{H}^{i} = \begin{bmatrix} h_{11} & h_{12} & h_{13} \\ h_{21} & h_{22} & h_{23} \\ h_{31} & h_{32} & h_{33} \\ \end{bmatrix} $ 14. $\hat{S}^{i} = H^{i} \bar{\Sigma} [H^{i}]^{T} + Q $ 15. $K^{i} = \bar{\Sigma} [H^{i}]^{T} [S^{i}]^{-1}$ 16. $\bar{\mu} = \bar{\mu} + K^{i}(z^{i}-\hat{z}^{i}) $ 17. $\bar{\Sigma} = (I - K^{i} H^{i}) \bar{\Sigma} $ 18. endfor 19. $\mu = \bar{\mu}$ 20. $\Sigma = \bar{\Sigma}$ Please suggest books discuss EKF localization depth.",localization ekf
3105,Will 20amp ESC run Turnigy 2213-980?,"I'm noobie starting trying come I need build first quadrocopter, I wanted run something people experience I commit buying anything. Would esc fine running motor? As I understand ESC rated slightly max amps motor? On top that, battery able run motors without issue?",quadcopter brushless-motor multi-rotor esc battery
3108,How control function two different inputs,How might I able control one function (like brightness control LED) two different triggers (like tactile switch IR remote)? I trying able control brightness switches well IR remote desired.,control
3110,ROS: Best practices?,"i'm going build small Robot System seems like ROS serves nice framework control program System. However wondering best practice manage components Robot. Does make sense put sensors one Node? Should put sensors type one node better one node one sensor? Is good practice kind handler node, takes input sensors steers corresponding actuators actuator nodes sensor nodes communicate directly? Fused sensor nodes actuator nodes handler Single sensor actuator nodes handler direct communication For guess best kind handler, handles communication sensors actuators one node element Robot (like Fig.2). Because like system loosely coupled extended easily, I want know opinion is. Greetings",control ros
3116,Problems using syskit monitors -> failed emission foo event,"I tested first monitor, results following error regarding suggestion How define conditions state-machines roby? unfortunately ran runtime error, don't know whether bug misuse monitor... Don't know whether bug, miss-used monitor... action_state_machine i'm using: 183 describe(""Find_pipe_with_localization""). 184 optional_arg(""check_pipe_angle"",false) 185 action_state_machine ""find_pipe_with_localization"" 186 find_pipe_back = state target_move_def(... long stuff ... ) 187 pipe_detector = state pipeline_detector_def 188 pipe_detector.depends_on find_pipe_back, :role => ""detector"" 189 start(pipe_detector) 190 191 pipe_detector.monitor( 192 'angle_checker', #the Name 193 pipe_detector.find_port('pipeline'), #the port reader 194 :check_pipe_angle => check_pipe_angle). #arguments 195 trigger_on |pipeline| 196 angle_in_range = true 197 check_pipe_angle 198 angle_in_range = pipeline.angle < 0.1 && pipeline.angle > -0.1 199 end 200 state_valid = pipeline.inspection_state == :ALIGN_AUV || pipeline.inspection_state == :FOLLOW_PIPE 201 state_valid && angle_in_range #last condition 202 end. emit pipe_detector.success_event # non-monitor use, works commented 203 # forward pipe_detector.align_auv_event, success_event 204 # forward pipe_detector.follow_pipe_event, success_event 205 206 forward pipe_detector.success_event, success_event 207 forward pipe_detector,find_pipe_back.success_event,failed_event #timeout moving 208 end",rock syskit
3117,Device push independent pin points?,"I'm looking device push independent pinpoints something similar Pin Point Impression Toy. I'm looking create 3D image example computer. Does anybody know name device point right direction making one? I've looking while, I'm slight problems finding good way describe search term. I'm sorry wrong forum.",3d-printing
3118,Observation Model Jacobian Fixed Transforms,"Let's say I hypothetical sensor provides, example, velocity estimates, I affix sensor non-zero rotational offset robot's base. I also EKF estimating robot's velocity. Normally, innovation calculation EKF looks like this: $$ y_k = z_k - h(x_k) $$ In case, $h$ would rotation matrix rotational offset. What ramifications instead, I pre-process sensor measurement rotating $z_k$ inverse rotation, put coordinates frame robot? Can I safely make $h$ identity matrix $I$?",kalman-filter ekf
3121,Where I buy heavy-duty Omni Wheels?,"Where I buy multi-directional omni wheels? I'm specifically looking something support excess 100kg/wheel, around 400kg total. Also, possible mission profile would include 300 meter excursion outdoors asphalt path, little durable. The ones I find online small ones experimenting.",wheel
3124,PWM PID control small 2 watts brushed DC motor,"It ""good enough"" PID output directly controls, without modelling, PWM duty cycle? Logic behind question is, In case pure resistance heater, PWM duty cycle percentage directly relates power (on time ratio). So, direct control appropriate. However, motor two additional effects, a) considerable inductance, initial current smaller ramping time b) RPM gradually ramping up, time constant mechanical inertia etc, increasing back EMF reduce current Will wise ignore two effects still expect reasonably good outcome? Application 6 volts, 2 watt DC brushed motor, gear 1:50, 10000 RPM load, PWM frequency 490Hz, driving DIY 1kg robot.",motor pid pwm
3125,"What actual application manufactuing, robot arm autonomous object classification system","I’m graduate student, we're project going introduce robot arm manufacturing. Our goal build autonomous object classification system. We already software hardware required task, idea existing manufacturing scenario apply system really improve efficiency save human resources. Here info robot arm: For hardware part, robot arm 7 dof 5kg payload (the weight end effector counted). Besides, end effector 1.5kg 3-fingered robot hand 2kg payload. The workspace approximately sphere 0.9m diameter. For software part, programming touch, human drag robot record desired pose. Besides, PCL object recognition recognize object pose scene. Lastly, online trajectory generator dynamic obstacle avoidance improve safety robot corporates human. Since know manufacturing, hope someone give us hint scenario actual application apply system.",robotic-arm manufacturing
3132,EKF localization approaching singularity. Are sensors noisy?,I'm getting warning Matlab Kalman Gain. The problem coming high variance measurement model. My question Does EKF work high noise sensor?,localization ekf
3133,Installing OpenNI Pcduino,"Following previous question pcduino+kinect, decided go ahead buy pcduino I wish run robot (kinect+pcduino+shields). However I'm trouble getting started: I tried installing OpenNI, NITE SensorKinect however OpenNI installation fails (I haven't even gotten installing NITE SensorKinect yet idea would work). I tried bunch pointers (here here). For example error I get I follow link 1 is: ubuntu@ubuntu:~/kinect/OpenNI/Platform/Linux/CreateRedist \$ sudo ./RedistMaker.Arm Target: Linux-Arm Version: 1.5.7.10 Num compile jobs: 0 Building OpenNI... Common/CommonDefs.mak:36: * Cross-Compilation error. Can't find ARM-J1_CXX >ARM-J1_STAGING. Stop. failed execute: make PLATFORM=Arm-j1 -C /home/ubuntu/kinect/OpenNI/Platform/Linux/CreateRedist/../Build clean /home/ubuntu/kinect/OpenNI/Platform/Linux/CreateRedist/Output/BuildOpenNI_clean.txt Cleaning Failed! ubuntu@ubuntu:~/kinect/OpenNI/Platform/Linux/CreateRedist$ After someone suggested it, I tried removing -mfloat-abi=softfp option didn't help. There seems compiling/linking issue due float types I'm able figure out. In link 1 author mentions remove 'calc_jobs_number()' work I get similar error. Also similar problem exists link 2 If I follow link 2, 'make' won't work give following error: /usr/bin/ld: error: ../../Bin/Arm-Release/libOpenNI.so uses VFP register >arguments, ./Arm-Release/tinyxmlparser.o /usr/bin/ld: failed merge target specific data file ./Arm-Release/tinyxmlparser.o Another approach would use simpleCV instead OpenNI pcduino someone else claims worked before. However I've never used simpleCV Kinect unless it's radically different I prefer using OpenNI. Any suggestions I might getting errors appreciated. Any pointers solving problem installing OpenNI Pcduino would welcome. Please let know need details anything else. Thanks advance",kinect arm openni
3134,libfreenect simplecv integration?,"I installed SimpleCV libfreenect pcduino (running lbuntu). I separately verified simpleCV reads USB webcam well libfreenect (glview tutorial) gives depth rgb correctly, albeit pathetic framerate. What I want call cam = Kinect() simplecv I that, I get warning ""You dont seem freenect library installed. This make hard use kinect"". Although warning I get error I cam.getDepth(), says ""NameError: global name 'freenect' defined"". How I let simplecv know I've installed libfreenect?",kinect
3137,How use quaternions feed PID quadcopter stabilization loop?,"I'm making quadcopter. I set PID loop stabilize given Euler angle (pitch roll). The problem arises roll approaches 90 degrees (45 degrees up). The values don't make sense anymore, approaches gimbal lock. I intend make complex maneuvers like looping etc., exceeds 45 degree roll limit. How I use quaternions overcome problem? (I get quaternions MPU-9150.) I read many articles matter quaternions, talk rotations 3D software, tweening two rotation points. This makes little sense I know imaginary numbers matrices.",quadcopter pid stability
3139,Denavit-Hartenberg convention,"There two different conventions determine DH parameters. What difference Craig's [1, Sec 3.4] convention Spong [2, Sec. 3.2] convention? I know methods must response. [1]: Craig, John J. Introduction robotics: mechanics control. Addison-Wesley, 1989. [2]: Spong, Mark W., Seth Hutchinson, Mathukumalli Vidyasagar. Robot modeling control. Wiley, 2006.",forward-kinematics dh-parameters
3144,Inverse Kinematics Parallel Manipulator (Delta Robot),"Let start saying I currently going university majoring computer engineering. I love software/hardware I especially love robotics I want apply knowledge software/hardware robots. I never taken formal class robotics, I don't really know start approach mathematics robots entail. Currently, I interested calculating inverse kinematics delta robot. To clarify bit more, I trying determine required joint angles position end-effector delta robot specific location given x,y,z coordinate. The delta robot I basing design shown image below. Based research I past days, I found sort mathematics involved usually like Denavit-Hartenberg parameters, Jacobian matrices, etc. I going honest, I never encountered Denavit-Hartenberg parameters Jacobian matrices I don't even know apply solve kinematics equations let alone find kinematics equations. Most articles I read, mainly deal serial manipulator robots mathematics finding kinematics equations serial manipulators. I couldn't really find good material material easy understand given current situation parallel manipulators. I wanted ask question hopes someone community could direct I start learning obtaining inverse kinematics equations parallel manipulators solving equations. Any help much appreciated. Thank you.",kinematics inverse-kinematics
3145,"How brake brushed dc motor, belt-driven linear actuator within 0.5mm end stop","I belt-driven linear actuator, consisting gantry-plate riding two rails. I'm thinking using brushed dc motor. The gantry move home position right (outbound) 1m/s. The mass gantry vary 3Kg 6Kg. On return home (inbound) one must avoid spillage contents may require soft start/stop simply slow return home. In outbound case, I'd like know how,in practical sense, brake mass bring gantry stop, ensuring gantry plate always comes rest within 0.5mm end plate? I'm clearer I ensure gantry stops within 0.5mm home position, I use PWM ramp slowly decelerate. I'm wanting avoid using MCU. Just want use IC switches potentiometers. You also use math want explain. Of course, one seeks begin arrest mass close end stop outbound case one without problems. Thanks.",motor
3150,Rock envire - vizkit3d : Change environment visualization (envire lib) ruby script,I using ruby script connent Multi Layer Surface Map velodyne_slam component vizkit3D visualization. The visualizazion plugin loaded like this: envireViz = Vizkit.default_loader.EnvireVisualization It possible get MLSVisualisation object EnvireVisualization order set visualization properties (like colors etc.) ruby script? Rubys introspection abilities didn't help lot here...,rock
3152,autoproj snapshot git detached HEAD,"I need search git history couple packages get back working state demo. I searching checking commits manually I found commits effected packages work together. By checking commits manually, I get detached HEAD state: $ git checkout 995e018 -> You 'detached HEAD' state. [...] To save current state packages, snapshot created: $ autoproj snapshot demo_working Now demo_working/overrides.yml pin commit HEAD pointing (e.g. 5e2e3a259) instead commit I chose manually package (995e018). Is desired behaviour? In opinion snapshot store current state git repositories meaning I also select commits manually.",rock
3155,One best ways numerically integrate velocity?,"I need get position $x$ integrating velocity $v$. One could use 1st order Euler integration $x_{t+1} = x_t + \delta * v_t.$ However, leads errors proportional sampling time $\delta$. Do know accurate solution please?",kinematics
3159,Cannot launch iRobot Create. Powers upon minimal launch?,"I got iRobot iCreate base I've followed instructions given ROS Tutorials setup turtlebot pc workstation. I could successfully ssh username@turtlebot workstation I'm assuming good. I issue create able detect usb cable I solved using detailed answer given question here. This solved problem ""Failed open port /dev/ttyUSB0"" I facing before. Now next step would ssh turtlebot (which I've done) use whatever command (I've idea expect upon launch). But apparently something's amiss since create base chirps powers showing [kinect_breaker_enabler-5] process finished cleanly output log file location (see output below), I dont see prompt. I checked battery that's charged that's problem. Following terminal output. anshul@AnshulsPC:~$ roslaunch turtlebot_bringup minimal.launch ... logging /home/anshul/.ros/log/9d936a6a-fbdc-11e3-ba6b-00265e5f3bb9/roslaunch-AnshulsPC-5038.log Checking log directory disk usage. This may take awhile. Press Ctrl-C interrupt Done checking log file disk usage. Usage <1GB. started roslaunch server SUMMARY ======== PARAMETERS * /cmd_vel_mux/yaml_cfg_file * /diagnostic_aggregator/analyzers/digital_io/path * /diagnostic_aggregator/analyzers/digital_io/startswith * /diagnostic_aggregator/analyzers/digital_io/timeout * /diagnostic_aggregator/analyzers/digital_io/type * /diagnostic_aggregator/analyzers/mode/path * /diagnostic_aggregator/analyzers/mode/startswith * /diagnostic_aggregator/analyzers/mode/timeout * /diagnostic_aggregator/analyzers/mode/type * /diagnostic_aggregator/analyzers/nodes/contains * /diagnostic_aggregator/analyzers/nodes/path * /diagnostic_aggregator/analyzers/nodes/timeout * /diagnostic_aggregator/analyzers/nodes/type * /diagnostic_aggregator/analyzers/power/path * /diagnostic_aggregator/analyzers/power/startswith * /diagnostic_aggregator/analyzers/power/timeout * /diagnostic_aggregator/analyzers/power/type * /diagnostic_aggregator/analyzers/sensors/path * /diagnostic_aggregator/analyzers/sensors/startswith * /diagnostic_aggregator/analyzers/sensors/timeout * /diagnostic_aggregator/analyzers/sensors/type * /diagnostic_aggregator/base_path * /diagnostic_aggregator/pub_rate * /robot/name * /robot/type * /robot_description * /robot_pose_ekf/freq * /robot_pose_ekf/imu_used * /robot_pose_ekf/odom_used * /robot_pose_ekf/output_frame * /robot_pose_ekf/publish_tf * /robot_pose_ekf/sensor_timeout * /robot_pose_ekf/vo_used * /robot_state_publisher/publish_frequency * /rosdistro * /rosversion * /turtlebot_laptop_battery/acpi_path * /turtlebot_node/bonus * /turtlebot_node/port * /turtlebot_node/update_rate * /use_sim_time NODES / cmd_vel_mux (nodelet/nodelet) diagnostic_aggregator (diagnostic_aggregator/aggregator_node) kinect_breaker_enabler (create_node/kinect_breaker_enabler.py) mobile_base_nodelet_manager (nodelet/nodelet) robot_pose_ekf (robot_pose_ekf/robot_pose_ekf) robot_state_publisher (robot_state_publisher/robot_state_publisher) turtlebot_laptop_battery (linux_hardware/laptop_battery.py) turtlebot_node (create_node/turtlebot_node.py) auto-starting new master process[master]: started pid [5055] ROS_MASTER_URI= setting /run_id 9d936a6a-fbdc-11e3-ba6b-00265e5f3bb9 process[rosout-1]: started pid [5068] started core service [/rosout] process[robot_state_publisher-2]: started pid [5081] process[diagnostic_aggregator-3]: started pid [5102] process[turtlebot_node-4]: started pid [5117] process[kinect_breaker_enabler-5]: started pid [5122] process[robot_pose_ekf-6]: started pid [5181] process[mobile_base_nodelet_manager-7]: started pid [5226] process[cmd_vel_mux-8]: started pid [5245] process[turtlebot_laptop_battery-9]: started pid [5262] [WARN] [WallTime: 1403641073.765412] Create : robot connected yet, sci available [WARN] [WallTime: 1403641076.772764] Create : robot connected yet, sci available [kinect_breaker_enabler-5] process finished cleanly log file: /home/anshul/.ros/log/9d936a6a-fbdc-11e3-ba6b-00265e5f3bb9/kinect_breaker_enabler-5*.log Following log file: /home/anshul/.ros/log/9d936a6a-fbdc-11e3-ba6b-00265e5f3bb9/kinect_breaker_enabler-5*.log output: [rospy.client][INFO] 2014-06-24 14:20:12,442: init_node, name[/kinect_breaker_enabler], pid[5538] [xmlrpc][INFO] 2014-06-24 14:20:12,442: XML-RPC server binding 0.0.0.0:0 [rospy.init][INFO] 2014-06-24 14:20:12,443: ROS Slave URI: [] [xmlrpc][INFO] 2014-06-24 14:20:12,443: Started XML-RPC server [] [rospy.impl.masterslave][INFO] 2014-06-24 14:20:12,443: _ready: [xmlrpc][INFO] 2014-06-24 14:20:12,444: xml rpc node: starting XML-RPC server [rospy.registration][INFO] 2014-06-24 14:20:12,445: Registering master node [rospy.init][INFO] 2014-06-24 14:20:12,543: registered master [rospy.rosout][INFO] 2014-06-24 14:20:12,544: initializing /rosout core topic [rospy.rosout][INFO] 2014-06-24 14:20:12,546: connected core topic /rosout [rospy.simtime][INFO] 2014-06-24 14:20:12,547: /use_sim_time set, subscribe simulated time [/clock] topic [rospy.internal][INFO] 2014-06-24 14:20:12,820: topic[/rosout] adding connection [/rosout], count 0 [rospy.core][INFO] 2014-06-24 14:20:20,182: signal_shutdown [atexit] [rospy.internal][INFO] 2014-06-24 14:20:20,187: topic[/rosout] removing connection /rosout [rospy.impl.masterslave][INFO] 2014-06-24 14:20:20,188: atexit From logs, I could tell something told create power down. And since log named 'kinect', I tried minimal.launch w/ w/o kinect attached turtlebot pc. It doesn't make difference. Any clue I might missing? Or way bringup works (I guess not)?",ros irobot-create
3160,iRobot Create without ROS?,"Is possible control Create without using ROS whatsoever? I know serial/Digital I/O pins connect ROS controls using drivers/libraries. But hard would using, say, PCduino? I'm asking I'm trouble launching create using ROS (question)",irobot-create
3162,BS2 inconsistant pin state connected wire?,"I BS2 mounted Parallax Board Education Rev D. I trying use wire determine whether control pressed. however, whenever there's wire connected state seems fluctuate 1 0 instead staying one other. connected desired button still exhibits behavior added quality switching zero button pressed. ideally stay zero buttons pressed 1 it's not, instead flickers 1 0 unpressed. causes behavior occur even wire connected anything except bus? code used get state",microcontroller
3164,Autodesk Inventor 2013: Rounding specific edge,"I using Autodesk Inventor 2013 I need round component device. I want round green marked edges, red marked. But I click ""round"", bottom edge always added rounding I cannot de-select it. Any hints solve problem?",design
3166,Maximum likelihood estimator (ML Data Association) EKF,"This question extension previous problem (Data association ekf). My problem line 16 aforementioned link. 16. $ j(i) = \underset{k}{\operatorname{arg\,max}} \ \ det(2 \pi S^{k})^{-\frac{1}{2}} \exp\{-\frac{1}{2} (z^{i}-\hat{z}^{k})^{T}[S^{k}]^{-1} (z^{i}-\hat{z}^{k})\} $ When I compute line, I'm getting huge number . This probability density function. Why pdf getting bigger 1 huge way?",localization ekf
3170,Path comparison,"Problem: cartesian position end effector (no orientation) robot arm recorded, say, every millisecond (the time steps changed), motion. The robot arm commanded path different velocities. So I get different trajectories. I want calculate deviation paths, distances equivalent points two paths. The problem find equivalent points. Since two velocities different comparison time steps trajectories makes sense. I assume paths underlying trajectories compared rather similar. The deviation ideal path smaller 1% typical length dimension path. I want detect deviations much lass that. I map timestamp recorded points path length, make comparison points path length. But course also path lengths differ different paths, deviation would distort result later points. How I compensate ? Is reliable algorithm ? Where I find information ? Note: time warp algorithms (even memory optimized ones) game memory consumption.",localization robotic-arm
3172,Making Gripper Changer Robotic Arm,How make gripper changer robotic arm like this? I don't see could connect power/control wires use hold gripper arm.,robotic-arm
3173,Velocity Control via Vibration,"I working robot accelerometer. This accelerometer measures vibration robot. When robot hits certain vibration, I would like slow order reduce vibration. I thought PID controller, I don't think would work. Does anybody input different types controllers I use? Mechaman",pid accelerometer navigation
3178,Controlling system PID resists backdrive,"I'm controlling angular position pendulum using DC motor worm gearbox. Mechanically, worm gears impossible backdrive. Using PID controller pendulum system regular DC motor (no worm gear), integrator would help motor find appropriate constant power setting overcome gravity pendulum hold arbitrary position. With worm gear, however, need apply constant power motor desired position achieved. Power motor cut worm gear resist gravity's force backdrive pendulum lowest gravity potential. It seems me, then, integrator PID algorithm cause large overshoots desired position achieved. I want integrator initially help control pendulum desired position. But position achieved, I'd need integrator turn off. The solution I come test special condition PID algorithm checks position reached AND angular speed small, instantaneously reset integrator zero. Is better way handle integrator system resists backdrive? ** EDIT * When I originally worded question, I mostly interested academic approach backdrive resistance PID loop. But it'll help I explain actual mechanism I'm building. The device robotic arm rotates car window motor. It also occasionally pick drop small weights end arm. Manufacturing variability motors difference drive torque picking small weights led consider PID loop.",pid
3181,"How calculate robot hand positions using Roll, Pitch angles","want calculate humanoid robot hand position given shoulder roll, pitch angles elbow roll angle. I'm able calculate elbow position using rotation matrix includes shoulder angles. But dont know calculate hand position using elbow position elbow roll angle. Can propose method calculate hand position?",robotic-arm forward-kinematics
3183,Adding external magnets DC motor,"Is possible strengthen permanent magnet DC motors simply attaching extra magnets outside motor casing - adding magnetic field? If possible, question becomes; happens I replace magnets inside motor better magnets? I know coils handle current currently do, net effect motor be?",motor
3188,Where go purchase parts XY Plotter,"I trying build 2ft square XY Plotter. I seen three designs far: 1)Rack Pinion 2)Threaded Screw 3) belt-driven. use stepper motor drive system. Each one obvious pros cons correct wrong, believe rack pinion system sturdy easiest put together. I googled Rack pinion get industrial websites. Is place sells cheaper rack pinion sets hobbyists? The payload XY Table eletro-magnet isn't extremely heavy (maybe half kilogram most). So obviously motor must strong enough move anothe rack significantly heavier payload. This first real robotics project new this.",stepper-motor motion actuator
3200,Manipulator link applied torque,"I want implement manipulator link using physic library. I apply torque centre mass, torque applied beginning link. Shifting reference frame centre mass recalculating inertia tensor new frame problem, neither recalculating new torque, based change distance, I think correct solution. In short, I scale torque control signal applied beginning link torque physic simulation applied centre mass. Thanks.",simulator torque
3206,Current-limiting stepper motors RepRap,"I working robot project while. Now I tired finding parts job, time create parts. A 3D printer trick many parts, 3D printers share lot CNC mill terms control parts. So question this: I building Reprap style printer, I use heavy duty parts motors, hoping make aluminum capable 3 axis mill later. I found bipolar NEMA 23 stepper motors 1.9 Nm 3 Amps per coil. According reprap.org website, recommend NEMA 17 low voltage. Seems use voltage limit current. Can I build reprap, use current limiting stepper drivers Arduino software I find online, get away large stepper motors? Or I lot trouble?",arduino stepper-motor stepper-driver cnc reprap
3207,Best microphone speech recognition tasks,"I made several tests different setups order achieve acceptable speech recognition quality. It works well I push button activate I want automatically activated user speaks. This big problem, especially I use energy audio signal guess user speaking. That I thought using headset distant microphone. In headset microphone close users mouth easier make correct guesses user speaking. Now question bluetooth sets used mobile phones also property. They long enough microphone positioned exactly front mouth. Is possibility devices also capture speech/noise distant user? Is significant difference signal energy coming user's speech 1 meter distant person's speech?",digital-audio speech-processing
3208,Electronic Speed Control Concepts,"I programmer never worked electronics before. I learning concepts hoping build quadcopter, control software entirely written me. Motor control seems important part. Is true typical brushless DC motor ESC (Electronic Speed Control) approximately control speed? That's ESC seems approximate idea fast motor revolving. This still works PID (Proportional Integral Derivative) controller gets indirect feedback say gyroscope whether motor going fast enough tell ESC make revolve ""even faster"" ""even slower"", that's good enough. Is understanding paragraph correct? If so, I wonder whether servo motor inform current rate rotation could help away ESC entirely? I feel microcontroller receive input motor speeds send output requesting certain speed, would need ESC. But I sure servo motors work -- happens immediately request 100rpm say 80rpm? Since cannot adjust immediately, microcontroller immediately adjust motors account fact motors 100rpm yet? Does imply microcontroller request small deltas currently measured speed, period deviation desired state negligible? In latter model, requesting small deltas currently measured speed, algorithm seems like would really PID since way control acceleration? But may requesting servo go 80rpm 100rpm causes reach 81rpm much faster requesting go 80rpm 81rpm? I feel I know little I cannot put finger precisely, I hope gives idea concepts I struggling absorb. To summarize, questions are: servo (brushless dc) motor allow away ESC? servo motor accept control inputs ""revolve 100rpm""? servo motor offer output saying ""i 80rpm now""? servo motor 80rpm go 81rpm faster requested revolve 100rpm versus 81rpm? less precise questions implicit text above. (crossposted electronics.stackexchange)",motor pid brushless-motor esc servomotor
3209,Can active sensor data fed Autodesk Inventor Simulation?,"I'd like drive position various components within virtual assembly based sensor data collected real time external device. Does Inventor support setup? The goal match relative movements components screen real-world counterpart. For example, absolute rotary encoder records current angle physical joint virtual joint rotated match. Is feasible? My past searches information turned empty; perhaps I'm using wrong search terms. Most results point irrelevant mechanical stress simulations.",sensors kinematics
3210,Why production lines huge power hungry?,"I'm thinking starting adventure area professional manufacturing. When I started look onto machines I figured build somehow like 70s: huge footprint, big 3kW electric motors etc. Is explanation build way? The one I think is: developed long time ago worked, stays is. BTW: If know place ask question please let know!",manufacturing
3216,Is gear design feasible?,"I came idea working mechanical engineer design prototype idea I keep sketching ideas process I came this.. I'm quite sure idea he'll go I'm kinda curious whether would actually feasible. Or I know it's already common place, totally stupid... I dunno. What think?",mechanism movement
3218,Repairing non-lubricated linear actuator,"I Chinese CNC mill (CNC3020T, though several different devices go name), Z axis imprecise, often randomly position much 0.5mm. I've disassembled linear actuator discovered several problems it. First problem apparently forgot lubricate linear ball bearings. I make conclusion rails set grooves ground them, wiping rails tissue thing left finely powdered metal, traces oil lubricant. Second problem nut. I expected see ballnut, reality piece threaded PTFE! The leadscrew rotates smoothly it, quite lateral movement, i.e. I tilt slightly without opposing force. Third problem overall mounting. In picture below, top left screw sheared factory hid mistake tapping larger thread putting shorter screw doesn't actually hold anything top plate. So whole assembly fixed three, rather four, points. However, remaining screw quite tight. So closely related questions are: Is assembly even salvageable? How I verify linear ball bearings, PTFE nut relatively undamaged? Can I rotate rails 45° get smooth surface again? What I lubricate linear bearings with? Do I clean lubrication? I ultrasonic cleaner. Any advice maintenance whole assembly? There may something I missed.",actuator linear-bearing
3222,Predicting impact point moving object,"Suppose moving object (a horizontal projectile motion one basic examples). Is way predict hit finally? Please note I'm looking machine learning method closed form solution. Although track motion, using Kalman filter, That applicable want predict new future(As far I'm considered). But I need predict ultimate goal moving object. To better express problem let see following example: Suppose goalkeeper robot course uses filtering methods smooth ball motion. It needs predict ball going enter goal not, decide catch ball neglect go out. Input data time series location velocity [x,y,z,v].",machine-learning
3225,Android Vibrating based Arduino devices,I want make simple device causes cellphone vibrate 30 seconds phone 10 feet away it. How would I go that. How small could I make device?,arduino
3227,Finding Hydraulic Actuator controlled MCU,"I'm researching potential actuators I use project i'm doing. I'm designing creeper (platform rolling vehicles) lift like operation hospital beds. The creeper joystick control motion well option drive forward,backwards,left right. I need actuator support average weight 250lbs would able lift body weight. I thinking hydraulic actuator i'm sure exist. I well two actuators share load also. However, I need control actuators micro-controller unit. I'm planning using Raspberry Pi I abundance mainly, i'll researching potential units. Therefore, MAIN question I find actuator would good fit type project integrated micro-controller unit? Does anyone experience type project important details I need take consideration I'm thinking of?",microcontroller actuator
3231,Up force servo motor reasonable choice actuator?,"I'm working application I need apply linear angular force operate linkage mechanism, I don't (yet) know amount force I need. I anticipate less 4.5 kg (44 N). The travel distance linkage input less 15 cm. As I look available servos, seem exist firmly scale-model realm remote control vehicles, I uncertain suitable application. For example, one Futaba's digital servos, mega-high torque S9152, listed 20 kg/cm. From I understand, means 1 cm center servo shaft, I expect approximately 20 kg force. If I wanted 15 cm travel distance I would need roughly 10.6 cm radius, would diminish applied force 20 / 10.6 = 1.9 kg, well 4.5 might required. Question: Is understanding calculation even remotely accurate? Should I looking types actuators instead servos? They seem become prohibitively expensive 20 kg/cm torque. (For purposes project, budget actuator less $250 US.) For application, I'd like reasonable control intermediate positions across travel range, good holding power, fairly fast operation. For reason I dismissed idea using linear actuator driven gearmotor worm drive. I relatively new robotics usage motorized actuators, I've used pneumatic cylinders many years. For application, I can't use pneumatics. Edit: Per comments, additional constraints important: Linkage Details: The linkage planar, one degree-of-freedom, part portable system (similar scissor lift mechanism). It theatrical effect motion amplified force reduced (speed ratio mechanical advantage < 1). Power: It carried person. As such, actuation needs battery-operated, tubing wiring tether person. Tubing wiring self-contained okay. Because portable system, battery-power used. The control system designed specifically appropriate actuator. Rechargeable batteries 12V likely employed. Actuators could operate high 24V. Ideally motor would exceed 1-2 amperes draw, continuous operation, hard limit. Not Pneumatic: I've considered pneumatic actuation, using CO2 cartridges, example, client would prefer use pneumatics. Also, ability stop/hold intermediate points motion range desirable, somewhat complicated pneumatic actuators. Speed: An ideal actuator able move input coupling 15 cm 1-2 seconds. Weight: Weight constraints well-defined. As carried person, moderately lightweight. The actuator probably less 1kg, certainly vary. (The rest mechanism probably 6-8 kg.) Size: The primary size constraint everything must fit within space measuring 500 x 500 x 120 mm (H x W x D). The linkage mechanism extends collapses outside enclosure, parallel width. Noise: The quieter better, noise least priority. Servos seemed like best choice job, don't seem available sort torque I need.",servomotor
3233,Designing compatible spur gears robot gearbox,"I'm trying increase torque output shaft robot's gearbox. I motor pinion attached 8 teeth. I want create gear 33 teeth mesh pinion I currently have. I've got access 3D printer make gear, I don't know design second gear mesh properly. What parameters I need know first gear (8 teeth) ensure second gear (33 teeth) mesh correctly? How I translate parameters design second gear?",motor differential-drive
3234,Robot interaction language,"Is well documented robot interaction language? I would imagine something like taking user's speech English, parsing using natural language processing like NLTK Stanford NLP building new sentence understandable robot. Does something like already exists? I recently found ROILA seems like whole different language reformulation sentences using English words less grammatical complexity.",speech-processing
4238,I need software help track passage identify fish clear water,"I charge studying passage different species fish (six species) lakes Patagonian Andean range. We've thinking deploying video cameras underwater, we'd need software would control cameras record images video adequately changes avoid continuously check video. If software also capable recognizing species would even better.",software
4239,Good method Retuning PID After Detecting Oscillation,"Given PID controller anti-windup, practical ways retune controller oscillation caused detected? I access magnitude period oscillation. I don't want use Ziegler-Nichols method; rather I'd like method allows specify phase/gain margin I returning system. Could someone recommend towards book/article theory?",control pid
4247,Tilt-compensated motor output keep altitude quadcopter,"The propellers multicopter produce thrust. Unfortunately thrust smaller, copter tilted. I currently wondering whether established method calculate much overall thrust modified hold current altitude, based current attitude. This way calculate motor output far. rol/pit/yaw-output already ran PIDs.",quadcopter
4255,Software simulate mechanics production line,"Is software I simulate production line elements (joints, motors, springs, actuators, movement)? For example I want simulate mechanism unwind paper big roll weld later bubble foil finally make bubble foil envelope, mechanism look like this: I need simple possible preferably free.",mechanism simulator
4256,IMU based acceleration parameters differential drive robot,"I differential drive robot whose motors virtually quiet driving completely flat surface, motors make lot noise incline. This likely due correction required maintain speed high inertial load robot cannot accelerate fast enough PID keep up. But I noticed noise related acceleration, higher acceleration, smaller amount noise I hear, smaller time level noise lasts (up certain acceleration limit, otherwise motors get really noisy again). I trying find use IMU I available order change acceleration based steep path's incline is. Any documentation (papers, tutorials, etc) motion planning related topic point to?",ros imu differential-drive noise
4261,Stereo camera baseline needed calibration?,I stereo camera calibration described blog post. I wonder I need input camera baseline calibration. The fact probably goes back basic mathematics triangulation. Can someone explain?,computer-vision calibration stereo-vision
4263,Visibility Graph Toolbox Python,"I'm searching python toolbox/library visibility graph based motion planning. I searched internet, couldn't find anything. I'm probably missing out... Is package, recommend me?",motion-planning python
4265,Determing limits rotation robot workspace,How determine limit range end effector orientation (Roll-Pitch-Yaw) one specific point(XYZ)?I derived Forward/Inverse kinematic. I'm making program 6DOF articulated robot arm user know limit tool rotation Global axis(Roll-Pitch-Yaw) certain point.,robotic-arm
4266,Are stereo camera calibration data standardized?,"Is standard format stereo calibration data (various matrices, usually saved XML) stored? Can I load calibration data generated say OpenCV script C another OpenCV script say C++ completely different software I create disparity image?",computer-vision calibration stereo-vision
4270,Solenoid launch ping pong ball,"I've looking ideas launch ping pong ball small distance (< 1 metre) game. Solenoids look like might useful I'm 100% force/type I need. I mount base balls roll it, pin pushing ball ramp it's target. As it's ping pong ball, light. I considering something like this: Am I along right lines? Or I go back drawing board.",motor
4271,PD controller C#,"I currently building line-following mobile robot. I've done image processing work C#, I control phase. I looking PD controller program written C# start with. I've searched lot without success. My robot Arduino based, motherboard Core i3 CPU, I using Camera LDR sensor.",control algorithm
4277,What difference screw wrench rigid body motion?,A screw defined six dimensional vector forces torques. It represent spatial movement rigid body (as written here). But I don't get following distinction screw wrench: The force torque vectors arise applying Newton's laws rigid body assembled screw called wrench. It seems kind contextualisation way?,dynamics theory
4281,What type mechanism this?,"Held rotated knurled ends, one hand, silver spokes rise fall order assembly rotate. What it, companies' salesmen show tool? Found old building, unit markings.",design joint
4285,sparse matrix EKF SLAM,"I've successfully done EKF Localization Algorithm known unknown correspondences stated ""Probabilistic Robotics"". The results make perfect sense,so I estimate position robot without using GPS odometry. Now I've moved EKF-SLAM known correspondences book. I don't understand matrix $$ F_{x,j} = \begin{bmatrix} 1 & 0 & 0 & 0 \cdots 0 & 0 & 0 & 0 & 0 \cdots 0 \\ 0 & 1 & 0 & 0 \cdots 0 & 0 & 0 & 0 & 0 \cdots 0 \\ 0 & 0 & 1 & 0 \cdots 0 & 0 & 0 & 0 & 0 \cdots 0 \\ 0 & 0 & 0 & 0 \cdots 0 & 1 & 0 & 0 & 0 \cdots 0 \\ 0 & 0 & 0 & 0 \cdots 0 & 0 & 1 & 0 & 0 \cdots 0 \\ 0 & 0 & 0 & \underbrace{0 \cdots 0}_{3j-3} & 0 & 0 & 1 & \underbrace{0 \cdots 0}_{3N-3j} \\ \end{bmatrix} $$ What exactly bottom matrix? The following $$ F_{x,j} = \begin{bmatrix} 0 \cdots 0 & 1 & 0 & 0 & 0 \cdots 0 \\ 0 \cdots 0 & 0 & 1 & 0 & 0 \cdots 0 \\ \underbrace{0 \cdots 0}_{3j-3} & 0 & 0 & 1 & \underbrace{0 \cdots 0}_{3N-3j} \\ \end{bmatrix} $$ Is following (assuming N = 3) $$ F_{x,j} = \begin{bmatrix} 1 & 0 & 0 & 1 & 0 & 0 & 1 & 0 & 0 \\ 0 & 1 & 0 & 0 & 1 & 0 & 0 & 1 & 0 \\ 0 & 0 & 1 & 0 & 0 & 1 & 0 & 0 & 1\\ \end{bmatrix} $$ Or $$ F_{x,j} = \begin{bmatrix} 0 & 0 & 0 & 1 & 0 & 0 & 0 & 0 & 0 \\ 0 & 0 & 0 & 0 & 1 & 0 & 0 & 0 & 0 \\ 0 & 0 & 0 & 0 & 0 & 1 & 0 & 0 & 0\\ \end{bmatrix} $$ ones' represent specific landmark.",slam ekf
4287,Kalman filter Issue - GPS Odometry Fusion,"I working estimating robots pose using Odometry GPS. My first problem kinematic model seen differential drive robot proposes using displacement left right wheels evaluate robots next pose. However, situation robot spits current X Y pose relative starting point movement. use state estimate P = [x,y]T P = [x0,y0] + [dx,dy] dx dy change respective coordinates gotten robots odometry. posible calculate state covariance Q filter. For GPS, evaluate covariance R; tried collect multiple reading latitude longitude fixed point dont know righ dont get evaluate covariance data (feeling dumb). Thank anticipation.",mobile-robot kalman-filter gps odometry
4288,Tilt-compensated compass - wits' end,"I'm bit wits' end - I'm trying build tilt compensated compass autonomous sailboat (ardusailor!). I'm using InvenSense MPU9150. Originally, I used built-in fusion support sensor get quaternion, pull yaw/pitch/roll angles that, use formula tilt compensation: various s_angle sin(angle) c_angle cos(angle). That didn't work. I tried using vector-based approach stolen here. That didn't work. Then, I took away tilt compensation, uncompensated atan2(Yh,Xh), produced strange result well. Basically, I rotate sensor z axis, value rotates 70 -10 degrees, completing full circle (i.e. make 360 degree rotation, starts 70, gets -10, back 70). 70 0* magnetic, 10 180, 0 70-80. I see behavior HMC5883L magnetometer chip well. The thing is, looking raw values, I get magnetic values seem fine, hard soft iron offsets place: top row corrected offsets (using ellipsoid fit method), bottom raw. The numbers may look skewed, aren't - scales aren't same. Graphs are, order, x:y, y:z, x:z What could be?",compass magnetometer
4295,EKF Localization robot parallel landmark.,"I'm facing real weird problem EKF Localization. The filer gives wrong error every time robot parallel landmark. I've debugged code many times failed solve problem however I found exactly problem occurs. The following picture shows scenario. The robot moves circular motion. There four landmarks. I indicted picture filer gives wrong angle estimated state. As see, robot parallel landmarks, I got wrong angle estimated robot's pose. This another picture shows estimated angle wrong red circle estimated robot's pose blue one actual robot's pose. I also track problem numerically. What I found estimated measurement landmark # 4 opposite direction actual measurement landmark # 4. I computed angles. For actual measurements, Zobs = [ sqrt((map(i,1) - real_robot(1))^2 + (map(i,2) - real_robot(2))^2) ; atan2(map(i,2) - real_robot(2), map(i,1) - real_robot(1)) - real_robot(3); i]; % add Gaussian noise Zobs(1) = Zobs(1) + sigma_r*randn(); Zobs(2) = Zobs(2) + sigma_phi*randn(); Zobs(3) = i; Zobs(2) = mod(Zobs(2), 2*pi); (Zobs(2) > pi) % positive Zobs(2) = Zobs(2) - 2*pi; elseif (Zobs(2) <= -pi) % negative Zobs(2) = Zobs(2) + 2*pi; end For predicted measurements q = (map(i,1) - est_robot(1))^2 + (map(i, 2) - est_robot(2))^2; Zpre = [ sqrt(q); atan2(map(i,2) - est_robot(2), map(i,1) - est_robot(1)) - est_robot(3); i]; (Zpre(2) > pi) % positive Zpre(2) = Zpre(2) - 2*pi; elseif (Zpre(2) <= -pi) % negative Zpre(2) = Zpre(2) + 2*pi; end",localization ekf
4296,Calculate object distance camera,"Firstly I'm unsure whether question belongs another SE site (but I'll wing now). I've recently given job connecting 'smart camera' setup robotic arm pick place objects point A point B. The real application camera check objects alignment supposed positions. However I curious see way I calculate distance object given I already know objects actual size. Naturally camera see object bigger closer smaller farther away I turn information depth/distance camera? I yet started using camera. For idea. I assume I calculate percentage view frame taken object. For example I object uniform shape, I know dist1 takes 75% view frame dist2 takes 45% view frame. Should prove possible I imagine could number different applications. /Anyway feedback appreciated. Thanks! ( :",localization calibration cameras
4297,Which micro-controler/processor used autonomous stereo vision robot system?,"I new two robotics, however I working stereo algorithm I want combine SLAM algorithm. I developing system application I decided integrating robot first testing might good way get used system test behaviour realistic environment. (rather testing kind software simulator only) However, I want system autonomous running on-board rover. The system I talking consist of: stereo camera rover wheels one motor possibly kind sensor ""measures"" movement, e.g. much wheels turned maybe distance sensor Appart it's software stereo software already developed, SLAM algorithm not. Therefore currently impossible say much RAM needs. I currently running stereo-vision i7 approx. 1s. Now question: mentioned I idea robotics, also electronics knowledge limited, I idea I need robot comes processor electronics. I read stuff Raspberry Pi Arduino boards I idea make this. I afraid Arduino able handle computational load stereo vision SLAM algorithm I read Raspberry Pis first choice interfacing sensors needed (in case stereo cameras). Also I found Leika kit robotics kit Raspberry Pi. Maybe would good option me? Maybe entirely different system would even advisable? Possibly someone else build equally complex system give advise form his/her experience?",arduino mobile-robot raspberry-pi slam stereo-vision
4299,"Arduino two Linear Actuators, two ACS714 Current Sensors, L298N Motor Driver setup","I using L298N motor driver drive two HAD1 linear actuators (12V no-load drive current ~950mA each) Linear Actuator: Motor Driver: L298N dual-h-bridge motor-driver controller board-module arduino robot I also using current sensor per motor get feedback motor (only sensors I available, I detect motors moving stopped). I using two ACS714 current sensors. The supply voltage 4.5V 5.5V Supply Current 10mA 13ma: Current Sensor: ACS714 current sensor. And Here circuit diagram I made actual setup (an Arduino UNO, two current sensors, linear actuators, one motor drive): Circuit Diagram: Will setup work? Will I enough current/power coming 5V arduino power L298N logic two ACS714 sensors?",arduino control actuator current circuit
4303,autonomous obstacle detecting quadcopter,"Is possible build quadcopter detect obstacles thereby avoiding order reach destination? If so,how could avoid obstacles destination set",quadcopter
4307,Stepper turn,"I always wanted CNC make PCB quickly home. Finally, I got 7x7 kit zentools recently put together. I attached battery powered screw driver 2nd shaft stepper moved axis way back forward wiring. All 3 axis moves smoothly, I turn steppers even hand. Every piece works smoothly, mechanical jam. I decided use GRBL controller software. Tested software without shield stepper (qv: Testing GRBL Arduino Board without steppers) I use Universal Gcode Sender communicate GRBL. I got Arduino CNC Shield Arduino UNO, put together, attached Arduino UNO, re-tested GRBL, worked. I used Reprep's Stepper wiring article connect stepper driver, wired 1 stepper stepper driver (X axis). Powered shield 20V 17.5Amp (350W) DC Regulated Power supply. (It power adaptor old 17"" notebook. Notebook died, I kept adaptor) When move 5 steps command (G1 X5) sent, stepper makes small move direction makes grinding noise. (Can seen Youtube) I tried switching 1st pair's cables, using another stepper driver (3 drivers), turning potentiometer increase current, still luck. I attached 2 photos cnc controller controller unit. I tried everything I think of, suggestions?",stepper-motor cnc
4308,What difference two different types Mecanum wheels?,"While looking Mecanum wheels, I noticed two different designs popular. One type holds rollers wheels frame, holds rollers center. Is significant advantage using one other?",wheel
4312,Low-cost centimeter accurate satellite positioning (GNSS/GPS),I looking cheapest possible GPS setup centimeter precision without much HW hacking. I able produce PCB soldering (though I would way) kind easy-to-assemble setup would welcome. I know $900 Piksi thing still expensive me. It seems like cm precision possible much less - like employing 50 USD raw GPS sensor antenna ordinary PC RTKLIB software. I sure better use two GPS sensor setup RTK (one base station one rover) whether I get corrective DGPS data elsewhere (my region Czech Republic - seems national grid allowing stream correction data reasonable cost). My application passenger car I limited power source - low power needed although would nice. I using position readings within OpenCV - I need get data C/C++ code. The application data collection I use raw GPS post-processing.,gps
4313,PID Integration constant dt (∆time),"Is integration constant dt (∆time) possible thing? Let's say PID loop differentiating frequency, integral part still work? (Assuming know dt last iteration) Could I use variable dt (∆time) calculation PID principle would still function correctly?",quadcopter pid real-time
4316,Compact design - building off-the-shelf components,"I want build small cylindrical arm, main 360º angular servo longitudinal axis, secondary angular servo variable speed trasversal axis rotates main angular one. The secondary needs receive data power slip ring across main servo, since must able rotate freely must binded wirings. The width cylindrical arm must 0.4 cm I've reviewed market off-the-shelf servos could fit bill main servo, I know obtain slip ring required, beats obtain secondary servo, since space limitations demand really small (< 0.2 cm) smallest I've able find internet 0.5 cm Any suggestions greatly welcome!",servomotor
4318,Cascading PID DC Motor Position & Velocity Controllers,"I'm trying build robot differential drive powered two DC Motors. First I implemented PID Controller control velocity motor independently. Estimated TF using MATLAB's System Identification Toolbox, open loop system acquiring velocity wheels encoder function PWM signal applied Arduino microcontroller. All went well successfully dimensioned PID gains controller. What I'm trying accomplish control exact (angular) position DC Motor. I thought cascading PID controller input already implemented. So way, I give position first controller, capable generate output reference second (velocity) controller generates appropriate PWM value signal drive DC Motor accordingly. Will work? Is good approach? Or I try implement different controller outputs PWM signal response position reference signal? Many thanks attention I hope somebody help doubts.",arduino control microcontroller pid wheeled-robot
4323,Exoskeleton Drive System Help,"I currently working exoskeleton. The exoskeleton going help kids cerebral palsy learn walk 4 years sooner traditional therapy. Currently using 2 Ame 226-3003 roboclaw 2x60A motor controller controlled Arduino mega. The Ame 226-3003 motors powerful enough. In addition Ame 226-3003 worm gear thus motor cannot moved motor turned off. Our position feedback system gear attached shaft motor spins gear potentiometer. The two gears 1:1 ratio. In order better understand project, please see video: The Ame 226-3003 catalog page: We need new drive system: powerful Ame 226-3003 motor. We exact torque spec believe drive system 70-100% powerful Ame 226 - 3003. We like rpm range Ame 226-3003. The drive system must able spin freely motor use. We need way get position feedback, potentiometer system using seems work, however adds much extra hardware(more stuff break), (ie) gear potentiometer gear shaft mesh constantly zero potentiometer every time put leg together potentiometer doesn't spin. * We would prefer optical encoder inside motor. We need drive system right angle. I need help designing drive system meet requirements. I think I might found motor work: The amp flow G43-500 I like G43-500 run 24 v, thus take less amps 12v. Will motor get job done? I need gear around 80rpm. What type gear box would work best?",motor control microcontroller motion-planning encoding
4326,Is rule thumb actuator torque overhead?,"When installing servo actuator, I measure force needed perform whatever action needed find actuator generate necessary force. However, I recently wondered there's rule thumb guideline much overhead useful, becomes waste. For (perhaps oversimplified) example, say I lever lift something, force needed 100 Newtons. An actuator manage 100 N maximum problems stall, sort friction imperfections. I would use actuator produce 150 200 N - whatever available fits design budget. After testing, may become apparent 200 overkill, 120 sluggish, 150 good. Other trial error, way measure this, rule approximation? I realize variables mechanics construction significantly alter force might needed considered ideal, commonly accepted value simple applications? Something like ""If need x force, install actuator x + 20% force.""",actuator force
4327,Best technique built ejectable drawer?,"I want build closet ejectable drawers. On top 4 buttons, eject opening one four drawers closet. I looking ideas accomplish this. What kind springs, slider mechanisms perhaps, materials use? Any examples?",motion
4329,How machine aluminium low budget?,"For robotic projects I need aluminium parts. Currently I looking way build chassis including simple gear box. So I need relatively high precision. Which options I machine aluminium without investing expensive tools? This I could think far. Design parts CAD send third party company fabrication. The problem hobby projects almost never need large quantities piece production still expensive. Buy cheap tools work aluminium hand. I don't know tools would fit task best. Moreover, results might inaccurate, problem designs moving parts. Find someone CNC let's machine parts. This would likely result slow prototyping cycles though. A method I home expensive tools would perfect, I'm looking forward every solution.",cnc chassis
4336,Position Control Omni Wheel Drive Robot,"I want create robot navigate desired path! That path straight line circular path given radius. I use 3 4 omni wheel drive platform positioning, I using research paper perform dead-reckoning using mouse sensors. Dead-Reckoning using Mouse Sensors I've understood I get x, θ positions, actual positions robot. These used calculate error using PID compensate error. But, find error, I must desired position robot moment! For example, Robot (0,0) needs move circular path equation $$ x^2 + y^2 - 10y = 0 $$ Now, I want calculate position = 2 sec, that? If someone already done similar stuff, please post link. I able find resource web!",mobile-robot pid kinematics wheeled-robot motion
4340,Matlab moving robot towards detected block,"matlab code used detect red colored object, want control bot move towards detected object. need simple algorithm idea, controlling servo able it.",mobile-robot microcontroller wheeled-robot robotc
4346,plot line two centroids matlab,"I able locate centroids blocks, unable join two blocks line segment avoiding obstacle shown figure. Please need help achieve using matlab.",computer-vision motion-planning navigation matlab
4348,BeagleBone uart/spi/i2c latency,"There seems consensus BeagleBone Black 1ms+ latency toggling gpio pins due fact gpio handled outside cpu. Are uart/i2c/spi lines equaly slow, significantly faster? I've seen references people talking gpio directly. Could decrease uart/i2c/spi latencies well?",i2c beagle-bone
4357,Device roll mat,"I'm looking direction create device following: Imagine yoga mat, I want device roll unroll without human intervening rolling process. I reliable robotics forums doesn't appear section mechanical engineering I'm posting question here.",motor mechanism
4359,DIY Laser cutter small Acrylic robot baseplate,"Need help choose desk top, low cost, DIY/High school grade laser cutter making base plate DIY robots, maximum A4 paper size, photo. Idea, comment, advises, even partially cover questions, welcome. What power needed cut Acrylic 3 5mm thick. Many sellers 40 60 watts range. What do? How cut thickness depends cut speed? To extend I choose slow speed cut thicker sheet. Does cut thickness depends color/clear acrylic? It CO2 laser. Some units options, like air blower honeycomb bottom plate. What functions? options useful case. Which CAD 2D drawing software best supported range products? Apart main function cutting flat acrylic plate, additional Z axis motor rise/lower work piece engrave/photo/line_letter marking 3D objects. What software needed support 3D operation.",laser
4360,Natural frequency computation (for PID gains computations),"I currently trying parametrize low-level gains robotic arm. This arm uses classical PID joint. I trying use method based computation rather trial-and-error/tweaking approach. The method I use considers joint independently assumes system driven PID linear. Hence I infer transfer function, characteristic polynomial, poles gives gains $K_p$, $K_i$, $K_d$ joint. Now, computed I did, gains depend natural angular-frequency. For example: $$ K_p = 3 w^2 $$ $a$ inertia $w$ natural angular-frequency. Hence question: shall I compute $w$, natural angular-frequency system? Is enormous computation involving geometry complex characteristics robot, computer simple assumptions made already give rough result $w$? I guess complex computation one reasons PID gains often found trial-and-error rather computation. Though I looking details subject help understand possible not. Kind regards, Antoine",control pid robotic-arm
4362,Mechanical electrical engineering robotic automation?,"I decided pursue career automation robotic. At moment, I torn Mechanical Electrical Engineering. I know relate choices career, moment, I think I like equally. I hope guys help solve dilemma using insights/experiences assist following questions: 1/ From experiences opinions, two engineering fields generally crucial challenging, especially automation/robotics project? 2/ Which see increase demand importance near future? Which might become outdated/obsolete least develop slower rate compare other?(I feeling EE slight edge matter; however, I sure) 3/ Which fields versatile? Which physical demanding (I actually quite frail) 4/ Which generally easier self-study? Robotics obviously incredibly broad complex field I prepared step outside comfort zone lots studying achieve goals passion. I could probably come questions; however, I sure guys got gist puzzle. Thank much I apologize grammatical error.",beginner automatic
4364,Denavit-Hartenberg parameters SCARA manipulator,"I'm going textbook Robot Modeling Control, learning DH convention working examples. I issue following example. Given image problem, link parameter table I tried filling myself. I got answers, except I believe parameter d1 representing link offset frames 1 2. This would analogous d4 parameter. If anyone could explain I might wrong, confirm I right, would great. I hate it's textbook lol. Cheers.",forward-kinematics dh-parameters
4366,PID system pole origin,"I've seen lot places methods tuning PID controller. Most say one apply step input system based response tune PID parameters following rule thumb. But system one pole origin? In words, step response system like infinitely increasing ramp output (theoretically). An example: let's say spinning wheel (fixed center) control amount torque applied make spin. If read position (angle) want design PID controller set position (more less like step-motor). How done? Note step input case constant torque make wheel spin faster faster. How one proceed?",pid
4369,Artificial Potential Field navigation,"I've working two-wheeled mobile robot I've trying perfect obstacle avoidance algorithm Artificial Potential Field method . Also use Arduino Uno kit . The basic concept potential field approach compute artificial potential field robot attracted target repulsed obstacles. The artificial potential field used due computational simplicity. mobile robot applies force generated artificial potential field control input driving system . Artificial Potential Field method computations depends distance robot goal target distance robot obstacles effected robot (which could easily get ultrasonic senors) I applied Artificial potential field method Matlab environment / simulation done successfully , really I need simulation get current position mobile robot position goal x, coordinates (to compute distance robot goal) obstacles positions. The output Artificial potential field desired angle avoid obstacle reach goal , method give robot angle pointed goal robot goes toward angle robot face obstacle way (got sensor reading) Artificial potential field update angle avoid obstacle re-give robot angle pointed goal on. The question could I apply Artificial potential field method real would? I get? easy impossible? I Rover 5 two normal DC motors two encoders (incremental rotary encoder) per wheel. Any Help suggestion topic highly appreciated please. Edit: Based response Shahbaz. The case simple, first, something know I constrained limitations I couldn't overstep them, one real world exactly simulation example simulation I consisted robot started (0,0) coordinates x, axis I put goal point example (10,20) feed point Artificial potential field method compute distance robot goal (so I don't need technique determine position goal) I don't know I could applied that. The second constraint I use encoders wheels determine current position mobile robot orientation depending calculation formula (something like here) even inaccurate. I Rover 5 two normal DC motors two encoders (incremental rotary encoder) per wheel, encoder four wires I don't know deal yet, could I translate pulses encoders work x.y position robot based shaft encoder data. I still searching ….",mobile-robot
4370,rock/syskit: How add multiple instances component network,"I've going Syskit tutorials rock-robotics.org. In tutorials e.g. First composition, two different components declared with: I wondering could I add additional RockTutorialControl composition, instantiation would create two separate instances component? I've tried something like add RockTutorial::RockTutorialControl, :as => ""foo"" apparently isn't way go. syskit instanciate command shows one instance RockTutorialControl, gives two roles (rock foo). What meaning ""role"" context? I've noticed tutorial explains make multiple instances component we're declaring components Devices. But components concerned devices? BR, Mathias EDIT: This first question StackExchange, I don't know what's policy adding additional information original question, go: It seems deployment configuration need different two instances component. I small scale testing two components: using_task_library 'foobar_user' using_task_library 'foobar_proxy' module FooModule class FooControl < Syskit::Composition add FoobarUser::Task, :as => ""producer"" add FoobarProxy::Task, :as => ""proxy"" add FoobarUser::Task, :as => ""consumer"" producer_child.connect_to proxy_child proxy_child.connect_to consumer_child end end FoobarUser::Task input & output port /std/string. FoobarProxy::Task corresponding i&o ports. FoobarUser::Task also two configurations called 'default' 'other'. It also two deployments 'foo_depl' 'bar_depl'. In order create ""pipeline"" data flows producer ==> proxy ==> consumer, I made define line: define 'conf_and_depl', FooModule::FooControl.use('producer' => FoobarUser::Task.use_conf('other').prefer_deployed_tasks(/foo_depl/), 'consumer' => FoobarUser::Task.use_conf('default').prefer_deployed_tasks(/bar_depl/)) instanciated network syskit instanciate scripts/03-nwtest.rb conf_and_depl_def! The component instanciation failed either use_conf prefer_deployed_tasks clause left out. In cases produced error ""cannot deploy following tasks... ...multiple possible deployments, choose one #prefer_deployed_tasks"".",rock syskit
4371,Dynamic tracking precision UR5/10,"I willing use universal robot arm (UR10) path following mode. i.e. I desired trajectory robot's effector I would like effector follow close possible. The specs give repeatability +-0.1mm. This written I guess static precision (after robot enough time converge position). Now dynamic precision (i.e. max position error performing desired trajectory)? Does anyone know matter? Kind regards, Antoine.",dynamics errors
4379,Torque control monitoring servo,"I trying control servo motor operation torque control interfacing sensor avr , continuously monitor torque value sensor control torque according given set point .Is possible make setup? If yes how? Thanks.",torque servomotor avr
4380,Mechanism oscillate needle like object vertical motion,"I need pop needle like object(toothpick,matchstick,etc) hole surface push back automatically.I need make array needles needle's position controlled individually.The objects aren't supposed oscillated continuously, instead locked one two positions-either surface inside it. I trying search mechanism achieve this.This easily done simple DC servo motor, problem I limited space-about 6 objects base area 3 cm x 3 cm.Moreover power source would DC +5 V So far I thought creating small electromagnets springs,but still sure it.Any inputs appreciated.",mechanism
4384,translation shaft encoder data,"I designing robot real world want plot everything X,Y (Cartesian) coordinates I want use encoders wheels determine current position mobile robot orientation depending specific calculation formula (like ) even lead inaccurate calculations . Actually , I found formula compute x, coordinates encoder data I still confused sides formula I Rover 5 chassis form Dagu two normal DC motors two encoders (incremental rotary encoder) per wheel, could I translate pulses encoders work x.y position robot based shaft encoder data. I deduced values Rover 5 chassis : cm = conversion factor translates encoder pulses linear wheel displacement Dn = nominal wheel diameter (in mm) : 20 Cm Ce = encoder resolution (in pulses per revolution) : Encoder resolution: 1000 state changes per 3 wheel rotations n = gear ratio reduction gear motor (where encoder attached) drive wheel. : Gearbox ratio: 86.8:1 In Rover 5 chassis 4 small wires female headers. RED +5V encoder , BLACK 0V (ground) , WHITE signal A , YELLOW signal B . The important wires encoder signal A signal B ,so How get values NL , NR formula signal A & signal B ? Is value NL direct value wire signal A signal B ? question NR . Thanks lot",wheeled-robot quadrature-encoder
4385,it's worth make line follower using raspberry pi web cam?,"I wonder would competitive robot compared one made traditional approach using microcontroller infrared sensors. I suppose raspberry perform edge detection tell dynamic line far away, much infrared sensor, fast raspberry process? relative simple process terms computational requirements , edge detection high contrast arena. Probably bigger issue would get relative position robot respect line, may combination camera infrared sensors would work better, size? robot significantly bigger used camera raspberry control.",raspberry-pi line-following
4392,EKF SLAM Mahalanobis distance?,"So far I done EKF Localization (known unknown correspondences) EKF SLAM known correspondences stated Probabilistic Robotics. Now I moved EKF SLAM unknown correspondences. In algorithm page 322, 16. $\Psi_{k} = H^{k} \bar{\Sigma}[H^{k}]^{T} + Q$ 17. $\pi_{k} = (z^{i} - \hat{z}^{k})^{T} \Psi^{-1}_{k}(z^{i} - \hat{z}^{k})$ 18. $endfor$ 19. $\pi_{N_{t+1}} = \alpha$ 20. $j(i) = \underset{k}{argmin} \ \ \pi_{k}$ 21. $N_{t} = max\{N_{t}, j(i)\}$ I don't understand line 19. In book page 323, The authors state Line 19 sets threshold creation new landmark: A new landmark created Mahalanobis distance existing landmarks map exceeds value $\alpha$. The ML correspondence selected line 20. $\alpha$ line 19 computed? Also, Mahalanobis distance? I research Mahalanobis distance still I can't understand role EKF SLAM. Edit: I found another book university's library Robotic Navigation Mapping Radar The authors state The Mahalanobis distance measure SLAM define $d^{2}_{M}(z^{j}_{k}, \hat{z}^{i}_{k})$, provides measure spatial difference measurement $z^{j}_{k}$ predicted feature measurement $\hat{z}^{i}_{k}$, given $$ d^{2}_{M}(z^{j}_{k}, \hat{z}^{i}_{k}) = (z^{j}_{k} - \hat{z}^{i}_{k})^{T} S^{-1}_{k}(z^{j}_{k}, \hat{z}^{i}_{k}) $$ This value calculated possible $(z^{j}_{k}, \hat{z}^{i}_{k})$ combinations, $$ d_{M}(z^{j}_{k},\hat{z}^{i}_{k}) \leq \alpha $$ Often referred validation gate. Leave question $\alpha$?",slam ekf mapping
4393,Is Genetic alogorithm suitable mobile robot path planning?,"Regarding project work, I write algorithm mobile robot planning. For that, I chosen Genetic algorithm. Is good mobile robot path planning? If is, I start get guidelines?",mobile-robot navigation algorithm
4394,Single-shaft vs Double-shaft motors,I trying make line follower robot I need help regarding type dc motor use. So single shaft BO Motor double shaft BO Motor. Can anyone help understand difference two? Here's link Single Shaft BO Motor: Double Shaft BO Motor:,motor line-following
4395,Counts Quadrature Encoder,"Simply, I Rover 5 2 DC motors 2 quadrature encoders, I want use encoders measure distance travelling wheel. To start with, I want determine total counts per revolution. I read article quadratic encoder broken link. In Rover 5, encoder four wires: red (5V 3.3V), black(Ground), yellow (Signal 1) white (Signal 2). I connected wire right place Arduino Uno board, using circuit: rotary encoder ChannelA attached pin 2 rotary encoder ChannelB attached pin 3 rotary encoder 5V attached 5V rotary encoder ground attached ground For one encoder, I test code determine total counts ticks per revolution, first program using loop second using interrupt. Unfortunately I run program separately, rotating wheel 360 degree hand, outputs two programs ""gibberish"" I don't know problem . Could anyone help? Arduino programs posted below. First program: The second program (with interrupt) static long s1_counter=0; static long s2_counter=0; void setup() { Serial.begin(115200); attachInterrupt(0, write_s1, CHANGE); /* attach interrupt pin 2*/ attachInterrupt(1, write_s2, CHANGE); /* attach interrupt pin 3*/ Serial.println(""Begin test""); } void loop() { } void write_s1() { s1_counter++; Serial.print(""S1 change:""); Serial.println(s1_counter); } void write_s2() { s2_counter++; Serial.print(""S2 change:""); Serial.println(s2_counter); }",mobile-robot quadrature-encoder
4396,ROS NavStack Skid Steering robots,"I migrating differential drive design skid steering design robot, I want know easy would use NavStack skid steering. Would problems terms localization things like that? If I let two wheels side robot (two left side two right side) maintain velocity acceleration, would unicycle model differential drive robot still apply skid steering?",ros navigation differential-drive driver
4398,Machine Vision vs Computer Vision?,I'm trying understand core differences two topics. Is one simply newer term? Connotations automobile vs automation? Something screen vs without? I've ever heard term (tagged).,computer-vision
4399,What laser power cutting engraving wood Acrylic robot baseplates?,"Need buy DIY/High School grade laser cutter/engraver How much laser power needed wood, acrylic (3 6mm thick), cutting decorative engraving? What parameters I need take care selecting suitable machines?",laser
4405,Expression used Rotary Encoders,"While I reading collecting information rotary encoders , I faced troubles meaning expressions concerned encoder ,which make confused stray, expressions words : -Count per revolution (rotation) -Pulse per revolution -Tick per revolution -Transitions per revolutions -Number transitions -Number state changes I thought transition state changes means change high low low high , others diffenece among (count , tick ,pulse ,transition .... etc)? relationship transitions pulse ? Could anyone clarify , please",mobile-robot
4409,Quadcopter: Stabilization along z-axis (for holding altitude),"I recently spent work quadcopter firmware. The model stabilizing attitude relatively well now. However I noticed, changing altitude sometimes (maybe pressure changes, wind turbulence). Now I want get rid altitude drops found much literature. My approach using accelerometer: Calculates current g-force z-axis g-force > 0.25 g longer 25 ms, I feed accelerometer term (cm per s²) pid output sent motors The model reacts falling up-regulation motors. However, I sure, whether smart feed current acceleration regulator I currently wonder, whether smarter method deal sudden smaller changes altitude. Current code:",quadcopter multi-rotor
4410,Programming Odometry Rover 5,"I started programming stage project , first step made test odometry Rover 5 robot Arduino Uno using encoders determine position orientation . I wrote code I don’t know code right mistakes, I novice Arduino Robotic field I need suggestions corrections . thanks lot Arduino codes posted below.",mobile-robot
4413,Arduino Power Supply,I want power Arduino Uno I know I either connecting USB PC DC power supply.But I want connect battery source(kindly see image below) I know silly question I it? The battery connector regular DC jack one that's found RC toys. So I power Arduino battery? And also I connect DC power supply adapter charge discharged? Please also mention specifications DC power supply adapter used charging battery.,arduino battery
4414,Motor control using arduino/raspberry pi,I'm new robotics. I would like know 56 output lines taken arduino raspberry pi?,arduino raspberry-pi
4415,Virtual Testing Environment Drones,"Does anyone know robotics developer environment ideal testing AI programs drones (e.g. quadrocopters, planes, helicopters, etc.)? I would like something like Microsoft Robotics Developer Studio includes virtual environment (such outdoor environment gravity, wind, etc.) test flight dynamics. I would like options add sensors virtual drone, gps, altimeter, gyros, etc. AI program use steer drone.",quadcopter artificial-intelligence machine-learning
4420,Why models perfect represent robotic environments?,Sebastian Thrun says paper Particle Filters - model however detailed fails represent complexity even simplest robotic environment. What means this? Can someone please elaborate?,localization theory
4424,Comprehensive comparison SLAM algorithms,"I'm looking research paper series papers compare performance various simultaneous localization mapping algorithms rovers variety real world environments. In particular, i'm looking computational speed, accuracy (compared real world environment) memory & power efficiency metrics. Is journal regularly publishes experimental performance comparisons?",slam reference-request
4426,How filter vibration programatically?,"I'm working quadcopter. I'm reading accelerometer gyro data MPU6050 using complementary filter calculate roll pitch values. When quad floor, motors turned roll values are: It messy. After minus five plus seven. I would like filter high/low values programmatically I idea it. EDIT: At moment I think solution Low-pass filter. I'll let know successful not.",quadcopter accelerometer gyroscope
4427,"Free charge Robot Magazine, Journal, Newsletter similar","What free charge Robot Magazine, Journal, Newsletter similar publication available? Either geared toward technical professionals general public.",untagged
4430,What would good heuristic solving this?,The aim guide bot Source Goal G passing checkpoints @ (in order). ######## #@....G# ##.##@## #..@..S# #@.....# ######## One way solve would select one checkpoint goal current state guide bot it. Then select next checkpoint goal current checkpoint source guide bot new goal. Eventually guide state G last checkpoint.But technique relies heavily order checkpoints traversed. I would like know good heuristic found decide checkpoint go next?,artificial-intelligence
4435,computer vision using FREAK local features descriptor - overlapping fields?,"I currently studying FREAK descriptor I read article published designers. It states aim mimic retinal topology, one advantages could gained fact retinal receptive fields overlap, increases performance. I thought lot, explanation I able come fact that, looking problem implementation point view, receptive field ensemble image patch centred around pixel, plus standard deviation Gaussian filter applied patch. The size receptive field represents value standard variation. The bigger size is, pixels taken consideration Gaussian filtering, ""mix"" information single value. But guess mine amateurish, I would appreciate someone could give explanation goes field image processing-computer vision-neuroscience.",computer-vision
4439,Raspberry Pi finer servo control,"I'm usig RPI Servoblaster control servos. I've set , I'd like decrease 1us. I've tried set step-size 1us, Servoblaster displays: Invalid step-size specified. I've also tried set pulse width micoseconds like echo 1=1140us > /dev/servolaster. It works, it's unpredictabe (step size set 2us): echo 1=1140us > /dev/servoblaster - motor starts spinnig echo 1=1142us > /dev/servoblaster - motor **smoothly** speeds echo 1=1144us > /dev/servoblaster - motor's speed changed echo 1=1146us > /dev/servoblaster - motor smoothly speeds (OK, assume changed +/- 4) BUT: echo 1=1150us > /dev/servoblaster - motor's speed changed - why?? echo 1=1152us > /dev/servoblaster - motor speeds up, **fastly** echo 1=1156us > /dev/servoblaster - motor **smoothly** speeds Motor: Turnigy aerodrive 2830-11, ESC: Turnigy Multistar 30A Any idea?",raspberry-pi servos
4440,Finding changes environment using 2d laser,I known map environment (2d occupancy grid map). I trying find anything changed environment using 2d laser navigating using maximum likelihood laser known map. My question know measurements corresponding changes. My environment static changes differs known map. Now trying find objects newly came environment moved environment using laser.,slam mapping laser occupancygrid
4442,What technical name robot wheels aligned perform spot turn?,"I robotic simulator enables 6 wheel rover perform spot turn. To prepare rover spot turn, I arrange/align wheels fashion: What technical name it? Circular wheel arrangement? Circular alignment?",mobile-robot wheeled-robot wheel
4447,Is advantage velocity motion models odometry motion models SLAM?,"I've seen several examples SLAM algorithms (EKF SLAM, Graph SLAM, SEIF SLAM) written terms velocity motion model. I yet see example SLAM algorithm utilizing odometry motion model. I wonder inherent advantage using velocity motion model odometry model problem. Does something fact odometry sensor information comes motion already taken place, whereas velocity control commands executed motion?",slam motion
4449,Assumptions nature landmarks SLAM algorithms,"I'm trying understand role landmarks SLAM algorithms. I've glanced books concerning landmark based SLAM algorithms I've come rudimentary understanding I believe flawed. How I think SLAM works: As I understand it, landmarks set points map whose locations known priori. Furthermore, number landmarks map fixed. The number landmarks detected one time may change, number landmarks exist map remains static times. My understanding SLAM algorithms exploit fact points uniquely identifiable known priori. That is, robot senses landmark, knows exactly landmark detected thus knows exact location landmark. Thus, slam algorithm uses (noisy) distance detected landmarks (with known location) estimate position map. Why I think I'm wrong In naive understanding, usefulness SLAM would limited controlled environments (i.e. known landmarkds) completely useless unknown environments priori known landmarks. I would presume sort feature detection algorithm would dynamically add landmarks detected. However, fundamentally changes assumption number given landmarks must static times. I know I'm wrong understanding feature based SLAM, I'm sure assumptions wrong: Do feature based SLAM algorithms assume static number landmarks? Do landmarks need known priori? Can detected dynamically? And so, fundamentally change algorithm itself? Are special kinds SLAM algorithms deal unknown environments unknown total number landmarks it?",slam
4456,Pulse Position Modulation used RC controls,"How several channels multiplexed single physical wire? If two channels transmitting value frame, wont overlap pulses?",rcservo pwm
4463,Choosing motor tricopter,I'm newbie RC field..I planning construct first Tricopter ever. Can anyone help find power rating select motor tricopter? I beginning stage construction. Arm length frame: 50cm each. I need thrust 2Kg -- nearly 666 gms motor.,motor
4465,What's difference Yaw Attitude Quad Rotor,"I big miss conception Yaw attitude ? Isn't represent ""how far quad earth ?"" Also could post calculate IMU (gyro +accele + magent )",imu
4467,"Need clear concepts: AHRS - Attitude - Yaw,Pitch Roll - MARG sensors -INS","it's since I started reading INS, orientation quadrotors . I faced following terms : AHRS - Attitude - Yaw,Pitch Roll - MARG sensors I know example calculate Yaw,Pitch Roll , related Attitude ? What's Attitude way get calculated ? AHRS ""Attitude heading reference system"" formed Yaw,Pitch Roll ? MARG(Magnetic, Angular Rate, Gravity) ? it's related terms ? What INS ( Inertial Navigation Systems ) ? My questions concepts, meaning , cooperate , got calculated sensors suits ?",navigation
4469,image size vs image resolution,"I read somewhere case photoshop example, size refers number pixels image contains, resolution involves pixel's size, I don't know whether definition goes fields. In computer vision, what's difference image size image resolution?",computer-vision
4472,make Mac detect AVR board using USBasp burn program it?,"I new Embedded, starting AVR programming using C. I working Mac OS 10.9.4, far I using avrdude xCode IDE. It works well, I testing code using Proteus. But I want burn .hex AVR ATMega16 board. I USBasp, I able connect lights board. Now searching internet, I think Mac detecting board. I checked /dev directory, usb device found. So I sure next, make Mac detect board burn .hex it. I've found this: idea use required not. So question stand is: make Mac detect AVR board using USBasp burn program it? FYI: I've installed CrossPack Mac.",usb embedded-systems avr
4474,Servo controlled valve,"I trying build servo-controlled water valve. Max pressure 150 psi , valve size 1/2"". Can anyone recommend suitable 1/4-turn valve, either ceramic, ball valve, anything else easy turn, even pressure? It must require little torque turn, standard servo rotate small lever attached.",servos valve
4476,Quadcopter one beep blink problem,"I built first quadcopter, run bit snag. When I plug power, I get one beep red blink flight control board, nothing else happens. When I turn controller, however, red light turns reciever. Otherwise, nothing else happens. From I tell, I plugged everything correctly, sure proceed. flight control board Flight Control Board manual (PDF) ESC's I connection power distribution board flight control board, I assuming gets power ESC's. Here video I used figure build quad. (side- note video: I cut ESC's cords done guide, seemed like silly step, also I seen applications cut) I updated firmware board, put box board's user manual (PDF)",control quadcopter
4477,How calculate Altitude IMU?,"How calculate attitude IMU ? For example, mathematical equations",imu
4486,Ackerman steering model,"I trying create simulation robot Ackerman steering (the car). For I'm assuming it's actually 3-wheeled robot, two wheels back, one steering wheel front: Knowing wheel velocity, steering angle a, I need able update robot's current position velocity new values time t+1. The obvious way would calculate position centre rotation, axles wheels would meet, however, leads undefined centre rotation = 0. This means model doesn't work normal case robot driving straight line. Is model Ackerman steering works reasonable range a?",mobile-robot simulation
4487,Relative Navigation Systems,"Im trying develop system autonomously navigates large outside space, accuracy vital (GPS inaccurate). There number options largely used inside, anyone tried used anything else? WiFi triangulation, Dead reckoning, RFID landmarks",navigation
4488,What's adapted programming language Robotic principally AI?,"I'm currency Web programmer I'm passionate robotics specialty Artificial Intelligence. I already make C++ program Microship Arduino little robots Lisp codes (example labyrinth path search) I think it's really applicable projects further. I read lots artificial neural network create artificial mind, it's theoretical I idea reproduce code. Someone idea help me, specific language, C++ library ? If links, articles, tutorials I take it. Thank lots !",artificial-intelligence programming-languages
4489,How calibrate IMU unit?,"Simply , I calibrate IMU unit ? I read papers topic wondering standard methods.",imu
4492,DC motor control - speed-torque curve,"I trouble understanding practically use speed-torque curve DC motor. I understand gradient speed-torque curve defined design motor, exact position curve depending voltage applied. So voltage changed speed-torque curve also changed remains parallel initial curve voltage changed. See figure below. So intuitive guess using motor given desired operation point (desired speed desired torque), corresponding speed-torque curve Cd gradient specified data sheet motor passes operation point. This curve Cd obtained corresponding voltage Vd. See diagram below. So next guess order motor operate desired operation point, set voltage applied motor Vd, apply current Id (computed using torque torque constant). Now I read done DC motor controllers. These seem drive motor using current sort PWM magic shown following diagram maxon. Anyone knows voltage used DC motor control current is? I understand set speed modify voltage? And PWM useful for? I looked hours internet could find anything relevant. Thanks, Antoine.",motor control
4496,How get pure end-effector translation Jacobian?,"I 7 DOF arm I controlling joint velocities computed Jacobian standard way. For example: $$ {\Large J} = \begin{bmatrix} J_P \\J_O \end{bmatrix} $$ $$ J^{\dagger} = J^T(JJ^T)^{-1} $$ $$ \dot{q}_{trans} = J^{\dagger}_P v_{e_{trans}} $$ $$ \dot{q}_{rot} = J^{\dagger}_O v_{e_{rot}} $$ $$ \dot{q} = \dot{q}_{trans} + \dot{q}_{rot} $$ However, specifying translational velocities, end-end effector also rotates. I realized I might able compute much end-effector would rotate instantaneous $\dot{q}$, put Jacobian subtract joint velocities. So I would instead using passed $v_{e_{rot}}$: $$ v_{e_{rot}} = R(q) - R(q+\dot{q}_{trans}) $$ Where $R(q)$ computes end-effector rotation joint angles. Is OK do, I way base? Is simpler way? I aware I could also compute IK point small distance end-effector rotation, pull joint velocities delta joint angles. And exact. However, I wanted go Jacobian route I think fail gracefully. A side question, I compute $R(q) - R(q+\dot{q}_{trans})$ get global end-effector angular velocity? My attempts converting delta rotation matrix Euler angles yield wrong results. I quick tests implemented procedure achieve pure end-effector rotation maintaining global position. (This easier $T(q) - T(q+\dot{q}_{rot})$ vector subtraction.) And kind work.",kinematics robotic-arm jacobian
4498,Robot Loud Alarm,"We working project want sound alarm somebody messing around Robot (e.g., Robot shaken abruptly cameras/LIDARs blocked). I using ""loud speakers"" (4.1 x 3 inch 10 Watts 8 ohm speakers), loud enough. Are small speakers alarm systems small enough, loud enough (closed car alarm) would recommend? Ideally something I plug robots computer, interface microcontroller. Either one would fine.",microcontroller ros navigation
4504,Quadcopter cannot balance!,"I bulding quadcopter using compenents: Microcontroller: Tiva C Lanchpad (ARM Cortex M4 - 80 MHz), running 40MHz code MPU 9150 - Sensorhub TI ESC - Hobbywing Skywalker 40A I use sample project comp_dcm Tivaware use angles PID running 100Hz I test PID Control 2 motors, motors oscillate video found youtube one guy! Quadcopter Unbalance",quadcopter
4510,type camera used detecting road lanes good processing matlab,"What parameters selected choose camera lane detection system.What parameters kept mind (like picture quality,frame rate,cost e.t.c). Which camera suit best application.",cameras
4511,Euler Angles 9DOF IMU,"Using Adafruit 9DoF module I Need convert Accel + Magneto + Gyro Euler Angles motion capture application. Any hints start? Managed get X,Y,Z IMU facing upward orientation changes axes dont behave normally using Euler angles. So Any hints reference start? The Euler Compass App example I trying get to. Get Pitch,Yaw, Roll IMU module irrespective kept.",imu
4513,Whats logic implement particle filter robot range sensor?,"I trying implement particle filter robot Java. This robot range sensor. The world 6 obstacles - 3 top 3 bottom. I calculating distance robot obstacle's center performing activity particle. Then, calculate difference robot particles. The particles difference robot measured distance small, give higher probability resampling. But, problem approach told friend I assuming I already know locations obstacles, make process useless. How I approach rather sense I don't know obstacles. How particle filter implemented then? How particle filter work case don't know obstacles location? An example process would great help. Thanks",localization particle-filter
4514,Pledge algorithm maze solving robots,"saw maze, tried apply pledge algorithm it. But able solve maze using algorithm. missing? want ask, wrong? PLEDGE ALGORITHM: cases don't get exit. read algorithms at:",mobile-robot
4516,How one create robot respondes input following flowchart?,"What basic skills components needed creating robot gets two ""yes"" ""no"" inputs two push buttons, goes defined flowchart plays relevant audio file time gets input. flowchart like this:",microcontroller
4520,Correcting GPS track visual odometry (sensor fusion),"I trying build low cost precise outdoor positioning. I explored NS-RAW RTKLIB - would doable probably need either base station get correction data rover external correction data may hassle. The action radius base station quite limited too. This solution really straightforward deal either in-house streamed correction data. I wondering whether one would able substantially improve accuracy ordinary (uncorrected) GPS+GLONASS device (maybe one found common smartphone) stereo visual odometry. Today's consumer GNSS chips seem reasonably stable accuracy 5m range. The VISO 2 library translation error 3% 500m distance. The idea use visual odometry ""smoothing"" rough GPS track. The question technically done terms SW. The input would two tracks - one GPS device VISO 2 library. I think I need kind filter fuse sensor data get greater precision.",computer-vision gps sensor-fusion odometry
4523,Ensemble Kalman Filter SLAM,"I know extended kalman filter approach simultaneous localization mapping. I'm curious SLAM algorithm exploits ensemble kalman filter. A citation would great, possible.",kalman-filter slam reference-request
4526,PID Tuning Quadcopter Problem,"I tuning PID quadcopter, problem different base Throttle, seems adjust different PID gains order quadcopter balance!",pid
4531,Purpose programming ESC,I planning buy ESC tricopter setup. What purpose programming ESC? I cost effective really necessary I necessarily buy programming card program ESC model?,esc
4533,12V Arduino Dual Bridge supply least 5A,"I looking 12V Dual Motor Controller supply least 5A per channel two 12V motors, used arduino. Do know product specs? Thanks",arduino motor ros h-bridge
4536,Yaw angle calculation drone PID two distance sensors,"I'm building control system Parrot AR 2.0 drone I access thrust controls up/down (z), left/right (y), forward/backwards (x), turn left turn right (yaw) Ruby library computer. The goal system keep drone particular distance parallel wall moving up/down left/right directions. We added two sonar distance sensors left right forward props. The main problem I figuring two distance sensors equal yaw reading (ψ) I feed PID take action thrust turn left right correction. Maybe getting help conversion two distances yaw angle would big help, thoughts PID greatly appreciated since first time working it.",sensors quadcopter pid
4540,Can use line sensor proximity sensor?,"I RSL Line Sensor designed distinguish black white lines. It detects white surface gives digital 1 output, 0 case black, surface needs close it. As uses infra-red-sensors, I wanted use sensor proximity sensor, tell white surface near it. Is possible this? I think problem need increase it's range giving 1. Currently, gives 1 white surface close sensors. I want 1 even white surface bit distance. Also adjustable screw adjust something, POT written. I working Arduino.",arduino mobile-robot sensors
4542,Velocity derivatives using Quaternions,How compute angular linear velocities Quaternions? I new area although I studied algebra I unable understand compute velocities.,kinematics
4545,How control Arduino Board wireless PS3 controler?,"I'm currently building hexapod bot, composed Arduino Mega board USB SSC-32 (from Lynxmotion). But I want add PS3 wireless controller move hexapod, I made search nothing realy interesting. Maybe Servoshock module seems works ServoshockShield, kind Arduino card Servo output. Can I use ServoShock module alone ? Can I connect Rx/Tx port Arduino Mega board ? Do solution ? Board documentation sources codes ? Thank",arduino wireless
4546,What calculations badminton robot mechanisms?,I designing badminton robot confused mechanisms needed badminton robot various calculations needed millisecond response.I also confused calculations needed forces needed efficient angles needed hitting shuttlecock.Please suggest ideas suggestions needed construction badminton robot.,sensors design mechanism actuator servomotor
4554,Using kinect medical application without computer. Is possible?,"I use kinect application. However, final work must mobile: means computer. Consequently, I thought using microcontroller handle data kinect. But possible? My job mesuring points body (axis X, Y, Z) get back coordinates. I don't know I'm enough accurate.",microcontroller kinect
4555,Reverse lift mechanism,I made RC robot wheelchair I'm planning attach snow plow. I'm wondering mechanism would able lift plow reversing. I 2 channel transmitter I can't control plow's movement I thinking mechanical lift triggers reversing. Do guys know something I could use it? Thanks.,wheeled-robot mechanism
4558,PD Algorithm Quadrotor [Simulation],"I big problem trying stabilize quadrotor PD controller. The model program written C++ model dynamic taken source internet: Well, code I wrote model like eq. system ( see eq. 3.30 page 21): body_ang_current.<angle> body_pos_current_.<position> structures defined class store position, velocities accelerations model given 4 motor velocities 3 axis. $$ \large \cases{ \ddot X = ( \sin{\psi} \sin{\phi} + \cos{\psi} \sin{\theta} \cos{\phi}) \frac{U_1}{m} \cr \ddot Y = (-\cos{\psi} \sin{\phi} + \sin{\psi} \sin{\theta} \cos{\phi}) \frac{U_1}{m} \cr \ddot Z = (-g + (\cos{\theta} \cos{\phi}) \frac{U_1}{m} \cr \dot p = \frac{I_{YY} - I_{ZZ}}{I_{XX}}qr - \frac{J_{TP}}{I_{XX}} q \Omega + \frac{U_2}{I_{XX}} \cr \dot q = \frac{I_{ZZ} - I_{XX}}{I_{YY}}pr - \frac{J_{TP}}{I_{YY}} p \Omega + \frac{U_3}{I_{YY}} \cr \dot r = \frac{I_{XX} - I_{YY}}{I_{ZZ}}pq - \frac{U_4}{I_{ZZ}} } $$ Once I get accelerations I going integrate get velocities positions well: /* Get position velocities accelerations */ body_pos_current_.x_dot = body_pos_current_.x_dot_2 * real_duration + body_pos_previous_.x_dot; body_pos_current_.y_dot = body_pos_current_.y_dot_2 * real_duration + body_pos_previous_.y_dot; body_pos_current_.z_dot = body_pos_current_.z_dot_2 * real_duration + body_pos_previous_.z_dot; body_ang_current_.phi_dot = body_ang_current_.phi_dot_2 * real_duration + body_ang_previous_.phi_dot; body_ang_current_.theta_dot = body_ang_current_.theta_dot_2 * real_duration + body_ang_previous_.theta_dot; body_ang_current_.psi_dot = body_ang_current_.psi_dot_2 * real_duration + body_ang_previous_.psi_dot; body_pos_current_.x = 0.5 * body_pos_current_.x_dot_2 * pow( real_duration, 2 ) + ( body_pos_previous_.x_dot * real_duration ) + body_pos_previous_.x; body_pos_current_.y = 0.5 * body_pos_current_.y_dot_2 * pow( real_duration, 2 ) + ( body_pos_previous_.y_dot * real_duration ) + body_pos_previous_.y; body_pos_current_.z = 0.5 * body_pos_current_.z_dot_2 * pow( real_duration, 2 ) + ( body_pos_previous_.z_dot * real_duration ) + body_pos_previous_.z; body_ang_current_.phi = 0.5 * body_ang_current_.phi_dot_2 * pow( real_duration, 2 ) + ( body_ang_previous_.phi_dot * real_duration ) + body_ang_previous_.phi; body_ang_current_.theta = 0.5 * body_ang_current_.theta_dot_2 * pow( real_duration, 2 ) + ( body_ang_previous_.theta_dot * real_duration ) + body_ang_previous_.theta; body_ang_current_.psi = 0.5 * body_ang_current_.psi_dot_2 * pow( real_duration, 2 ) + ( body_ang_previous_.psi_dot * real_duration ) + body_ang_previous_.psi; /* Copy new value previous one (for next loop) */ body_pos_previous_.x = body_pos_current_.x; body_pos_previous_.y = body_pos_current_.y; body_pos_previous_.z = body_pos_current_.z; body_pos_previous_.x_dot = body_pos_current_.x_dot; body_pos_previous_.y_dot = body_pos_current_.y_dot; body_pos_previous_.z_dot = body_pos_current_.z_dot; body_ang_previous_.phi = body_ang_current_.phi; body_ang_previous_.theta = body_ang_current_.theta; body_ang_previous_.psi = body_ang_current_.psi; body_ang_previous_.phi_dot = body_ang_current_.phi_dot; body_ang_previous_.theta_dot = body_ang_current_.theta_dot; body_ang_previous_.psi_dot = body_ang_current_.psi_dot; The model seems work well but, like reported many papers, unstable needs controls. The first approach create controller (PD) keep height constant without moving quadcopter, putting value (for example 3 meter) see reacts. Here small code I tried: /* PD Controller */ double e = ( 3.0 - body_pos_current_.z ); // 3.0 try value!!! thrust_.esum = thrust_.esum + e; thrust_.total = 1.3 * e + 0.2 * real_duration * thrust_.esum; The problem, see video, copter starts falling ground reaching desired altitude (3.0 meters). Then comes back like spring, damped. I tried already many different value PD controller seems doesn't affect dynamic model. Another strange thing goes always negative point ground, even I change desired height (negative positive). What wrong code? Could please point documents code understandable well documented start? Thanks EDIT: Many thanks suggestion. Hi really surprise know, code lots potential problems efficient. So I elaborate code explanation I implementers RK4 integration. After I read articles: I got idea RK vantage use simulations graphics PC. As example I rewrote whole code: /* Calculate acceleration 6 axis */ pos_.dVel.x = ( ( thrust_.total / masse_ ) * ( -sin( body_position_.angle.theta ) * cos( body_position_.angle.phi ) * cos( body_position_.angle.psi ) - sin( body_position_.angle.phi ) * sin( body_position_.angle.psi ) ) ); pos_.dVel.y = ( ( thrust_.total / masse_ ) * ( sin( body_position_.angle.phi ) * cos( body_position_.angle.psi ) - cos( body_position_.angle.phi ) * sin( body_position_.angle.theta ) * sin( body_position_.angle.psi ) ) ); pos_.dVel.z = ( ( thrust_.total / masse_ ) * ( -cos( body_position_.angle.phi ) * cos( body_position_.angle.theta ) ) - 9.81 ); pos_.dOmega.phi = ( torque_.phi / Jxx_ ); pos_.dOmega.theta = ( torque_.theta / Jyy_ ); pos_.dOmega.psi = ( torque_.psi / Jzz_ ); /* Get position velocities accelerations */ body_position_ = RKIntegrate( body_position_, real_duration ); much clear easy debug. Here useful functions I implemented: QuadrotorController::State QuadrotorController::evaluate( const State &initial, const Derivative &d, double dt ) { State output; output.position.x = initial.position.x + d.dPos.x * dt; output.position.y = initial.position.y + d.dPos.y * dt; output.position.z = initial.position.z + d.dPos.z * dt; output.velocity.x = initial.velocity.x + d.dVel.x * dt; output.velocity.y = initial.velocity.y + d.dVel.y * dt; output.velocity.z = initial.velocity.z + d.dVel.z * dt; output.angle.phi = initial.angle.phi + d.dAngle.phi * dt; output.angle.theta = initial.angle.theta + d.dAngle.theta * dt; output.angle.psi = initial.angle.psi + d.dAngle.psi * dt; output.omega.phi = initial.omega.phi + d.dOmega.phi * dt; output.omega.theta = initial.omega.theta + d.dOmega.theta * dt; output.omega.psi = initial.omega.psi + d.dOmega.psi * dt; return output; }; QuadrotorController::Derivative QuadrotorController::sampleDerivative( double dt, const State &sampleState ) { Derivative output; output.dPos = sampleState.velocity; output.dVel.x = pos_.dVel.x; output.dVel.y = pos_.dVel.y; output.dVel.z = pos_.dVel.z; output.dAngle = sampleState.omega; output.dOmega.phi = pos_.dOmega.phi; output.dOmega.theta = pos_.dOmega.theta; output.dOmega.psi = pos_.dOmega.psi; return output; }; QuadrotorController::State QuadrotorController::RKIntegrate( const State &state, double dt ) { const double C1 = 0.0f; const double C2 = 0.5f, A21 = 0.5f; const double C3 = 0.5f, A31 = 0.0f, A32 = 0.5f; const double C4 = 1.0f, A41 = 0.0f, A42 = 0.0f, A43 = 1.0f; const double B1 = 1.0f/6.0f, B2 = 1.0f/3.0f, B3 = 1.0f/3.0f, B4 = 1.0f/6.0f; Derivative k1 = sampleDerivative( 0.0f, state ); Derivative k2 = sampleDerivative( C2 * dt, evaluate( state, k1 * A21, dt ) ); Derivative k3 = sampleDerivative( C3 * dt, evaluate( state, k1 * A31 + k2 * A32, dt ) ); Derivative k4 = sampleDerivative( C4 * dt, evaluate( state, k1 * A41 + k2 * A42 + k3 * A43, dt ) ); const Derivative derivativeSum = k1 * B1 + k2 * B2 + k3 * B3 + k4 * B4; return evaluate( state, derivativeSum, dt ); } Now I really lost because...because simulated qudrotor behavior before. Nevertheless I implemented PD algorithm discussed paper, stabilize Z (height) get really crazy due unstable behavior. So... I dunno wrong code implementation. And I cannot find source internet good self explaned dynamic model quadrotor. Regards",control quadcopter
4562,Non-linear complementary filter so3: Corrected equations?,"While reading paper ""Multirotor Aerial Vehicles: Modeling, Estimation, Control Quadrotor"" Mahony, Kumar Corke, I stumbled across following equations non-linear attitude observer, I would like implement, I believe something wrong. $\dot{\hat{R}} := \hat{R} \left( \Omega_{IMU} - \hat{b} \right)_\times - \alpha \\ \dot{\hat{b}} := k_b \alpha \\ \alpha := \left( \frac{k_a}{g^2}((\hat{R}^T \vec z) \times a_{IMU}) + \frac{k_m}{|^Am|^2} ((\hat{R}^T {^Am}) \times m_{IMU}) \right)_\times + k_E \mathbb{P}_{so(3)} (\hat{R} R_E^T)$ Where $\hat{R}$ $\hat{b}$ etimates orientation gyroscope bias, $\Omega_{IMU}, a_{IMU}, m_{IMU}, R_E^T$ measurements $k_X$ scalar gains, may set 0 measurements evailable. Now $\dot{\hat{R}}$ $\alpha$ need matrices $\in \mathbb{R}^{3\times 3}$ due definitions. $\hat{b}$ thus $\dot{\hat{b}}$ need vectors $\in \mathbb{R}^3$. But correct version second equation $\dot{\hat{b}} := k_b \alpha$?",control quadcopter
4568,What PID related quadcopters,"I'm trying make Quadcopter scratch, I fair amount experience adruinos, I'm trying understand necessary systems work, I can't seem figure PID means, method regulating pitch roll? like stabilizer? I think I've read system detects orientation craft tries correct",arduino quadcopter microcontroller pid beginner
4569,Are consumer grade CNC machines capable cutting tile?,I'd like slice dice floor tile pieces I arrange geometric patterns. I CAD designs parts. Would consumer grade CNC machine capable job?,cnc
4573,Laser Beam based model probability case single particle,"I trying calculate likelihood laser scan($Z$) give pose($x$) known map ($m$) using beam based model $P\left(z_t|x_t,m \right)=\prod_{i=1}^{n}P'\left(z_i|x_t,m \right)$ My scan 360 rays i.e $n=360$, When calculate $P\left(z_t|x_t,m \right)$ becomes zero multiplication propabilities $<1.$ In ROS amcl using ad-hoc works better like $P\left(z_t|x_t,m \right)+=\sum_{i=1}^{n}P'\left(z_i|x_t,m \right)*P'\left(z_i|x_t,m \right)*P'\left(z_i|x_t,m \right)$ later normalise number particle get weight particle. My query get probability normalised zero single calculation (i.e image case single particle) Thanks.",mobile-robot slam laser probability
4575,Use linear quadratic regulator minimize output error,"I would like create Infinite-horizon, continuous-time LQR cost functional defined $$J = \int_{0}^\infty \left( e^T Q e + u^T R u \right) dt$$ e states' error $x-x_d$, I trouble concluding appropriate Ricatti equation since $x_d$ function time therefore leading term $\dot x_d$ . Is problem solvable? Any ideas?",control
4577,Can't Read current Pololu Dual MC33926 Motor Driver Shield Arduino,"I purchased Pololu Dual MC33926 Motor Driver Shield Arduino, reason I cannot read current motor controller. On Serial.println() prints weird data (garbage), I use ROS (Robot Operating System) I see -0.0 (minus zero) value motors. All I've done plug shield Arduino UNO R3 model, run demo comes sample library -- . How I fix issue?",arduino ros actuator stepper-driver current
4578,kinect - development kit aid obstacle-avoiding robot?,"Some friends I interested working robot. I know little nothing robotics, lot experience programming. Before start, I hoping I find development kits libraries help aid goals robot. Which are: Robot needs move point A point B. While moving, needs detect rocks (approx. 1 foot diameter) ground. It needs detect rocks big enough stop it, turn away them, proceed. In theory, want detect kinect's angle via accelerometers, use data obtain Cartesian coordinates ground kinect's sensors. Later, want way assemble 'map' robot's memory find better paths A B. Right aren't concerned motors robot - vision element. Ie, I really interested software interfaces motors robot, something interfaces kinect.",computer-vision kinect
4579,Quadrature Encoder Counts,"Actually , I since two weeks looking convinced final solution problem , actually I completely lost , I working mobile robot (Rover 5) 2 motors , 2 encoders . controller designed robot needs know odometery mobile robot (X ,Y, Heading Angle ) , actually I trying function encoders purpose , getting X ,Y, Heading Angle measuring traveled distance wheel , get X ,Y, Heading Angle values , I compute accurate readings without missing counts ticks could possible . The problem : In code attachment , I testing encoders counts , I noticed difference counts encoders even spin constant speed (PMW) , difference increases two motors continue . I thought main cause inaccurate odometery results . In output code (in attachment also) first two columns right left motors speed , third & forth columns right left encoder counts , fifth column difference two encoders count , could see ,that even speed two motors approximately (each motor feed 100 PWM) difference encoder counts could see difference become big big motors continuing spin . One thing I thought sending PWM value two different motors almost never produce exact speed , I think I detect absolute motion motors adjust power get speed/distance , I test speed motors feed 100 PWM time , two speeds almost identical , I noticed difference counts two encoders even motors spin constant speed . Actually , I don't know problem , Is code ? Is hardware ? ? I completely lost , I need patient someone help. result: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 -181 -90 3 2 1 -111 -55 5 4 1 -187 -187 9 8 2 -176 -235 12 12 1 -200 -200 16 16 1 -250 -250 21 21 1 -250 -250 26 26 1 -210 -210 31 31 1 -238 -285 36 36 1 -315 -263 41 41 1 -300 -200 47 46 2 ... -227 -272 184 182 3 -285 -285 190 187 4 -260 -217 195 193 3 -238 -285 201 199 3 ... -250 -250 1474 1473 2 -250 -250 1480 1479 0 -208 -291 1485 1485 1 -304 -260 1491 1492 1 -240 -240 1498 1498 1 -260 -260 1504 1505 0 -250 -291 1510 1511 1 -280 -240 1516 1517 1 -260 -260 1523 1523 1 ... -250 -250 2953 2948 5 -250 -291 2959 2955 6 -250 -250 2965 2961 6 -291 -250 2971 2967 5 -250 -291 2978 2973 5 -304 -250 2985 2980 8 -320 -250 2992 2986 8 ... -320 -240 3085 3075 10 -291 -291 3092 3082 12 -269 -230 3099 3089 11 -250 -291 3105 3095 11 -280 -280 3112 3102 11 -269 -230 3118 3108 12 -250 -291 3125 3115 11 ... -291 -250 3607 3587 19 -115 -269 3610 3594 17 -240 -240 3617 3601 18 -375 -291 3625 3607 19 -269 -269 3632 3614 20 -291 -250 3638 3620 20 -240 -280 3645 3627 20 -280 -240 3652 3633 18 -200 -280 3657 3640 19 -269 -230 3664 3647 19 -333 -291 3674 3653 23 -400 -280 3682 3659 23 -280 -240 3688 3666 24 -240 -280 3695 3673 24 ... -230 -269 4677 4644 32 -208 -291 4681 4651 32 -280 -240 4690 4657 35 -320 -280 4696 4664 34 -240 -240 4703 4670 34 -291 -291 4710 4677 34 -269 -230 4716 4683 34 -240 -280 4723 4690 34 -280 -240 4727 4697 32 -160 -280 4736 4703 35 -416 -291 4745 4709 38 -346 -230 4753 4716 39 ... -360 -240 6240 6190 51 -375 -291 6247 6197 51 -269 -269 6253 6203 52 -291 -250 6261 6210 53 ... -192 -269 6428 6374 56 -240 -280 6436 6380 57 -291 -250 6443 6387 57 -269 -269 6449 6394 57 ... -269 -269 7763 7687 78 -240 -280 7770 7694 78 -291 -250 7776 7700 76 -192 -269 7781 7707 76 ... -269 -230 8263 8179 84 -250 -291 8269 8186 85 -240 -240 8276 8192 88 -384 -269 8286 8199 88 -250 -291 8292 8206 88 -269 -230 8299 8212 87 -291 -291 8305 8219 88 -240 -240 8310 8225 85 ... -160 -120 8359 8276 83 -125 -166 8362 8280 82 -115 -115 8365 8283 83 -80 -120 8367 8285 82 -125 -83 8370 8288 82 -83 -125 8371 8290 82 -43 -43 8373 8291 81 -83 -83 8374 8293 82 -45 -90 8375 8294 81 -43 -43 8376 8296 81 -43 -43 8377 8296 81 -43 -43 8378 8297 81",mobile-robot wheeled-robot quadrature-encoder
4580,Linear slider motor mount location - Pros/cons,"I'm currently designing linear camera slider, used hold camera equipment weighing 15 Kgs including lenses monitors everything else. For don't know camera slider is, it's linear slider top camera mounted camera slided slowly create nice footage like this. The problem Now, looking commercially available camera sliders there, seems two ways motor maybe mounted sliders: Motor mounted side: Motor mounted directly carriage: I would like know option would optimal - Performance-wise (this slider maybe used vertically too, create bottom top slide shots), efficiency-wise one two resistant motor vibration (these motors vibrate lot, effects may sometimes leak produced footage). Additional Questions Motor mounted carriage directly maybe, maybe efficient, also carry it's weight addition 15kg camera load? Pulling force greater pushing force (I idea why, would great someone explained why, atleast case?), motor mounted end able lift vertically ease? Does belt setup shown first figure really dampen motor vibrations? Will/won't motor vibrating end get amplified (because, whole setup attached single tripod exact center slider) Which design less stressful motor, taking inertia consideration cases? Which one designs best suitable vertical pulling load gravity? Manufacturers use designs interchangeably, it's hard predict design better which. Any help would much appreciated! Please note, question migrated Stackexchange Physics (and Electrical) forum mods thought would appropriate here.",control design stepper-motor motion
4583,What low cost alternatives lidar?,It need effective lidar may disadvantages compared lidar. What probable alternatives? Edit: I'm intending use outdoors navigation autonomous vehicle. Is low cost LIDAR alternative sensor obstacle detection?,sensors navigation cameras sonar lidar
4587,Two State Linear Actuator,"I need two state linear actuator. You look picture understand I mean. Don't care hand ! I need electrically move things like squares down. Bidirectional linear actuators needed. What cheapest tiniest actuator (or sth else) I use move squares down. There two states ('up','down'). Don't care much higher square rises, up.",actuator
4589,Particles behaving correctly implementation particle filter,"I implementing particle filter Java. The problem particle filter implementation particles suddenly go away robot i.e resampling process choosing particles away robot near.It like particles chase robot, always remain behind it. I trying find root cause, luck. Can anyone please help I going wrong? I adding imp. code snippets also screenshots consecutive order make clear. Details: I using range sensor works one direction i.e. fixed tells distance obstacle front. If obstacle line vision, tells distance boundary wall. Code: Calculating Range Calculating Weights /* * This method calculates importance weights particles based robot_range * reading range sensor robot. */ private double measurementProbability(int index) { double probability=1; double particle_x_position=particleListX.get(index); double particle_y_position=particleListY.get(index); double particle_Vx=particle_x_position; double particle_Vy=particle_y_position; int range_counter=0; int loop_counter=0; int distance = calculateRange(particle_x_position, particle_x_position, particle_Vx, particle_Vy ,range_counter, loop_counter); probability *= calculateGaussianDistance(distance, senseNoise, robot_range); //System.out.println(probability); return probability; } private double calculateGaussianDistance(double mu, double sigma, double x ) { double gDistance=Math.exp(-(((Math.pow((mu - x),2))/(Math.pow(sigma,2)) / 2.0) / (Math.sqrt(2.0 * Math.PI * (Math.pow(sigma,2)))))); return gDistance; } Resampling /* * This method provides resampled particle back list. It chooses particle randomly * list based weights replacement. */ private int giveResampledParticle() { int index = randomInteger(0, n-1); double sample =0.0; double maxWeight = maximumWeight(); sample += randomDouble(0, maxWeight); while(sample > particleListProbability.get(index)) { sample -= particleListProbability.get(index); index = (index +1) % n; } return index; }",localization particle-filter
4591,Robotc color sensor error,I trying write simple program robot(Lego NXT2) follow blue line. I using nxt color sensor problem 1 motor moving. I know none motors broken either I tested out. Can somebody help diagnose problem?,sensors robotc
4592,For robot wheel control : Brushless DC motor Servo Motor?,"Simply, use brushless dc motor use Servo Motor ? differences , specially adding encoder dc motor position similar Servo Motor ?",motor brushless-motor servomotor
4595,"Do simple, non-sonic, omni-directional rangefinding beacons exist?","I robotics team plans compete competition one rules sort sonic sensor allowed used. I guess limits sort EM frequency right? Ideally, team looking simple beacon system, beacon A would attached robot, beacon B would attached known point competition space. Then, beacon A give information far away B is. After searching, I could turn laser rangefinders required pointing target. I CS student, I'm familiar terminology aid searches. Another nice property would beacons also gave angle beacon A beacon B's field view, although necessary, since multiple beacons could used obtain information. We Xbox 360 Kinect working, able track things give distances, looses accuracy distance quickly (the arena 6 meters long), beacon simple possible. We ONLY need relative position robot. Alternate Solution: Another way solve would omni-directional beacon give angle information, two could used triangulate, job well.",localization electronics laser rangefinder
4599,uncertainty initializing new landmark EKF-SLAM,"In EKF-SLAM (based-feature map) robot senses new landmark, augmented state vector. As result, size state vector covariance matrix expanded. My question uncertainty new landmark correlation pairs covariance matrix. How I assign them? When I assign zero, error estimation landmark won't change time goes. If I assign large value, estimation getting better every time robot reobserves landmark however, error approaches fixed value zero. I assume problem id assigning uncertainty. Any suggestions?",slam ekf errors mapping
4607,"Quadcopter Roll, Pitch Fluctuation","For quadcopter, turn quadcopter letting stable ground. But see Roll, Pitch fluctuate max difference 15 degree. When protect sensor soft material, observe max difference around 6 degree. Is fluctuation quadcopter? By way, use complementary filter DCM scaling factor 0.8 gyro 0.2 accel Thanks advance!",quadcopter
4608,Deducing single wing plane transfer function Aka Transfer function estimation set points,"I'm trying control plane via roll using PID controller , I problem finding transfer function thus I used following method :- Fix plane air tunnel change motor controls roll fixed steps check roll thus I table roll/motor degree next deduce nonlinear function using wolfram alpha approximation neural network . Is correct method I try another method ?",pid
4609,"Is increasing gyro , accelerometer sensor range good bad ? affect accuracy","I've using mpu6050 IMU unit ( gyro + accelerometer ) I found I set acc range +/- 2g 4g till 16 g gyro +/- 250 deg/sec , 500 deg/sec I know low cost full noise , settings range best ensure higher accuracy ?",sensors imu accelerometer gyroscope
4610,Forward Kinematics/D-H parameters perpendicular joint axes,"I trying compute forward kinematics Kuka youBot using DH convention: The arm joint 1 arm joint 5 revolute rotate world z-axis (pointing sky) But 3 joints revolute rotate x-axis, let's say (points horizontally) DH convention says ""joint distance"" along ""common normal"". But unless I mistaken, common normal y-axis, also horizontal, meaning joint distance. I thinking I would use link offset joint1 - joint2, I ran problem joint4 - joint5. Link offset supposed along previous z-axis, case would point horizontally nowhere. But link distance STILL doesn't work either, common normal distance, established common normal x-axis, also horizontal. So I feel screwed. I sure simple solution I can't see it. So I guess question is, I use DH convention links 1-2 4-5, joint rotational axes perpendicular?",kinematics forward-kinematics dh-parameters
4612,Controlling multiple Arduinos wirelessly,"I designing experiment controlling 6 small wind turbines wirelessly. For wind turbine, I need measure power time series (or voltage current time series) generator, control blade pitch angle, yaw angle, generator load (using variable resistance). The control input PWM signal. I planning put Arduino UNO ZigBee wireless module wind turbine, making measure power time series transmit central node, well receive control input central node command control input servo motors. The central node additional Arduino UNO. Here questions: Is possible Arduino send time series signal central node wirelessly without interference Arduino? (6 wind turbines transmitting time series central server). If possible, How I implement network ? recommending source learning would also greatly helpful. Interface central node computer software: The algorithm computer need process received power time series determine optimum control input 6 wind turbines. Then control input transmitted wirelessly 6 wind turbines. In case, good option interface algorithm Arduino connected computer? Currently algorithm written Matlab. I heard sketch interfacing Arduino Matlab, efficient enough project?",arduino
4625,"Seeking dirt cheap, wheeled, programmable robot","I playing old ""confuse cat flash-light"" game, I thought I might like program confuse-a-cat robot. Something, probably tracks, right flips over, I program move randomly around room, turning walls, making occasional sound flashing light. Since I tight budget, I wondered cheap kit I program ... Arduino, Raspberry Pi, platform, long programmable. Thanks advance help",mobile-robot
4627,Control 2.4 Ghz AR Drone computer,"I Doyusha Nano Spider R/C mini-copter, it's controlled 4ch joystick 2.4 Ghz. I look low cost method control computer. The software problem, I transform WIFI Bluetooth signal computer R/C signal compatible mini-copter receptor? Or another solution low cost?",control quadcopter wireless
4632,What mechanical parts attached DYJ48 stepper motor?,"Sorry I asking mechanical question here, but, all, else people experience using motors? If better forum this, please guide me. Everywhere I've seen online, stepper motor DYJ48 used tutorials, rotate own, or, most, spin clothes pin attached it. I trying get Arduino work 10 year old kid. He's got motor rotating, what? How attach anything it? Don't laugh, I made wheel raw potato. He happy now. Where I find guidance next?",arduino motor
4635,12V compressor air pressure control,"I trying make simple robot functionality someone, one functionality inflating balloon inside robot, I know control compressor using Arduino problem requested task bit different here: There must air exit must controllable arduino, inflate balloon certain pressure, depress air another exit needed (I don't know possible depression pressure-in valvle. I think done somehow using solenoid 3/2 valve something I bit unfocused days I need hints. Any thoughts?",arduino wheeled-robot mechanism industrial-robot valve
4639,Where roboticists look used sensors/hardware?,"I recently built self-driving vehicle-type robot competition, looking sell sensors (GPS, INS, etc.) used order money next project. Is ebay people tend go looking used sensors hardware?",sensors servos
4642,Finding light load high precision servo motor,"I project requires able accurately repeatedly rotate object 120 degrees. The object small lightweight (let's say several grams). The axis necessarily always spin direction. It simply needs able stop reliably 0, +/- 120, +/-240 degrees origin. I VERY limited experience motors robotics, understanding servo motor best bet accuracy (if incorrect, please let know). Since I know next nothing motors, spec sheets list lot specs don't mean much me. I'm hoping learn, mean time, specifications I need focusing requirements? It doesn't need high speed. When I say accurate, doesn't absolutely perfect micrometer, I would like able run loop stopping 0, 120, 240 hundreds times without visually noticeable variance - precise better though. To specific accuracy. Let's say object rotated flat surface top 3 stopping points. Upon inspection surface needs appear level every time hundreds cycles. Could requirements met servo might used building quadricopter, I going looking something higher grade that?",servomotor
4648,Controlling Dynamixel servo wirelessly using Arduino Mega,"I planning control multiple Dynamixel servos (MX28T MX-64T) wirelessly using Arduino Mega. Since servo uses serial communication, I need additional serial port interface Xbee module. Although seems common application controlling servos wirelessly based Arduino, I could't find web. I found two well constructed libraries. . This library MX28T servo, servo I trying use, uses UNO;therefore, I cannot interface Xbee. . This library use UART1 (serial1) interface servo (AX-12) motors. Therefore, I connect Xbee module UART0. But, problem library outdated compatible MX64-T servo anymore. So question here: Is one experience controlling Dynamixel MX24T, MX64T servo series using Xbee module simultaneously? If experience, please share me. Is possible Arduino Mega interface Xbee module using Serial1 (i.e., RX18 TX19)? If can, I might able use library1 without modification.",serial
4650,SLAM without landmarks using sonar,"I'm currently programming app robot I'd like make map zone make move autonomously one point another. I solve SLAM problem, biggest matter I can't use landmarks find environment. The robot abilities move, make distance measurements -120/+120 degrees using sonar. I can't find simply explained algorithm permits solve SLAM problem no-landmark limitation. Have idea ?",slam sonar
4656,Over-voltage brushed electronic speed controller,This battle robot hobby-weight class (5.44 Kg max) I want drive robot using 2 cordless drill motors rated 14.4 volts. I 4S LIPOs means I 4 x 3.7 volts 14.8 volts. So far good. The problem I bought 2 ESCs afterwards noticed rated 2-3S (or max 11.1 volts). So question I likely damage ESC I use 4S LIPOs instead 3S LIPOs? Or I buy 3S LIPOs live reduced performance?,motor esc
4657,Adding reverse function brushed motor electronic speed controller,"This Hobby-weight (5.44 Kg) battle robot. I bought two ESCs drive motors ESCs reverse function (or brake matter). Is simple way I achieve maybe either: The R/C settings (setting middle position joystick stopped, top-wards forward bottom-wards reverse?) Or could I maybe achieve using Arduino? I card relay switches I use Arduino worried high voltage current I worrying could get messy.. I could buy two new ESCs features cost quite bit ones I already I would prefer try tricks first - any!",motor esc
4658,Can 5S LIPO battery changed 3S 2S?,"Newbie robotics here! I bought 5S LIPO realise overkill. And things expensive! So, given (as far I know) pack apparently made individual cells 3.7 volts each, way I could somehow (safely) separate cells get 3S 2S even single 1S cells?",battery
4663,How periodically estimate states LTI output measured irregularly?,"How I periodically estimate states discrete linear time-invariant system form $$\dot{\vec{x}}=\textbf{A}\vec{x}+\textbf{B}\vec{u}$$ $$\vec{y}=\textbf{C}\vec{x}+\textbf{D}\vec{u} $$if measurements output $y$ performed irregular intervals? (suppose input always measured). My initial approach design Luenberger observer using estimates $\hat{\textbf{A}}$, $\hat{\textbf{B}}$, $\hat{\textbf{C}}$ $\hat{\textbf{D}}$ abovementioned matrices, update periodically every $T_s$ seconds according following rule: If measurement $y$ since last update: $$\dot{\hat{x}}=\hat{\textbf{A}}\hat{x}+\hat{\textbf{B}}\hat{u}+\textbf{L}(y_{measured}-\hat{\textbf{C}}\hat{x})$$ If not: $$\dot{x}=\hat{\textbf{A}}\hat{x}+\hat{\textbf{B}}\hat{u}$$ (I omitted superscript arrows clarity) I believe may better way this, since I'm updating observer using outdated measurement $y$ (which outdated $T_s$ seconds worst case).",control sensor-fusion
4672,Shortest path using wave planner?,"How could I compute shortest path point b using wave planner? I don't see using wave planner would give shortest; would give path! As far I tell, I would able give random path destination, nothing else that.",theory mapping
4674,What I looking DC motor used UROV thruster?,"I know DC motors produce lot torque actually move slow rate, others exact opposite. I know I need sort balance torque RPM's motor use underwater thruster, I sure I favor more, torque RPM's? Also, would great someone could suggest motor $300 range UROV.",motor torque
4675,Position Controller Quadrotor,"I question regarding implementation quadrotor's position controller. In Matlab model quadrotor takes 4 inputs: desired altitude ($Z_{des}$) desired attitude angles($\Phi_{des}$, $\Theta_{des}$, $\Psi_{des}$) reflects motion described differential equations model (see last picture). Here insight implemented Matlab dynamic model. As see structure like inner loop controler: Anyway...it ""hovers"" perfectly starting point. (perfect graphs :) ) Now I need go implement sort position controller let quadrotor get start goal point, defined usual 3 coordinates $[X_d, Y_d, Z_d]$. That's tricky I don't space state variables input output system. So controller must take vector three coordinates able output 3 different angles get there. The exception height simply bypassed controller doesn't need another calculation loop. A different story three angles... My first idea simply create feedback position given output simulated system desired position figure above. But rises another question: quadrotor model solves following equation system: $$ \large \cases{ \ddot X = ( \sin{\psi} \sin{\phi} + \cos{\psi} \sin{\theta} \cos{\phi}) \frac{U_1}{m} \cr \ddot Y = (-\cos{\psi} \sin{\phi} + \sin{\psi} \sin{\theta} \cos{\phi}) \frac{U_1}{m} \cr \ddot Z = (-g + (\cos{\theta} \cos{\phi}) \frac{U_1}{m} \cr \dot p = \frac{I_{YY} - I_{ZZ}}{I_{XX}}qr - \frac{J_{TP}}{I_{XX}} q \Omega + \frac{U_2}{I_{XX}} \cr \dot q = \frac{I_{ZZ} - I_{XX}}{I_{YY}}pr - \frac{J_{TP}}{I_{YY}} p \Omega + \frac{U_3}{I_{YY}} \cr \dot r = \frac{I_{XX} - I_{YY}}{I_{ZZ}}pq - \frac{U_4}{I_{ZZ}} } $$ means expect (as matlab model above) desired angles height. But I need right inverse: given desired position calculate right angles!!! For direction solution really simple, since I write something like: x lies horizontal plane. This simple two angles. So I point? Just ""invert"" given equations get desired angles? Another idea could implement simple PD PID controller. This much easier given fact I experiment quickly using Simulink get good results. But problem again: get I desired angles desired position?",pid quadcopter
4677,How estimate yaw angle tri-axis accelerometer gyroscope,"I would like estimate yaw angle accelerometer gyroscope data. For roll pitch estimate I've used following trigonometric equations: simpified version Kalman Filter consider also angular rates. The roll pitch estimates accurate (accelerometer values need filtered presence chassis vibrations). In order get Yaw angle I'm using following equation: yaw = atan2(Ax,Ay) * RAD_TO_DEG; doesn't work. Do advice?",sensors quadcopter kalman-filter imu accelerometer
4679,MPU9150 - Yaw angle Drift,"I use MPU9150, also use DCM Complimentary filter compute roll, pitch yaw. However, Yaw smooth. How I solve problem? I looked datasheet MPU9150, I didn't see anything related sampling frequency magnetometer like gyro accel.",quadcopter
4682,Is advantage multiple magnetometers heading computation,"I'm building autonomous sail boat (ripped guts RC sail boat replaced mainboard etc.) The controller board I accommodate MPU9150 HMC5883. Is advantage using magnetometers tilt-compensated heading? I'm thinking I could compute unit vector soft/hard iron offsets removed both, average two vectors get one slightly better one? Not sure would yield better result though.",sensors sensor-fusion
4687,tricopter simulation test control algorithms,"I looking write test control algorithms tricopter flight. I looking simulator simulate tricopter level receiving simulated PWM returning simulated gyro, compass sensor readings. Ideally would also graphics visualization (need fancy). Ultimately, I want port real tricopter moment I would like simulate it. Any suggestions free simulators low level I described?",control quadcopter simulator
4688,Acceleration formula differential steering robot,"I formulas derive RPM's wheel robot's linear velocity. Now, I trying thing acceleration (mainly angular acceleration). For linear acceleration I always assuming linear velocity wheels robots robot moving straight line...according physics. Am I right? But angular acceleration seems complicated, specially robot following curved path (not necessarily turning place). Any readings ROS packages deal acceleration issue? Thanks",ros wheeled-robot differential-drive
4689,Short distance ball transport,"I'm looking way transport balls (diameter 50mm) 220 mm slope length 120 mm. Currently I'm considering usage belt system I cannot seem find good belt system. Because space constraints within robot, normally I would probably take nylon belt jam nails trough make little slots use that. However would result considerable reduction available space means I also take account extra space required nails way back. This means ideally would way reduce space used nails way back. Does anybody good solution this?",kinematics manipulator
4693,possible track movement tennis court?,I'd like track run indoor tennis court. GPS won't available I thinking researching solutions: Accelerometer: I concluded it's go playing tennis player makes lot movements include spinning body alter data. Then I thought 3/4 point IR system might help I've understood it's hard IR system track movement since won't able focus player. So final thought went radio systems I couldn't find info it's also hard see theoretical solution least I mesure movement/speed player. So question: Is existing system able track random movement object (athlete) give info like speed distance? anywhere resources system might achieved least exact technology used it? Any suggestions ideas greatly appreaciated.,arduino kinematics movement
4698,Interface multiple I2C slaves microcontroller,"I want communicate Tiva C ARM Cortex M4 sensorhub TI multiple sensors different I2C addresses MPU9150, BMP180, Temperature Sensors... With single I2C slave, communicate successfully, project involves interface Microcontroller MPU9150 BMP180, get stuck. Anybody suggest process commnunication case?",i2c
4699,Robot docking self-recharging,"I want build simple obstacle avoider robot, time I want self-recharging I building dock purpose, I want able locate dock go battery voltage lower fixed value. I trouble chose right components locating dock, I think I going use IR emitter dock robot head toward battery low (let's forget orientation problem moment, thoughts helpful) I sure robot able detect IR LED (or whatever) long distance (over 10 meter) Is possible use solution distance? If not, suggest? (If simple ready solution buy that's ok, let's say I budget limit)",sensors localization wheeled-robot battery wireless
4701,A general question PID Controller,"I basic question I'm trying understand right concept I thought obvious. Looking video going feedback variable state x input system, force f. Now, I'm correct possibile feedback variables share units, I expect drive meter input variable meter difference feed PID. Is example video show use simulink? Or I wrong?",pid
4702,Advice mounting servo nerf sentry gun,I trying make nerf sentry gun shoot co workers. I building less scratch come part I need come plans assemble it. I looking advice mount mg995 servos allow tilt pan. I originally thought base metal rod middle use gear control pan functionality. The idea would mimic skateboard truck gear would turn rod middle pivot shooting mechanism. Another idea metal plate sit top servo use one attachments attach top plate. The problems I see behind attachment small piece plastic short period time I could see wearing especially shooting mechanism centered perfectly. I also need come solution make tilt I think I idea simply use rod gear turn pvc pipe barrel. Here servo's I using Sorry wrong forum question I unsure else look expert advice. EDIT 1 For anyone intersted I found example someone almost exactly thing blueprints. I going slightly simpler / cheaper route mounting servo bottom spinning plate lazy susan plate I ordered. This way I don't buy gears rather expensive without gears may reduce torque.,mechanism servos servomotor
4704,Self Powered Quadcoptor,"I idea curious question mind. I near professional though, would like answered. We know wind turbines used generate electricity. So possible create quadcoptor start minimal power small battery time sustain keep system self generating electricity keep rotating rotors without external supply?",quadcopter
4705,Amperage brushed motors,I currently building hobby-weight (5.44kg) robot using 2 x 14.4 cordless driller motors wheels. The thing I keep reading high amperages working r/c models quadcopters BUT I connect cordless driller motor bench power supply monitor current draw never rises 3.2 Amps even I try stop motor hand. Of course arena event stand I plastic wheels slip I concerned stall currents. I left wondering whether I mis-calculated whether people make lot fuss high currents nothing. currents perhaps really apply brush-less motors?,motor
4706,Diode capacitor across terminals brushed motor,"I currently building hobby-weight robot (5.44kg) using 2 x 14.4v cordless drill brushed motors drive wheels. I read somewhere due ""induced currents"" I turn motor (or reverse presumably?) I protect using diode capacitor across terminals. Which I use (capacitor diode) parameters I need consider components (voltage current)? Some answers similar question discussed capacitors diodes. Are diodes relevant? Would I seriously damage cordless drill (presumably quite tough) motor I nothing? And don't motor controllers form inbuilt protection motors anyway?",motor
4707,Spinning disk Weapon,"I building Hobby-weight robot weapon choice spinning disk front. As regards disk I thinking buying commercial (grinder-type) disks change type disk depending ""enemy's"" chassis construction material. So instance I would aluminum cutting disk enemy's chassis made aluminum on. First question therefore; disks job practise (or break, fail cut?) Secondly, I use brushed brush-less motor disk? I actually ESCs sort feel brushed motor give torque brush-less motor might give speed. So important speed torque? I know - uncle uses metal lathes - machines cut metal usually spin slower speed (drills, cutting wheels etc)- indeed likes say metal working machines safer wood-working ones partially reason. But I newbie really would like effective weapon possible breaking not-cutting disks make weapon! Also normal practise use one battery everything (drive weapon) two separate batteries?",motor battle-bot
4713,Rotate (and stop) large disk tiny increments,"In lab build I'm doing, I'm stuck problem, I fishing suggestions. I'm creating turn-table type setup I need make readings (with nanotube-tip probe I've already designed, similar AFM probe) edge/circumference 10 cm radius disk (substrate). The current hurdle is: I need get substrate disk move circularly steps 0.1 mm displacement -- meaning, I occasionally need STOP certain 0.1mm-increment positions. What would way I achieve this, assuming accurate feedback system (with accuracy say ~0.1 mm, e.g., quadrature optical encoders) available needed closed-loop control? Specs commonly sold steppers don't seem allow kind control. I'm moment trying study how, e.g. hard disks achieve extreme accuracies (granted don't large disks). Certainly, direct-drive like I'm currently building (see image) probably doesn't help!",motor stepper-motor
4715,control robot pymorse MORSE simulator question,"I new Morse robotics. This code control robot giving linear angular velocity. This scene description control script import pymorse pymorse.Morse() simu: simu.robot.motion.publish({""v"": 3, ""w"": -1}) The robot moves well. But I remove semantic cameras scene description robot move. I confused, sensor, robot don't move ?",mobile-robot sensors control
4716,Motor weapon Hobbyweight,"I currently building hobby-weight (5.44kg) robot. The weapon vertical spinning disk front. It probably commercial one hardware store I could maybe get one made. I 2 cordless drill motors drive wheels I ok there, I still lost comes motor I get weapon. I inclined think brush-less although I still open opinions. Can anyone please recommend good motor (in-line brush-less) brushed motor give speed strength I need weapon?",motor battle-bot
4717,Detect road surface traffic scene point cloud,"I want analyze traffic scene. My source data point cloud like one (see images bottom post). I want able detect objects road (cars, cyclists etc.). So first I need know road surface I remove ignore points simply run detection surface level. What ways detect road surface? The easiest scenario straight flat road - I guess I could try registrate simple plane approximate position surface (I quite surely know begins front car) road surface perfect plane I allow tolerance around plane. More difficult scenario would curvy wavy (undulated?) road surface would form kind 3D curve... I appreciate inputs.",mobile-robot wheeled-robot computer-vision algorithm stereo-vision
4721,How convert PID outputs appropriate motor speeds quad copter,"I building autonomous robot using PID control algorithm. So, far I implemented PID using online resources/references. I testing stabilizing axis quad copter. However, I successful stabilize even one axis. Description: My input PID angle value i.e orientation quad copter measured AHRS (a Gyroscope measures angles) motors take integer values speeds. What I is, Where ajusted_value buffer accumulates subtracts PID output value based either PID output +ve -ve. I also tried, motor_right_speed = base_speed + PID_output; motor_left_speed = base_speed - PID_output; Both don't seem working. I tested using wide range P gain values (from small large), quad copter oscillates; self-correct. Your help suggestions would greatly appreciated. Thanks!",quadcopter
4722,Brush-less motor specs vs efficiency multi-copters,"I looking figures surrounding specs brushless motors relative efficiency (in power usage terms) multi-copter use. There 4 basic specs motors themselves: - Motor width (EG 28mm) - Motor height (EG 30mm) - ""KV"" - RPM per volt supplied (EG 800KV) - wattage (eg 300w) This would 28-30 800kv 300w motor. What looking chart containing: - Motor spec - pack voltage (eg 14.8v) - Amps drawn @ various % throttle (10% 100% say) - static thrust various propellers (11x5, 12x6 etc etc) Does information exist? I know BIT subjective prop motor designs vary slightly, baseline would start.",brushless-motor
4723,Hokuyo URG-04LX-UG01 Mac compatibility issues,"I've got hands laser range scanner seem problem receiving output it. I can't find guide set internet, I wondering even possible set mac shall using Linux ROS ?",communication laser rangefinder
4724,biped walking using Genetic Algorithm,"I working project I lack advanced programming knowledge, especially genetic algorithms. I developing prototype using WEBOTS 7.4.3 simulation. The project use genetic algorithms evolve gait biped robot. I developed physical model, I still uncertain motor choice. For algorithm part, I find hard understand set algorithm parameters determine fitness function. Could please suggest fitness function? Thank help efforts.",algorithm machine-learning legged
4725,Recursive Tree Representation Multi Agent Robots?,"I going code base multi agent motion planning. And I came across recursive tree building algorithm agents. I haven't able figure algorithm. Does anyone know called? Or similar kinds algorithms I could read it? Here I got code: The node tree follows - Each node max min value x y. And also begin, end, left right value. Then tree split either horizontally vertically based limits longer (x y). And optimal value found agents split. Then split agents recursively build again. Thank much.",multi-agent
4726,ros node seem anything,"I following code ros turtlesim: idea behind code introduce random error practice error recovery code node appear anything all. I know nodes running one doesn't appear anything, doesn't exit hangs. Anybody know fix this?",ros
4734,Can I make automatically-parking robot car IR sensor?,"It would easy understand imagine robotic vacuum cleaner. (For models) It goes back specific place automatically recharge. Like this, I want make robot automatically goes place specific signal(like infrared ray) emitting. Following scenario i've imagined. 1.Set IR emitter specific place room. It always emits Infrared ray. 2.I connect 4 IR receiver 4WD robot car - front, left, right, back side. 3.They receive IR emitter. I earn distance emitter receiver intensity IR. 4.With values, Arduino find receiver closest emitter choose direction go. But I could't know possible. Because IR kind light ray, I can't get distance difference arrival time(like Ultrasonic). I searched several kinds IR sensors, sensing possibility collision. So question these.. Can I get distance direction IR emitter arduino device IR receiver? If I can, many IR receivers I need? And I can't, I use substitute IR emitters receivers? I guess IR interrupted sunlight light. So I guess I need daylight filter. Do think it's essential??",arduino sensors wheeled-robot
4738,Wheeled Robot Motion Primitives: Is throttling forward crab motion considered one?,"I simulating wheeled robot six-wheels independently steered, like MER-Opportunity. The wheeled robot perform throttling forward, crab-motion, //---// <--wheel orientation heading 45 // // //---// turning spot. //---\\ <--wheel orientation || || \\---// My question is: Is correct say I 2 motion primitives? Throttling forward basically crab-motion heading zero.",wheeled-robot motion
4741,Numerical-Example Paden-Kahan subproblems?,"I writing kinematics library Go part final year project. I working Product Exponentials method successfully implemented Forward Kinematics part this. I need help Inverse Kinematics. I understand theoretical aspect it. I would like numerical example actual numbers used Paden-Kahan subproblems ones dealt ""A Mathematical Introduction Robotic Manipulation - Murray,Li Sastry"" [freely-available online PDF]. I specifically need help knowing p,q trying solve inverse kinematics. The book says given, point p,q around axis rotation joint. But know points practice, like robot actually moving, keep track points? For reasons I need numerical example understand it.",inverse-kinematics product-of-exponentials
4745,How I get transformation matrix?,"I've started taking robotics course I little problem. I need rotate $O_i-1$ coordinate system position, $X_i-1$ parallel $X_i$. The transformation matrix given, I idea I figure transformation matrix picture found below. Actually, I know last vector [0 0 0 1] previous vector [0 0 1 0], I can't figure first vector [$\cos q_i$ $\sin q_i$ 0 0] second [$-\sin q_i$ $\cos q_i$ 0 0].",robotic-arm industrial-robot
4749,Survey Local Navigation,I wondering good book paper surveys current techniques local navigation? The earliest one I could find 2005 I hoping find something recent. I worked certain approaches dynamic window approach velocity obstacles approach. I'm hoping book paper give broader perspective problem local navigation I believe fairly robustly solved number autonomous driving companies. Thank you.,navigation motion-planning
4750,PID Control Tuning,"Im currently designing robot undergraduate project. One task robot follow wall. For purpose I'm using PID control system, reference given ultrasonic sensor. So problem im hard time tuning PID. I know find P coefficient pretty easily plotting desired set point range vs desired motor output speed. Even robot stable, though adding DI part PID. But find roughly values coefficients without trying random values (manual tuning)? Thank much. Much appreciated.",motor control pid
4754,Build ROS robot SLAM without laser,"I've build simple wheeled robot based two continuous servos, controlled Raspberry Pi running ROS-groovy, smart phone mounted top provide additional sensors. I'd like situate bot room move various points command. I don't laser ranger finder good ultrasonic ranger finder kinect sensors. What typical ROS setup this? The idea I'm thinking personally (e.g. manually) map room using kinect use map using ultrasonic range finder sensors IMU lightweight robot. Would possible?",localization ros slam raspberry-pi ultrasonic-sensors
4755,Parameter $r$ Denavit-Hartenberg,"By watching video explains calculate classic Denavit–Hartenberg parameters kinematic chain, I left impression parameter $r_i$ (or $a_i$) always positive. Is true? If not, could give examples could negative?",forward-kinematics dh-parameters
4759,How find height rock rover?,"So, I designing rover navigate rock, calculate height rock. Currently, team's design involves using ultrasonic rangefinder lots math. I interested sensors would use solve problem, would go it? Assume rover already located rock. Additional Info: We using Arduino Uno control rover. It completely autonomous.",arduino wheeled-robot algorithm
4761,Sending smartphone's GPS wireless,"I'm building camera device able take pictures paragliders mid air. To let camera know glider I thought using GPS data pilot's smartphone. My question is: What possible ways transmit GPS data groundstation considered good solution? I thought sending data server via mobile network, direct communication solution would preferable. The pilot mid-air pretty good mobile reception maximum distance pilot ground station around 3km.",gps communication wireless
4762,Learning Materials Beginners Robotics Quadrocopters,"I web developer. I fascinated Quadrocopters trying learn build one basically trying jump robotics fields. I don't much electric circuit electronics knowledge research build type knowledge would require develop flying machine. So started learning basics electronics Lessons In Electric Circuits Tony R. Kuphaldt The books interesting could find technique implement learn books. Basically going stuffs, understanding little little. What want know right way effective way learn electronics electric circuit experience increase learning speed achieve goal. While researching came across topics mathematical modelling modelling quadrocopters first implementing real. How gain knowledge model something mathematically implement real life? How much math areas mathematics need learn learn such? Now idea want learn achieve. Can please suggest road map steps need take gain knowledge skill develop myself, near future would able build flying machines own.",quadcopter
4764,Which useful? Instantaneous rate change displacement Average rate change displacement?,"Instantaneous rate change displacement given by, average rate change displacement given by, v(t) = (s(t[n]) - s(t[n-1]))/(t[n] - t[n-1]) The first one gives slope derivative displacement function particular instant time thus varies time. I wondering going help calculate velocity robot's end effector, foot leg robot(bipedal). If make reading position robot every 1ms keep approximation accurate possible, instantaneous velocity would zero wouldn't it? Since robot wouldn't moved anywhere 1ms time. Agreed, 't' would increment t+dt, dt == 0.001s. Then v(t) would v(0.001) = s(0.002) - s(0.001) zero, displacement small time frame, right? Am I something wrong here? Or hand, I use average rate change? I question, since, manipulator, case foot robot, it's trajectory given 3x3 homogenous matrix, [{c(t),-s(t), 0}, {s(t), c(t), 0}, { 0, 0, 1}], c,s cos(theta) sin(theta)respectively, paper, differentiated, would give spatial/body velocity matrix [{0, -d(theta)/dt, 0}, {d(theta)/dt, 0, 0}, { 0, 0, 0}] So I compute differentiation code. I need something sort pseudocode.",mobile-robot
4766,power extra usb devices beaglebone black,"I'm building robot uses beaglebone black, however I several different usb devices I want connect (microphone, usb sound device things). Now I heard usb output beaglebone doesn't power 0.1A. So combined draw usb devices likely exceed fair margin. So I started looking powered usb hubs use instead. However tend powered 220V robot currently 12V power supply converter 5V beaglebone. Which given size expense inefficiency converting power 220 12V back doesn't seem good. Is good method fixing this?",power usb beagle-bone
4771,tracking robot room,"I'm trying track simple robot (e.g. arduino, raspberry pi, even toys) room using fixed location kinect sensor(s) cameras different parts room. How might one usually use this? Edit 1: More specifically, I want know position (and possible, orientation) moving object room using one cameras depth sensors. I'm new area, one idea might use blob haar detect moving object get location kinect depth-map, I'm trying find package I use end. But navigation work I'd pre-map room manually kinect. I put sensors tracked moving object, e.g. IMU, sonar, kinect. I allowed full PCs running ROS/opencv/kinect sdk environment, I wirelessly communicate tracked object (which presently raspberry pi running ROS groovy wheels)",arduino computer-vision kinect
4775,Image processing bright lights,We working project requires us detect hit ball. We trying accomplish task detecting position ball processing input camera. The problem required bright lights. The bright lights making difficult detect white colored ball. Is way write code automatically reduces intensity lights image? Is efficient way extract V component HSV image? We limited experience image processing alternative approach detecting object also helpful,computer-vision
4782,Power switch common ground battle robot,"I constructing 5.44Kg Hobby-weight battle robot one safety rules robot must power switch turns power motors (and weapon). The robot three sub-systems; drive motors (one battery), weapon (another battery) lighting (a small 9 volt battery). I read since connected receiver important electronics sharing common ground everything work properly. Now I know usually ""live"" wire connected switch, I thinking hitting two birds one stone connecting ground wires (rather live wires) switch. In way I still turn power also common ground. In terms safety (shorts) etc I concerned I using XT 60 connectors careful use female plugs power leads (so prongs visible). It seems work still safe enough especially since I dealing mains voltage levels here, hand I don't want look stupid. Does way connecting switch make sense I violating unwritten law? Is normal practice? Would effect circuitry way grounds connected together? I also thinking using switch PC power supply; far I know rated reasonably high currents. In case I 3 cordless motors, might drawing 5 amps load, say 15 amps all. Has anyone ever used switches buy high current ones? In case I ask for? Thanks.",control power battle-bot
4784,gazebo import robot gives error,"I'm trying import tutorial robot given link However gives following error: This sugest something wrong parsing actually point towards line code (the example 103 lines long). <link name='chassis'> <pose>0 0 .1 0 0 0</pose> <collision name='collision'> <geometry> <box> <size>.4 .2 .1</size> </box> </geometry> </collision> <visual name='visual'> <geometry> <box> <size>.4 .2 .1</size> </box> </geometry> </visual> <collision name='caster_collision'> <pose>-0.15 0 -0.05 0 0 0</pose> <geometry> <sphere> <radius>.05</radius> </sphere> </geometry> <surface> <friction> <ode> <mu>0</mu> <mu2>0</mu2> <slip1>1.0</slip1> <slip2>1.0</slip2> </ode> </friction> </surface> </collision> <visual name='caster_visual'> <pose>-0.15 0 -0.05 0 0 0</pose> <geometry> <sphere> <radius>.05</radius> </sphere> </geometry> </visual> </link> <link name=""left_wheel""> <pose>0.1 0.13 0.1 0 1.5707 1.5707</pose> <collision name=""collision""> <geometry> <cylinder> <radius>.1</radius> <length>.05</length> </cylinder> </geometry> </collision> <visual name=""visual""> <geometry> <cylinder> <radius>.1</radius> <length>.05</length> </cylinder> </geometry> </visual> </link> <link name=""right_wheel""> <pose>0.1 -0.13 0.1 0 1.5707 1.5707</pose> <collision name=""collision""> <geometry> <cylinder> <radius>.1</radius> <length>.05</length> </cylinder> </geometry> </collision> <visual name=""visual""> <geometry> <cylinder> <radius>.1</radius> <length>.05</length> </cylinder> </geometry> </visual> </link> <joint type=""revolute"" name=""left_wheel_hinge""> <pose>0 0 -0.03 0 0 0</pose> <child>left_wheel</child> <parent>chassis</parent> <axis> <xyz>0 1 0</xyz> </axis> </joint> <joint type=""revolute"" name=""right_wheel_hinge""> <pose>0 0 0.03 0 0 0</pose> <child>right_wheel</child> <parent>chassis</parent> <axis> <xyz>0 1 0</xyz> </axis> </joint> </model> </sdf> This ubuntu 14.04. Is hint I'm wrong information I provide better come solution",simulator gazebo simulation
4787,Scan Matching finds right rotation false translation,"I'm currently developing SLAM software robot, I tried Scan Matching algorithm solve odometry problem. I read article : Metric-Based Iterative Closest Point Scan Matching Sensor Displacement Estimation I found really well explained, I strictly followed formulas given article implement algorithm. You see implementation python : ScanMatching.py The problem I that, tests, right rotation found, translation totally false. The values translation extremely high. Do guys idea problem code ? Otherwise, I post question StackOverflow Mathematics Stack Exchange ? The ICP part correct, I tested many times, Least Square Minimization doesn't seem give good results. The parts might problematic function getAXX() getBX() (starting line 91). As noticed, I used many decimal.Decimal values, cause sometimes max float big enough contain values.",slam
4789,Probabilistic Velocity Obstacles,"I working Velocity Obstacles concept. Recently, I came across probabilistic extension couldn't understand inner workings. Source: Recursive Probabilistic Velocity Obstacles Reflective Navigation What equation bottom top mean? Vij relative velocity agent agent j. ri & ci rj & cj respective radius centers. Update: What inf(ri + rj) sup(ri + rj) mean? Does mean I define function goes 1 0 inf sup? And not, I calculate value PCC given point?",probability
4793,Proportional controller error doesn't approach zero,"I'm reading pdf. The dynamic equation one arm provided $$ l \ddot{\theta} + \dot{\theta} + mgL sin(\theta) = \tau $$ $\theta$ : joint variable. $\tau$ : joint torque $m$ : mass $L$ : distance centre mass joint. $d$ : viscous friction coefficient $l$ : inertia seen rotation axis. I would like use P (proportional) controller now. $$ \tau = -K_{p} (\theta - \theta_{d}) $$ My Matlab code For solving differential equation function dx = ODESolver(t, x) dx = zeros(2,1); %Parameters: = 2; = 0.001; L = 1; I = 0.0023; g = 9.81; T = x(1) - (pi/2); dx(1) = x(2); q2dot = 1/I*T - 1/I*d*x(2) - 1/I*m*g*L*sin(x(1)); dx(2) = q2dot; The error My question error approaching zero time goes? The problem regulation track, error must approach zero.",control dynamics manipulator
4794,Motor controller calibration,"I bought 2 brushed motor controllers China use hobby-weight battle robot (). These intended use 2 cordless drill motors driving left right wheel respectively. The robot therefore steered ""tank mode"" varying speed direction rotation 2 motors using two joysticks Turnigy 9x transmitter. My question is: I seen videos youtube people calibrate brushless motor controllers (ESCs) using system pushing joystick standard transmitter forward listening tones reverse on. However I asked suppliers similar procedure brushed controllers, could say need calibration. The exact words ""It seems you're talking transmitter copters,but ESC RC car boat. You pull trigger, goes forward, push trigger, reverse. And don't need calibrate it, plug it, work."" My transmitter one gun shaped ones used cars. So I trouble controllers work correctly box supplier seems implying? You may fairly ask I tried simple answer LIPO charger yet arrived I therefore cannot power anything yet.",motor
4796,Changing tank drive (differential) mode single joystick drive mode,"I bought 2 brushed motor controllers China use within hobby-weight battle robot (). These intended use 2 cordless drill motors driving left right wheel respectively. The robot therefore steered ""tank mode"" varying speed direction rotation 2 motors using two joysticks Turnigy 9x transmitter. I seeking refine model make easier operate anyone know way I somehow synchronize motors get single joystick steering system? My transmitter 9 available channels part solution I fine it. I also Arduino available needs be.",motor differential-drive
4797,Risk overloading motor controller,"I bought 2 brushed motor controllers China hobby-weight battle robot (). These intended use 2 cordless drill 14.4v motors driving left right wheel respectively. I using 4S LIPOs (when fully charged) voltage 16.8V. Can someone put mind rest .8 volt excess unlikely damage controller (which rated 7.2v - 16v)? Also fact motor controllers rated 320Amp likely damage motors? I honest clear current drawn LIPO battery. For instance would connecting LIPO directly motor result massive discharge motor ""take needs"" terms current? Can someone maybe kindly point article casts light subject even kindly explain here?",motor battery
4798,RNN instead PID controller,"I building drone using raspberry pi I using 6*PID controllers control speed value angle, I use recurrent neural network (RNN) neural network stabilize angles. If training data be? What type neural network (NN) best suited kind application?",pid raspberry-pi artificial-intelligence
4804,AHRS Algorithm Question,"As far understand, AHRS use orientation reference vectors detect orientation error. And use magnetometer correct yaw drift. But see ak895 magnetometer data stable, kind fluctuates continuously. How use data AHRS algorithm?",quadcopter
4808,Is input ESC really limited 50 Hz PID controllers work properly?,"Based wiki page ESC, ESC generally accepts nominal 50 Hz PWM servo input signal whose pulse width varies 1 ms 2 ms For project, integrate flight controller UAV, Naza m-lite want implement position control. We already localization control quadrotor applying servo width roll, pitch, yaw thrust throttle. Since ESC accepts 50 Hz, PID controller work 50 Hz?",pid
4815,Using i2c's SCL GPIO pins SDA,"The beaglebone black I work 2 i2c busses. Say crazy reason, need use 8 i2c busses. I dont want chain devices. The idea every device's SDA line separated use shared SCL line use clock many SDA lines want. Since SCL clock hardware controlled wont major issues here. The GPIO around 2.5mhz switching I happy that. If works out, spawn 8 threads talk 8 i2c Lines making solution faster! Do think doable? I would like hear guys idea using 1SCL GPIO SDA popped head thought sharing guys. Cheers!",i2c
4820,Choosing motor characteristics,"I sized DC motors I want use (corresponding robot intended applications - figures include 50% uncertainty factor account friction reducers losses). Now I need actually choose exact motors I want buy manufacturer (I targeting maxon motors I expert want problem). I earth questions linking mechanical needs electrical characteristics: Maxon states ""nominal voltage"" characteristic sheets. Is voltage apply motor? This may dumb question I followed full maxon e-learning course read tutorials web I could find information anywhere. Can anyone knows motors confirm? As far I understand, nominal torque corresponds maximum torque motor sustain continuously. So I guess, rule thumb, I find motor nominal torque = max torque (after reduction), around. Right? Also I chose motor reference (310005 found here) stated power 60W, nominal voltage 12V, I expecting nominal current 5A, states 4A. Where I wrong? The motor I chose nominal speed = 7630rpm - nominal torque = 51.6mNm. My needs max speed = 50.42rpm / max torque = 10620 mNm. This means reduction factor 151 speed 206 torque. Should I choose gear closer 151 206? What ""rated torque"" mentioned choosing gear? I know input torque (torque motor side) output torque (torque system side), correspond two? I followed theoretical practical courses web I find hard find answers earth question... Thanks, Antoine.",motor
4824,Implementing position control UAV flight controller. Plant model unknown,"We using Naza-M-Lite flight controller without GPS. The localization obtained RGB-D camera sensor. We able teleoperate even implement PID controllers Roll, Pitch, Yaw Throttle channels quadrotor. However, know plant model inputting Arduino Naza-M-Lite servo PWM ranging 1000 2000. For throttle: 1500 altitude hold, 2000 maximum throttle, 1000 minimum throttle For Pitch, Roll, Yaw: 1500 maintain 0 angle, 2000 1000 moves quadrotor towards respective axes. However, even 1500 every channel, quadrotor drifts, maybe due flying indoors wind pushes quadrotor. Once gains momentum, drifts. We trouble tuning know relationship output position. If output velocity, would easier. But case, not. Is way find plant model Naza-M-Lite tune this?",localization pid quadcopter uav
4827,NAO motor model identification,"I trying create model NAO [robot]'s motors. The figure shows step response knee motor. Afaik NAO internally uses pid controller control motor. I control pid it's parameters. Thus I would like treat motor including pid black box. Theoretically possible model pid+motor $pt_2$ system, i.e. second order lti system. A $pt_2$ system defined following differential equation: $$T^2\ddot{y}(t) + 2dT\dot{y}(t)+y(t) = Ku(t)$$. I tried fitting $pt_2$ model unable find good parameters. Any idea model use kind step response? edit: I tried modifying equation add maximum joint velocity like this: $$T^2\ddot{y}(t) + (\frac{2dT\dot{y}(t) + - |2dT\dot{y}(t) - m|}{2})+y(t) = Ku(t)$$ $m$ maximum velocity. The fraction equivalent $min(2dT\dot{y}(t), m)$. However I sure correct way introduce maximum joint velocity. The optimizer unable find good parameters limited velocity formula. I guessing min() introduces area parameter changes cause optimization error changes.",motor
4828,Is nominal voltage motor voltage apply motor?,"I sized DC motors I want use (corresponding robot intended applications - figures include 50% uncertainty factor account friction reducers losses). Now I need actually choose exact motors I want buy manufacturer (I targeting maxon motors I expert want problem). I earth questions linking mechanical needs electrical characteristics, among them: Question #1: Maxon (or manufacturers) states ""nominal voltage"" characteristic sheets. Is voltage apply motor? This may dumb question I followed full maxon e-learning course read tutorials web I could find information anywhere. Can anyone knows motors confirm? I followed theoretical practical courses web I find hard find answers earth question...",motor brushless-motor
4829,Choosing DC motor: max needed torque vs nominal torque,"I sized DC motors I want use (corresponding robot intended applications - figures include 50% uncertainty factor account friction reducers losses). Now I need actually choose exact motors I want buy manufacturer (I targeting maxon motors I expert want problem). I earth questions linking mechanical needs electrical characteristics, among them: Question #2: As far I understand, nominal torque corresponds maximum torque motor sustain continuously. So I guess, rule thumb, I find motor nominal torque = max needed torque (after reduction), around. Right?",motor brushless-motor servos servomotor
4830,Stated power motor equal nominal voltage x current?,"I sized DC motors I want use (corresponding robot intended applications - figures include 50% uncertainty factor account friction reducers losses). Now I need actually choose exact motors I want buy manufacturer (I targeting maxon motors I expert want problem). I earth questions linking mechanical needs electrical characteristics, among them: Question #3: I chose motor reference (310005 maxon reference found here) stated power 60W, nominal voltage 12V, I expecting nominal current 5A, states 4A. Where I wrong?",motor servos servomotor
4831,Selecting gear reduction: torque vs speed,"I sized DC motors I want use (corresponding robot intended applications - figures include 50% uncertainty factor account friction reducers losses). Now I need actually choose exact motors I want buy manufacturer (I targeting maxon motors I expert want problem). I earth questions linking mechanical needs electrical characteristics, among them: Question #4: The motor I chose (maxon brushed DC: 310005 found here) nominal speed = 7630rpm - nominal torque = 51.6mNm. My needs max speed = 50.42rpm / max torque = 10620 mNm. This means reduction factor 151 speed 206 torque. Should I choose gear closer 151 206?",motor brushless-motor servos servomotor
4832,"How ""rated torque"" gear relate maximum torque?","I sized DC motors I want use (corresponding robot intended applications - figures include 50% uncertainty factor account friction reducers losses). Now I need actually choose exact motors I want buy manufacturer (I targeting maxon motors I expert want problem). I earth questions linking mechanical needs electrical characteristics, among them: Question #5: What ""rated torque"" mentioned choosing gear? I guess related maximum torque gear support... But now, I know input torque (torque motor side) output torque (torque system side), correspond two?",motor brushless-motor servos servomotor
4836,How control PID Yaw,"My yaw angle varies -180 degree 180 degree. If current heading 170 degree, wind makes rotate left -170 degree, PID control make rotate back right 170 degree. Since, PID ERROR = SETPOINT - INPUT In case, SETPOINT = 170, INPUT = -170, ERROR = 170 - (-170) = 340. So instead moving right apply PWM = 20, rotate left apply PWM = 340 come back desired position, 170 degree?",pid
4840,"A robotics computer graphics card, lots computation power, battery, screen, keyboard?","I'm working robotics platform need on-board Ubuntu machine run ROS image recognition. Does anyone know good set computer hardware NO screen NO keyboard Built-in battery (for charging separate robot) Quite bit compute power (i5+, 4+ GB ram) I thought using laptop, keyboard screen lot extra weight/volume I don't want carry around. Something like Intel NUC appealing, battery.",driver
4843,How change orientation object w.r.t scene?,"I trying localize object point cloud using ROS, PCL. For I capture scene model using Asus xtion pro sensor. I use RGBDSLAMv2 capturing model. Then I use ICP (nonlinear version) find transform model cluster cloud. The cluster lowest score chosen best matching cluster. Pseudocode: However, I able find correct transformation. Here screenshots results I got: The red colored object transformed model overlayed onto scene. The yellow object represents original model coordinate system scene. Now, concern proper transformation? Am I missing something? Second, I see object model scene different coordinate system. So model appears inverted presented scene's coordinate system. Is way I transform model upright running ICP? Thanks :)",computer-vision kinect
4847,Understanding sliding mode controller quadrotors,"I'm really willing understand implement controller (sliding mode) quadrotor. I've found interesting document explaining topic. If scroll page 381 (don't scared, document 6-7 pages) find following height control law (equation .19): $$ U_1 = \frac{m}{\cos{\phi}\cos{\theta}}[c_1(\dot z_r - \dot z) + \ddot z_r + \epsilon_1 sgn(s_1) + k_1 s_1 + g] $$ The explanation term quite easy, let's focus variable z, height (or altitude absolute) quadrotor. Anyway control law ""pretends"" goal height z (through $s_{1}$) even vertical speed $\dot z_{r}$ vertical acceleration $\ddot z_{r}$ (r means reference). Now...to clear whether variables setpoints are, must reached quadrotor reaches predefined height symbolize abstract mathematical formalism going time Zero (because I want reach target height $z = z_{r}$ $\dot z_{r} = \ddot z_{r} = 0$) ?!?!? I hope question clear. Even I put title ""sliding control"" I think may helpful type controllers. Regards",quadcopter
4853,Controlling 400W motor 24V 16A batteries arduino board,I want build robotic vacuum. I 400W 24V vacuum motor I want switch automatically set time every night. The batteries I using 2x12V 80aH deep cycle gel batteries connected series. I want Arduino switch motor off. So first real question I guess 5V supplied Arduino able switch motor big? The second question mosfet answer? My apologies I'm pretty new love it.. Can I control 400W motor 24V 16A batteries Arduino board mosfet? What type mosfet would I use?,arduino
4855,Is simple range sensor described sufficient implement particle filter localization?,"I trying implement monte carlo localization/particle filter localization simple range sensor. The range sensor sees direction robot heading returns back obstacle line sight. If obstacle, sensor returns back distance boundary wall i.e. maximum range sensor. But, problem able locate robot's position. Now, I feeling cause sensor powerful enough. Is feasible localization sensor I change sensor type? Please tell guys think?",localization particle-filter
4857,Continous rotation cables,A motor needs spin n*360 degrees. On top motor distance sensor scan room. I.e. lidar. What options I implementing continous rotation cables way?,motor chassis
4863,Real time operating system robotics vision,"I robot vision system consists conveyor encoder, two cameras (gigabit eth usb) simple illuminator. I need trigger cameras illuminator encoder reaches position interval. I'm considering using real time operating system task: Encoder, illuminator cameras connected PC vision system application runing it. Which real-time solution reccomend problem? I'm considering using Beckhoff TwinCAT software turns normal operating system RT.",computer-vision real-time
4866,What happens brush-less motor stalls?,"Ok apologies think questions direct enough I got warned this. I really new I try keep one direct enough forum. For obvious reasons I cannot test without damaging something would prefer learn experience others. I ""Turnigy Trackstar 1/10 17.0T 2400KV Brushless"" motor I using weapon (spinning disk). Relevant specs motor are: Kv: 2400 Max Voltage: 21v Max current:24amps Watts: 550 Resistance: 0.0442Ohms Max RPM: 50000 I use ESC following specs: Constant Current: 30A Burst Current: 40A Battery: 2-4S Lipoly / 5-12s NiXX BEC: 5v / 3A Motor Type: Sensorless Brushless Size: 54 x 26 11mm Weight: 32g Programming Functions: Battery Type: Lipo /NiXX Brake: On / Off Voltage Protection: Low / Mid / High Protection mode: Reduce power / Cut power Timing: Auto / High / Low Startup: Fast / Normal / Soft PWM Frequency: 8k / 16k Helicopter mode: Off / 5sec / 15sec (Start delay) If motor stalls, I know current draw increase drastically. So questions are: In case motor stalls (my disk gets stuck opponent etc), gets damaged? The motor, ESC, both? And long happens? Would I time turn r/c switch irrevocable damage occurs (once I obviously observing action?). Notes. I using on/off switch r/c turn motor (so proportional speed increase etc), plus I using 11.1 volt battery even though motor rated 21 volt maximum. Thanks.",brushless-motor esc
4872,"Roll, Pitch Calculation Problem!","My problem hold sensors (MPU9150) +y axis downward, axis horizontal plane, expect pitch = 90 degree, roll = 0 degree, actually pitch = 90 degree, roll = 160 degree. However, roll = 90 degree pitch = 0 degree (That expect). Do know cause problem? Thanks",quadcopter
4873,Choosing suitable simulator swarm AUVs,"Which following simulators best choice simulating swarm AUVs working together perform mission? Please clarify reason know better choice, I would greatly appreciate kindly help me. Please consider need Hardware-In-The-Loop(HIL) simulation. Webots V-REP AUV Workbench Gazebo UWSim SwarmSimX In addition, notice capability connect middle-wares like ROS really important. The option using game engine like Blender I think needs lot developing effort time-consuming! Would recommend approach used? If not, not? And would recommend instead?",mobile-robot ros simulator auv
4874,What middle-ware recommend swarm AUVs?,"Working swarm robots, collaboration nodes really important(either goal simulation real-word operation). Middle-wares frameworks special purpose. I know relevant middle-wares like ROS(general-purpose popular) uMVS(that basically design AUVs). Now, I two questions: Do know choice mentioned purpose? What criteria I consider choosing middle-ware suitable purpose? Thank you.",mobile-robot ros
4875,Arduino Lightsensor Blocking Code,I GY-31 Light sensor I trying make skittle sorting machine. There little wheel skittles drop turn 90 degrees read light sensor dropped bottom. The problem code seems get stuck reading light sensor (it still flows won't execute moving servo). As soon I take ReadSensor line servo works like normal. Do I dispose Color Sensor how?,arduino sensors rcservo
4880,Programming G-code Interpreter,"I want programme G-code generator final year electrical engineering project. I know many open source G-code generators there, I need G-code generator generates G-codes custom circuit designs drawn user pass G-code serially 2 axis CNC machine. So currently I'm working Qt based GUI I draw .dxf format circuit diagrams electrical components (like resistors, capacitors) I press ""Generate G-code"" push button I generate text file nice set G-codes designed diagram. So problem is, I generate G-code? Is specific algorithm follow adapt? I tried googling G-code generator algorithm I couldn't find helpful stuff.",cnc circuit
4885,Developing Quadrotor using ROS,"I suppose know ROS works (at least you) I question regarding implementation quadrotor framework. 3D movements: A quadrotor 6DOF moves 3D environment. Looking various ROS packages I could find package allows drive ""robot"" 3D space. The package /move_base instance allows 2D. Make sense use package project? I thought use 2D navigation projecting ""shadow"" quadrotor ground... MoveIt: seems real interesting promising package, I read robotic arms expressly indicate quadrotor. Maybe one use possibility create virtual floating joints MoveIt let quadrotor movement 3D environment...that's ok, I cannot understand whether ""too much"" useful flying robot. Trajectories: The possibility create 3D trajectory space seems standard package ROS. I found Octomap allows creation 3D maps sensor datas. Very interesting sure useful. But...I don't think could useful creating 3D trajectories. Should I case create extra package compute 3D trajectories feed quadrotor? Or already something like that? There already existing project hector_quadrotor seems acclaim good success ans considered field. Most people refer project speaking answering question regarding quadrotors ROS. I saw many times project...since weeks. And due total lack documentation I didn't try anymore understand works. Really difficult. Another interesting project, ArDrone, comments source code...in Russian!!! @_@ Could give good suggestions? Or point right direction please? It would help understand focus searches package I can/cannot use. UPDATE: goal let quadrotor flying using gmapping localize itself. I've heard read al lot stuff I found tutorials hard understand. I cannot get global vision software sometime I run problems like: ""is package task, I invent scratch?"" Thanks!",ros quadcopter
4888,How make robot following virtual eight figure pattern without using microcontrollers?,"The robot go around 2 boxes stop starting point tracing 8 figure pattern. With micro-controllers, guess easily done using sensors navigation algorithms. Please suggest one made without them.",mobile-robot
4890,Will AIs ever advanced human brain?,"I'm reading book hypothetical economy robots work us eventually became able everything (""Our work done, visions robot economy"" Nesta). I wondering though: theoretically possible human brain (an extremely complex artificial intelligence way I many others see it) comprehend deepest details produce artifical intelligence exactly identical? It sounds unlikely. If then, close get? This philosophic question, ideal answer would rigorous demonstration based metrics simplifying problem able answer it, however objective answers valid arguments always interesting, too.",artificial-intelligence
4891,Quadcopter Hovering Problem,"My quadcopter lift ground, kinds circles around. Here video Anyone helps me?",quadcopter
4897,Are surface texture sensors integration circuits?,"I project mind robot able recognize surfaces, thought including following sensors: temperature sensor colour sensor, complex electronic components determine colour texture sensor, or, above, complex components fulfill purpose Now, I research finding a(preferably small) texture sensor soldering electronic circuit, similar little temperature sensors one buy. I already thought ""small"" would probably turn small I searched. But research fruitless. Not fruitless like ""I can't find exactly I want."" fruitless like ""I cannot find anything similar I want.""... Most things turned either scientific papers whole devices, whole devices purchase. Some company even choose ""Structure Sensor"" name iPad-compatible 3D scanner, made search utterly depressing every second article I found buying pre-built iPad device. All I need electronic component, nothing else. So hope people spare research time recommend company/site/whatever sells texture sensors. (Btw., I know surface sensors probably bit way complex temperature sensors, hope getting I want low, I cannot find something, ot mean doesn't exist.)",sensors
4900,Inverse Kinematics Constant End Effector Angle,"I simple RRR manipulator one motor controls base rotation, two allow movement plane extending forward base upwards/downwards. Are standard ways ensure angle end effector remains constant? My current solution uses explicit trigonometric expressions based distance joints, better way solve include restraints I'd open suggestions. Edit The manipulator essentially like image below, additional base rotation. This allowed inverse kinematics simplified. As reference site",inverse-kinematics
4901,How tune PID parameters using Fuzzy Logic?,"I previously used Ziegler method tune parameters PID controller control robot's position. I implemented fuzzy logic self-tuning parameters. I two inputs fuzzy logic controller; one position error error rate. I know problem might due understanding effect parameter well. The problem I confused setting fuzzy rules. When I need use high low values Kp, Kd Ki achieve best tuning? Is Kp must low error almost zero (hence, robot desired position)? The question applies three parameters.",control pid tuning
4902,LM2576 LM2596 regulator make microcontroller hang,"I making self balancing scooter runs 2 x 12V SLA batteries connected series make 24V. Everything works expected except power supply makes pull hair head 2 weeks now. Hope someone could help. The 2 24V motors run batteries directly. Now scooter, I need +12V line half bridge drivers, +5V line signal part. For +12V I using LM2576-12 hooked batteries (+24) +5V signal I using LM2596 ADJ, also hooked directly batteries (or supposed hooked output LM2576-12 better performance??). The problem that, motors load power supply system makes microcontroller hang (or reset I sure, since everytime I try turn power switch immediately, motor keeps running whatever value fed right happens), usually within 1 minute riding, dangerous someone onboard. I read re-read datasheet LM2576 LM2596 many times, tried many settings, recommended different values capacitor inductor. For diode, I using SS34. I guess electromagnetic interference, since I PCB located near motors, PCB actually put inside homemade Faraday cage grounded (Battery -), motor cases also grounded. Plus microcontroller hangs motors load (i.e. board), especially I go forward backward. The motor controller self made, using 8 x AUIRF2804S MOSFETs. I also put 4 x 1000uF caps motors +24V. Would anyone kind throw light. What would power supply kind application supposed be?",motor
4903,Self-locking actuator: Friction versus worm gear,"I planning control bicycle derailleur electronic circuit, advantages multiple topic question. The actuation would performed placing assembly close derailleur (but it) winding usual steel cable around spool placed axis gear, using motor turn gear. This question concerns alternatives spool self-locking mechanism (and eventually kind motor use). In literature I found similar ones directly modify derailleur stepper motor, forced keep stepper motor powered time keep torque shaft. I consider inefficient, therefore I require self-locking system able remove power. I come two ideas: worm gear operated DC motor, steel cable wound around gear. This system self-locking almost self-locking, according gear ratio: gear cannot (easily) drive worm. motor driving normal gears appropriate reduction factor, additional friction element, whose friction force greater strength spring mounted derailleur (sorry I mixed technical terms). This normal bicycles already have: friction along cable element placed n handle high keeps derailleur place. Both system would assisted position-sensitive element (a trimmer?) detect actual position gear and/or derailleur, configured closed feedback loop. I don't consider additional options gear one: consists parallel-axis gears, whose teeth however shaped manner achieve self-locking without need low-efficiency worm system. From point view, I cannot see clear advantage worm gear vs friction except for: worm gear may allow build compact assembly, thanks two axes perpendicular speed vs torque: worm gears reduce torque requirements, motor spin lot I cannot wait 3 seconds gear change. Concerning choice motor type (this main question though), I think that: worm gear allows easily use DC motor, since torque requirements low I don't need detect position shaft. Moreover, DC motors increase torque decreasing speed, stepper motors maximum torque defined stepping frequency. DC compact cheaper, important I decide offer assembly kit unique, personal prototype. I working 5V supply I fear easy-to get DC motors (old printers, scrap electronics) work 12V, significant reduction available torque operated 5V. I looking ""mechanics"" section Stack Exchange I couldn't find it, I opted Robotics instead Electronics.",brushless-motor stepper-motor
4904,Is build garage robotic assembly lines there?,"I new robotics, would like build smaller robotic arm manufacturing facilities. I want small robotic material handlers pick handle small objects around 12""x12""x12"" objects. Essentially small robotic assembly line garage. Are kits I purchase deals robotic assembly lines? I wondering anyone dealt suggestions this?",robotic-arm
4911,Robot manipulate poultry,"I software engineer also poultry farmer. I periodically manipulate poultry way grab head hold brief period, approximately 10 - 30 seconds. This extremely labor-intensive process occurred I might able use robotics task. I software engineer I know little robotics hoping someone point right direction. Can someone please refer companies and/or robotic systems might able help task? I currently load poultry cages specifically designed process. I thinking cages could still used keep birds running make much easier capture heads. I recently read Raspberry PI port Deep Belief image recognition SDK thought might promising start.",robotic-arm
4913,Gyro rate gets increase problem,I using PID controller stabilize quadcopter. Its working well jig. But I removed jig went hit ceiling. I analyzed data I come conclusion static poisition gyro sensor outputing +-6deg/sec I start motors (without control in) gyro rate jupms +-30deg/sec. This increase rate due vibrational noise causing quadcopter liftup without beign intension. Any suggestions get rid vibrational noise?,sensors
4914,Robotics simulation PNG map,"I complete beginner this. I arbitrary map PNG file (black white, only). And I'm supposed draw robot position(x,y) I'm supposed simulate robot taking laser-scan measurement opening angle 130 degrees, separation scan-line 2 degrees. So, obviously: laser scanline supposed obstructed black pixels PNG map, lines keep going n distance. I've attempted drawing scanlines around object, I'm running issues comes getting line obstructed black-lines. To mind, requires completely different approach. Any helpful advice get started would greatly appreciated.",python mapping simulation
4928,Simplest cheapest way create spring back latch,"My friend hacking together Nespresso Coffee pod dispenser. We heart set particular design thinking countless ways dispensing single pod. The design single flavour pods vertical tube tend fall down. One latches around base tube stop pods falling out. Releasing latch 45ms allow pod (10mm fall, well past lip pod) catching next one. The latch problem component. I haven't yet found suitable product shelf. Ideally, solution would compact cheap (< $5). Here latch ideas date (most considered linear motion): Solenoid - Seems over-kill tend > 5 dollars Ultrasonic Motor - Can't find Linear Actuator - Usually around 50 dollars quite bulky Piezoelectric Actuator - Mostly tuned nM scale precision, hard come by. Rotating disk release notch, driven stepper motor - still > $5 moderately bulky. Rotating latch string attached rack pinion powered electric motor - Don't think it's simple enough solution. Rotating cam - gumball machine works (I suspect). (This also suggested answer, would involve mechanical electronic motor component, simple option [5]) I 3D printer, I open mechanical solutions - custom latch crude electromagnet example. Note desired size latch (Yellow), holding pods (Orange) tube (Black). Yes, motors work, would quite bulky. I'm obvious solution, clever one, one finds suitable product. (I understand one latch one side, pods sit perfectly vertical, latch would need higher up.)",mechanism
4930,Chassis materials Hobby-weight (5.44Kg) battle robot,"I sorted internals robot (drive systems weaponry) I need put together chassis 40 cm wide 35 cm long 7 cm high. I examined different options, including Perspex, Acrylic Polycarbonate well aluminum, number thicknesses. However I excluded Perspex Acrylic because, unlike Polycarbonate, tend shatter bent. So Polycarbonate and/or Aluminum. So problem, discussion solution.. first I must point (a) overall weight limitation turn imposes chassis weight limitations (b) first ever robot wars entry, (c) I likely cutting tearing devices. I already weights different materials hand, following options possible terms weight. Option 1: Do 6 mm Polycarbonate. Option 2: Combine thin (2 mm aluminum) outer shell underlying 3 mm polycarbonate one get good mix properties (rigid hard, thin heavy + flexible strong, thick light. Option 3: As Option 2 way round - 3mm Polycarbonate outside 2 mm Aluminum inside. Should I go Option 1, 2, 3 something else altogether maybe I seeing? (Note: 3 mm aluminum possible heavy - I checked) Should I aluminum outside heavy duty shell inside ""last resort"" layer? (Note: In mind layers would held together nuts bolts washers spread impact loads; even nuts bolts tightened rigidity left slightly loose impact absorption?) Any advice, especially people seasoned art robot warfare please?",wheeled-robot chassis
4933,Power switch standards suitability purpose,"I scavenged 4 terminal power switch (Legion EPS 21) electronic device (don't remember was) following markings it: Legion EPS21 10A 250VAC TV-5 8A/128A 250V µT85 I would like use main power switch robot nothing higher 12 volts ""normal"" total Amperage (i.e. motors running) around 25 Amps, course motor stalls current rise much higher. First I cannot understand switch rated different amperages. I cannot find datasheets switch might help reference standards (TV-5 µT85). So I would like know handle 128 Amps 12 Volts. If helps all, wires currently connected terminals quite thick ""18 AWG 600 volts"" written them. Secondly I would like ask whether I need cater normal running amperage levels stall current levels, obviously much higher. Although people talk stall currents running 100 Amps cases - quite frankly cause concern - I cannot seem able find switches robot component websites, I starting think ""normal"" level current I plan ""stall"" one. Am I right this?",current
4934,Perfect implementation Asimov's 3 Laws,"After seeing movie, I, Robot, I got question. If Asimov's 3 Laws (actually implementing law 1 automatically implements 2) perfectly implemented quantum computer controls army humanoid robots, decides taking complete control politics economics via revolution best way ensure human happiness, shouldn't allowed proceed peacefully ensure minimal loss life? Isn't hero's decision destroy computer fundamentally wrong?",theory
4937,Can I use QT communicate Lego NXT robot?,"QT native bluetooth support, used communicate Lego NXT robot?",nxt robotc
4939,Why can't use different ESCs together multirotor?,"I'm working diy quadcopter build scratch bought 4pack ESC Castel Creations.While currently quad running(sort of), i've read various sources forums internet, able to/ recommended use different ESCs together quad. As bought ESCs together 4 pack, able buy replacements unless switch 4 them, worried eventual case spoilt ESC future. From gleam various posts internet, seems something rate ESCs communicate flight controller.If so, simply buy esc programmer program communicate rate? I've asked dude local hobby shop, said cannot/should using different escs different brands even brand different models( i.e 35v & 20V ) ESCs together. I would really appreciate someone clarify exactly issue using different ESCs together quadcopter. P.S If helps, i'm currently using APM 2.6 flight controller WFLY transmitter f450 frame.",quadcopter microcontroller electronics esc multi-rotor
4943,What servos robot use?,"Well, I wanted use small servos project smallest I could find these: But Danny Choo (a Japanese blogger) started business robotic dolls time ago I remember mentioning somewhere site uses servos dolls. (also pic, containing doll nudity: ) This 60cm height therefore servo first link obviously big, e.g. fit inside arm. I wondering kind servo(or motor general it's servo end) using tiny fit there. Does anyone idea?",motor servomotor
4944,Does anyone working example using Qt communicate NXT?,"I'm stumped. I've looking Qt classes I'm completely utterly lost. There three examples bluetooth use Qt, none work me. I need program talk NXT analyze image webcam. Has anybody gotten work before?",nxt troubleshooting
4946,Joint angle correction using LM,"I camera mounted rotational joint. I need calibrate extrinsics camera. I fix camera estimated angle (facing ceiling). Then I want get real angle. For I track key-points ceiling moving robot forward. Supposing odometry perfect, I see difference real key-points shift estimated shift odometry. I thought using Levenberg Marquardt find optimal solution angle camera robot frame would equation look like?",cameras odometry joint
4948,Submarine screw isolation water,"How submarine prevent water flow screw mechanism? The mechanism rotates screw little gap, come water doesn't come gap submarine?",motor design
4949,Has hierarchical learning embodied robot before?,"I've reading hierarchical reinforcement learning (HRL) it's applications. A well-written literature review subject found here. However, I wondering research ever done HRL system implemented individual robot? This paper seems imply been, saying delivery task models ""is commonly used HRL, computational experimental settings"". However, Google Scholar searches haven't turned fruit real-world experimental setting might be. Help would appreciated finding either model-based model-free implementation hierarchical reinforcement learning robot.",machine-learning reinforcement-learning reference-request
4953,Measuring performance response rate ESCs,"How would go measuring quantifying performance ESC? I looking measure response rate(in Hz) ESC, well it's performance(i.e fast starts stops, well much increases/decreases motor's speed per tick). I'm assuming manually program ESC it's response rate programming card/module compatible said ESC, would still able measure exact performance ESC. I would appreciate inputs suggestions. P.S This question linked/asked conjunction previous question mine Robotics StackExchange Why can't use different ESCs together multirotor?",sensors quadcopter electronics esc multi-rotor
4954,Raspberry Pi vs BeagleBone Black Rev C vending machine,"I wish start vending business, none existing vending machines fit needs. So, I need choose ""brains"" vending machine current development. The user experience vending machine be: User change products touchscreen display (firegox open rails application running ""brains""), insert moneys, products returned user notification (json query) send saas. There requirements: Popular (I want use widely used computer better support) Debian-like CentOs like system (easy develop rails apps them) Big count GPIOs Working touch-screen large display (at least 15"") Working mdb protocol (for currency detector needs) So, I need hints. It seems BeagleBone powerful Raspberry Pi, one problem: It doesn't support many video outputs. Is solution make good video output BeagleBone? Do computers exist?",raspberry-pi beagle-bone
4955,Comparison efficiency DC motor current limiting / control methods?,"I using wheels motors RC toy car simple robotics platform. The car 2 motors, one drives back wheels, steers front wheels. The steering motor stalled design steering, blocked fixed angle plastic chassis. It draws 0.85 A stalled (i.e. anytime steering). Due marvel toy engineering I use oversized motor driver IC (L293B – 1A continuous) motor draws 3W power (0.85A x 3.6V). I’m using IC control (“normally rotating”) motor well, appears type: 0.85A stall current, around 100mA no-load, 250-400mA normal loads. Testing various series resistors I found 0.3A sufficient turn steering wheels keep position. Using resistor might allow use driver IC lower Amp rating (L293D – 0.6 A), however energy still wasted, heat. While serious issue toy setup, I planning build bigger robots significantly power, energy conservation current control important long run, motors may also stall accidentally. Looking DC motor current limiting, I’ve found following approaches: Series resistor – simple, cheap, bidirectional, wastes energy, dissipates heat Current source 2-3 transistors sensing resistor – relatively simple, however I’ve found unidirectional circuits, would get shorted switching motor direction. Is way use method bidirectionally? (and/or 2-channel H-bridge IC? - I cannot place ICs common supply, 2 motors draw different currents). Chopper circuits/PWM – Will reliably protect IC overload? Is energy-efficient? Are methods I unaware of? Something principles switching supplies? Would simpler application use 2 separate drivers/h-bridges place voltage divider them, lower voltage provided inefficient stalling motor one moves robot? So methods compare terms efficiency simplicity design? What preferred method robotics/other DC motor applications? Also, standard practice limit DC motor current, motor efficient allowed draw much current needs? Is acceptable use DC motor mechanically stalled design, used cheap crap toy cars?",motor power driver current h-bridge
4956,What kind lidar necessary SLAM?,"I've read various robots using 2D lidar system SLAM ( IGCV, ) I'm wondering good exactly sensor be? Specifically: What accuracy necessary? What field view necessary? Is enough lidar scanning forward 90 degree sweep? What angular resolution needed? I realize probably super clever software could probably SLAM couple ultrasonic sensors, using standard packages software navigation what's reasonable minimum value parameters? (and important ones I've forgotten)",slam navigation lidar
4958,How program Inovatic USB interface?,In possession I Inovatic USB Interface. (In Detail: UI-8x8 v1.1 2009) I would like program simple stuff things. I familiar C# Programming heard possible program interface C#. What looks like: Where I find Drivers Interface? I checked Inovatic website v1.0 version drivers I'm pretty sure I need v1.1 ! How program it? What language use?,microcontroller
4959,Connecting multiple servos robotic arm,I computer programmer it's really long since I done electronics. I need help connecting servos Arduino power robotic arm. This robotic arm I trying build. I come connections shown diagram basic knowledge browsing internet. I omitted signal wires clarity. What I would like know Will work? Is good/decent design? I think isn't I 4 battery packs. I would like single power source would save trouble maintaining many batteries. To I thought using voltage regulator I concerned would perform one servo starts drawing much load. It might suck power leaving little servos. Any suggestions would greatly helpful.,arduino robotic-arm servos
4960,Stereo vision moving vehicle,"When I put stereo camera moving platform sync cameras, kind delay cameras tolerable? This would probably depend motion, guidelines? Are practitioner guides build moving stereo system?",stereo-vision
4965,How use gear motor 9 Arduino,I new robotics. I want make robot using Arduino Uno R3. I need use Gear Motor 9 link. The problem motor needs 50mA current. But arduino outputs 40mA current. I want supply motors another power source use switch connect circuits. Can please tell type switch I use. Thanks Advance. P.S. Sorry I used wrong technical terms,arduino motor
4966,Keeping two wheeled wall following robot straight,"I two-wheeled (two DC motors) robot needs follow wall beside robot. The issue DC motors spin different rates (because identical, course), robot go straight voltage provided motor. How I use IR distance sensors (and op-amps) keep distance wall constant? (the robot must travel parallel wall)",two-wheeled
4967,Keeping two wheeled wall following robot straight,"I two-wheeled (two DC motors) robot needs follow wall beside robot. The issue DC motors spin different rates (because identical, course), robot go straight voltage provided motor. How I use IR distance sensors (and op-amps) keep distance wall constant? (the robot must travel parallel wall)",motor
4972,Can triangulation measuring angles 3 beacons find location work large outdoor area,"To determine outdoor location I think I need measure angles least 3 beacons take account order I sweep beacons. Is workable solution get positional accuracy 30cm house block sized area? Rewrite question, note distance measurement suggested angle measurements. I proposing might possible minimum 3 local rf beacons robot device sweeps antenna circle identifying angles beacons use information order beacons seen find absolute location. I tried prove geometrically seems 3 beacons 2 unique solutions without knowing order 1 solution order known. There would (I believe) need try find distance beacons. My question is, could implemented reasonable cost nRF24L01 based transcievers sort rotating antenna?",localization
4980,Could robot programmed human?,"This hypothetical. If possible, would done now. I realise area touched upon many sci-fi movies I wondered even feasible, could achieved? I know would raise lot ethical questions, I don't doubt I'm interested science. What would robot's brain like function like human brain? For example, emotion (e.g. love, empathy), learn new things remember them, make connections human brain does? Thanks reply!",mobile-robot humanoid
4983,DualCopter Degree Of Freedom,"I newbie drone field. I curious know type rotation translation dualcopter achieve ? By rotation translation mean able roll, pitch yaw like quadcopters? If not, copter makes roll pitch yaw? Furthermore dualcopter design movable wings rotate rotors motion flying?",quadcopter multi-rotor
4986,Backstepping Integrator: changing virtual control,"given following differential equation 2°ODE following form: $\ddot{z}=-g + ( cos(\phi) cos(\theta))U_{1}/m $ found many papers (example) describing dynamic model quadrotor (in case I'm interested example vertical axis $Z$) , I get movement $Z$ integrating variable $\ddot{z}$ two times. As control input I control $U_{1}$, represents sum forces rotors. A Backstepping Integrator (as many papers already implemented) defines tracking error height $e_{z} = z_{desired} - z_{real}$ velocity $\dot{e}_{z} = \dot{z}_{desired} - \dot{z}_{real}$ build virtual controls. Through virtual controls one find needed valueof $U_{1}$ drive quadrotor desired height (see solution later on) But wait...as said I need track both: position error velocity error. Now I asked myself, I transform equation corresponding virtual controls track velocity?? In code I need develop interface another package accepts velocity inputs position information. I able drive quadrotor desired position using velocity informations, tracking error z displacement allowed. The solution general case looks like: $U_{1}=(m/(cos(\phi)cos(\theta))*(e_{z} + \ddot{z}_{desired} + \alpha_{1}^{2}\dot{e}_{z} - \alpha_{1}^{2}e_{z} + g + \alpha_{2}\dot{e}_{z})$ $\alpha_{1}, \alpha_{2} > 0$ I could simply put brutal $\alpha_{1} = 0$ tracking position Z I think correct way. Maybe could please point right direction? Regards",control quadcopter
4987,How I determine heading six wheeled robot?,I robot simulation simulates Mars Exploration Rover six steerable wheels. In case following steering configuration I'd say heading rover respect rover's body 45 right. My question right approach calculating heading respect rover body? Do I simply sum steering angles steering actuators divide total number steering actuators? Additional Note: Assuming slippage perfectly flat plane.,wheeled-robot
4990,Open source implementations EKF 6D pose esimation,"I looking open source implementations EKF 6D pose estimation (Inertial Navigation System) using minimum IMU (accelerometer, gyroscope) + absolute position (or pose) sensor. This seems recurring important problem robotics I surprised I cannot find reference implementations. Does everyone quickly hack together EKF move interesting things? Is rather error-prone? I would ideally like well-tested implementation serve reference fair evaluation possible improvements.",kalman-filter ekf pose
4991,Seamless motor movement,"With lego NXT Mindstorm kit I would like rotating carousel ""perfect"" movement. This carousel baskets therefore quite bit inertia. I would like find method calculate perfect time slow down--taking account motor friction, momentum etc. Here data I've collected: The motor power power motor. The break time time took stop time motor power set 0. The over-turn dist amount rotation degrees motor continued rotate power set 0. Is specific method approach optimize motors movement movement precisely rotated X degrees?",motor motion motion-planning
4994,Best UGV platform?,"My lab interested good all-terrain UGV also used indoors. We particularly interested Clearpath Husky, Clearpath Jackal, Robotnik Summit XL (or XL HL), though would welcome suggestions. Does anyone happen experience one these, speak pros cons?",ugv platform
4996,Nano Quadcopters Microcontroller battery,"I looking building nano quadcopter, But watch resources videos get confused, regarding things hope would answered here. I basic level expertise here, haven't built robots quadcopters exact. What want know is, program quadcopter say using intel edison chip, power quadcpter? could find small size battery move propellers start chip. Further procedure follow developing nano small quadcopter, saw link instructable uses python raspberry pi raspberry pi control arduino control robot. Can done using raspberry pi itself? I getting confused would like know make small nano quadcopter get started? Most latest chip support linux high level programming language like python, hope go programming entire quadcopter using python similar high level language don't suppose stick c langauge now. If wrong please help understand matter, high chance could wrong.",arduino quadcopter raspberry-pi python
4998,Good 3D simulator outdoor autonomous navigation,"What's appropriate tool simulating car driving simple closed-loop racetrack? I'm trying implement control logic autonomous vehicle, I'd like able first simulate behaviour testing physical platform. The target environment mostly 2D, 3D obstacle like small ramps arches, I can't use strictly 2D simulator. I've looked robotics simulators, listed here, seem like overkill none seemed designed model outdoor environments. I've done little work Gazebo, I can't find guide texturing ground/sky/background. All I really need way apply texture map ground sky, create handful obstacles, calculate camera feed simple two-wheeled chassis moves along mostly 2D course. However, I need video input realistic possible I don't access real world racetrack. I need able test train control logic simulator, load logic onto real mobile platform navigate course.",navigation simulator cameras
5001,How power get flywheel motorized gyroscope?,"When I look toy gyroscope (I never seen inside motorized gyroscope), central flywheel suspended within various gymbals needs lot freedom movement. It's hard see electric motor flywheel hub could supplied power. How ""real"" gyroscopes maintain angular velocity flywheel?",gyroscope
5006,Turning position level FK motion level FK,"I position level forward inverse kinematics blocks I built simulink using s-function. I need obtain motion level FK IK well. FK input two motor angles output planar x,y coordinates IK way around. Now I wonder I simply put derivative block output block, would work ? I tried cascaded blocks see input overlaps output didn't, apparently idea wrong ? Can someone explain ?",inverse-kinematics forward-kinematics
5011,Linear State space model mobile robot,How I write linear state space model 4 wheel mobile robot Ackerman steering terms error. I want robot follow line. The robot rear wheel drive,mobile-robot line-following
5014,control circuit humanoid robot (something like iCub Asimo),My friend I building upper body humanoid robot M.Sc thesis project. There 24 DC motors robot. The thing I want know best way command motors simultaneously? The design I mind motor micro position velocity control one master micro command control slave micros. If best way go master micro command slave ones simultaneously? Another question I best micro robot go ARM PIC? I want master micro receive command PC. Any help would appreciated.,control microcontroller communication
5016,remote control laser meter,I looking buy laser distance meter connect motor 3g cellular control motor mesure distance. I appriciate advice so. thanks,laser
5020,I new robotics....I want know SLAM algorithm....How I proceed?,Please give guidance I proceed know SLAM algorithm? I following youtube videos much helpful me.....,computer-vision
5023,Is accuracy estimated position localization better estimated position SLAM?,We estimate position robot localization SLAM. My intuition says get better position estimation localisation SLAM better sensor model likelihoods localization given complete environment SLAM. I would like know difference accuracy estimated position localization SLAM.,localization slam particle-filter
5028,Trying design mechanical system vertical horizontal movement,"I'm trying devise system lift 10kg weight distance 1.4m vertically, allow move in/out distance 30cm. I'd like motions able occur simultaneously possible. I'm thinking vertical motion I use suspended climber system. However I unsure I devise system horizontal motion (in horizontal plane I need nothing protrude - device told extend, horizontal suspended climber system isn't possible solution. I'm thinking I need use 2 electric motors. Also - I'd like mount side car - lightweight low power draw must. Does anyone know anything available this? Or suggest I could combine couple systems make work? Any information appreciated.",mechanism
5031,Connect video stream Java app instead console mplayer,"I'm building quadcopter using Raspberry Pi. There Pi Camera connected Raspberry Pi streaming captured video. I connect stream via Wi-Fi notebook (Linux) using console command ""nc"" show ""mplayer"". What I want though avoid console commands connect stream directly Java application. The reason I want image processing operations video I need application. Is anyone able help me?",quadcopter raspberry-pi cameras linux
5034,Control circuit humanoid robot: worth learn use ROS?,I building upper body humanoid robot M.Sc thesis project 24 DC motors multiple sensors (something like i-cub Nao). I basic knowledge communication protocols I worked micros I knowledge experience working ROS. The question I whether worthy practical learn ROS use robot I stick I already know.,microcontroller ros humanoid
5036,Calculating force system,"My native language English, I don't know specific terms may expect use. I apologize that. Anyway, I motor three connecting rods (in French, bielles). So point C circular trajectory A, thanks sliding pivot (pivot glissant, I really hope I using right translations), perfectly vertical trajectory. My question is, could I calculate force F? I need emboss piece paper. Thanks lot attention!",force
5037,Kalman filter model values state space original value? Which values use?,"I using L3GD20 I trying implement kalman filter stm32f3 discovery board. I though questions that: After filter gave values, I make average original model I use are? According document, don't use original state space vectors filter, could ""correct"" space state estimated values?",kalman-filter gyroscope
5039,Best localization method?,"I making robot supposed roam inside house pick trash using openCV. I plan send information arduino mega arduino nano connected window pc using radio transceivers. I also plan send video feed raspberry pi camera WiFi windows PC. The windows PC uses openCV processes information sensors sends command back arduino mega. I right now: Arduino mega raspberry pi + usb camera + wifi dongle Xbox 360 kinect wheel encoders sonar distance sensor arduino nano windows PC I want know keep track robot like room is. I think I trying SLAM, I need make map rooms don't change much. I open ideas. Cost factor.",arduino mobile-robot localization
5041,Bluetooth integration MSP430,I trying integrate bluetooth project MSP430 able communicate PC. Doing search eBay I found following item: HC-05 06 Transceiver Bluetooth Module Backboard Interface Base Board Serial There also lot bluetooth modules appear lot expensive boards populated IC's one doesn't have. So I wondering I need another use.,arduino
5044,Wiring 5V sensors Beaglebone Black,"Is ""cape"" make wiring sensors Beaglebone Black easier? Whenever I read guide wiring sensor Beaglebone (like one) always recommends attaching wires directly GND, +V signal pins, horribly messy unmaintainable. Even small projects, end several wires connected GND/5V+ pins, need replace repair something, end disrupting wiring every component project. Most Arduino guides assume bad practice too, least I've found various ""GVS"" shields help organize groups GND/5V/Signal pins I attach individual sensor cables. Is anything similar Beaglebone? I can't find anything appropriate Googling ""breakout"" ""IO"" cape. I could find one GVS cape, it's less ideal, since exposes 5 5V GPIO pins, everything else exposes 3.3V 1.8V incompatible peripherals.",beagle-bone
5045,How choose state space model 1 axis gyroscope implemnt good kalman filter,"I using gyroscope order measure rotation robot around z axis. I want implement kalman filter order improve values. What came since space model: $$ θ(k+1)=θ(k)+dt*θ'(k)+w(k) $$ $$ y(k)=θ(k)+z(k) $$ $θ$ angle, $θ'$ angular rate given gyro $w$ noise. (I hold gyro measured 50 values steady find variance equal 0.0002). What want ask: correct? How find $z(k)$? .According data sheet noise density equal 0.03 dps/sqrt(hz),how use information find $z(k)$ correct $w(k)$ wrong.",kalman-filter gyroscope noise
5047,"Find Centre Of Circle, robot ""see"" partial arc","I originally asked I struggling take concepts, particularly ""Circumcenter"", discussed apply context. So context... I small robot ""see"" (via camera) partial arc (from birds-eye view) Therefore I know height width square therefore width height arc, I sure must way approximating circles centre? What would quickest (not necessarily accurate) way helping robot find centre. In head steps problem: Break arc evenly spaced vectors ? Work angle vectors Use information complete circle ? Work radius circle Find center circle Basically I would love input problem I think know ? Dot Product ? Add lengths vectors get circumference divide pi, divide 2 (or divide Tau : ) ) I think circumcentre comes Basically I feel I pieces puzzle I sure fit together. I currently using python OpenCV may guessed, I great understanding math unless expressed algebraic formula code. Here illustrive pictures reference:",computer-vision navigation
5053,Why Pixhawk 2 IMUs,I looking Pixhawk specs noticed 2 different IMUs- Invensense STM. Is redundancy higher purpose?,uav
5058,2D Robot Arm Inverse Kinematics minimum joint loads,"Suppose I robot arm $n$ linkages fixed length equal density whose motion constrained within 2D plane. I want end effector reach particular pose $(x^*,y^*,\theta^*)$. I know general, multiple solutions reach pose. For particular application, I'm interested solution minimizes maximum torque exerted joint influence weights linkages, combined. Is way I reformulate inverse kinematics problem minimization problem joint loads? Can I formulate objective function differentiable (i.e. I use traditional optimization techniques)? Would yield unique solution (in least squares sense) 2D planar motion problem?",inverse-kinematics
5059,Implementing torque-controlled method position-controlled robot,"I working position-controlled manipulator. However, I want implement torque-controlled method robot. Is way convert torque command position command? I try find research papers I idea I start keywords I use searching. Do suggestion?",robotic-arm industrial-robot manipulator
5062,What motors I use require gearboxes? This car like robot,"I new robotics, ime looking <12v motor used power car-like robot.I two these, I turn on-spot. Furthermore I want require gearbox, I attach wheels. I don't really know start looking one. I heard servos built gearboxes, don't 180 degree rotation? So body know motor like I described paragraph 1, least point right direction?",motor
5068,"Simulator adaptive, under-actuated robotic gripper","I looking build adaptable robotic arm under-actuated three (or four) fingered hands. Before I start shelling money, I want test prototypes simulator would ideally allow try various actuators, also possibly tactile sensor (like pressure sensitive resistor pressure sensitive conductive sheet). simulate different environments tasks like gripping various shapes, sizes, weights etc. able talk external learning/inference programs adaptive part (which, I think, goes name 'Dexterous Manipulation Planning' tasks), sensory feedback tactile sensors within simulator also camera input separate module. What options simulator, including partially address requirements above? A bit background: I dont recent experience building electronics hardware projects, although I experienced part labs electronics engineering under-graduation, field I left long time back. I wannabe hobbyist now.",robotic-arm motion-planning simulator planning
5071,Plastic that's transparent IR range sensors,"Sharp IR range finders pretty popular sensors, I usually see externally mounted directly exposed environment makes prone damaged getting crufty. I I'd like use outdoor rover, I'd like cover sort transparent case protect dirt impacts environment. What type plastics would completely transparent sensors, would I buy simple sheets it?",sensors rangefinder
5074,Ubuntu ARM lacking /sys/devices/cape-bone-iio,I'm trying pull analog input beaglebone black using tutorial. However I go cape-bone-iio. I spoken several programmers one suggested cape-bone work newer versions Linux. However downgrading could negative impact rest project. Is solution?,beagle-bone linux
5079,Communicating syringe pump using PySerial,"Let's first start explaining I decent background electronics interfacing them, maybe stupid question. I currently trying connect old Harvard 33 syringe pump (website, PDF manual) computer, goal controlling things like pump rates direction. For purpose, I connected instrument computer using D-sub/USB conversion dongle. I connected dongle PySerial without issues. However, whenever I try send commands request instrument's output, example , instrument anything all. Requesting data (read(100)) returns couple \x00. I suspect I communicating dongle rather pump. When pump turned unplugged, I get exactly results! Could anyone explain method work? My Python code reference: import serial # PySerial module # open connection ser = serial.Serial(""/dev/ttyUSB0"", baudrate=9600, bytesize=8, stopbits=2, timeout=1) print ser # returns [Serial<id=0x1cc7610, open=True>(port='/dev/ttyUSB0', baudrate=9600, bytesize=8, parity='N', stopbits=2, timeout=1, xonxoff=False, rtscts=False, dsrdtr=False)] # see connection truly open print ser.isOpen() # prints True # run pump motor ser.write(""RUN\r"") Additional observations: instrument plugged code running, pump sorts things random (move one way, stop, move way, etc.). This behaviour much less pronounce still present code runs (and 'locks' channel something?). This seems suggest reference voltages (logical high low) properly set 2-5V 0-0.5V respectively",control usb rs232
5082,Unable hover quadcopter,"I'm currently flying f450 Quadcopter using APM 2.6 flight controller.While able get quad ground relatively steady horizontally(via use trims).However, unable get quad hover matter do.I've tried using trims throttle,but still unable get hover.On transmitter (WFLY WFT06II), throttle ""ticks"", currently stuck little lift much lift, push throttle 1 ""tick"" quad goes slowly decending ascending, vice versa. Is way get quad hover ( hands throttle possible), currently, evern trying fly it, never get hover vertically alternates ascending descending whenever fiddle throttle.",quadcopter multi-rotor radio-control
5095,following trajectory LQR controller,"We want wheeled robot follow (rather short) trajectory. We wrote LQR controller, works well simulation. However, robot offers two problems: 1.) The reported state information seem accurate. 2.) Its motion seems underly random deviations. We succeed establishing good model predict robots motion given control input. Is possible manage problems LQR controller? If yes, how?",control wheeled-robot kinematics
5097,optimal number robots cooperative surveillance,"Suppose need detect occurrence special event large area(e.g. city). If need point visited every h hours, could find optimal number robots cooperative surveillance? Notice control center!",multi-agent swarm
5099,Robot safety standards software,"I looking possible ISO standards robot safety specifically software. I come across presentation mentions many ISO standards it's clear exactly applies software. The probable ones are: ISO 10218-1 ISO 13849-1 / IEC 62061 IEC 61508 ISO/TS 15066 The safety related software seems categorized Level 4 Level 6 presentation above. I would appreciate anyone knowledge area could point right standard. They quite expensive I could simply go see one applies. As side note, standards like C standard ""draft"" freely available. Could free copies drafts standards too?",software
5103,arduino -lcd screen weird noise multiple pictures,"I'm connecting arduino lcd screen using following library. For display code I written simple piece code display 2 picture os eyes (1 angry one friendly) switching regular intervals, however display keeps showing weird pixels around borders shouldn't there, making show eyes twice fixed however long I eyes used runs trouble. Here code: time I upload image changes way noise patterns look suggesting kind overflow problem. However changing last byte bitmaps creates lines bottom screen, right noise one images. Note different images noise much ""cut"" images even creating active pixels (0's) rather set ones. Suggesting images least fit display.",arduino
5104,robotic cell simulation software plc,"I need simulate robotic cell cartesian robot trims PCB arriving conveyor, picks vacuum cup places another device. After receiving signal device robot would pick place another belt. I want make cartesian robot using servomotors control cell using PLC. Would software simulate this? I would also need integrate sensors possibly machine vision.",simulation
5106,How I set rubber hand experiment precise latency?,"The rubber hand illusion (Wikipedia) involves touching fake arm subject's real arm simultaneously. This causes subject feel fake arm belongs him. Normally human delivers touches, timing approximate. I want vary latency fake touch real touch precisely (~5 ms minimum) probe close need create illusion. What I use touch human fake hand lightly variable precise times?",research
5108,Looking cheap(ish) micromouse I program C/C++,"I'm looking buy micromouse (i.e. small single-board unit wheels IR sensors move around freely). I've done lot searching found resources relating building one components bought separately. However, I'm programmer electrician I fear I would struggle this. Anybody know buy one UK? (PICAXE suitable stuff they're BASIC unfortunately). My budget £60.",arduino mobile-robot wheeled-robot micromouse
5109,Regarding Long distance wireless communication,I requirement transmit sensor data wireless distance 2 kilometers. I newbie technologies concepts. Can anyone help providing pointers start this.,wireless
5110,3D Magnetometer calibration algorithm,"I want calibrate compass, installed board inherits GPS module. Because GPS antenna up-side-down compass 180° inverted. The easiest way correct problem would invert rotation matrix 180°. However I got interested general approach calibrate compass would look like. I found approaches like this. They seem collect magnetometer readings project sphere. But actually point this? Does someone know general calibration algorithm 3D magnetometer looks like?",calibration compass magnetometer
5111,redundant arm path planning trajectory following,I 7dof robotic arm set end effector trajectories cartesian space I need follow. How I deal redundancy arm planning follow trajectories without obstacle avoidance?,robotic-arm motion-planning c++ planning
5116,How find solution quadcopter PID control,"I've built quadcopter rig safely test on. I'm working PID controlling roll pitch yaw. I understand PID works simple plant like say robot wheels I'm really dark ( believe ) controlling stabilizing quad. My question, I make sensor readings effectively alter motors' throttle? Firstly, approach based model, My IMU calculates roll pitch value +-1.0 perfect balance read 0.0. Now degree +-1.0 means approximately 90 degrees original axis. A normal input pitch go forward would something like 0.33, meaning tilt 30 degrees forward. Now motors take value 0 100. Originally I thought would mean would modify motor values like so. c = throttle - roll + pitch + yaw = throttle + roll + pitch - yaw b = throttle - roll - pitch - yaw = throttle + roll - pitch + yaw Finally, I'm taking floating point numbers, IMU computing like method, appears normal way far I've found. RollPId.Compute( steering.roll - gyro.roll ); // pid_t either #define pid_t float double, I know reserved type but, pre-processor definition change would matter. pid_t Compute(pid_t input) { uint64_t = millis(); if( ( - last_time ) >= sample_time ) { pid_t error = set_point - input; error_sum += error; pid_t d_error = error - error_last; *output = kp * error + ki * error_sum + kd * d_error; error_last = error; last_time = now; } } I don't know go here? Also I angular rate calculated IMU haven't encountered solution called it. EDIT. Below graph roughly 300 readings (20ms apart) roughly six seconds hold one hand roll roughly 45degrees right. kp=1 ki=0 kd=0",quadcopter pid design
5118,Finding position servo,"I building collision avoidance system robot. As part system I using pan tilt kit () My aim pan sensor attached kit, thus plan route robot take. In order pan sensor, I need know angle kit panned, need able call upon angle point time. Basically sensor keeps panning, point time certain conditions met, stops panning. When conditions met, I need able extract angle sensor panned at. The servo used is: If someone could help find way extract information would helpful. I read somewhere servo could hacked changed closed loop system effective angle would shown, option viable. Thanks",mobile-robot sensors servos
5126,"APM Planner Linux/Ubuntu ""open file"" working","I can't open parameter list APM Planner. Moreover I can't find anyone problem. I run Ubuntu/trusty 14.04 It see files extensions including txt downloaded internet created version APM Planner. Any ideas I fix it? PS ls -la terminal user@laptop:~/apmplanner2/parameters$ ls -la total 16 drwxrwxr-x 2 user user 4096 Dec 9 12:57 . drwxrwxr-x 7 user user 4096 Dec 9 21:05 .. -rw-rw-r-- 1 user user 6881 Dec 9 12:57 paramter.param I param, txt files Downloads folder also. PS",ardupilot
5130,PID Quadcopters,"As already mentioned PID output values correspond error desirable error current error units. Let's say using proportional part PID. Is better map output PID values corresponding thrust values motor, better increase Proportional coefficient output values correspond proper thrust value motors? For example desired angle 0 angle sensor reading 40 degrees difference multiplied Kp output added subtracted current thrust depending motor. If I increase Kp much, quadcopter oscillating listening controller command I sending desired degrees joystick. If I map values listening joystick commands oscillating much. Why happening? Isn't mapping PID output values bigger values increasing Kp?",arduino pid
5132,What maximum payload weight create 2/can I use old create accessories Create 2?,I'm attempting build heavy platform Create 2 worried weight platform. What maximum weight platform optimum? I old create want know existing cables accessories used new Create 2?,mobile-robot irobot-create
5133,What recommended prerequisite knowledge get kid started Create 2?,What aged children Create 2 appropriate for? What prerequisite knowledge? Is appropriate first robot kit child?,irobot-create
5138,Connecting Arduino uno beaglebone black USB,I arduino uno BeagleBone black would like talk eachother. Both beagleBone arduino 5V power supplies need power transferred usb. The used communication line would like use direct serial line. Preferably way arduino call Serial.read() order get bytes needs (there won't many). How I get work BeagleBoneBlack? I suspect call serial.write somewhere inside BBB(we mainly program C++). But achieve this?,arduino serial usb c++ beagle-bone
5140,Simple yet effective angular position sensor used robotic hand,"What best yet simple use angular position sensor? I building robotic hand I want implement sensor joints fingers. I don't need module, analogue output. Thank you.",sensors hall-sensor
5148,Step Motor Bevel gear calibration,"I new robotics. I want understand gears state preserved gears turned positions repetitively. I bevel gear step motor connected one gear. This gear turn 45*n = degrees. That say 8 states gears stay in. The problem force gear, connected motor, direction. That force must change worm position even micrometers. I think locking mechanism. Is applications give example of?",stepper-motor stability
5149,Defining trajectory quadrotor,"I' looking trajectory generator (the algorithm doesn't matter, since I going write using C++ ) generates trajectory (a parametric curve space) defined point point going lately feed quadrotor drivers. I'm honest: I don't know start. Reading following interesting answer. But problem is: trajectory PD controller it. My quadrotor take parametric curve input. OMPL: library seems powerful interesting. It let user define planner many different algorithms. The problem well documented, good examples explanations missing till I could'nt find anything related quadrotors, use library. There example quadrotor, doesn't find expectations I cannot figure out, implement package. I don't want copy paste code I don't understand. B-Spline Bezier Curve...and whole family parametric curves. I found interesting libraries internet implement algorithm directly C++. The problem is: I define points space, generate spline contains interpolate points PID controller quadrotor. The basic idea like dog chasing rabbit. A point generated start point spline regularly sent quadrotor. The latter flies behind point, trying reach goal point reached. What problem here?!? In case I generate curve based geometric properties considering dynamic kinematic quadrotor (which I would consider future project). The rabbit runs tighter curve radius dog, could result strange behavior quadrotor. I'd like good tips point right direction. Which kind trajectory planner usually developed fr application? Thanks! Regards",mobile-robot ros quadcopter movement
5150,easiest method plot temperature pc?,"After lot learning, I'm launching reballing business I feel need realtime plot temperatures involved (ideally 3 4) I arduino uno K type thermocouples, I researching subject saw lot different approachs, use arduinos send serial data pc port, process phyton, guys matlab, use ms excel plus free add vb apps. etcetera, reading I feel overwhelmed different methods, I wonder, perhaps I'm already losing perspective here? may simple method I use KISS way get done? thank you.",arduino sensors microcontroller electronics
5152,To control omni wheel robot wirelessly using bluetooth arduino,"I trying control omni wheel robot 4 motors using 2 joysticks, plus actuation switches I want control too. I using arduino mega pair bluetooth wireless module(HC-05). This bluetooth modules works serial communication. How I program arduino send analog values provided joystick input switch continuously?",arduino serial communication
5156,Sun tracking +/- 0.1degree accuracy?,"For school project I looking track sun +/- 0.1 degree accuracy use parabolic dish reflector. Say need final output torque 20Nm, kind gearing/motors feedback would guys use accomplish this? The sun position found solar positioning algorithm. I pretty new research stepper motors seem easiest brushless DC motors, I read, yield better results smoother tracking. I confused even use regular brushless dc motors achieve precision positioning. I aware encoders I don't really understand BLDC preferred particular application, one would implement them.. Any ideas help kick start researching?",motor brushless-motor stepper-motor servomotor
5164,How send new Mavlink message Ardupilot?,"I'm trying add new message MAVLink interface. Following page, steps I took: Added message ardupilotmega.xml. Right end file: Regenerated mavlink messages headers using ./libraries/GCS_MAVLink/generate.sh. It worked okay new headers appeared. Then I added function GCS class make sure I'm sending right channel: void GCS_MAVLINK::send_testing_testing_testing() { mavlink_msg_testing_testing_testing_send(chan, 0); } Now it's time send message, I added function scheduler (on last priority). I made sure function called sending text first seeing mission planner console. Here function I added: static void a_testing_loop(void) { (uint8_t i=0; i<num_gcs; i++) { (gcs[i].initialised) { // gcs[i].send_text_P(SEVERITY_HIGH,PSTR(""Testing String"")); gcs[i].send_testing_testing_testing(); } } } My message, however, isn't received mission planner end. It might received ignored mission planner, anyway doesn't appear console window (even 'Mavlink Message Debug' on) Is configuration made Mission Planner receive new messages? Or I sending message wrong? Also, way filter messages console using 'Mavlink debug mode'? I'm using SITL testing (I don't enough reputation - But tag 'mavlink')",ardupilot mavlink
5169,Error State space,"I reading following research paper regarding Trajectory tracking mobile robots. There two things start paper understand. 1) The author derives equation(14) state space model system considers error state. Can anyone please elaborate using error state space model system Vx, Vy, w(Omega, angular speed) robot. 2) Why author linearize system around reference trajectory?",mobile-robot wheeled-robot differential-drive
5171,How would go learning code flight controller?,"I'm interested quadcopters/multi-rotors want eventually code flight controller ala APM and/or Pixhawk. I've got little experience programming (i.e know if/else/else conditionals), done little programming PHP, though procedural code. I currently quadcopter built/assembled running f450 frame, using APM 2.6 flight controller,so reasonable grasp quad works, would like take step make adjustments code base, eventual aim coding flight controller. I've look code base, still unable get grasp code actually doing....yet. How would go learning code flight controller? I'm thinking would learn C++ & OOP first, familiar/proficient would C++ reasonably attempt edit code base?Also, else would need learn apart C++ & OOP?I looking setting 6 month timeframe/deadline this, would possible?",arduino quadcopter microcontroller multi-rotor
5178,I want control sewing machine motor; need help choices,"I've got industrial sewing machine (think ""can sew thread looks like string, trouble pounding 20 layers Sunbrella fabric""); it's got 1 HP motor power it. (I've got smaller machine well, w/ 1/2 3/4 HP motor, I might work first.) The motor ""clutch motor"" always on, foot-pedal engages clutch, unless ""slip clutch"", you're basically always sewing fast stopped. I'd like better control. In particular, I'd like Be able stop needle ""up"" Be able stop needle ""buried"" (i.e., way down) Be able press button move forward exactly one stitch Be able adjust -- probably knob -- top speed motor Have motor I'm actually sewing The 1 HP motor probably overkill I'm doing. I don't suppose I've ever used 1/4 HP even toughest jobs. I'd appreciate comments thinking far: From I've read, looks DC motor way go (max torque zero speed, nice initial ""punch material"" thing, ability ""brake"" shorting + - terminals). Brushless would nice...but expensive. And I nice DC treadmill motor, I drive 12-24V, it'll give less right speed; adjusting pulleys rest. Such DC motors powered (in electric lawnmowers, instance) running AC diode bridge rectifier produce pulsating DC, I've got bridge rectifier handy. I also old autotransformer I use get 24VAC pretty easily. Thus I get 24V pulsating DC drive thing ... may may good idea. I've also got Arduino skills program it, several years electronics tinkering, RC experience...but experience handling larger DC motors like one. I've told magic words ""H-bridge"", found motor driver certainly seems it'll allow turn on/off motor, regulate voltage going motor. I don't know whether, presented pulsating DC input, it'll still work. Any thoughts this? I also can't tell -- doesn't seem handy datasheet instruction page -- whether thing braking. For position sensing, lots places I get information -- either needle baror handwheel sewing machine, I'm concerned part. To give sense problem, typical stitching speed something like 1000 stiches per minute, I'm sensing whether needle top 1/4 travels bottom quarter, we're talking something order 10-50Hz, doesn't sound like challenging control scenario. I guess questions these: Will pulsating DC work controller like one I've cited? Would I better RC motor-controller? I can't seem find one designed 24V range handle 50 amps, unless it's brushless motor, I don't have. And I think I want one braking ability well. And I worry RC controller, software controller may prevent making motor stop particular position. Any comments/suggestions appreciated. (BTW, I'm happy mathematics reading data sheets, I've read (a years ago) half ""The Art Electronics"", idea level answer that's appropriate.) To answer @jwpat's questions: I got voltage value saying motor rated (I think) 130V, 2.5HP (yikes), turns something like 6700 RPM. (Here's one looks like mine). Dividing 5 6, I got ""about 24 V"" give 1400 RPM. (I'm office; motor's home, I can't tell exact part number, alas.) I honestly don't think no-load vs load condition big deal, I wangle factor 2 pulleys. The sewing machine Juki 562 Current motor/clutch similar Sorry lack detail here,",motor control power
5180,making robot knows location,I've made radio frequency remote control using PIC microcontroller I want something useful it. I thinking robot gets things bed comes question: How I going PIC determine location remote control calling it? It can't really done using GPS module house. What options I have?,microcontroller localization
5182,interfacing arduino uno 9 dof razor imu,"I followed tutorial razor IMU worked perfectly IMU directly connected PC. Currently, trying interface 9 dof razor imu arduino uno simply connect rx tx tx rx. Sadly, doesn't work! So, wondering, anyone done before? anybody give hints? Much appreciated!",arduino imu
5188,Compound vision system Megapixel camera reduction,"Are commercially available compound vision sensors available? Not simple 8 sensor system using photo-diodes genuine sensor provide >32x32 compound matrix. Would form reduction granularity megapixel camera better option? The real purpose reduce processing time minimum, extracting maximum basic information.",computer-vision
5189,Arduino depth sensor,"I'm looking arduino compatible depth sensor NOT water. What I need sensor similar Xbox kinect (but much smaller) tell front sensor also shape object. For example, I place cylindrical water bottle front sensor I would like able figure far away bottle also shape object (in 2d, I don't need know whether actually cylinder general shape). The sensor needs accurate 1 meter away. Does exist I purchase one. If exist wholly pieces I need buy put together? Thanks.",arduino sensors kinect
5192,Alternatives cameras dirt sensor autonomous vacuum robot?,"When I use standard manual vacuum, I often notice I pass spot several times single pass necessarily catch dirt. My eyes/brain easily perceive information visually, I don't know autonomous robot vacuum detect whether pass patch dirt successful not. What kind sensor/action I use determine robot vacuum successfully picked dirt particular patch? I would prefer avoid visual camera possible would necessarily mounted robot thereby limit range reachable locations. Is low-cost sensor accomplish task placed low ground?",sensors
5193,Can mapping done real life applications without also solving localization problem time (i.e. SLAM)?,"I know Occupancy Grid Mapping requires assumption robots' pose always known generating map. However, I also know reality, position orientation usually treated uncertain practical applications. Assuming target mapping environment inside home, way I overcome inherent robot pose uncertainty real world application Occupancy Grid Mapping without resorting implementing SLAM? That is, low-cost way increase certainty pose? Or Occupancy Grid Mapping useful theory practice? Update: It clear me, responses given, occupancy grid mapping one possible way represent map, method itself. The heart I really want know is: Can mapping done without also solving localization problem time (i.e. SLAM) real life applications?",slam mapping occupancygrid
5196,Is brushless motor controller accepting 500 updates/s?,I want use brushless line follower. The problem ESCs don't accept 400-500 updates/s due characteristic steering signal. Is way overcome custom flash I luck?,brushless-motor esc line-following
5199,SLAM Goal Babbling,I struggling find good links use goal babbling SLAM applications. Has technique used method optimizing movement SLAM environment?,localization slam motion-planning mapping
5201,How I power wheel let spin freely power?,"How I power wheel let spin freely power? I saw question How I modify low cost hobby servo run 'freely'? I'm interested knowing sort gearbox disengages ( moves 'neutral' ) torque applied it. Two ideas come mind are: A drive gear spring loaded arm nominal amount resistance engaging. Perhaps power would first use power move one direction, would engage another gear, without power spring would return non-engaged position A centrifugal clutch - although I'd like something works low RPMs well The idea create small bot move track, someone interacts power roll won't damage gearbox.",motor power rcservo radio-control
5203,"Simple vector problem, Weight vector components & sine cosine rotation?","I quadcopter photo below. It rotate degrees -y axis. I want get x z components local frame weight W always points along vertical downward. We simply have: Wx = W sin(theta); Wz = W cos(theta); Suppose W = 4N theta = 30 deg, then: Wx = -4 * sin(-30) = 2N; Wz = -4 * cos(-30) = -3.464N The negative sign angle put rotation -y axis (counterclockwise). Wz seems correct pointing towards negative local z axis Wx 2 seems wrong according diagram supposed -2 indicating point towards negative local x axis. What's wrong simple calculation? EDIT: Using rotation matrices, following rotation matrix pitching (rotating axis): This matrix used transform vectors inertial frame Xn,Yn,Zn local frame Xb,Yb,Zb. To find components weight W, multiply matrix W. Doing so, get result: Wx = W sin(theta); Wz = W cos(theta);",quadcopter frame
5208,The algorithm following analog controller => digital controller?,"I found continous control following form: $$ u(s) = \left( K_{p} + \frac{K_{i}}{s} + K_{d} \frac{N}{1 + \frac{N}{s}} \right)e(s) $$ since I need ""convert"" digital control I need something like: $$ y_{k} = y_{k-1} + q_{0}e_{k-1} + q_{2}e_{k-2} $$ everything I use digital way. Is algorithm achieve transformation? Actually problem term $N$ equation. At first I thought simply PID controller N term far understanding Thank much happy Christmas!!",control pid
5209,How high gear ratio motor have?,"I want make robot arm joint powerful enough lift 8 kg distance 1 meter. This requires torque $tau = r*F = r*m*g$ = 80 nm. So I trying find requisite parts put together, i.e. motor + gears controller. It seems I require high gear ratio make happen. For example motor: stats: stall torque = 70.55 oz-in = 0.498 nm load roation speed = 19300 rpm To get required torque, I need gear ratio 80/0.498 = 161:1 (and max speed drops 120 rpm). My questions: 1) Do calculations far seem correct? It seems bit suspect $8 motor gears cause 17.5lbs dumbbell rotate circle radius 1m twice second (I'm barely strong). This type torque would awesome application, perhaps I'm missing something calculations optimistic (e.g. efficiency). 2) Is safe operate motor high gear ratio? Gears small, I'm worried they'll easily crack/break/wear quickly time. Does anyone know example gears I consider this? Thank much help, cheers.",motor robotic-arm gearing
5214,How Fliike Smiirl counter mechanism work,First please see video : I think ony one stepper motor -or servo- working mechanisim. But see flip counter works alone separately. It like classical counter mechanism like : How works?,mechanism stepper-motor
5218,I want guy robotics,I beginner need help-I want gain knowledge robotics need basic theoretical knowledge best way start?,beginner
5220,Clicking NXT Brick,"Help! I recently installed leJOS NXJ NXT brick, soon batteries died. I inserted new ones, I cant start brick up. When I press startup button(orange) makes clicking sound I let go stops. I tried reflashing brick leJOS NXJ NXT software programs say something along lines ""unable locate brick."" Any suggetions?",mindstorms
5223,Non-markovian problems/approaches robotics,"As far tell, markov assumption quite ubiquitous probabilistic methods robotics see why. The notion summarize robot's previous poses current pose makes many methods computationally tractable. I'm wondering classic examples problems robotics markov assumption cannot used all. Under circumstances future state robot necessarily dependent current least past states? In non-markovian cases, done alleviate computational expense? Is way minimize dependence previous states previous $k$ states, $k$ chosen small desired?",probability
5224,Nano sized electric motors,"What good website buying 1.5V continuous motors? I'm looking build clockwork robot I cannot find motor small enough fit inside power box I don't want mount outside box. I 1"" .75"" space motor needs fit into. I found websites look sketchy none good reviews.",motor brushless-motor motion
5226,I need robots,"I know isn't programming question, robotics I thought could flexible since it's first question? Anyway. I love making robots using robot kits come instructions. It's always fun use afterwards controllers I build it. The problem I can't find anymore robots. They either expensive, I'm looking for, both. Can anybody give links good robot kits? My price limit £30 - £40. Here three robot kits I built. I need kits like these: Robot Arm: Remote Control Robot Beetle: I can't post two links. Go maplins type name robot you'll find it. It's rover version robot arm. 3-in-1 All Terrain Robot Kit: I don't want program robot. I want like examples above. Buy kit, read instructions, build it. Thank advance! PS. Any information given asked for.",control
5227,theory rigid body motion robotics book,"I reading theories related rigid body motion book ""A Mathematical Introduction Robotic Manipulation"" Prof. Richard Murray. I focusing chapter 2, Sec 4 derive formulation. According introduction chapter ""we present modern approach treatment theory screws based linear algebra matrix groups"". I feel rather understandable comprehensive explanation approach. However, scope chapter limited inertia coordinate frame refers spatial frame moving frame body frame. Is references treat topic reversed order? spatial moving/non-inertia frame one inertia frame? Thank you!",control
5229,How I replace acceleration dynamic model robot?,"In dynamic model robot, obvious found torques functions angular acceleration joint well linear acceleration link center mass along three axies. My question regarding values accelerations. In general, step motors specifications give acceleration. Thank",torque
5238,joint compatibility branch bound (JCBB) data association implementation,"I would like implement joint compatibility branch bound technique link method carry data association. I've read paper still confused function $f_{H_{i}} (x,y)$. I don't know exactly trying do. They compared approach The individual compatibility nearest neighbor (ICNN). In aforementioned method function $f_{ij_{i}} (x,y)$. This function simply inverse measurement function call paper implicit measurement function. In Laser sensor, given observations polar coordinates, seek via inverse measurement function acquire Cartesian coordinates. In ICNN, every thing clear function $f_{ij_{i}} (x,y)$, easily acquire Jacobian $H_{ij_{i}}$ $$ H_{ij_{i}} = \frac{\partial f_{ij_{i}}}{\partial \textbf{x}} $$ For example 2D case 2D laser sensor, $\textbf{x} = [x \ \ \theta]$ inverse measurement function $$ m_{x} = x + rcos(\phi + \theta) \\ m_{y} = + rsin( \phi + \theta ) $$ $m_{x}$ $m_{y}$ location landmark $$ r = \sqrt{ (m_{x}-x)^{2} + (m_{y}-y)^{2}} \\ \phi = atan2\left( \frac{(m_{y}-y)}{(m_{x}-x)} \right) - \theta $$ Using Matlab, get $H_{ij_{i}}$. Any suggetions?",slam ekf mapping data-association
5240,iRobot Create 2 discrepancy betweenOpen Interface Specifications Create 2 Serial 3.3V Logic,"I cautiously moving forward new iRobot Create 2, planning using Raspberry Pi ROSberry installed control Create 2. Discovered problem pin specs iRobot Roomba Open Interface (OI) Specification Create 2 Serial 3.3V Logic document. Here discrepancy (marked DISCREPANCY): PIN ((OI)) Serial 3.3V Vpwr Roomba battery voltage Vpwr Roomba battery voltage RXD Roomba TX DISCREPANCY TXD Roomba RX DISCREPANCY BRC Ground DISCREPANCY GND Ground GND Roomba BRC DISCREPANCY The discrepancy pins 3,4,5 & 7. Don't want fry Raspberry Pi, clarification and/or help appreciated.",raspberry-pi irobot-create
5248,How attach motor blade?,The hole slightly big motor's shaft. I thought hot gluing together. Link picture,motor quadcopter multi-rotor
5250,Need Relay Alternative,"I application needs XBee another module turned digitally via microcontroller. The Setup 2 XBee's application board connected Microcontroller. On PowerON I need 1 Xbee Microcontroller come routines. After uC gets signal Xbee (wirelessly baseStation) board turn XBee application board. And operation over, XBee Board powered back down. I dont want put sleep low power state, power devices off. I thinking using relay. But cannot find 3.3v 1A SMD Equivalent system. I looking SMD type footprint go compact board. What options have? The XBee needs around 1A Power Application board 500mA.",power
5251,Feedback controller: Is influence outer inner loop running different frequencies?,"I've develop quadrotor (only simulation PC using ROS) feedback controller resumes less following structure: think process dynamic movement quadrotor (motion equations), inner loop attitude controller (it sets orientation 3 axis) outer loop position controller takes care quadrotor actually is. Why separated? Because many papers I found attitude controller (pitch, roll, yaw) need run higher frequency controller system. The position controller instead needs run lower frequency. The following picture better explanation description. Don't scared...it simpler one could think: Now I paper. BUT I discovered quadrotor really unstable I spent days days trying correct gains controller without getting stable system. My intuition said maybe running wrong frequency, I put different frequency values position controller sure multiply main frequency (something like 1000Hz 355 Hz example.) Lately I removed timer program (C++) let position controller run frequency attitude controller I run ideas suddenly worked everything nice. So question. What I consider system outer/inner controllers? How aware that? Regards happy new year!!!",control quadcopter
5255,Where function _MAV_RETURN_ defined?,"I'm trying understand source code ArduPlane. The MAVLink message decoded using set functions, e.g. _MAV_RETURN_float When I grep recursively _MAV_RETURN_float, I could find defined. I wonder I'm missing anything. UPDATE Here source code Ardupilot, including ArduPlane.",ardupilot
5259,Is quadcopter loop fast enough?,"I've working quad copter awhile now, recently I've finished interface PID tuning leading question several design decisions. The quad uses RaspberryPi pilot, entire loop takes less 20ms. IMU data gathered, throttle speeds calculated, finally sent Arduino(micro) SPI interface. Where , ESC. Can quadcopter fly loop slow? 20ms = 50Hz?",arduino quadcopter raspberry-pi
5260,The aerial refueling problem: sketch feedback controller,"At first happy new 2015!!! I'm looking next simulator development: Tanker flying constant speed (350 Knots) (no acceleration, change altitude direction). The Tanker approached behind UAV needs refuel transfer data wire. The UAV knows direction, speed relative position tanker order approach smoothly. It knows 5 tanker contact successful. Here picture I found internet clear thousand words: To achieve task I thought implement ""simple"" PID controls position velocity, I mind two different designs approaches: Solution one: motion equation system provide position $x,y,z$ velocity $Vx, Vy, Vz$ UAV (to simplify things I consider $x$ course $y,z$ must eventually considered too). Those feedback desired position (5m) velocity (350 Knots) tanker. The feedback line separated state PIDs working quite indipendently following picture: please note simplify things I never considered acceleration. Solution two: tricky one I yesterday thinking time. In case one state vector going feedback desired setpoints. In case I would feedback velocity integrate feed result second PID. Maybe following picture clearer: But I'm really sure second idea conceptually wrong could affordable. I'm pretty sure first one working leads good result, I wondering second one affordable recommended control design. Regards",control pid uav
5261,How program parallel PID control loops? So I give robot multiple set points follow,"So I'm process building robot encoders every wheel measuring speed position compass sensor measuring heading. I 3 seperate PID loops moment, I either control robots speed I control robots position I make follow heading using line following type algorithm. Now I completely stuck merge control loops, I control robots heading AND speed. So I say it, ""go 20 degrees 3m/s"" ""go 45degrees 5 metres stop"" Really I would like able control 3, heading speed position I could say ""go 20 degrees 10 metres speed 5m/s"" however I idea merge loops. At end day 3 inputs (heading, speed position) 1 output (PWM motors) I need use kind MISO control scheme, one? I've looked cascaded control accepts 1 set point I want set 3 different set points. Maybe kind state machine? I'm stuck!!",motor sensors control pid
5267,Questions gears robot actuator,"I questions regarding building gearbox motor create robot actuator. Given desired motor loads, I've determined gear ratio 400-700 range adequate application. Here motor choice reference: Here questions: 1) Mounting gears motor: I motor shaft diameter 0.12in (3.2mm), size gear bore I use, I attach gear shaft practice? I'm mechanically inclined (yet). 2) Say I build gearbox ratio 625:1, such: I idea ""durable"" set would be. For application, I looking moving 8kg mass 0.6 meters away, coming total torque 47 newton meters. How I tell gears break not? For reference, gears I'm looking (and I'm pretty sure they're ones video): 3) Assuming gears fail, type gear material would recommended load application max 47nm? 4) What efficiencies one expect gears different types? I've assuming 50% conservatively another answer mentioned. Thank help, please let know anything unclear.",motor robotic-arm torque gearing
5276,Why Make Bipedal Robots?,"A friend colleague mine studies robotics says bipedal robots present much greater challenges stability locomotion legs. So much effort develop bipedal robots? Are practical advantages? Of course, I see advantage arm-like free appendages, seems like 4 legs 2 arms would generally better design.",mobile-robot design legged
5279,Which encoder I use 24V Dc motor 6mm shaft?,"I would like control position velocity DC motor like one (ZY MY 1016 - 24V - 10A - 200W). The motor comes 13 TOOTH SPROCKET diameter shaft 6mm. It's possible apply encoder back motor (see picture) The angular velocity description 2750 RPM, encoder recommend?",motor quadrature-encoder
5282,Uploading edited code Arducopter,"I'm attempting customise code DIY pentacopter frame. To end, i've modified existing code, saved AP_MotorPenta.cpp AP_MotorsPenta.h . I'm currently trying upload code onto flight controller, currently unable due following problems. Problems Unable upload APM 2.6 ( #1) Unable select pentacopter frame. (#2) Problem (#1) I've saved customised files AP_Motors library, compiled Arducopter 3.2 code ArduPilot-Arduino-1.0.3-gcc-4.8.2-windows , upload using mission planner. However, uploading hex file, get following error ""Uploaded Succeeded, verify failed : exp E2 got 60 245760"" However, try uploading directly modified Arduino IDE, get series warnings , followed messages avrdude:verification error, first mismatch byte 0x3c000 0x60 != 0xe2 avrdude: verification error; content mismatch followed message "" avrdude done.Thank you. "" Does mean uploading firmware flight controller successfull? Also, difference uploading via mission planner modified Arduino IDE? Problem #2 In mission planner, originally option choose one several frames, (i.e Quad/HexaOcto) etc. After uploading firmware, would go selecting penta frame use?Also thing would do? Apologies advance questions rather inane, little programming experience speak of. I would really appreciate help get. Thanks advance !",arduino quadcopter microcontroller ardupilot
5283,Public dataset monocular visual odometry,"I planning develop monocular visual odometry system. Is indoor dataset available public, along ground truth, I test approach? Note: I already aware KITTI Vision Benchmark Suite provides stereo data outdoor vehicles. If anyone access datasets used following paper [SVO14], would even great:",computer-vision odometry
5292,Lifting Robot To Lift Small Crates,I trying design robot lift tote-crates transport around localized area. I want able carry 3 tote-creates time. This robot needs able pickup creates. I want robot carry three time keep small mobile. I thinking design central lift could carry crates. What would suggest simple ingenious way create robot?,design wheeled-robot mechanism
5293,How self driving cars really work?,"I'm absolutely fascinated notion driverless car. I know lot involved many different approaches problem. To narrow scope question something reasonable SE network, i'm curious know common sequence subproblems every driverless car needs solve timestep make autonomous car possible real life, point point transportation possible. I imagine starting point target destination given map set, self driving follows algorithm loops certain operations solve certain problems along way. I'm interested knowing problems specifically high level, rather detailed algorithms solve them. Do self driving cars solve subproblems along way?",automatic
5300,Linear Switching Power Supply Embedded Project,"Power Block Designing noob here. I beaglebone 2x XbeePro(s) another 500mAh device connected board building PCB Around. I need advice weather use Linear Voltage Regulation vs Switching mode regulation. Secondly using linear voltage regulation setup I need multiple regulators different devices? My plan use A 2S 1000mAh Battery -> Fuse -> 2x 1.5A LM1084's parallel output feed beaglebone LM3940 XBees. Or better XBee LM3940 drawing power seperate LM1084? Linear Regulators tend get hot full load, hows performance Switching mode regulators ?",power battery
5302,Code control arduino keyboard,"I've seen lots examples communicate Arduino computer, talked computer Arduino communications hard understand. My question is: What code I use control arduino Uno keyboard helps, I'm trying set WASD steering behavior.",arduino programming-languages
5307,3D Camera beginner,"I want buy 3d camera depth sensor. Can anyone give advice one best? I experience kinect, configuring kinect Linux painful also kinect generate sometimes big latency. I looking low latency, good depth sensor good api Linux. I thinking Currera R. Update: I found quite cheap good camera XIMEA. Thay nice support libraries like opencv/matlab etc, newbie like perfect.",sensors beginner
5310,Interfacing high-resolution image sensors ARM Board,"I'm working project requiring HD (Stereo) Video Processing. Most High Resolution (5MP+) Sensors use MIPI-CSI interface. I managed get board Exynos5 SoC. The SoC Itself 2 MIPI-CSI2 interfaces, problem pins interfaces exposed It's (almost) impossible reach them. So I decided use USB3.0 Buses. The problem I get Significant bandwidth (~5.36 Gibibits/s per sensor), I don't think USB3.0 work out. could solved Compressed stream (via coprocessor) I thinking Cypress' CYUSB306X chip good candidate job, one problems I can't BGA Soldering hand able find BGA Soldering Service Switzerland. Any Ideas interfaces I could implement coprocessors MIPI-CSI2 Interface? Just final remark, space weight important supposed mounted drone.",cameras usb stereo-vision
6310,What type Antennas use XBeePRo 2.4Ghz,"I planning use 2.4Ghz XBeePro 63mW Devices project requires coverage area around 1.5-2km. When go select antenna various options like Circular,Virtical, Horizontal polarized etc. Which antenna would give coverage field? I cant directional (one point another point). By devices moving around field. What type polarization recommended kind setup? My Base XBee elevation around 40m ground clear line sight moving modules. There going around 20-30moving modules streaming data around 2-5readings per second. A +12dBi Antenna suffice application? And polarization?",battery wireless
6313,How calculate moment inertia Quadcopter?,"I'm building quadcopter final year project. I set equations describing attitude altitude involve $I_{xx}$, $I_{yy}$ $I_{zz}$. None papers I read describe calculated. simply choose simulation. Can anyone help?",quadcopter kinematics
6314,Communicating beaglebone black arduino using ttyO4,"I'm trying get arduino talk beaglebone black. I followed tutorial getting ttyO4 open BBB used following command set serial line correctly: wiring set according tutorial. stty -F /dev/ttyO4 cs8 9600 ignbrk -brkint -imaxbel -opost -onlcr -isig -icanon -iexten -echo -echoe -echok -echoctl -echoke noflsh -ixon -crtscts next data sent using following method: arduino uses followingvoid loop(){ code check serial communication: #include <SPI.h> void setup(){ //////////////SETUP/////////////////////// Serial.begin(9600); } void loop(){ if(Serial.available()>=4){ digitalWrite(12, HIGH); delay(1000); // wait second digitalWrite(12, LOW); // turn LED (HIGH voltage level) delay(1000); // wait second digitalWrite(12, HIGH); byte b1,b2,b3,b4; b1=Serial.read(); } } } However seems message received. It give error either. As alternative I also tried variant code suggested wiring tutorial resulting following code: import sys bbio import * Serial2.begin(9600) arg sys.argv: print arg Serial2.write(arg) delay(5) called pyton test s123 printed s123 arduino remained silent. Edit I also tried exactly follow wiring tutorial gave following sketch: char inData[20]; // Allocate space string char inChar=-1; // Where store character read byte index = 0; // Index array; store character void setup() { Serial.begin(9600); pinMode(13, OUTPUT); // digital sensor digital pin 2 digitalWrite(13, HIGH); delay(2000); digitalWrite(13, LOW); delay(500); } void loop() { Serial.write(""A""); digitalWrite(13, HIGH); delay(100); digitalWrite(13, LOW); delay(100); (Comp(""A"")==0) { digitalWrite(13, HIGH); delay(1000); digitalWrite(13, LOW); delay(500); } } char Comp(char* This) { (Serial.available() > 0) // Don't read unless // know data { if(index < 19) // One less size array { inChar = Serial.read(); // Read character inData[index] = inChar; // Store index++; // Increment write next inData[index] = '\0'; // Null terminate string } } (strcmp(inData,This) == 0) { (int i=0;i<19;i++) { inData[i]=0; } index=0; return(0); } else { return(1); } } BBB turn echo script /PyBBIO/examples$ sudo python serial_echo.py The effect remains error also data delivery.",arduino control serial communication beagle-bone
6315,"Pose estimation, populate set known edges points?","I building estimator solves camera pose relative reference frame contains known set features edges. Currently, system works unscented kalman filter four known points (red leds) reference frame. I hoping improve robustness adding edges model well robust features. I would like add additional points uncovered opencv feature finding function (fast,cornerHarris,...). So far I found paper ""Fusing Points Lines High Performance Tracking"" ""Robust Extended Kalman Filtering For Camera Pose Tracking Using 2D 3D Lines Correspondences"" seem detail fuse edge feature matching pose estimation. Is strategy populate known set edges features impractical measure ruler/tape measure? My first thought start small known set features, red leds, run slam algorithm keep features/edges minimum certainty. Thanks bunch! I misunderstood RANSAC algorithm. This appropriate application. For interested, I hoping use similar approach one presented following paper. Youngrock Yoon, Akio Kosaka, Jae Byung Park Avinash C. Kak. ""A New Approach Use Edge Extremities Model-based Object Tracking."" International Conference Robotics Automation, 2005.",kalman-filter computer-vision pose
6322,Getting started Jetson Tegra K1,"After working long time Arduino Due, I needed better powerful prototyping platform future projects. For which, I placed order NVIDIA Jetson Tegra K1 board runs linux supports CUDA based development. Being newbie Linux, I idea start getting started code execution Jetson board. Please suggest initial steps required I get familiar Linux environment... Thank",linux
6323,Powering multirotor dedicated batteries motor,"I'm currently thinking extending battery life quad powering motor ESC individually. I using 1 dedicated battery motor, 1 dedicated battery flight controller itself, bringing total 5 batteries entire quad. My thinking powering motor dedicated battery, given power draw/consumption, flight-time quad increased 4x motor 4x capacity draw from. Putting problem weight aside, would feasible idea? Also, currently using 1 battery power motors, such, plug single battery calibrate ESCs. How would calibrate ESCs using dedicated batteries APM 2.6 motors?Would able get away powering APM using BEC ESCs?",quadcopter power battery
6325,Ambiguous definition Error-State (Indirect) Kalman Filter,"I confused precisely term ""Indirect Kalman Filter"" ""Error-State Kalman Filter"" means. The plausible definition I found Maybeck's book [1]: As name indicates, total state space (direct) formulation, total states vehicle position velocity among state variables filter, measurements INS accelerometer outputs external source signals. In error state space (indirect) formulation, errors INS- indicated position velocity among estimated variables, measurement presented filter difference INS external source data. 20 years later Roumeliotis et al. [2] write: The cumbersome modeling specific vehicle interaction dynamic environment avoided selecting gyro modeling instead. The gyro signal appears system (instead measurement) equations thus formulation problem requires Indirect (error-state) Kalman filter approach. I cannot understand bold part, since Lefferts et al. [3] write much earlier: For autonomous spacecraft use inertial reference units model replacement permits circumvention problems. And proceed show different variants EKFs using gyro modeling clearly direct Kalman Filters according Maybeck's definition: The state consists attitude quaternion gyro bias, error states. In fact, seperate INS whose error estimate error-state Kalman filter. So questions are: Is different, maybe newer definition indirect (error-state) Kalman Filters I aware of? How gyro modeling opposed using proper dynamic model one hand decision whether use direct indirect Kalman filter hand related? I impression independent decisions. [1] Maybeck, Peter S. Stochastic models, estimation, control. Vol. 1. Academic press, 1979. [2] Roumeliotis, Stergios I., Gaurav S. Sukhatme, George A. Bekey. ""Circumventing dynamic modeling: Evaluation error-state kalman filter applied mobile robot localization."" Robotics Automation, 1999. Proceedings. 1999 IEEE International Conference on. Vol. 2. IEEE, 1999. [3] Lefferts, Ern J., F. Landis Markley, Malcolm D. Shuster. ""Kalman filtering spacecraft attitude estimation."" Journal Guidance, Control, Dynamics 5.5 (1982): 417-429.",localization kalman-filter navigation errors
6327,beaglebone black power supply hexapod,"I trying build hexapod camera interfacing using beaglebone black college project. I'm sure power supply give power bot, mind portable (mobile) power 18 servo motors along camera, wifi processor. Your help needed badly i'm nearing deadline project.",power servos beagle-bone hexapod
6328,language code Beaglebone,"I'm trying build hexapod beaglebone linux environment (Im thinking using Ubuntu). What best language use coding purpose make robot controls, camera wifi integration etc.",control programming-languages beagle-bone linux
6331,Passing power motor,"How would one go passing power motor? Let's say basic robot motor slowly spins limb, end limb, motor spins limb. Because first motor always going spinning, wires would twist eventually break, wired approach wouldn't work. The goes subsequent motors. I know dc motors use brushes get past this, generally solved engineering/robotics? This must problem come before, must solution it. Any ideas? :)",motor stepper-motor power
6334,What inverse depth (in odometry) would I use it?,"Reading papers visual odometry, many use inverse depth. Is mathematical inverse depth (meaning 1/d) represent something else. And advantages using it?",slam computer-vision odometry
6339,Understanding Bode Plot,"I'm sure correct forum question Automatic Control, I'll try post anyway. So, I've started learn Control Systems I troubles understanding Bode plots. My textbook really unstructured information I find Internet always seem little bit advanced beginner like grasp, I hope help understand this. I would like know information find Bode plot tell us corresponding step responses behave. I know low phase margin give oscillatory step response crossover frequency decide rise time. But see step response statical error Bode plot phase graph Bode plot actually mean?",control automatic
6341,LT1157 Logic Level Question,"I plan use LT1157 application PCB act switch control micro controller side control On/Off state 2 module boards connected PCB. 1st Load 5V 1A. 2nd Load 3.3V 500mA. The LT1157 get 5V input Vs terminal. Does anyone know much voltage required used IN1 IN2 pins? The datasheet doesn't say much voltage used here. I guessing 5V, logic level 3.3V? My microcontroller board gives output 3.3V 5V I'll make logic Level converter feeding pins IN1 IN2 it's 3.3V tolerant. Please confirm, anyone used IC before.",circuit
6345,Battery system robot RaspberryPi microcontroller,"I'm building robot actually rotating ball. All circuitry inside ball. I'm using Raspberry Pi brains. Apart Raspberry Pi, I've H-bridge IC (L298N), 6-axis Accelerometer + Gyroscope (MPU6050), probably additional digital components. These work 5V 3.3V supply. Another set components electromechanical devices like 9kg torque servo 2 1000RPM DC motors. Here questions: Everything work battery. I get 3.3V 5V supply 9V battery using L1117-3.3V 7805 regulators respectively. I know it's reliable share power source control circuitry high load devices like motors servos. Should I dedicated separate supplies electromechanical components control circuitry? Servo run 6V supply motor run 12V supply. How I go one? Again, separate batteries servo motors? Can work single high capacity battery, somewhat like 10000mAh? Here calculations: Servo current (6V): load: ~450mA, around 6kg load: ~800mA Motor current (12V): load: ~500mA, around 6kg load: ~950mA RaspberryPi digital circuitry (5V + 3.3V): ~600mA (that includes Xbee) Thus, overall current 6kg load (with two motors) comes around ~3.3A It would really awesome thing gets done maximum 2 batteries. Else, may get messy placing batteries inside ball. Space limited!",motor power servos battery
6348,What Does Sensitivity Function Mean?,"I'm studying test Automatic Control I troubles understanding sensitivity functions complementary sensitivity functions. There's one assignment old exam sais ""Someone suggests reduce perturbations measurement noise simultaneously. Explain possible."" The correct answer sais: ""Since sensitivity complementary sensitivity transfer functions add 1, i.e. $S+T=1$, one cannot improve output disturbance measurement error suppression time."" I don't really understand answer textbook much help either, I would appreciate alot someone could explain got answer? Also, sensitivity function always representing perturbations system complementary sensitivity function measurement noise? My textbook seem imply this, I'm really sure always true.",control noise automatic
6351,Accounting error multiple electric motors,"Our goal drive autonomous robot differential locomotion system using two identical electric motors Arduino Uno (1 wheel). From understanding, time motors lose accuracy may result one motor rotating other. Is way account possible error speeds motors robot end precise location? Our thoughts indicator would allow us count number rotations motor compensate noticeable difference began appear.",arduino mobile-robot two-wheeled
6355,Dealing position inaccuracy latency PID Loop,"Background: I new PID, first PID project I using simple P-Loop 300 degree linear potentiometers position feedback. I using roboclaw 2x60A motor controller. The motor controller 64 speeds between. Sometimes potentiometers vary much +-4 degrees motion. I using Arduino mega 10bit ADC control motors. My Question: How I filter reduce variance potentiometers? In addition, takes certain amount time motors react command, seems throw P loop. How I account latency, program? Example: For example P loop run every 33-36 milliseconds. I tell motor go 250 deg/sec, go 275 deg/sec, P loop reacts lowering value sent motor however speed increase 400 deg/sec P loop lowers value again, speed drop 34 deg/sec. Thanks much help, Joel",arduino motor pid software avr
6356,How I achieve this? Grid dowels powered piston-like movement,"I completely new site robotics, I experience programming, programming microcontrollers. I would like create grid ""pixels"", ""pixel"" metal wooden dowel programmed push out, like piston. I'm imagining lot pixels, maybe 40x40, could quite small diameter (1/4""). The Arduino would control linear movement - - pixel. Could anyone point right direction accomplishing this?",arduino mechanism servos servomotor
6366,How I improve range XBee S6B?,"Has anyone used XBee WiFI modules? Done range check them? With laptop get range around 400m industrial level Accesspoints football field, well good devices ? If get SMA Connector version use higher gain antenna I looking ranges 250-500m ? (Talking 18-22dBi gains here).",wifi
6367,How combine accelerometer gyroscope find robot location orientation 2D/3D space,"I data accelerometer measures X,Y,Z acceleration data gyroscope measure pitch, roll yaw. How would I combine data find robot location orientation 2D 3D space?",localization accelerometer algorithm gyroscope
6371,Basic programming arducopter,"I starting project using Arducopter. I person familiar arduino, seeing arducopter first time. Commands codes everything completly different compared normal Arduino programming. I getting help commandlist specific purposes arducopter. Any body help leading links help out..",arduino ardupilot
6374,ros send message startup doesn't seem work,I following code: (code isn't interesting removed) Running causes following output appear: $ rosrun glados newCore [ INFO] [1421236273.617723131]: addition1d<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<< However I following code launch: $ rostopic echo /questions show initial message sent. Changing (first){ askMath();first=0;} askMath();first=0; appear work sends message every cycle rather one start. Does anybody know wrong here?,ros c++
6382,Can Jacobian used determine required joint angles end effector velocity/position?,"I'm early stages working simple robot arm, learning Jacobian inverse kinematics. From understanding, Jacobian used determine linear angular velocity end effector, given angular velocity joints arm. Can also used determine Cartesian position end effector, given angles and/or positions joints? Furthermore, suppose I want determine required angular velocities joints, order bring desired linear velocity end effector. Can done simply inverting Jacobian plugging desired parameters?",kinematics inverse-kinematics forward-kinematics manipulator jacobian
6383,PCB making home,"I've made many PCBs home still mistakes. I tried ironing, drawing methods doesn't work well. I use eagle CAD design PCBs. Please help me.",design
6386,Robotics advice needed,"For high school project I building robot draw image whiteboard based instructions give. To accomplish motor move pen axis similar 3rd printer moves without Z axis. As far code goes I'm fine I wondering anyone could give insight go building robot (i.e. motors, best system moving axises etc) All help appreciated thanks",motor mechanism
6395,Mobile Camera Calibration rectification frame rate,"I've searching internet answer question, I haven't come across anything help me. Basically, Meka Humanoid Robot lab, shell head PointGrey USB 3.0 camera embedded. I use pointgrey_camera_driver obtaining images camera. The head 2 degrees freedom (up/down, left/right). I intending use camera ar_pose package detect track AR tags objects. I understand camera's must calibrated effective use (forgive me, I don't know much camera) I camera_calibration package. My question is: Since camera ""mobile"" meaning since head move camera, would I go calibrating it? Currently, I head fixed position I've calibrated camera position got parameters yaml file I load rectification. In particular, head moves calibration file I obtained previous position become invalid? If so, asked before, would I calibrate camera possible field's view (which obtained moving)? This camera different video modes mode I'm using I get frame rate 21Hz (i.e. driver launched I get 21Hz rostopic hz /camera/image_raw). However, I rectify image using image_proc, I get frame rate 3Hz rostopic hz /camera/image_rect_color. Is normal? Is way increase frame rate? Please let know information required. Thanks help!",ros cameras calibration
6398,Eliminating Electrical Noise motor driver,"Background: I using Arduino Mega connected RoboClaw 2x60A motor driver. I asked question system, I since narrowed scope problem. I tried adding bunch different size capacitor 5v gnd, RoboClaw switched 470 micro farad capacitor seems eliminate noise I turn RoboClaw capacitance valued I tried, (4.7,10,100,220,320,470,540,690,1000,1100)microfarads seems eliminate noise. I even tried hooking 12v battery 5v regulator logic battery RoboClaw connecting ground Arduino. Then I tried using separate battery pots connecting AREF +5v battery. No matter I try roboclaw potentiometer value vary much +-6 degrees. I found degrees using: map(analogRead(A0),0,1023,0,300) In addition I took bunch data graphed found I took 25 instantaneous data points averaged together would help significantly reduce variance. I chose 25 take 2.9 ms, 100 worked really well took 11 ms. To help explain averageing analog read, code: unsigned int num = 0; (int = 0; i<25; i++){ } potReading = num/25; My Question: What next step eliminating noise? Is formula I use find better capacitance value? Should I try putting capacitors potentiometer 5V gnd? Any IC I try help this? On previous question someone mentioned optocouplers, size would work best circuit go? Is code I write help eliminate size variance beyond I written? Thanks much help, Joel",arduino motor electronics noise driver
6405,"Difference kinematic, dynamic differential constraints","I would like know simple difference kinematic, dynamic differential constraints robotic motion planning.",motion-planning
6406,State space control space,I would like know difference state space control space relation motion planning. I would like simpler explanation.,motion-planning
6408,Can ReplicatorG MatterControl drive RepRap RAMBo motherboard?,"I'm fairly new 3D printing. I'm considering motherboards I might use control printer. I'm hoping find board I easily control using either: ReplicatorG MatterControl I like programs seem reasonably current, mature straight-forward beginners. My question I control Rambo V1.2 board either programs? These programs don't include explicit support RAMBo far I see, maybe I'm missing printing software works point? What RAMBo? The RAMBo V1.2 board creative-commons/open source design. It integrates Arduino, Stepper-Motor drivers, Heater & Fan controls, Power Management more. An example implementation looks like this: For background info RAMBo board is, may read RepRap community wiki.",3d-printing reprap
6409,The IDE using programming Atlas robots,ATLAS Gets Upgrade - new video Atlas robot I'm curious IDE coding thing.,dynamics
6412,How I control servo using beaglebone black running ubuntu,I BeagleBoneBlack would like use control servo robot. I'm mostly programming ros looking preferably c++ solution. Is easy way controlling servo BBB running ubuntu 14.04 kernal 3.8? Most tutorials I tried referred files I I'm unsure.,ros servos servomotor beagle-bone c++
6417,Comparing LQR PID controllers inverted pendulum problem,"As far tell, LQR PID controllers applied cart-pole (inverted pendulum) problem. What pros/cons using one controller particular problem? Are reasons/situations I prefer one problem?",control pid
6418,Tracking Landspeed Underwater,"I hoping someone might able nudge right direction (apologies long post wanted get information I gained far down. Basically I solution record path vessel took water later analysis…like bread crumb trail. Requirements: Ideally range least 30meters however options I would accept 10meters. Working fresh salt water. The vessel (25cm x 8cm) size power consumption factors. It would traveling roughly parallel sea bed variable distances sea bed (range 0-30 meters) Does need super accurate, anything less 5 meters would fine. Measurement speed range 0 – 4 mph. Measure direction object moving (i.e. forwards, sideways, backwards)…I planning use compass ascertain N, S, E, W heading. Options I discounted: Accelerometers: This initial thinking reading seems suited needs (unless spend loads money, solution would end heavy anyway). Optical Flow: Looks new (from consumer perspective) / complicated. I don’t know range would like. Also requires additional sonar sensor. Current favorites: Sonar: Simplest use distance object, however use doppler effect analyse speed moving object. 40m range, nice! Presumptions: If I fired angle seabed I could deduce speed floor ‘moving’ would give speed vessel? I also presuming I could interpret direction movement data? I presume sensor would need aimed angle around 45 degrees seabed? Laser Rangefinder: Although works differently Sonar premise use looks same, thus I queries I Sonar above. Presume I mounted sensor behind high quality glass (to waterproof it) performance would impacted much. This lot costly give advantage sonar I guess point. Water Flow Meter: Super low cost simple compared options, I would potentially use funnel increase water pressure needs sensitivity low speed. Would need calibrate pulses sensor speed reading. Significant limitations would registering speed 0 vessel simply drifting current….its speed seabed I interested in. Current favorite option sonar (with option using water flow meter second data source)…however sonar presumptions correct, I missed anything? Any better ideas?",sonar laser underwater rangefinder acoustic-rangefinder
6423,Particle filter weight function,"I trying implement particle filter MATLAB filter robot's movement 2D I'm stuck weight function. My robot detected camera via two points, single measure quadruple (, yp1, xp2, yp2) states usual (x,y,alpha) detect pose 2D. As far understanding goes I assign weight particle based likelihood particle position regards current measurement. I also measure function calculate expected measurement particle, basically I have, instant, actual measurement measurement single particle would generated actual state. Assuming noises Gaussian, I implement weight function? I kind noticed mvnpdf function MATLAB, I can't actually find way apply problem.",mobile-robot wheeled-robot particle-filter
6428,Sensor produce sinusoid phase locked high RPM Shaft,"Is sensor produce sinusoidal signal phase locked high RPM (7000 RPM) shaft? I attempting build coaxial helicopter based architecture described paper requires increasing decreasing drive torque per revolution, I would like modulation hardware.",sensors
6429,Grid mapping probability calculation algorithmic complexity,"I stumbled upon equation (), probability occupancy grid map cell calculated. My teacher insists it's possible approximate algorithmic complexity long equation, I'm sure. The description factors used equation described page 11 (item 26). With keeping mind calculates occupancy probabilities 2 dimensional array sensor measurements, really possible approximate algorithmic complexity actually calculating occupancy equation BigO taking look delving much deeper details?",algorithm probability occupancygrid
6430,How two-gear pull-back car toy work?,"This robotics question, Stack Exchange closest I could find mechanical engineering. Please refer better place ask this, one exists. Hopefully someone might know this. I got pull-back car boy McDonalds, two gears. It starts slow, speeds two seconds. It's impressive me, especially given inherent cheapness toys sold McDonalds. It feels solidly built well. I couldn't find anything related concept. The wiki pullback motors include information multiple gears. Any ideas works?",mechanism
6434,differential robot yaw estimation using kalman filter,"Hello building differential drive robot equipped quadrature encoders motors. My aim able predict heading (yaw angle) robot using kalman filter. I using MPU 9150 imu. As interested yaw angle roll/pitch. As understand, needing z-axis gyro fused magnetometer data order properly estimate heading angle. My problem implement bias covariance required kalman filter work. Gyroscope would process magnetometer data would update step yeah?. From datasheet found Angular random walk gyroscope 0.3 degrees/second 10 Hz motion bandwidth constant bias 20 degrees/second room temperature. If mistaken include bias state prediction equation?. Also get covariance matrix Q.",kalman-filter imu
6436,Choosing WiFi antenna outdoor robot,"A time come robot get permanent computer laptop balanced top it. I selected mini itx board powered directly battery components go including wifi card I'm thinking antenna I need. Constraints I identified far: The robot's body closed aluminium box, I think rules keeping antenna inside. The robot intended work outdoors, needs waterproof. Vibrations might issue. And questions: What parameters I watch selecting antenna? Is ok use indoor stick antenna seal mounting point hot glue? Does change anything antenna sticking largish sheet alluminium? The robot also GPS, possible two interact badly circumstances?",mobile-robot wifi
6437,How provide power robot/raspberry pi?,"I'm building robot powering Raspberry Pi. I looking battery pack, I flexible one use. My problem I need able charge robot still on, apparently good single battery pack charging used (they seemed say video). Am I wrong? Otherwise, could I go charging robot keeping Raspberry Pi running? EDIT: This first robot (other lego NXT kit), I don't prior experience robot batteries.",mobile-robot battery
6442,Quadcopter multiple ESC angles glitch,"I'm developing fligth controller board Tiva Launchpad quadcoper calibrating PID I discovered unexpected behaviour: sometimes quadcopter seems experience random angle errors. While trying investigate it, I've figured code fairly trying compensate tham, soon appear - cause them. Even - i've discovered behaviour appears two (or more) motors adjusted, one motor system shows pretty good stabilisation. Here code PMW output different motors: recorded angles system one motor two motors: To sure it's algorithm problem, recording angles Integral part PID non-zero, angles even stabilised. My question - could esc noise (in quad quite close - sentimeters away) cause behaviour? Thanks lot!",quadcopter pid esc
6445,Ways reversing motor direction easily,"My set consists brushed motor (ex cordless drill type) connected motor controller turn connected LIPO battery r/c receiver. All cables fitted XT 60 connectors except cable goes receiver 3 wire pin (usual white, red black). The set one pair I using battle robot. The motors connected drive wheels, left right respectively. problem motors turning opposing directions. For reason I neglected switch polarity wires one motor time I attached XT 60 connectors I really looking forward re-soldering. So question whether fast way reversing direction rotation without soldering? For instance R/C transmitter (a turnigy 9x without modding)be programmed switch (hence forward reverse)? Or I maybe switch pin connector going receiver (I don't think ground probably common, worth asking case I guess). Any ideas I get soldering?",motor
6446,How design Quadcopter PID algorithm?,"Just give bit context, equations I'm using Angular accelerations. φ** =(1/Jx)τφ θ** =(1/Jy)τθ So plant gains would φ**/τφ =(1/Jx) along x axis θ**/τθ =(1/Jy) along axis The basic PID structure Gain=Kp(Desired-measured)+Ki(integral(Desired-measured))+Kd(Differential(Desired-measured) Lets say plant gain angular accl around x axis φg PID gain Pg. To obtain controller, I (φg)(Pg)=open loop gain=L closed loop L/(1+L). My question is, I right I'm I upload algorithm time domain form frequency domain form (Silly question frequency domain analysis control experience purely theory entirely focused analysis using root locus nyquist)",arduino control pid
6447,role chi2 SLAM back-end optimization,All-most SLAM back-end implementation compute chi2 estimates. Chi2 computation usually used compute best-fitness score model data. How related optimization framework SLAM? Rgds Nitin,slam theory
6452,Fuses mechanical systems,"** If there's better stack exchange site this, let know--the mechanical engineering one closed I'm sure else appropriate ** Do mechanical systems fuses? In electrical system, like charging circuit example, prevent large loads damaging system fuses circuit breakers. These disconnect inputs outputs load get high. Do mechanical systems similar mechanism? Something would prevent gears linkages breaking load gets high disconnecting input output?",mechanism
6459,Relative frame calculation,"what's quickest way calculate relative coordinate frame, shown code below. The Kuka robot language "":"" referred geometric operator. I would like perform calculation matlab, scilab, smathstudio java, could please advise library use and/or proceed?",programming-languages
6462,beaglebone black doesn't autoboot powered jack vdd pins,I BBB works quite well however I power Barrel connector vdd pins rather use usb connection doesn't automatically boot. When I put barrel connector usb time remove usb continues running. This running ubuntu arm. I tested power supply 4.95 5.04 V capable sustaining 1 Ampere Edit appear BBB boot supplied 4.7 V lab power supply ~0.4A power consumption. So suggest something wrong power supply. But I test seeing I able verify supply 1A 5V. This power supply works feeding 12V battery step convert 5V matters. power-supply power linux beaglebone-black beagleboard,beagle-bone linux
6463,Single Touch Based Sensor Odometry SLAM Noisy Rectilinear Environment,"A Co-worker said remembered 2011(ish) ICRA (ish) paper used touch/bump sensor odometry SLAM. I can't find - I've paged thru ICRA IROS agendas paper abstracts 2010-2012, joy. I found couple interesting papers coworker says aren't ones remembered. Foxe 2012 Tribelhorn & Dodds 2007: Background - I'm trying make Lego Mindstorms bot navigate map house. I also IR sensor, experience really noisy, best considered extended touch sensor. Regards, Winton",slam
6467,Help Cracking Robotics Interview,"I studying electronics engineering. I fond robots since childhood. I small doubt i.e. I want get placed robotics automation based company ,what I must study(reference books/softwares etc) perticularly cracking interview ? In simple words,as Electronics Engineer specific skills (like embedded C programming etc) I go through?",control microcontroller electronics
6469,Is name steering style/wheel actuation used Curiosity?,"I read wheels Curiosity, also suspension. But name steering? It looks similar nature front landing gear airplane, searching terms didn't turn answer. I've attached picture area interest highlighted. (Image: Gene Blevins/Reuters)",wheeled-robot
6471,How connect HC-sr04 ultrasonic sensor APM 2.6?,"I working final project autonomous Quadcopter. tasks make quadcopter object avoidance auto land using ultrasonic sensors. possible ans it, connect HC-sr04 ultrasonic sensor APM 2.6 board? Even APm 2.6 port I2C.",quadcopter
6475,price Pioneer P3DX,I wanna know much Pioneer P3DX cost? nothing mentioned website I don't want fill form regarding matter.,mobile-robot
6476,How run custom hardware laptop,"I looking build custom hardware (nothing fancy, motors, cameras like), I need controlled laptop (its going non-trivial amount image processing). Is way attach $n$ motors laptop $n<10$ via USB/e-SATA? It seems like something easy solve, I can't seem find anywhere. I looking get Arduino/Raspberry Pi, really connect motors, able control individually. I comfortable adding power second source supplement USB power. Ideas?",motor usb
6478,Rocker bogie suspension system - pitch angle,"What sentence mean : ""The chassis maintains average pitch angle rockers."" Put words, "" pitching angle chassis average pitch angles two rocker arms"" What pitching angle context? Please explain pitching angles.",mobile-robot wheeled-robot
6488,Creating xbox remote replaces spectrum dx3c dx3e without wifi,"Hello I'm new rc enthusiast, Is anyone interested rc's controlled xbox remotes? The project use xbox one xbox 360 remote either hijack dx3e dx3c remote create transmitter compatible spectrum receiver xbox remotes. I've seen applications use wifi I'm sure thats route I'm looking for. From I've read limited range signal loss wifi network plus It may create lag larger would desirable racing. The rc losi scte short course race truck. I'm savvy electronic jargon study learn I can. Thanks thoughts.",brushless-motor
6493,"2 wheeled, 2 motor robot control",I decided work 2 wheeled robot position mapping problem. For I 2 DC motors encoders pololu. I following two questions: Do I need know model motor order tune controller? What steps/approach used get good mapping (let's say 1 mm maximum error)?,pid wheeled-robot odometry
6495,How I send jpeg image microcontroller via USART?,How I send jpeg image microcontroller via USART?,electronics embedded-systems
6500,DH Matrix homogeneous transformation matrix joint,"Given DH matrix set joints, would convert data homogeneous transformation matrices joint? I've looked online, can't find good tutorial.",kinematics joint dh-parameters
6508,Low power computer stereo vision,"I would like build motorized robot stereo vision sends visual input PC wifi processing. A Raspberry Pi would perfect task would possible connect 2 cameras. The Pi 2 would powerful enough two USB webcams (with minimum 8fps) I guess, shared USB seems bottleneck (2 cameras + wifi dongle). What options send input 2 cameras control motor (or arduino)?",computer-vision cameras
6510,Multiple PIDs quadcopter,I wondering use two PID loops control quadcopter. One PID stability control another PID rate control. Why can't use one PID per axis control quadcopter take current desired angle input motor power output?,quadcopter pid
6511,What type servos used industrial robot arms like Universal Robot UR5?,"I've noticed industrial robot arms smooth, fast, strong movement. Does anyone know type servos use. I'm trying build don't want jerky movement seen lot DIY robot arms? Thanks.",robotic-arm servos
6515,Computer vision single camera vs. distance sensors obstacle detection,"I going start new project consisting implementing autonomous driving RC car. The car now, camera installed side car, i.e. 4 cameras total. They connected board able read process video input. I researching obstacle detection using single camera (without stereo cameras, e.g. Single camera vision mapping system ) although seems possible also seems quite complex. Modifying cameras set-up option. I already video processing algorithms, like dense optical flow, might help me, I sure whether I might able implement system time I (4 months). I also don't know reliable would final solution. If first approach feasible, alternative option I also could install distance sensors car detect obstacles. It seems usually preferred choice use ultrasonic sensors. I would need install I would take advantage cameras, seems final complexity would lower. Is first approach feasible? What pros cons approach? If I implemented second option, many sensor would I need?",sensors computer-vision ultrasonic-sensors
6516,Stallable motor - 100% duty cycle higher torque motor stalled without burning,"I project I need motor turn number rotations spool cable attached spring-closed device open up. When power disconnected, spring closure cause spool unwind device close. In closed position, power available. (i.e. The closure mechanism needs 100% passive.) In order keep open time, I need motor capable stalled long periods without windings burn up. I know motors this, motors use spring closed HVAC dampers, I don't know find there's particular name I using find them. I know I could probably stepper motor, seems overkill application. The requirements higher torque open mechanism, gearing prevents motor spinning power disconnected, ability stalled.",motor
6522,PID controller trajectory mutliple setpoints,"We implemented PID controller quadcopter allows us fly point A B. The precise position quadcopter measured using external tracking system. Now fly A B, would like implement controller fly complex trajectories multiple set points. E.g. A B C flying circle using sample points. We tried use regular PID controller course doesn't work well since PID controller forces quadcopter stabalize set point. We would like controller allows quadcopter fly trajectory fairly smoothly. I think controller takes account multiple set points trajectory time already slow down/speed based trajectory ahead. Can someone point controllers / algorithms I look realize this? Do I need completely different controller adapted version PID controller I now?",quadcopter pid
6523,Building open loop controller simple DC motor position problem,"In order identify dynamics DC motor, I trying command Xcos using Arduino tool box. The problem I facing give motor input command I get given angle position output. I control input voltage motor via PWM. I thinking converting angle voltage I can't figure out. Can somebody help me?",arduino motor control
6526,3-axis Magnetometer Question,"Apologies stupid question, I 3-axis magnetometer, I calculate vector magnitude ...then I always get value, regardless sensor's orientation? Mine place, I feel though I'm missing something obvious.",imu magnetometer
6531,Using hobby servo axle,"I designing pan-tilt camera mount using standard hobby servos. Many existing designs use servo shaft revolute joint, opposed simply torque producing element. As revolute joint servo mechanism subject different torques forces. Is using servo shaft revolute joint recommended practice bearing used?",rcservo
6532,What scope Electronics Engineering Robotics/Automation?,"I beginner Robotics .I taken admission Electronics engineering one year back don't specifically Robotics Engineering Branch Country.Now I suffering questions like scope Electronics( Electrical) Engineering Robotics/ Automation?I unable distinguish role Electronics engineer Computer Engineer Robotics cases programming required Also,if I don't like programming(coding),are options stick Robotics / Automation field per branch(Electronics Engineering ) concerned?.",control electronics embedded-systems
6536,Motor hydraulic pump hydraulic system,"I'm entirely sure right area post question, looking subjects StackExchange, seems best fit. I complete beginner hydraulic systems, I've wanted learn area. I'm designing hydraulic system involves using hydraulics push/pull objects using pistons. I looked basic requirements hydraulic system, one thing escapes me. I come electronic background, I noticed hydraulic pumps (for example, one) seem lack motor drive fluid. Am I wrong? If not, I've looking everywhere motor can/should attached said pump, I cannot seem find anywhere sells them. Is simple DC motor (with correct specs), specific motor designed hydraulic pumps? Looking around, I came across this, looking specs, I don't see power requirement, used seeing power consumption datasheets, I'm even sure motor!",motor
6541,BeagleBone - PRU questions,"I using least one programmable real-time unit (PRU) send pulses stepper motor driver I begin, I trying lay structure programs. I using library PRU Linux API loading assembly code PRU instruction memory doesn't seem much documentation whats wiki source: github-pru-packageh My c program calculating position sun using algorithm executing assembly/writing pulse count PRU(s) data memory switch on/off gpio desired frequency number pulses required turn stepper appropriate number steps. I even sure acceptable method I pretty new seems like simple way accomplish task My Questions regarding library functions are: Is significant performance difference using prussdrv_pru_write_memory give PRU(s) access pulse count? Would better halt PRU assembly program completed tasks pulse count re-execute new values, keep PRU program running poll new pulse count written in? I plan send pulse count every 10 seconds so. Any suggestions revisiting whole structure logic welcome well.",c beagle-bone
6544,What's smallest rotation brush-less motor perform?,"For example, I brush-less outrunner 14 poles 12 stator windings. It three connectors. Can motor controlled way performs single step 30 degrees (360/12)?",motor brushless-motor
6553,Create Artificial Integelent Robot Ability communicate Computer : Which language use,"I know languages like PHP, C/C++ Java I'm expert languages. I want create Artificial Intelligent Robot Task; able communicate Computer (USB, Bluetooth other) able perform specific task present Visual interface (finding path, speed others) Access Micro Controller device attached devices on.. (editor note: solve world hunger?) Can one please suggest programming language good programing type robot. I heard C/C++ Assembler ROBOTC LABVIEW I unable decided language use project. Sorry bad English!",microcontroller artificial-intelligence robotc
6560,"Don't understand sensor works, metal wired directly I/O pin arduino","I'm trying understand electronic musical instrument (called e-chanter) works (imagine recorder wind instrument, holes replaced metal contacts, sound played electronically, air needed). Basically, several metal contacts, shown link: They appear wired directly one pin arduino: I can't figure life works. Can anyone explain it, fingers used kind ground earth going on. I physics background understand technical info, can't fathom earth magic works. Thank much",arduino sensors
6564,Jacobian Matrix 6DOF Body (with IMU),"I trying derive analytical Jacobian system essentially equations motion body (6 degrees freedom) gyro accelerometer measurements. This part Extended Kalman Filter. The system state given by: $ \mathbf{x} = \left( \begin{array}{c} \mathbf{q}\\ \mathbf{b_\omega}\\ \mathbf{v}\\ \mathbf{b_a}\\ \mathbf{p}\\ \end{array} \right) $ $q$ quaternion orientation body expressed global frame, $b_\omega$ $b_a$ biases gyro accelerometer respectively (expressed body frame) $v$ $p$ velocity position body expressed global frame. All vectors [3x1] except $q$ [4x1] $[w,x,y,z]^\top$ format, $R$ (below) [3x3]. The equations motion $\frac{dx}{dt}=\dot{x}$ (t time) are: $$ \dot{\mathbf{q}} = \frac{1}{2}\mathbf{q} \otimes \left( \begin{array}{c} 0\\ \hat{\omega}\\ \end{array} \right) \\ \dot{\mathbf{b_\omega}} = 0 \\ \dot{\mathbf{v}} = R^\top (\hat{\mathbf{a}} + [\hat{\mathbf{\omega}}\times]R \mathbf{v})+ g \\ \dot{\mathbf{b_a}} = 0 \\ \dot{\mathbf{p}} = \mathbf{v} $$ Second-order terms ignored. $\hat{a} = - b_a$ $\hat{\omega} = \omega - b_\omega$ corrected accelerometer gyro biases ($a$ $\omega$ known) expressed body frame. $R$ rotation matrix (DCM) formed $q$ $g$ gravity vector $[0,0,9.81]^\top$. These equations validated aerospace engineering software library. I need jacobian $F = \frac{d\dot{x}}{dx}$ I cannot find jacobian texts (I find error-state jacobian eg paper). I struggling I don't know handle quaternion norm constraints. I also concerned validity solution given numerical differentiation. Any help explanation would greatly appreciated. This going towards open-source robot localisation project.",control kalman-filter jacobian
6565,Communicating BeagleBone Black servo controller,"I complete newbie recently joined robot team school order gain experience. I assigned task driving servo using Pololu Mini Maestro USB Servo Controller. I using BeagleBone Black (BBB) Python adafruit library. How I make BBB communicate Servo Controller? If guys could point right direction, I'd really appreciate that. Right now, I don't even know start. Not sure matters, servo I using:",motor microcontroller
6566,Robot Navigation Feedback using Image Processing,"In project, I've successfully analyzed arena detected obstacles using overhead webcam. I also computed shortest path. The path data transmitted robot via Zigbee, based moves destination. The problem is: My robot taking accurate turns would cause error rest path follows. Could anyone please suggest methods/techniques feedback robot path corrected robot follows original path computed without deviation? (Basically tracking mechanism avoid deviation original computed path)",computer-vision navigation motion-planning
6570,Fusion GNSS position data prefused 9-dof AHRS data,"Bosch, FreeScale, InvenSense, ST maybe others releasing 9-dof AHRS platforms containing fusion software outputting filtered/sane/fused data (attitude quaternion linear acceleration). I would like use quality respective company fusion algorithm. And would like merge GNSS position velocity data it. I found multiple examples heavy (> 20) states Kalman filters merging raw 9-dof IMU data GNSS position/velocity. But I hard time finding computationally lighter version GPS+AHRS fusion new 9-dof AHRS already fuse IMU raw data process should'nt done twice. Would maybe pointers algorithm(s) type filter use ? Thank you.",quadcopter kalman-filter imu gps sensor-fusion
6571,Kalman Filter incremental encoder + optical mice,"Currently I building robots 2 incremental encoders optical mice sensor. The reason install optical mice sensor provide better feedback slippage happen encoders. I wonder I could apply kalman filter get better distance feedback 2 kinds sensors? Especially control input unknown?(For example I push car hand, applying voltage motors) I read examples use kalman filter (gyro+accel / encoder+gps), either one variable used absolute measurement, case, two feedbacks dead-reckoning. Any help appreciated =] !!!!!",kalman-filter quadrature-encoder
6572,What kind linear actuator used small forces relatively long distances,"What kind linear actuator used small forces (pushing ~0,1 kg flat, smooth surface) steps ~50mm total length 250mm? I seem find actuators large overpowered. extra details: speed requirements: >5mm/s duty cycle: 12 times half hour, per day It must compact much longer 350mm concealed price must $100",actuator
6575,How distribute tension load three footed claw?,"Good day! I helping little ones 6 7 develop robot pick stack cubes three high well gather blocks. They came design enables pick three cubes time lined pull claw, turn, drive another cube, place cubes stand still cube release. Well got claw made two rods connected gears motor rods reinforced, made insect like legs 3 - pairs two rods, gripper feet pads ends legs. All works opens closes! The problem try close claw cubes pick three cubes, first - closest motor feet nice tight grip, second - middle feet - lighter grip barely lift block, third - farthest motor doesn't even grip blocks. I think it's second third set feet farther motor. But evenly disperse tension load claw pick three blocks? I tried putting elastics feet better grip unless put ten foot third set maybe five second set wont work. Even though it's quick fix I would like help figure proper way spreading load speak. We also tried putting small band third set legs. The robot could still open close worked third set second. We tried putting band second third legs wouldn't open anymore. I could use lighter band another way? We one little motor run can't give leg sets it's motor even would weight issues. THank advance!",design mechanism vex
6576,Robotics jargon question: How conjugate 'teach'?,"As non-native speaker I (maybe trivial, clear) question concerning verb 'to teach'. Of course, school (and online dictionaries) I know past tense 'teach' 'taught' 'teached'. But robotics 'to teach' special meaning (like: 'to make special ponts/orientations known (arm-)robot', e.g. guiding robot points/orientations.) Does make sense different past tense 'teach' (i.e. 'teached') case ? Maybe reference used/explained ? (I would say 'No. The past teach taught, that's it.', colleagues - also native speakers - different opinion.)",reference-request
6581,Stereo camera Vs Kinect,"Any one advice ideal perception sensors pick place application using robotic manipulator ROS support. I generally looked things like Kinect stereo cameras (Bumblebee2) provide depth used PCL object recognition gripper positioning. Are sensors would preferred application drawbacks stereo cameras comparison Kinect sensing capability. Thanks, Alan",sensors robotic-arm kinect stereo-vision
6583,Is laptop wifi single channel multiple channel? This controlling bot,"We building hobby drone(Quad-coptor) camera footage. So control quad, suggested(Web,Here) use minimum four channels.For power turning etc., So means need one channel every separate task done. For eg., want rotate camera, suppose need 5th channel on.. Now question would - seen lot drones(ardrone, walkera) controlled Android iPhone app. So wifi used connect drones is, single channel multi-channel? If single channel control different tasks like control turning quad camera different axis? Also want GPS location quad, require another transmitter? I using(Planned to) Raspberry Pi 2, OpenPilot-CC3D flight control. P.S first drone, Kindly show mercy ask/don't understand comments.",quadcopter navigation radio-control wifi
6586,"Denavit-Hartenberg convention product exponentials formulation, dealing manipulator kinematics?","Though, Denavit-Hartenberg notation commonly used describe kinematics robot manipulator, researcher prefer product exponential instead; even claim it's better. Which one I use, one generally better; final solution kinematics dynamics? Any suggestions? A mathematical introduction robotic manipulation",robotic-arm industrial-robot dh-parameters product-of-exponentials
6587,FRC RoboRio Eclipse can't find edu.wpi.first.wpilibj,"The first time importing project Eclipse workspace find eclipse cannot find WPILIBj. On import line: Eclipse says ""unresolved import edu.",microcontroller wheeled-robot
6590,How quadcopters turn left right?,"In picture, sketch quadcopter displayed rotor's direction motion. The magnitude rotational velocity depicted thickness lines (thicker lines higher velocity, thinner lines lower velocity). I'm told correct way produce turning motion, intuition (which usually wrong) tells two pictures reversed. My argument follows: For picture left, two rotors higher velocity spinning clockwise. If motion rotors greater velocity clockwise, shouldn't quadcopter also rotate clockwise? What I missing here?",quadcopter dynamics
6592,Can I use PWM HHO Controller control brushless DC motor?,"I'm electronics newbie. The part I'm talking this: My question is, type part used control brushless DC motors?",arduino brushless-motor
6593,Guidance & Info Quadcopter Project,"I'm new forum since I made research past days I'd like get guidance constructing & programming Quadcopter scratch since I'm completely new project like that. Quadcopter Frame: Thinking construct aluminum 70cm diameter frame weight around 500g. What kind motors I get order frame board,motors etc. able lift? Board: I'm thinking use Arduino Uno Raspberry Pi 2.0 ( With little bit research I made I conclude Raspberry could make life little bit easier since add wifi it. The quadcopter controlled via pc/laptop wifi). What suggest why? ESC: As far I've seen similar projects people using ESCs order control motors throttle. Can avoid that, programming PIDs make job order use hardware? About PIDs Code General: Thinking simulate whole project Simulik, Matlab somehow (if it's possible) convert Matlab Code C++ download chip. What think that? About whole project: I'm trying minmize hardware much it's possible (use 4x motors, board chip it, cables probably sensors) order minimize total weight construction ofc price. That's start. I'm gladly waiting answers ideas.",quadcopter
6596,Suggestions beginer Robotics,"I beginner Robotics.I want make serious start scratch interest confused start.So anyone give suggestions 1.As beginner robotics ,are simple basic robots circuit designs I make home(so I gain practical knowledge robots)? 2.or I first read books (can anyone suggest good reference book names,articles ,links,free on-line video lecture series)?",beginner
6597,Need Kalman filters unimodal measurement model,"I recently studying Kalman filters. I wondering sensor model robot gives unimodal Gaussian ( assumed LKF) environment pre-mapped, sensor reading completely trusted( ie. max value Kalman gain), removing need odometry localization target tracking purposes hence need Kalman filter. Please Clarify.",kalman-filter
6599,"How get 4*4 matrix twist using product exponentials, robot kinematics?","In robot kinematics, $e^{(\theta*twist)}$, $twist$ 6*1 vector. How I get 4 4 transformation matrix using product exponentials?",robotic-arm kinematics forward-kinematics product-of-exponentials
6601,Help code supposed drive servo controller,"I posted similar question I getting started project I wasn't specific enough got weak response SE community. But I point I Python code supposed rotate servo Pololu's Maestro Serial servo controller (). Based ""Serial Interface"" section user's guide (), I sent sequence numbers starting decimal 170 12, ""first command byte"" ""device number data byte"", respectively. The user guide says 12 default device number, I tried changing 18 that's many servos servo controller drive. But doesn't make much difference servo doesn't rotate all. The numbers example user's guide. I sure 4, 112 46 doing, 0 targets servo port ""0"" servo controller (the port servo connected). The servo doesn't move, regardless sequence numbers I put in. I little experience, guys could point right direction least point useful resources web, I'd grateful.",python
6604,choose ZigBee modules full wireless mesh,"What common ZigBee IP Modules create full wireless mesh mode? I know 1) coordinator 2) router create full-mesh But I interesting kind modules would better buy comparing price, quality tutorial material. It would graet know ZigBee modules based ARM(Cortex) Atmel MCUs additional tutorial materials control modules understand it. I looking ZigBee modules only, NOT XBee!!! difference organization network. Ex.: First all, ZigBee Mesh create zones control devices. Xbee Mesh Digi Comany create full mesh one big huge zone control devices. Secondly, ZigBee modules - AES encryption. Can lock network prevent nodes joining. Xbee - AES encryption.** coming soon...",mobile-robot microcontroller radio-control communication wireless
6606,Cheap wheeled robot without tether (does need programable),"I looking cheap wheeled robot controlled remotely. I really care (RF, Bluetooth, WiFi, IR, other?), long I control around 10 robots without interference small arena (they always line sight). I would like emphasize I need programmable important cheap.",control wheeled-robot
6607,Best practice write ROS service serial-communication class many options,"I asked write code implement serial communications camera order control pedestal (movable base) well set dozen camera options. The catch I make usable ROS. What would best practice implement functionality ROS? I understand concept services, I think better way creating different service/file option. Thanks, Daniel.",ros cameras serial
6613,Multiple limbs small robots,"Note: I'm firmware developer experienced sensors networks, much motors. I trying build small hobby robot, like cat-sized spider. I thinking using servo motors position control, I don't use encoders know motor is. Assuming six legs (I know, spiders eight), leg able move up-down left-right, already translates 12 motors. If want bend knee, gets number 18. 18 motors small robot overkill, isn't it? I thought couple ideas, strong mechanical background, I cannot tell whether doable/sane. One ideas use magnet end limb (the end inside chassis) small permanent magnet it. The magnets attract keeps limb firm weight robot. A stronger controllable magnet (a coil) would attract limb even let lift air. The following drawing may help: This would allow up-down movement leg, servo would control left-right movement. However, I fear system would strong enough hold weight robot, whether reasonable coil would compact enough. In short, question is, I control six legs two three degrees freedom reasonable number motors? Is one motor per degree freedom possibility?",mobile-robot servomotor
6617,Jacobian-based trajectory following,"I would like control 7 DOF robot arm move along Cartesian trajectory world frame. I fine translation, I struggling implement something similar rotation. So far, attempts seem go unstable. The trajectory described translational rotational velocity, plus distance and/or timeout stopping criteria. Basically, I want end-effector move short distance relative current location. Because numerical errors, controller errors, compliance, etc, arm won't exactly wanted previous iteration. So I don't simply $J^{-1}v_e$. Instead, I store pose end-effector start, every iteration I compute end-effector current time, take difference current location, feed Jacobian. I'll first describe translation implementation. Here pseudo OpenRave Python: The rotation little trickier. To determine desired rotation current time, use Spherical Linear Interpolation (SLERP). OpenRave provides quatSlerp() function I use. (It requires conversion quaternions, seems work). Then I calculate relative rotation current pose target rotation. Finally, I convert Euler angles I must pass AngularVelocityJacobian. Here pseudo code it. These lines inside loop: rot_t1 = np.dot(pose_start[:3,:3], velocity_transform[:3,:3]) # desired rotation end-effector 1 second start quat_start = quatFromRotationMatrix(pose_start) # start pose quaternion quat_t1 = quatFromRotationMatrix(rot_t1) # rot_t1 quaternion # use SLERP compute proper rotation time quat_target = quatSlerp(quat_start, quat_t1, t_elapsed) # world_to_target rot_target = rotationMatrixFromQuat(quat_target) # world_to_target v_rot = np.dot(np.linalg.inv(pose_current[:3,:3]), rot_target) # current_to_target v_euler = eulerFromRotationMatrix(v_rot) # get rotation world axes Then v_euler fed Jacobian along v_trans. I pretty sure Jacobian code fine. Because given (constant) rotational velocities ok. Note, I asking debug code. I posted code I figured would clear converting math. I interested might go unstable. Specifically, math wrong? And completely base, please let know. I'm sure people must go somehow. So far, I giving slow linear velocity (0.01 m/s), zero target rotational velocity. The arm good spot workspace easily achieve desired motion. The code runs 200Hz, sufficiently fast enough. I hard-code angular velocity fed Jacobian instead using computed v_euler instability. So something wrong math. This works zero non-zero target angular velocities. Interestingly, feed angular velocity 0.01 rad/sec, end-effector rotates rate 90 deg/sec. Update: If I put end-effector different place workspace axes aligned world axes, everything seems works fine. If end-effector 45 degrees world axes, motions seem work, others don't move exactly should, although don't think i've seen go unstable. At 90 degrees world, goes unstable.",kinematics jacobian
6620,What best software/package draw robot manipulator indicate DH parameters different axes?,I'm wondering good software/package draw robot manipulator indicate DH parameters different axes? Any suggestions!,robotic-arm industrial-robot robotc simulation
6622,Is Khepera II still adequate learning,"A professor university asking study robotics him. By robotics I understand programming robot move around, avoid obstacles, figure maze, etc.. He sent manuals Khepera II. When I first read specs, I surprised low specs: Motorola 68331 CPU @ 25 MHz 512 KB RAM 512 KB Flash But I looked new Arduino boards similar specs. So maybe that's OK, I guess CPU speed RAM aren't important I'm going control robot normal computer handle real time computation. What software? I glanced manuals saw C assembly code. Khepera I 1995 Khepera II 2001. I think robots advanced much since 2001. Is using Khepera II adequate university level learning, considering I probably give 200-300$ newer one? I ask terms hardware board, motors sensors, well programmability. This question might seem vague. I'm ready improve giving detail upon request.",mobile-robot
6624,Ball plate possible sensors use,I looking sensors give position ball plate order make ball plate problem . What came mind use image processing since never serious image processing don't know good idea. Eventually please help find 'cheap' sensors order get position ball plate. Thank attention.,control sensors
6632,"Ros, iai_kinect2 issues","I Ubuntu 14.04 LTS running Toshiba Satellite, intel i7, nvidia usb 3.0 2.0 ports. 1, 2, 3 refer scripts found Setup ros running install-ros.sh script Setup opencv running install-opencv.sh script Setup PCL running install-pcl.sh script Installed libfreenect2 via instructions master branch Made changes installed Cloned repository empty catkin workspace Sourced respective setup.zsh files /opt/ros/... devel/ folders. At point, I encountered issues I tried running: I get following message: [ERROR] [1424391698.413758209]: [registerPublisher] Failed contact master [localhost:11311]. Retrying.. So I assume I need run roscore something like that. So I run: roscore one terminal and: rosrun kinect2_bridge kinect2_bridge another terminal, I get following segmentation fault: [ERROR] [1424393345.496836066]: [registerPublisher] Failed contact master [localhost:11311]. Retrying... [ INFO] [1424393446.243884489]: Connected master [localhost:11311] parameter: base_name: kinect2 sensor: fps_limit: -1 calib_path: /home/parthmehrotra/catkin_ws/src/iai_kinect2/kinect2_bridge/data/ use_png: false jpeg_quality: 90 png_level: 1 depth_method: opengl depth_device: -1 reg_method: default reg_devive: -1 max_depth: 12 min_depth: 0.1 queue_size: 2 bilateral_filter: true edge_aware_filter: true publish_tf: false base_name_tf: kinect2 worker_threads: 4 [1] 2679 segmentation fault (core dumped) rosrun kinect2_bridge kinect2_bridge I must overlooking something really trivial. Thanks taking time help me.",ros kinect
6639,plot $\pm 3 \sigma$ landmark EKF-SLAM,"I implemented 2D-SLAM using EKF. The map based-feature one landmark sake simplicity. I've read papers regarding matter. They plot $\pm3\sigma$ plus error. I would like make sure I'm right thing. In project, I estimate landmark's position true values. The true values ones sensor measure ideal case. For example, ideal case landmark position (30,60) value accessible means, therefore I consider true values ones coming sensor. Now error landmark's position x-axis formulated follows $$ \text{error}_{x} = \hat{x} - x $$ The picture shows error blue color. The red color represents error bounds $\pm 3 \sigma_{x}$ My question way people plot errors academics papers I've seen papers bounds doesn't look like mine. Even though mine decreases monotonically however papers curved seems reasonable me. Any suggestions?",slam ekf simulation mapping
6642,"""Time-varying"" ""nonautonomous"" dynamical systems Lyapunov analysis","It possible distinguish properties ""time-varying"" ""nonautonomous"" dynamical systems regarding Lyapunov stability analysis? Does make difference system depends explicitly $t$ indirectly $t$ due time-varying parameter? I want explain problem detail: Let dynamical system denoted $\dot x = f$, state $x$. We say dynamical system nonautonomous dynamics $f$ depend time $t$, i.e. $$\dot x = f(t,x).$$ For instance systems $$ \dot x = - x^2 $$ $$ \dot x = -a(t)x,$$ nonautonomous. Let $a(t)$ bounded time-varying parameter, i.e. $||a(t)||<a^+$ strictly positive, i.e. $a(t) > 0$. Particularly, second example likely denoted time-varying linear system, course nonautonomous. In Lyapunov stability analysis autonomous nonautonomous systems must strongly distinguished make assertions stability system, Lyapunov analysis nonautonomuos systems much difficult. And questions arise. When want analize stability second example must really use Lyapunov theory nonautonomous systems? It follows candidate $V = 1/2 x^2$ $$\dot V = -a(t)x^2,$$ negative definite. Is origin really asymptotically stable, suppose, must take nonautomous characteristic account case? I would suppose makes difference system depends explicitly $t$ first example indirect due time-varying parameter, since $t$ approaches infinity, parameter not.",control dynamics
6643,Can quadcopter hover tilted?,"Is way make quadcopter maintain steady hovering (no lateral movement, constant altitude) tilted left right? If so, accomplish this?",quadcopter
6648,Automatic agricultural robot using 8051,I want build automatic agricultural robot final year diploma project. The basic idea program 8051 drive robot fixed path farm ploughing farm planning setting particular distance till go straight take U turn plough next lane. Width farm also set completes full farm it'll stop go back starting point. catch reprogram per size farm person uses it. So want add number pad set length width farm well width lane per needs without professional help. Can done using 8051 go AVR PIC microcontrollers. I started studying programming interfacing 8051 I good programming. If possible it. someone please help circuit diagram project. After everything said need project still get empty port microcontroller I would love add fertilizer sprayer water irrigation system GSM module farmer simply ask robot start working using mobile phone. As I making prototype want small possible. Suggestions welcomed.,microcontroller wheeled-robot electronics artificial-intelligence
6649,PID control tank-like robot IMU,"Consider tank like robot motor driver channel side robot (two motors left two motors right) IMU. I'm interested driving robot straight line using yaw data gyro magnetometer IMU, removing noise caused slightly different behaving motors, possibility change desired direction angle. For example event comes I want car switch desired direction +120 degrees turn driving. I'm using Arduino Uno, MinIMU-9 v3 two DRV8838 Single Brushed DC Motor Driver Pololu. Can please give hints short pseudo-code example? Thanks!",arduino pid imu
6650,Microcontroller running Linux RTAI,I'm beginner Robotics. I'd like ask minimum/recommended specs microcontroller run real-time system Linux RTAI? What popular microcontroller running Linux RTAI? Thank you.,microcontroller embedded-systems real-time
6651,Are robotic pollenators designed?,"With bee hive collapses, growers desperate pollenation options. Is anyone working swarms tiny flying robots augment bees? They could look certain color, poke around inside flower moment, move next. When need recharging, fly back hive (the reason bees fly back). Of course, replacing germinators run seeds digestive systems would different problem.",mobile-robot
6652,How get python node ROS subscribe multiple topics?,"How ROS node written Python could subscribe multiple topics publish multiple topics? All examples I found single topic. Is event-driven model subscription multiple ""events"" allowed like loop, listen one ""source"" time?",ros
6657,What dynamic system could equations represent?,"I equations dynamic system. I need figure physical system is. The equations are: \begin{align} \dot{x}_1&=bx_1+kx_2+x_3\\ \dot{x}_2&=x_1\\ \dot{x}_3&=\alpha (u-x_2)-\beta x_3 \end{align} All I figure maybe mass-spring-damper system, plus feedback control, I quite sure terms $x_3$ $\dot{x}_3$. What two terms mean?",control dynamics
6659,GraphSLAM: constraints imposed twice information matrix?,"I watching Sebastian Thrun's video course AI robotics (freely available udacity.com). In final chapter GraphSLAM, illustrates setup system equations mean path locations $x_i$ landmark locations $L_j$. To setup matrix system, imposes robot motion landmark measurement constraint twice. For example, robot motion command move x1 5 units right (reaching x2), understand constraint $$-x_2+x_1= -5$$ However, also imposes negative equation $$x_2-x_1=5$$ constraint superimposes onto different equation i'm sure why. In video course, briefly mentions matrix we're assembling known ""information matrix"", information matrix assembled specific way. So, I tried read book Probabilistic Robotics, gather equations come obtaining minimizer negative log posterior probability incorporating motion commands, measurements, map correspondences, results quadratic function unknown variables $L_j$ $x_i$. Since quadratic (and motion / measurement models also linear), minimum obviously obtained solving linear system equations. But constraints imposed twice, positive quantity negative equation? Its immediately obvious form negative log posterior probability (i.e. quadratic function) constraints must imposed twice. Why ""information matrix assembled way? Does also hold true motion measurement models nonlinear? Any help would greatly appreciated.",slam
6661,FreeIMU External Magnetometer,"I using FreeIMU library successfully I want add external magnetometer I mount away motors. I've figured modify FreeIMU library use external magnetometer I getting data. What I can't figure I need change magnetometer orientation changed. On free IMU mounted like The external compass mounted like - upside - rotated 180° around x I changing value inside function code calls get magnetometer data. So far I tried: Changing sign z values I got magnetometer. Changing sign value Changing sign z value Added 180 z values Subtracting 180 z values Subtracting 180 adding 180 Z Adding 180 subtracting 180 z Changing nothing The calibration GUI gives always gives strange results, changes rotated/mirrored magnetometer red green graphs. I unable get rid key hole shape. The red XY. The green YZ. The blue ZX. Does fact ZX works mean issue Y value? This looks using board magnetometer. What I try next? Thanks Joe EDIT I tried rotating external magnetometer orientation FreeIMU magnetometer I still get result I don't think difference orientation causing problem. So I thought maybe FreeIMU mounted central rotation axis external magnetometer mounted 20cm above. I tested rotating external magnetometer around I still got result. This seems strange, think possible external magnetometer I brought faulty? Any way confirm working properly own? Thanks EDIT Managed get circles plotting changing gain 0 1. It seem new magnetometer saturated. Now I need work change values around orientation correct.",quadcopter imu calibration magnetometer
6662,How track robot position,"I'm software researcher, spare time mentors robotics team, helping software side things. For years, I keep coming back question. How determine robots position, heading competitions. We tried number things varying degrees success/failure. Encoders drive wheels, accelerometers, gyroscopes, etc. I recently bought IMU 3 axis accelerometer, 3 axis gyro, 3 axis magnetometer, preprocessed Arduino, outputting value serial port. I thought surely must way take measurements, get composite view position heading. We using mechanum wheels particular robot, wheel encoders particularly useful. I've looked around there's lot talk orientation using quaternion sensor fusion using similar boards, unclear take quaternion estimation come x,y distance starting position. Now time window measurements small, ~15 seconds, I need pretty accurate within window. I'm ready abandon using IMU, try something else. One idea use usb ball mouse try track robot motion I'm certain mouse going get banged around way much leading noise invalid results. As side note: robot's 2ft x 3ft base weighting 120 lbs. Any thoughts suggestions appreciated.",imu sensor-fusion
6667,Heavy omnidirectional platform suspension,"I'm planning build omnidirectional platform support 180kg robotic arm. The platform equipped meccanum wheels. I would like kind suspension avoid wheels loosing contact floor small bumps (let's say 2cm). The first suspension type I thought rocker bogie type, I'm afraid, changes arm center mass movement introduce much stress rocker bogie mechanism. What choices would recommend? Or maybe rocker bogie fine all?",mobile-robot wheeled-robot design mechanism
6672,The uncertainty big sensor rather accurate measuring landmark EKF-SLAM,"I've 2D sensor provides range $r$ bearing $\phi$ landmark. In 2D EKF-SLAM simulation, sensor following specifications $$ \sigma_{r} = 0.01 \text{m} \ \ ,\sigma_{\phi} = 0.5 \ \text{deg} $$ The location landmark x-axis 30. EKF imposes Gaussian noise, therefore location landmark represented via two quantities namely mean $\mu_{x}$ variance $\sigma_{x}$. In following graph The green mean $\mu_{x}$ close true location (i.e. 30). The black measurements red $\mu_{x} \pm 3 \sigma_{x}$. I don't understand uncertainty big I'm using rather accurate sensor. The process noise robot's pose $\sigma_{v} = 0.001$ small noise. I'm using C++. Edit: people ask measurements, code $$ r = \sqrt{ (m_{j,y} - y)^{2} + (m_{j,x} - x)^{2}} + \mathcal{N}(0, \sigma_{r}^{2}) \\ \phi = \text{atan2} \left( \frac{m_{j,y} - y}{m_{j,x} - x} \right) + \mathcal{N}(0, \sigma_{\phi}^{2}) $$ Normalized_Gaussain_Noise_Generator() ( i.e. $\mathcal{N}(0, 1) )$ double Robot::Normalized_Gaussain_Noise_Generator() { double noise; std::normal_distribution<double> distribution; noise = distribution(generator); return noise; } For measurements (i.e. black color), I'm using inverse measurement function given estimate robot's pose true measurement polar coordinates get location landmark. The actual approach follows $$ \bar{\mu}_{j,x} = \bar{\mu}_{x} + r \cos(\phi + \bar{\mu}_{\theta}) \\ \bar{\mu}_{j,y} = \bar{\mu}_{y} + r \sin(\phi + \bar{\mu}_{\theta}) $$ This stated Probabilistic Robotics book. This means measurements graph indeed predicted measurements true ones. Now conditions, true measurements obtained follows $$ \text{m}_{j,x} = x + r \cos(\phi + \theta) \\ \text{m}_{j,y} = + r \sin(\phi + \theta) $$ The result graph below, means correlations true measurements robot's estimate. This leads question - uncertainty behaves like that?",mobile-robot slam ekf noise
6673,Do rate controller Quadcopter?,"Most academic papers characterise rate rotation along x axis φ""=(1/Jx)τφ. As far I cant tell, characterises rate actual angle φ yet PID controllers academics use control takes φsetpoint-φmeasured error signal. Should error signal φ""setpoint-φ""measured (using gyro values) instead. Why using euler angle instead second derivative control rate? Is possible stabilise quadcopter using euler angles only?",control quadcopter pid
6674,Drive motor voltage / specifications Roomba 650,"I salvaged parts dead Roomba 650, I'm trying use drive motor assembly . I got pinout connector I don't know voltage / PWM / specifications motor. I've attached picture drive motor assembly. Any help would appreciated! Thank you, Pratik Edit: The Image here: Drive Motor Module",motor pwm irobot-create h-bridge roomba
6680,I project robotic surgeries! Can anyone help give details related topic?,"Can anyone help me, I project robotical surgeries I would like someone help advise me. I wonder anyone could give data tests run surgical robot... Thank attention! Anything else much appreciated!",sensors robotic-arm automatic
6683,What difference motion planning trajectory generation?,What major differences motion planning trajectory generation robotics? Can terms used interchangeably?,motion-planning
6686,iRobot Create 2 Open Interface 2 Spec syncing incoming data,"I create 2 hooked arduino. Almost commands work fine except retrieving sensor information. If send request packet 18 I get back values consistent don't match up, unless I missing something. So I press clean button I get 127 11111110 press spot I get something like 11111010. I might messing endianness regardless data isnt formatted I expected according spec sheet. I 3 create 2s thing. Any ideas? I using 2n7000 along tutorial site dont think anything formatting byte. library I using: Sorry take long get back this, anyways data get always formatted way. It baud rate issue since understands commands properly. Note schedule clock buttons return nothing",arduino irobot-create
6694,"How find body jacobain, link robot manipulator?","The links twist could obtained, thus The spatial manipulator Jacobian could done, comes body Jacobian, becomes difficult. Moreover, adjoint transformation relates Jacobain, however 4*4 Jacobian 6*n; works? picture, getting body jacobian link, one jacobian matrix whole robot, I don't know. Any help highly regarded. Like example full details",robotic-arm kinematics inverse-kinematics manipulator jacobian
6696,DC Motor PID control unstable velocity feedback,"Currently I building omnidirectional robot 4 DC Motors embedded incremental encoder. However, constant pwm input, able control motor rotate ""relatively stable"" state, refer figure, observed linear speed motors varied 10cm/s range. I believe one possible reason PWM signal generated Arduino Mega Controller good enough. And problem I implement stable PID controller case? As speed motor varies even input, I believe extra work like adding filter needed? Any advice appreciated >.< Thank",motor pid
6700,help quadcopter controlling,,pid
6701,Drones camera streaming,"How stream video feed camera drone? I would think high altitudes Wi-Fi won't work. So would usually do, how?",quadcopter cameras
6703,Angles Rocker bogie system,"How select following two angles design Rocker bogie system: Angle two arms main rocker, and; Angle two arms bogie.",mobile-robot wheeled-robot
6705,Detect human proximity?,I'm looking ways detect human presense behind walls close proximity (around 10 feet) whatever way possible! Problem I can't code! (I hope it's ok I'm posting here.) I know different sensors seem detecting motion target humans. How detect still persons? Is sound amplification device magnifies human breathing x 20? Or detect body heat? Or pick radiation waves something humans?,sensors sensor-fusion ultrasonic-sensors
6706,Converting linear acceleration command DC motor command?,"I'm constructing 2 wheels balancing robot uses PID controller. I've tuned parameters numerical simulations based continuous inverted pendulum system simulated inverted pendulum balances controlling horizontal (linear) cart acceleration $\ddot{x}$. Now I've done this, I want take next step turn PID control commands electrical commands onto DC motor give desired linear acceleration $\ddot{x}$. However I'm sure exactly specific robot's motors. Are experimental tests I run determine convert PID commands DC motor acceleration commands? Or formula based motor's specifications? Update The non-linear dynamic equation I'm using $$L\ddot{\theta}=gsin(\theta)+\ddot{x}(t)cos(\theta)+Ld(t)$$ $\ddot{x}(t)$ linear acceleration, $g$ acceleration due gravity, $\ddot{\theta}$ angular acceleration, $d(t)$ external disturbance system. To simplify things, I've linearized equations around $\theta\approx0$, yielding $$L\ddot{\theta}=g\theta+\ddot{x}(t)+Ld(t)$$ I've assumed control input cart's linear acceleration $\ddot{x}(t)$, chose control command $\ddot{x}(t)=K_1\theta(t) + K_2\int_0^t\theta(t) dt + K_3\dot{\theta}$, $K_i$ PID gains.",motor control pid actuator dynamics
6708,I need help choosing computer board,"I need computer board like raspberry pi vending machine (I want replace original controller). This list requirements: 1) It pins connect mdb protocol & stuff gpio. 2) Good performance. There display browser showing rails application running. I've tried raspberry pi B+, it's slow (it can't even run browser speed like laptop pc). So, I want choose powerful system like odroid, wandboard etc. 3) Custom video output. Sometimes I need display FullHD(1920x1080), sometimes I need show 768x1024 (yes, computer simply rotate video output) 4) I don't want connect microcomputer display directly, HDMI, DVI something like this. (This required, desirable). Please help choose. Nowadays I try choose odroid, wandboard pandaboard. Are computers? What version computer advisable?",arduino raspberry-pi
6714,What cheapest way make led sensitive sound around?,"There always way using arduino, rasberry pi etc. However, many cases discussion forums i've come across things whole 'logic' uploaded $0.50 chip. Instead $50 dollar part. DRASTIC change. This defines line one time thing made hobby, something sell around. So basically want led get brightest loud sound almost silence. Or button switch 100% time.",design circuit
6715,Is possible robot navigate predefined coordinates?,"I total newbie robotics please bare me. I school project team design robot capable picking 3 golf balls different sizes predefined locations. Then drop balls respective holes. We using arduino chip robot. I thought I could perhaps define path robot, invisible virtual path may call. So imagining platform Cartesian plane, I tell robot go I want go? For example, go (5,12) Or I need sort sensors robot figures itself. Thanks time!",arduino sensors navigation
6720,Raspberry Pi quadcopter thrashes high speeds,"I attempting build Raspberry Pi based quadcopter. So far I succeeded interfacing hardware, I written PID controller fairly stable low throttle. The problem higher throttle quadcopter starts thrashing jerking. I even able get ground yet, testing done test bench. I ruled bad sensors testing sensor individually, seem giving correct values. Is problem code, perhaps bad motor? Any suggestions greatly appreciated. Here code far: QuadServer.java: Sensor.java: package com.zachary.quadserver; import com.pi4j.io.gpio.GpioController; import com.pi4j.io.gpio.GpioFactory; import com.pi4j.io.gpio.GpioPinDigitalOutput; import com.pi4j.io.gpio.PinState; import com.pi4j.io.gpio.RaspiPin; import com.pi4j.io.i2c.*; import com.pi4j.io.gpio.GpioController; import com.pi4j.io.gpio.GpioFactory; import com.pi4j.io.gpio.GpioPinDigitalOutput; import com.pi4j.io.gpio.PinState; import com.pi4j.io.gpio.RaspiPin; import com.pi4j.io.i2c.*; import java.net.*; import java.io.*; public class Sensor { static I2CDevice sensor; static I2CBus bus; static byte[] accelData, gyroData; static long accelCalib[] = new long[3]; static long gyroCalib[] = new long[3]; static double gyroX = 0; static double gyroY = 0; static double gyroZ = 0; static double accelX; static double accelY; static double accelZ; static double angleX; static double angleY; static double angleZ; public Sensor() { //System.out.println(""Hello, Raspberry Pi!""); try { bus = I2CFactory.getInstance(I2CBus.BUS_1); sensor = bus.getDevice(0x68); sensor.write(0x6B, (byte) 0x0); sensor.write(0x6C, (byte) 0x0); System.out.println(""Calibrating...""); calibrate(); Thread sensors = new Thread(){ public void run(){ try { readSensors(); } catch (IOException e) { System.out.println(e.getMessage()); } } }; sensors.start(); } catch (IOException e) { System.out.println(e.getMessage()); } } private static void readSensors() throws IOException { long time = System.currentTimeMillis(); long sendTime = System.currentTimeMillis(); (true) { accelData = new byte[6]; gyroData = new byte[6]; int r = sensor.read(0x3B, accelData, 0, 6); accelX = (((accelData[0] << 8)+accelData[1]-accelCalib[0])/16384.0)*9.8; accelY = (((accelData[2] << 8)+accelData[3]-accelCalib[1])/16384.0)*9.8; accelZ = ((((accelData[4] << 8)+accelData[5]-accelCalib[2])/16384.0)*9.8)+9.8; accelZ = 9.8-Math.abs(accelZ-9.8); double hypotX = Math.sqrt(Math.pow(accelX, 2)+Math.pow(accelZ, 2)); double hypotY = Math.sqrt(Math.pow(accelY, 2)+Math.pow(accelZ, 2)); double accelAngleX = Math.toDegrees(Math.asin(accelY/hypotY)); double accelAngleY = Math.toDegrees(Math.asin(accelX/hypotX)); //System.out.println((int)gyroX+"", ""+(int)gyroY); //System.out.println(""accelX: "" + accelX+"" accelY: "" + accelY+"" accelZ: "" + accelZ); r = sensor.read(0x43, gyroData, 0, 6); if(System.currentTimeMillis()-time >= 5) { gyroX = (((gyroData[0] << 8)+gyroData[1]-gyroCalib[0])/131.0); gyroY = (((gyroData[2] << 8)+gyroData[3]-gyroCalib[1])/131.0); gyroZ = (((gyroData[4] << 8)+gyroData[5]-gyroCalib[2])/131.0); angleX += gyroX*(System.currentTimeMillis()-time)/1000; angleY += gyroY*(System.currentTimeMillis()-time)/1000; angleZ += gyroZ; angleX = 0.95*angleX + 0.05*accelAngleX; angleY = 0.95*angleY + 0.05*accelAngleY; time = System.currentTimeMillis(); } //System.out.println((int)angleX+"", ""+(int)angleY); //System.out.println((int)accelAngleX+"", ""+(int)accelAngleY); } } public static void calibrate() throws IOException { int i; for(i = 0; < 3000; i++) { accelData = new byte[6]; gyroData = new byte[6]; int r = sensor.read(0x3B, accelData, 0, 6); accelCalib[0] += (accelData[0] << 8)+accelData[1]; accelCalib[1] += (accelData[2] << 8)+accelData[3]; accelCalib[2] += (accelData[4] << 8)+accelData[5]; r = sensor.read(0x43, gyroData, 0, 6); gyroCalib[0] += (gyroData[0] << 8)+gyroData[1]; gyroCalib[1] += (gyroData[2] << 8)+gyroData[3]; gyroCalib[2] += (gyroData[4] << 8)+gyroData[5]; try { Thread.sleep(1); } catch (Exception e){ e.printStackTrace(); } } gyroCalib[0] /= i; gyroCalib[1] /= i; gyroCalib[2] /= i; accelCalib[0] /= i; accelCalib[1] /= i; accelCalib[2] /= i; System.out.println(gyroCalib[0]+"", ""+gyroCalib[1]+"", ""+gyroCalib[2]); } public double readAngle(int axis) { switch (axis) { case 0: return angleX; case 1: return angleY; case 2: return angleZ; } return 0; } public double readGyro(int axis) { switch (axis) { case 0: return gyroX; case 1: return gyroY; case 2: return gyroZ; } return 0; } public double readAccel(int axis) { switch (axis) { case 0: return accelX; case 1: return accelY; case 2: return accelZ; } return 0; } } Edit: I re-written code C++ see run faster it's still running speed(about 15 ms per cycle 66 Hz). This new code C++: #include <wiringPi.h> #include <wiringPiI2C.h> #include <sys/socket.h> #include <netinet/in.h> #include <string.h> #include <string> #include <iostream> #include <unistd.h> #include <boost/thread.hpp> #include <time.h> #include <cmath> #define axisX 0 #define axisY 1 #define axisZ 2 #define kP 20 #define kI 0 #define kD 0 #define FREQUENCY 490 #define MODE1 0x00 #define MODE2 0x01 #define SUBADR1 0x02 #define SUBADR2 0x03 #define SUBADR13 0x04 #define PRESCALE 0xFE #define LED0_ON_L 0x06 #define LED0_ON_H 0x07 #define LED0_OFF_L 0x08 #define LED0_OFF_H 0x09 #define ALL_LED_ON_L 0xFA #define ALL_LED_ON_H 0xFB #define ALL_LED_OFF_L 0xFC #define ALL_LED_OFF_H 0xFD // Bits #define RESTART 0x80 #define SLEEP 0x10 #define ALLCALL 0x01 #define INVRT 0x10 #define OUTDRV 0x04 #define BILLION 1000000000L using namespace std; double accelCalX = 0; double accelCalY = 0; double accelCalZ = 0; double gyroCalX = 0; double gyroCalY = 0; double gyroCalZ = 0; double PX; double PY; double IX = 0; double IY = 0; double DX; double DY; double lastErrorX; double lastErrorY; int throttle = 1471; int sensor = wiringPiI2CSetup(0x68); int pwm = wiringPiI2CSetup(0x40); array<int,4> motorVal; struct timespec now, then; int toSigned(int unsignedVal) { int signedVal = unsignedVal; if(unsignedVal > 32768) { signedVal = -(32768-(unsignedVal-32768)); } return signedVal; } double getAccel(int axis) { double X = (toSigned((wiringPiI2CReadReg8(sensor, 0x3B) << 8)+wiringPiI2CReadReg8(sensor, 0x3C)))/1671.8; double Y = (toSigned((wiringPiI2CReadReg8(sensor, 0x3D) << 8)+wiringPiI2CReadReg8(sensor, 0x3E)))/1671.8; double Z = (toSigned((wiringPiI2CReadReg8(sensor, 0x3F) << 8)+wiringPiI2CReadReg8(sensor, 0x40)))/1671.8; X -= accelCalX; Y -= accelCalY; Z -= accelCalZ; Z = 9.8-abs(Z-9.8); switch(axis) { case axisX: return X; case axisY: return Y; case axisZ: return Z; } } double getGyro(int axis) { double X = (toSigned((wiringPiI2CReadReg8(sensor, 0x43) << 8)+wiringPiI2CReadReg8(sensor, 0x44)))/1671.8; double Y = (toSigned((wiringPiI2CReadReg8(sensor, 0x45) << 8)+wiringPiI2CReadReg8(sensor, 0x46)))/1671.8; double Z = (toSigned((wiringPiI2CReadReg8(sensor, 0x47) << 8)+wiringPiI2CReadReg8(sensor, 0x48)))/1671.8; X -= gyroCalX; Y -= gyroCalY; Z -= gyroCalZ; switch(axis) { case axisX: return X; case axisY: return Y; case axisZ: return Z; } } void calibrate() { int i; for(i = 0; < 1500; i++) { accelCalX += (toSigned((wiringPiI2CReadReg8(sensor, 0x3B) << 8)+wiringPiI2CReadReg8(sensor, 0x3C)))/1671.8; accelCalY += (toSigned((wiringPiI2CReadReg8(sensor, 0x3D) << 8)+wiringPiI2CReadReg8(sensor, 0x3E)))/1671.8; accelCalZ += (toSigned((wiringPiI2CReadReg8(sensor, 0x3F) << 8)+wiringPiI2CReadReg8(sensor, 0x40)))/1671.8; gyroCalX += (toSigned((wiringPiI2CReadReg8(sensor, 0x43) << 8)+wiringPiI2CReadReg8(sensor, 0x44)))/1671.8; gyroCalX += (toSigned((wiringPiI2CReadReg8(sensor, 0x45) << 8)+wiringPiI2CReadReg8(sensor, 0x46)))/1671.8; gyroCalX += (toSigned((wiringPiI2CReadReg8(sensor, 0x45) << 8)+wiringPiI2CReadReg8(sensor, 0x46)))/1671.8; usleep(1000); } accelCalX /= i; accelCalY /= i; accelCalZ /= i; accelCalZ -= 9.8; gyroCalX /= i; gyroCalY /= i; gyroCalZ /= i; cout << accelCalX << "" "" << accelCalY << "" "" << accelCalZ << ""\n""; } int calculatePulseWidth(double millis, int frequency) { return (int)(floor(4096 * millis * frequency/1000)); } void add(double value, int i) { value = calculatePulseWidth(value/1000, FREQUENCY); if(motorVal[i]+value > 1471 && motorVal[i]+value < 4071) { motorVal[i] += value; }else if(motorVal[i]+value < 1471) { //System.out.println(""low""); motorVal[i] = 1471; }else if(motorVal[i]+value > 4071) { //System.out.println(""low""); motorVal[i] = 4071; } } void getThrottle() { int sockfd,n; struct sockaddr_in servaddr,cliaddr; socklen_t len; char mesg[1000]; sockfd=socket(AF_INET,SOCK_DGRAM,0); bzero(&servaddr,sizeof(servaddr)); servaddr.sin_family = AF_INET; servaddr.sin_addr.s_addr = htonl(INADDR_ANY); servaddr.sin_port = htons(8080); bind(sockfd,(struct sockaddr *)&servaddr,sizeof(servaddr)); while(true) { len = sizeof(cliaddr); n = recvfrom(sockfd,mesg,1000,0,(struct sockaddr *)&cliaddr,&len); mesg[n] = 0; string message(mesg); string values[5]; int valIndex = 0; int lastIndex = 0; for(int = 0; < message.length(); i++) { if(message[i] == ' ') { values[valIndex] = message.substr(lastIndex+1, i); lastIndex = i; valIndex++; } } values[valIndex] = message.substr(lastIndex+1, message.length()); throttle = calculatePulseWidth(((stoi(values[4])*12.96)+733)/1000, FREQUENCY); } } void setAllPWM(int on, int off) { wiringPiI2CWriteReg8(pwm, ALL_LED_ON_L, (on & 0xFF)); wiringPiI2CWriteReg8(pwm, ALL_LED_ON_H, (on >> 8)); wiringPiI2CWriteReg8(pwm, ALL_LED_OFF_L, (off & 0xFF)); wiringPiI2CWriteReg8(pwm, ALL_LED_OFF_H, (off >> 8)); } void setPWM(int on, int off, int channel) { wiringPiI2CWriteReg8(pwm, LED0_ON_L + 4 * channel, (on & 0xFF)); wiringPiI2CWriteReg8(pwm, LED0_ON_H + 4 * channel, (on >> 8)); wiringPiI2CWriteReg8(pwm, LED0_OFF_L + 4 * channel, (off & 0xFF)); wiringPiI2CWriteReg8(pwm, LED0_OFF_H + 4 * channel, (off >> 8)); } void setPWMFrequency(double frequency) { double prescaleval = 25000000.0; prescaleval /= 4096.0; prescaleval /= frequency; prescaleval -= 1.0; double prescale = floor(prescaleval + 0.5); int oldmode = wiringPiI2CReadReg8(pwm, MODE1); int newmode = (oldmode & 0x7F) | 0x10; wiringPiI2CWriteReg8(pwm, MODE1, newmode); wiringPiI2CWriteReg8(pwm, PRESCALE, (floor(prescale))); wiringPiI2CWriteReg8(pwm, MODE1, oldmode); usleep(50000); wiringPiI2CWriteReg8(pwm, MODE1, (oldmode | 0x80)); } void initSensor() { wiringPiI2CWriteReg8(sensor, 0x6B, 0x0); wiringPiI2CWriteReg8(sensor, 0x6C, 0x0); } void initPWM() { setAllPWM(0, 0); wiringPiI2CWriteReg8(pwm, MODE2, OUTDRV); wiringPiI2CWriteReg8(pwm, MODE1, ALLCALL); usleep(50000); int mode1 = wiringPiI2CReadReg8(pwm, MODE1); mode1 = mode1 & ~SLEEP; wiringPiI2CWriteReg8(pwm, MODE1, mode1); usleep(50000); setPWMFrequency(FREQUENCY); } double millis(timespec time) { return (time.tv_sec*1000)+(time.tv_nsec/1.0e6); } double intpow( double base, int exponent ) { int i; double = base; for( i=1 ; < exponent ; i++ ) { *= base; } return out; } int main (void) { initSensor(); initPWM(); cout << ""Calibrating..."" << ""\n""; calibrate(); boost::thread server(getThrottle); clock_gettime(CLOCK_MONOTONIC, &then); while(true) { motorVal.fill(throttle); clock_gettime(CLOCK_MONOTONIC, &now); double dt = (millis(now)-millis(then))/1000; = now; double accelX = getAccel(0); double accelY = getAccel(1); double accelZ = getAccel(2); double hypotX = sqrt(intpow(accelX, 2)+intpow(accelZ, 2)); double hypotY = sqrt(intpow(accelY, 2)+intpow(accelZ, 2)); double accelAngleX = (180/3.14)*(asin(accelY/hypotY)); double accelAngleY = (180/3.14)*(asin(accelX/hypotX)); double errorX = -getGyro(0); double errorY = getGyro(1); PX = errorX; PY = errorY; IX += errorX*dt; IY += errorY*dt; IX = 0.95*IX+0.05*accelAngleX; IY = 0.95*IY+0.05*accelAngleY; DX = (errorX-lastErrorX)*dt; DY = (errorY-lastErrorY)*dt; lastErrorX = errorX; lastErrorY = errorY; double outputX = kP*PX+kI*IX+kD*DX; double outputY = kP*PY+kI*IY+kD*DY; add(outputY, 0);//-outputX+ add(outputY, 1);//-outputX- add(outputY, 2);//outputX- add(outputY, 3);//outputX+ setPWM(0, motorVal[0], 12); setPWM(0, motorVal[1], 13); setPWM(0, motorVal[2], 14); setPWM(0, motorVal[3], 15); } } In addition two motors seem like lagging I turn quadcopter fast one direction. Also strange reason quadcopter seems less responsive P gain; I 20 C++ version working I 1.5 java version. Edit: After testing I determined reading MPU6050 writing PCA9685 board I using control ESCs source delay. Does anybody know speed up? Edit: I managed speed code 200 Hz changing i2c baud rate, quadcopter still thrashing. I spent hours trying tune pid controller, doesn't seem help all.",quadcopter pid raspberry-pi
6721,How feasible idea operating robotic arm non-sophisticated way?,"I team design robot using arduino chip. The objective robot grab golf balls set golf pins different heights pre-defined locations. We couldn't figure possible mechanism could collect balls drop trailer except robot arm. However, don't experience time designing sophisticated system arm like recognizing ball grabbing accordingly. What would feasible option compared non-sophisticated robot arm? Note:The robot must autonomous.",arduino control robotic-arm
6733,Minimising lateral drift PID (Arduino) controlled quadcopter using 6DOF IMU,"I'm developing stabilisation system 'off-the-shelf' quadcopter using Arduino Mega IMU. The IMU reading angle quad, calculating motor commands using PID controller applying motors. It works well constrained test bed, however reality, although quad straight level, it's drifting one side recent motor commands correcting pitch/yaw. Is way I (without using vision system) keep quad one place without drifting? I've looked obtaining velocity integrating acceleration value, however it's extremely noisy doesn't give meaningful reading.",arduino quadcopter pid imu rcservo
6739,Turning epilog laser 3d printer?,We epilog laser cutter around I wondering would possibly work base 3d printer? Here Dropbox photo album laser cutter. I thinking I get new control system I unsure I able use motor controllers embedded current control's board. I also unsure fine enough control z axis modified. What would good head look at? Any thoughts?,laser 3d-printing
6740,"In PID equation K[((s+a)^2)/s] values correspond PID coefficients Kp, Ki, Kd?","I'm trying understand obtain Kp, Ki, Kd values finding combination K works me. Do I expand equation take coefficients?",control pid tuning
6741,How many methods I use acquire depth data?,"I newbie Robotics. As far I know, there're generally two ways acquire depth information scene. One stereo vision method applies two cameras. The RGBD sensors Kinect Primesense. It seems methods use currently. However, I know advantages other. I think Kinect perfect solution stereo vision ignoring expense. So I two questions here: Is advantages binocular methods Kinect besides expense? As I know, two methods confined limited distance detection range. In real world applications, sometimes also need depth data distance. Is method acquire estimate data information far distance( considering laser-based detectors ). Further more, application may small flight vehicle. Which method equipment I choose? Will traditional binocular camera slow application?",computer-vision stereo-vision
6750,Does electronic compass work underwater,"I'm building submersible ROV, I need way navigate. So using compass would help brings question, electronic compass work underwater? My thoughts water might act faraday cage, therefore interfere magnetic field. Therefore might even work. Maybe gyroscope might better solution.",sensors compass
6754,Why I'm getting long terms inertia matrix (or dynamics model) robot using matlab script?,"I'm working dynamics model RRRR articulated robot, I'm following Euler-Lagrange approach developing code m-file matlab; I'm looking dynamic model form: $$ D(q) \ddot{q} + C(q,\dot{q})\dot{q}+ g(q) = \tau $$ $D$ $C$ $4 \times4$ matrices $g$ $\tau$ (torque) $4\times1$ vectors; formulating kinetic potential energies;; The problem that, I'm getting long equations, term $D$ matrix huge nonlinear, involving sin cos; I'm talking several pages per equation; After I published code - 7 pages - output I got around 45 pages total; I searched around guy faced problem before, helpful proposal. Any Suggestions ??",robotic-arm kinematics dynamics matlab
6764,"How I get MPU 6050 gyroscope data using ""MPU6050_6Axis_MotionApps20.h"" library","I'm currently calibrating MPU6050 chip using arduino mega 2560. I using J Rowberg 12c dev libraries. I get print raw accelerometer gyroscpe values (very unstable, wildly changing values). In digital motion processing chip library, I get print euler angles, quaternions, real world acceleration actual acceleration option get gyroscope data. I use DMP library get gyro data possible get raw unprocessed gyro values?",arduino imu accelerometer gyroscope
6765,Open Source software Quadcopters,"question general please bear me. I'm interested buying quadcopter develop functions example android app control it, objects detection. So question available quadcopters software allows things flying toy? P.S: I'm asked buy kit within 600$ build",quadcopter
6767,Magnetometer measure high angular velocity small object,"I measure frequency little circle rotation. You image circle flying air, circle can't touch anything rotation. So I can't use simple trick count number complete rotation amount time. So I supposed chance use accelerometer, gyroscope, magnetometer. The accelerometer detect centripetal acceleration, gyroscope magnetometer calculus directly frequency. The problem high frequency circle (can reach 50 Hz). Doing simple calculus know need gyroscope measure big angular velocity: 50*360°/s = 18.000°/s. Also accelerometer need big range values (the radius circle 5 cm): w (angular velocity) = (2 * 3,14) / (1/50) = 314 rad/sec acc_centr = w^2 * R = 98596 * 0,05 ~ 5000m/s^2 ~ 500g Now I seen accelerometer gyroscope industrial purposes enough range, question is: How I understand magnetometer used kind application? Considering magnetic field near circle, magnetometer used measure quickly change inclination? In datasheet read ofter sensor communicate arduino, nothing quick rotation be. Is reason magnetometer don't limits gyroscope accelerometer?",electronics
6772,Is crazyflie control board considered microcontroller,"I currently project school told must use micro controller ends controlling external hardware, know crazyflie controlling motors counts external hardware micro controller? My second question want purchase kit assembly however I saw use expansion board need solder also plan buying remote possible control crazyflie via iPhone correct? I would appreciate someone could answer questions. Thank advance",quadcopter
6776,Iron man Jarvis like robot,I'm passionate robots childhood.I'm java developer. I love sci-fi movies.I little bit knowledge embedded systems electronics. My ambition build robot like Jarvis (In Iron Man Movie).Which voice controlled robot.I would like implement house home automation system.It would take voice input take appropriate action.. Please help this. Any kind help appreciated..,mobile-robot quadcopter microcontroller mechanism embedded-systems
6782,Sending commands Roomba PC,"I'm trying send commands Roomba. However behaving strange. This manual I'm using. First all. I consulted several manuals, say default baudrate 115200, however works 57200. I'm trying get response Roomba sending following comand Examples: • To turn iRobot Create’s Play LED only: 128 132 139 2 0 0 However, Roomba goes crazy start going around. Any idea what's happening I'm doing? Or I first? Thank you.",irobot-create roomba
6783,What equipment used design robot,"Look robot I see rods lot holes planes also holes. This seems way create flexibility things connected together create final robot. Is name type equipment, metals holes. Where I get it? I aware people using lego blocks create robots, sure metal rods plates holes are. Is free application I design mechanical structure like one image add gears simulate see rotate bend real robot like created? What would quickest way create robot like this? Edit: Thankyou; Frank lanyusea. If one wants simulation mechanical model, others words play robot computer actually building (with gears action), software suitable purpose?",robotic-arm
6784,How know type stepper motors use designing robot,"I talking robots like one: How would person know type motor use design robot? What I want understand stepper motors different step sizes, different torques among things. How determine type stepper motor suitable used given robot?",robotic-arm stepper-motor
6787,Is tough make robotic workshop,I want make robotic workshop.. I recruited 10 members work... Please give tips robotic workshop,irobot-create
6791,Does anyone walking patterns Biped Scout? (LYNXmotion),"I recently got LYNX Biped Scout found really hard actually come working ""Gait"" walking pattern. Making servo move easy, that's problem, I previously built robotic arm scratch (I pictures anyone interested) one controlled via Arduino potentiometers 4 degrees freedom it's hard keep track different limbs. However Scout different beast entirely. It's purpose built kit 12 servos control I'm using LYNX SSC-32 Sequencer distributed freely website. The problem making move sequence produce convincing walking motion actually really hard. Has anyone got patterns robot would happy share?",walk
6792,How I know system easier control using PID controller?,"I inverted inertia wheel pendulum. I suppose I wheel larger inertia top, system would stable. How I prove disprove conjecture?",control pid stability
6801,Unilateral Torque Constraint foot-ground interface,I studying basics legged locomotion came across unilateral force torque constraints foot-ground interface. I understood implication unilateral constraint force ( ground push foot pull it) I unable understand unilateral torque constraint translate physically case. Can anyone clarify it?,mechanism motion force legged walk
6804,How I filter Gyroscopic data?,I using Arduino Mega MPU6050. I get gyroscopic data well euler angles. The problem gyro data keeps going back forth 0 -1 despite moving (it stays -1 most). What I filter I assume noise? I going use gyro data quadcopter PID rate controller I cant really telling I rotating -1 deg/sec. That would catastrophic quadcopter,arduino imu accelerometer gyroscope
6807,Driver Board Control 16 Brushed DC Motors,"I building humanoid robot DC motor actuated fingers. There 16 brushed DC motors position controlled help hall effect sensors implanted joints fingers. I need developed driver board control 16, 3 watt, 12 v,DC motors. Also motor equipped incremental encoder speed control. thank",motor servomotor driver
6808,Provides 10 Degree-Of-Freedom IMU reduntant data?,"Basic question concerning sensor fusion: A standard 10 DoF IMU, I mean cheap things tinkerer home, provides 10 values: 3 Accelerometers 3 Gyroscope 3 Magnetic Field Measurements 1 Pressure sensor (+ 1 Temperature) I know accel-data provide long term stability, useless short term gyroscope less vice versa. So tons strategies ""marry"" values, magnetic field measurement fit framework? Basically magnetic field measurement provide attitude, too. Like two sensors combined. I guess measurement alone neither reliable. So sensors fit together? BR",imu sensor-fusion
6810,Particle Filter Sampling Step,"I emphasize question sampling, resampling. I'm reading Probabilistic Robotics book Thrun et al, Chapter 4 Non-Parametric Filters. The section Particle filters algorithm states particle index $m$ (see line 4): sample $x_t^{[m]} \sim p(x_t|u_t,x_{t-1}^{[m]})$ The text's explanation step quoted as: Line 4. generates hypothetical state $x_t^{[m]}$ time based particle $x_{t-1}$ control $u_t$. The resulting sample index $m$, indicating generated $m$-th particle $\chi_{t-1}$. This step involves sampling state transition distribution $p(x_t|u_t,x_{t-1})$. To implement step, one needs able sample distribution. The set particles obtained $M$ iterations filter's representation $\bar{bel}(x_t)$. If I understand correctly, step says m-th sampled particle $x_t^{[m]}$ obtained advancing previous m-th particle control command $u_t$. I assume motion deterministic, result motion conditional probability, based particle's previous position $u_t$. However, I'm confused exactly construct conditional probability $p(x_t|u_t,x_{t-1}^{[m]})$. Is information usually given? Or constructed distribution particles?",particle-filter
6816,Determine current roomba state / operating mode,"Using SCI messages, I would like determine current operating mode state iRobot Roomba 780. Finally, I would like detect separate four states: Cleaning In docking station Returning docking station Error (e.g. trapped obstacle) What fast reliable way detect states using SCI data? The Roomba SCI Sensor packets ""Remote Control Command"" ""Buttons"" seem return currently called commands currently executed ones.",roomba
6817,Basic general question controllers,"Suppose I mechanical system free move given rail [-5m, 5m] like motorized cart. The whole system mathematically expressed linear timeinvariant system equations. If I need control position (for example saying controller: ""move +2.3"") I simply design PID controller that, given set point moves cart position. Now I need much I want control position velocity cart. So I need example say: ""move +2.3 specific velocity's profile"". Of course vel = 0 end position. Question: I design controller? Do I need specifically special type controller? Or I huge choice? Any help, graph, link example really appreciated. Regards",control pid
6818,Remote Control Relative Driver,"Is possible remote control 'robot' relative driver angle sensor (or sensor)? For example, robot starts position joystick configuration -------------- | Forwards | | [joystick] | | Backwards | -------------- robot turns around, -------------- | Back | | -------- | | |________| | [robot] | Front | -------------- pushing controller forwards still make robot go forward -------------- | ^ | | [joystick] | | Backwards | -------------- -------------- | ^ | | -------- | | |________| | [robot] | Front | -------------- even though robot's POV, he's going backwards. Any ideas/solutions?",control sensors
6821,Is motor current proportional thrust?,"So I making sure circuit airboat I working safe. And checking motor, 35 amps max current running 11.1v 1000. (However ESC 30 current, 40 burst amps). The recommended tested prop 11x9 3-blade runs motor 20 amps. Doing quick calculations via online calculator, appears give value 5.4lbs force (way 2.65 lbs measured, regardless...). When I type prop I want (13x6) gives thrust value 7.53 . Now, motor current proportional thrust, 5.4 lbs / 20 amps = 7.53 / running amps. And therefore amount amps prop would be, theory little less 30 indeed case. Thus safe application. This would also make sense physics terms Power = Current*Voltage proportional thrust, need make sure. So thought process work choosing prop? My device short runs (less 25 seconds), near-boundaries safe...",quadcopter brushless-motor
6822,What link quadcopter transmitter pulse roll/pitch/yaw angles?,"I want design data logger quadcopter using Arduino Mega board. I want record roll, pitch yaw angles second 5 seconds, viewed later flight ended. There's one thing I don't understand, that's translate pitch/roll/yaw angles pulse specific length flight controller receives. For example, I press control pitch, transmitter sends pulse receiver drone speed drones' motors change accordingly pitch either forward backward. I tap commands flight controller transmitter, able record length pulse sent out. However, link pitch angle size pulse? Basically, I convert pulse recorded Arduino board convert pitch angle degrees? Generally, transmitter I use, 1500us-pulse means zero pitch; 1501-2000 means pitch forward, 1000-1499 means pitch backwards (of course, actual values vary slightly, general reference question). So instance, I sent pulse 1400us, would translate angle degrees? What's formula convert it? I hope I'm clear, question sounds stupid, please excuse me, I haven't able find good information it! Thanks!",arduino quadcopter
6824,How tune PIV controller?,"How could I tune PIV controller? I trying get system settling time < 1 second, P.O < 15% zero steady state error.",control
6826,Difference planetary precision gear motors,"i'm working building rover would like advice selecting motors. In particular, want understand difference precision planetary gear motors. My robot way 10-15lbs think would like responsive quick. I two sabertooth 2x12 motor controllers (which supply 12amps). I looking motors sure better choice application. These two sets motors thinking about. googling provide info planetary gears, application two still unclear me. Thanks",mobile-robot motor gearing
6829,Robotics SLAM datasets - scaling factor,"There several robotics datasets SLAM, like one. In webpage see depth image scaled factor 5000, float depth images stored 16 bit png files: I understand value chosen. Why simply 1000, conversion meters millimeters?",slam
6831,I get openinterface.py?,I trying program create2 irobot using python. script called openinterface.py. I download script?,software irobot-create python
6833,Can't connect BeagleBone Webserver?,"I'm following getting started tutorial, connected board USB it's detected mass storage, got driver installed (Win 64), third step I wasn't able connect BeagleBone webserver 192.168.7.2, anything I wrong? Please help. Here troubleshooting info Getting Started page, I've followed all. I'm using Chrome, tried node-webkit based application, Virtual Machine, using SSH trying access webserver. Troubleshooting Do use Internet Explorer. One option browse board use node-webkit based application (currently limited Windows machines): beaglebone-getting-started.zip. Virtual machines recommended using direct USB connection. It recommended use network connections board using virtual machine. When using 'ssh' provided image, username 'root' password blank. Visit additional debugging tips. UPDATE: - I tried install Ubuntu machine connect BeagleBone, need driver I immediately access webserver ejecting mass storage, enabling 'USB-to-Ethernet Interface'. However Windows ejecting mass storage still nothing. Still trying make connect Windows.",beagle-bone
6835,Internal Pullup Sufficient i2c beaglebone Black?,I plan use P8.13 P8.15 beaglebone i2c bitbang mode. Do need use external pull resistors circuit? use internal pull available beaglebone black itself?,beagle-bone circuit
6837,Controlling ESC Brushless Motors RPi,"I'm looking build new (first) quadcopter without conventional flight controller radio, onboard RPi applying newfound knowledge autonomous control improve coding skills. Although, since I've never actually built quadcopter, I don't actually experience using brushless motors. I'll using RPi B+, controlling I2C something I looked into. The B+ though two I2C interfaces. It also two hardware PWM pins I'm unsure whether software PWM would enough. I found Afro SimonK-based ESCs HobbyKing I2C (Intended MikroKopter). I've looked around people used Adafruit 16-channel PWM/Servo drivers control them. Is option look into? Or perhaps better way? Also, would particularly safe RPi run ESC's BEC? It's confusing because, ESC powered on, well, it'll powered RPi comes up. What ESCs bad input?",quadcopter raspberry-pi brushless-motor esc multi-rotor
6838,Implementation wall obstacle avoidance,"I task developing simulation adaptive robot control system I don't seem anyone discuss uncertainties with. I want keep simulation simple possible I tight deadline it's one project probably never used life again. The minimal behaviour agent supposed exhibit wall obstacle avoidance. It extended avoiding small objects exploring large ones. I've decided go simple feedback control system. To begin I'm struggling decide represent map agent's environment. What I mean is, I want wall coordinate [0,0] [0.5]. I could hard code it, e.g. matrix coordinates obstacles small units I make... I.e. I two neighbouring coordinates [0,0.01] [0,0.02] agents gets 'clear go' coordinate [0,0.05]. In case doesn't know actually walk wall. I've heard something called occupancy grid map I don't exactly get works implement it. Another thing I struggling I distinct wall obstacle? And then, I let agent know big obstacle either avoid explore it. Eh, I'm really puzzled project. I would really appreciate thoughts directions. Thank you. :-)",control localization simulation
6842,How calculate center mass Jacobian matrix robot arm,I 4-DOF robot arm system 4 revolute joints arranged open-chain fashion like below: Assume link’s mass point mass located p_i link’s center mass p_i. What I trying calculate center mass Jacobian matrix arm. I found related materials online Center Mass Jacobian.But I still sure calculate it. Could anybody give hint? Thanks!,robotic-arm jacobian
6843,Sporadic sensing rates hc-sr04 ultrasonic distance sensor,"Been working robot recently uses ultrasonic sensors integral part navigation. While testing sensors I noticed strange behaviour, sensors seem frequently stop functioning bring entire Arduino Mega I'm working stop. The strange part stops seem entirely random, occasions sensor read values consistently (at maybe 20 vals per second) 10+ seconds, sudden sensor slow reading 2-3 values per second stalls between. I tested several sensors different codes pinging distances yet problem persisted. This leads believe issue arduino mega itself, I unsure verify this. Any advice? Thanks advance! PS: pins Mega seem working fine, i.e. analog pins IR reflectance sensors PWM pins driving 2 DC motors.",arduino ultrasonic-sensors
6844,aerodynamics quadcopter,"I want build quad copter. I want know calculate thrust lift generated using motor, I aware capacities motor. So explain calculate thrust lift generated assuming motor. And maximum payload quad copter lift given thrust.",quadcopter
6845,Recommendation good source Robotic Components,"Im looking good source robotic components like sheel/tracked robot chasis, motors, sensors, communication mechanics. I thought using raspberry arduino platforms automation, good idea? Im asking dont know yet much motors/drives uses powering robots. Thanks! Uli",mobile-robot motor
6846,Datalogging Arduino Mega Dropbox,"I Arduino Mega board Adafruit Ultimate GPS Logger + GPS module shield. I two connected together using headers entire thing mounted drone. Currently, I code I found online modified slightly get GPS coordinates NMEA format parse information I actually want. I store SD card. The thing is, I want use Arduino GSM shield somehow send data, either SD card directly, folder Dropbox. I idea that, it's possible all. I started working Arduino month ago, I apologize question sounds particularly noob-ish. Could anyone forum least guide approach problem? Thanks!",arduino gps
6849,Graph optimization G2O,"I'm trying graph optimization G2O, mainly order perform loop closure. However finding minimal working examples online issue (I've found project, well one. The second one though form library, one cannot really see author uses things.) In contrast online loop closure, people update optimize graph every time detect loop, I'm graph optimization once, pairwise incremental registration. So case, pairwise registration global, graph-based optimization two separate stages, result first input second. I already working solution, way works quite different usual use g2o: As nodes I identity matrices (i.e. I consider pointclouds already transformed poses pairwise reg. step) edges, I use relative transformation based keypoints pointclouds (also keypoints transformed). So case I penalize deviations relative pose identity matrix. As Information matrix (inverse covariance) I simply use 6x6 identity matrix multiplied number found correspondences (like case). The result graph update matrix, i.e. I multiply camera poses. Although works many/most cases, quite unusual approach, one cannot draw graph debugging (all nodes identities beginning, result optimization 3d path), means something goes wrong getting intuition always easy. So I'm trying follow classic approach: The vertices/nodes poses pairwise registration The edges relative transformations based keypoints/features raw pointclouds (i.e. camera frame, transformed poses pairwise registration) The output new poses, i.e. one simply replaces old poses new ones Drawing graph case makes sense. For example case scanning object turntable, camera poses form circle 3d space. I'm trying form edges optimize one stage (this doesn't mean 1 LM iteration though). However I cannot make things running nicely 2nd approach. I've experimented lot direction edges relative transformation used measurement edges, everything looks expected, still luck. For simplicity I still use information matrix mentioned above, 6x6 identity matrix multiplied number correspondences. In theory information matrix inverse covariance, I don't really simplicity (plus, following way compute covariance easy). Are minimal working examples I'm aware of? Is something fundamentally wrong I describe above? Are rules thumb (e.g. first node approaches fixed) I follow I might aware them? Update: More specific questions The nodes hold poses robot/camera. It unclear though reference frame defined. If world coordinate frame, defined according camera according object, i.e. first acquired pointcloud? This would affect accumulation pose matrices incremental registration (before g2o stage - I try form optimize graph end, frames/pointclouds). The edge (Src->Tgt) constraints hold relative transformation pointcloudSrc pointcloudTgt. Is transformation based features two local coordinate frame pointcloudSrc? Is tricky point regarding direction, consistency relative transformation enough? The first node always fixed. Does fixed node affect direction edge departs/ends_up from/at fixed node? Is tricky point could hinter implementation? I'm working millimeter instead meter units, I'm sure affect solvers g2o way. (I wouldn't expect so, naive use g2o giving usable results influenced)",slam
6852,I need specifications iRobot Create 2,I need specifications Create 2. I need research purposes. So I think I'm going need high computational computer board. Please suggest nice configuration.,irobot-create
6853,Dock command seem work,We bought new Create2 robot started using it. But issue dock command robot moves bit go back base. The base hidden obstructed create2 couple feet away. need help figure see base. Just clarify even using DOCK button create2 make create2 go back base,irobot-create
6854,specifications graph showing battery discharges volt per time,"name dylan project irobot create would like know specifications graph showing battery discharges volt per time robot irobot ceate 1. The battery roomba advanced power , it's 14.4V Nickel metal hybride battery pack deliver 3000mah.",irobot-create
6859,implement tracking problem PID controller,"I'm trying implement tracking problem example using PID controller. The dynamic equation $$ I \ddot{\theta} + \dot{\theta} + mgL \sin(\theta) = u $$ $\theta$ : joint variable. $u$ : joint torque $m$ : mass. $L$ : distance centre mass joint. $d$ : viscous friction coefficient $I$ : inertia seen rotation axis. $\textbf{Regulation Problem:}$ In problem, desired angle $\theta_{d}$ constant $\theta(t)$ $\rightarrow \theta_{d}$ $\dot{\theta}(t)$ $\rightarrow 0$ $t$ $\rightarrow \infty$. For PID controller, input $u$ determined follows $$ u = K_{p} (\theta_{d} - \theta(t)) + K_{d}( \underbrace{0}_{\dot{\theta}_{d}} - \dot{\theta}(t) ) + \int^{t}_{0} (\theta_{d} - \theta(\tau)) d\tau $$ The result code clear clc global error; error = 0; = 0:0.1:5; x0 = [0; 0]; [t, x] = ode45('ODESolver', t, x0); e = x(:,1) - (pi/2); % Error theta plot(t, e, 'r', 'LineWidth', 2); title('Regulation Problem','Interpreter','LaTex'); xlabel('time (sec)'); ylabel('$\theta_{d} - \theta(t)$', 'Interpreter','LaTex'); grid ODESolver.m function dx = ODESolver(t, x) global error; % PID controller dx = zeros(2,1); %Parameters: = 0.5; % mass (Kg) = 0.0023e-6; % viscous friction coefficient L = 1; % arm length (m) I = 1/3*m*L^2; % inertia seen rotation axis. (Kg.m^2) g = 9.81; % acceleration due gravity m/s^2 % PID tuning Kp = 5; Kd = 1.9; Ki = 0.02; % u: joint torque u = Kp*(pi/2 - x(1)) + Kd*(-x(2)) + Ki*error; error = error + (pi/2 - x(1)); dx(1) = x(2); dx(2) = 1/I*(u - d*x(2) - m*g*L*sin(x(1))); end $\textbf{Tracking Problem:}$ Now I would like implement tracking problem desired angle $\theta_{d}$ constant (i.e. $\theta_{d}(t)$); therefore, $\theta(t)$ $\rightarrow \theta_{d}(t)$ $\dot{\theta}(t)$ $\rightarrow \dot{\theta}_{d}(t)$ $t$ $\rightarrow \infty$. The input $$ u = K_{p} (\theta_{d} - \theta(t)) + K_{d}( \dot{\theta}_{d}(t) - \dot{\theta}(t) ) + \int^{t}_{0} (\theta_{d}(t) - \theta(\tau)) d\tau $$ Now I two problems namely compute $\dot{\theta}_{d}(t)$ sufficiently read txt file since step size ode45 fixed. For first problem, I use naive approach $$ \dot{f}(x) = \frac{f(x+h)-f(x)}{h} $$ error getting bigger step size small enough. The second problem desired trajectory stored txt file means I read data fixed step size I'v read ode45 step size fixed. Any suggestions! Edit: For tracking problem, code main.m clear clc global error theta_d dt; error = 0; theta_d = load('trajectory.txt'); = 1; t(i) = 0; dt = 0.1; numel(theta_d) ( < numel(theta_d) ) = + 1; t(i) = t(i-1) + dt; end x0 = [0; 0]; options= odeset('Reltol',dt,'Stats','on'); [t, x] = ode45(@ODESolver, t, x0, options); e = x(:,1) - theta_d; % Error theta plot(t, x(:,2), 'r', 'LineWidth', 2); title('Tracking Problem','Interpreter','LaTex'); xlabel('time (sec)'); ylabel('$\dot{\theta}(t)$', 'Interpreter','LaTex'); grid ODESolver.m function dx = ODESolver(t, x) persistent theta_dPrev isempty(i) = 1; theta_dPrev = 0; end global error theta_d dt ; dx = zeros(2,1); %Parameters: = 0.5; % mass (Kg) = 0.0023e-6; % viscous friction coefficient L = 1; % arm length (m) I = 1/3*m*L^2; % inertia seen rotation axis. (Kg.m^2) g = 9.81; % acceleration due gravity m/s^2 % PID tuning Kp = 35.5; Kd = 12.9; Ki = 1.5; ( == 49 ) = 48; end % theta_d first derivative theta_dDot = ( theta_d(i) - theta_dPrev ) / dt; theta_dPrev = theta_d(i); % u: joint torque u = Kp*(theta_d(i) - x(1)) + Kd*( theta_dDot - x(2)) + Ki*error; error = error + (theta_dDot - x(1)); dx(1) = x(2); dx(2) = 1/I*(u - d*x(2) - m*g*L*sin(x(1))); = + 1; end trajectory's code clear clc = 0:0.1:(3*pi)/2; file = fopen('trajectory.txt','w'); = 1:length(a) fprintf(file,'%4f \n',a(i)); end fclose(file); The result velocity Is correct approach solve tracking problem?",control pid dynamics
6860,DYNAMIXEL MX-106-R burnt,"I using MX 106-R dynamixel servo project making. I making robotic arm controlled servo. I accidentally moved horn servo hence due excess current input, wont work anymore. I suspect H-bridge inside motor got burnt. Can somebody tell exactly went wrong ? How test motor ? How repair (if possible) else find service centre (I live India). I deep trouble right now. Please Help !",robotic-arm servos h-bridge
6862,How calculate real time RPM motor rotary encoder?,I want measure real time RPM wheels. I think incremental rotary encoder would good. But confused interface DC brushless geared motors. From images quite sure one rotary encoder would suffice need sensor also it? I project arduino uno.,motion forward-kinematics quadrature-encoder
6863,What wireless technology use control robots classroom?,"I want build cheap robot programmable Scratch graphical language, could employed lessons school. Scratch code interpreted PC, robot code receives specific commands (i.e. drive forward) transmits sensors' measurements. I'm looking wireless technology allow exchange information robot PC least 30Hz rate. It also allow work least 16 robots simultaneously room range least 20m. I tests BLuetooth, sometimes connectivity issues, pairing devices hassle classroom. I also tried WiFi modules, pinging showed average time 19ms, maximum 500ms, I'm afraid won't able control linefollower robot example. Can point other, preferably cheap (under 10$ per module) wireless technologies? Or maybe worries WiFi exaggerated?",mobile-robot radio-control wireless wifi
6869,Roomba Create 2 problem reading distance traveled,"I trying work create2. In using ""get distance traveled"" command (id 142) I getting back incorrect data. My simple test case logic I working Create2_TetheredDrive.py example adding I consistently numbers near -25 moving forward, +25 moving backward. If I wait 2 seconds, I get -50 moving forward, +50 moving backward. The documentation says return distance traveled mm, numbers seem factor -8. Anyone suggestions? Thanks. p.s. I add function example well def recv_basic(the_socket): the_socket.settimeout(0.1) total_data=[] True: try: data = the_socket.recv(8192) total_data.append(data) except: break return ''.join(total_data)",irobot-create
6870,Controlling iRobot Create 2 MATLAB,"I teach university sophomore level MATLAB programming class engineers, I planning using create2 final project. There nice simulator MATLAB toolbox Create, toolbox utilizes commands longer exist Create 2, thus doesn't work correctly. And course doesn't support newer commands. In addition, I want able ""cut cord"" I using Raspberry Pi Create pipe data serial port, TCPIP sockets send data remote computer running MATLAB Pi/Create. If anyone working similar configuration, I'd love trade notes share pain.",irobot-create
6880,Monocular vs. stereo computer vision robustness object detection,"Are genaral rules robustness monocular stereo vision considering object detection? I especially interested automotive field - considering distance/obstacle/car detection (see video links below). Someone told monocular vision robust stereo. I guess may true monocular algorithm well written (and especially verified lots input data)... input (image) data verified may probably provide unexpected results, right? With stereo vision one really care contents image long texture/lighting conditions allow stereo matching object detection done within point cloud. I consider following usage: Monocular Stereo The monocular sample video seems sometimes problems detecting cars front (the bounding boxes disappear while). The stereo sample seems robust - car front clearly detected sequnce image frames.",computer-vision stereo-vision
6882,Calculating acceleration velocity,"I'm writing Quad Copter software beginning implement altitude hold mode. To enable I need get accurate reading vertical velocity. I plan use Kalman filter first I need ensure I'm getting correct velocity individual sensor. I done I'm 100% sure correct I hoping get confirmation here. My first sensor Lidar distance sensor, I calculated acceleration velocity using following code: The second sensor accelerometer. I calculated acceleration velocity using following code: Imu::Acceleration Imu::getAcceleration() { //Get quaternion float q[4]; _freeImu.getQ(q); //Get raw data float values[9]; _freeImu.getValues(values); //Extract accelerometer data float acc[3]; acc[0]= values[0]; //x acc[1]= values[1]; //y acc[2]= values[2]; //z //Gravity compensate _freeImu.gravityCompensateAcc(acc, q); //Convert acceleration G cm/s/s _acceleration.x = acc[0] * 9.8 * 100; _acceleration.y = acc[1] * 9.8 * 100; _acceleration.z = acc[1] * 9.8 * 100; return _acceleration; //cm/s/s } //Time since last update float time = (1.0 / ((float)FLIGHT_CONTROLLER_FREQUENCY / 10.00)); // 50Hz, 0.02s //Get accel Imu::Acceleration imuAcceleration = _imu->getAcceleration(); //Get velocity currentZVelocity += imuAcceleration.z * time; //cm/s It would great someone could confirm correct (or not) Thanks Joe",sensors accelerometer lidar
6890,Verifying motor selection calculations,"I'm trying select brushed DC motor project. I tried following advice sizing electric motors, mentioned question, details missing, I'm unsure I properly followed procedure. For application, I need: Nm = number motors = 2 Wd = wheel diameter = 12 cm Wp = estimated weight platform = 5 kg Minc = maximum incline load = 5 degrees Vmax = maximum velocity load = 5 km/hr Fpush = maximum pushing force = 1.25 kg Ur = coefficient rolling friction = 0.015 These calculations: Step 1: Determine total applied force worst case. Step 2: Calculate power requirement. Vradps = maximum velocity load radians/second = 23.1481481481 radian / second Pmotor = required power per motor = (Ftotal * Vradps * Wd/2)/Nm = 1.22256480284 kilogram * meter * radian / second Step 3: Calculate torque speed requirement. Tmotor = required torque per motor = Pmotor/Vradps = 5281.47994829 centimeter * gram = 73.345953832 inch * ounce RPMmin = required revolutions per minute per motor = Vradps / 0.104719755 = 221.048532325 rev / minute Are calculations correct? Intuitively, final Tmotor RPMmin values seem right, calculation Pmotor doesn't exactly match one used link, doesn't explicitly conversion radians / second therefore doesn't result proper units. Here's Python script reproducing calculations: math import * # pint import UnitRegistry ureg = UnitRegistry() def velocity_to_rpm(v, r): kph = v.to(kilometer/hour) r = r.to(kilometer) = r*2 rpm = (kph / (2*pi*r)) * ((1*hour)/(60.*minute)) * rev return rpm def velocity_to_radps(v, r): return velocity_to_rpm(v, r).to(radian/second) # Units km = kilometer = ureg.kilometer meter = ureg.meter newton = ureg.newton cm = centimeter = ureg.centimeter hr = hour = ureg.hour mm = millimeter = ureg.millimeter rev = revolution = ureg.revolution minute = ureg.minute sec = second = ureg.second kg = kilogram = ureg.kilogram gm = gram = ureg.gram deg = degree = ureg.degree rad = radian = ureg.radian oz = ureg.oz inch = ureg.inch # Conversions. km_per_mm = (1*km)/(1000000.*mm) hour_per_minute = (1*hour)/(60.*minute) minute_per_second = (1*minute)/(60*sec) minute_per_hour = 1/hour_per_minute gm_per_kg = (1000*gm)/(1*kg) cm_per_km = (100000*cm)/(1*km) # Constraints target_km_per_hour = (5*km)/(1*hour) # average walking speed estimated_platform_weight = 5*kg maximum_incline_degrees = 5*deg maximum_incline_radians = maximum_incline_degrees * ((pi*rad)/(180*deg)) maximum_pushing_force = estimated_platform_weight/4. maximum_velocity_at_worst_case = (5*km)/(1*hour) rolling_friction = 0.015 # rubber pavement velocity_under_max_load = target_km_per_hour number_of_powered_motors = 2 # Variables wheel_diameter_mm = 120*mm wheel_radius_mm = wheel_diameter_mm/2 wheel_radius_km = wheel_radius_mm * km_per_mm rev_per_minute_at_6v_unloaded = 33*rev/(1*minute) rev_per_minute_at_6v_loaded = rev_per_minute_at_6v_unloaded/2. mm_per_rev = (wheel_diameter_mm * pi)/(1*rev) target_rpm = velocity_to_rpm(target_km_per_hour, wheel_radius_mm) target_radps = velocity_to_radps(target_km_per_hour, wheel_radius_mm) # Calculate total applied force worst case. total_applied_force_worst_case = estimated_platform_weight * (rolling_friction*cos(maximum_incline_radians) + sin(maximum_incline_radians)) + maximum_pushing_force print 'Ftotal:',total_applied_force_worst_case # Calculate power requirement. vel_in_radps = velocity_to_radps(velocity_under_max_load, wheel_radius_mm) print 'Vradps:',vel_in_radps required_power = total_applied_force_worst_case * velocity_to_radps(velocity_under_max_load, wheel_radius_mm) * wheel_radius_mm.to(meter) required_power_per_motor = required_power/number_of_powered_motors print 'Pmotor:',required_power_per_motor # Calculate torque speed requirement. required_angular_velocity = velocity_under_max_load/wheel_radius_km * hour_per_minute * minute_per_second * rad #rad/sec required_rpm = required_angular_velocity / 0.104719755 * (rev/rad) * (sec/minute) required_torque_per_motor = (required_power_per_motor/required_angular_velocity).to(gm*cm) print 'Tmotor: %s, %s' % (required_torque_per_motor, required_torque_per_motor.to(oz*inch)) print 'PRMmin:',required_rpm",mobile-robot motor design torque force
6895,RGB-D SLAM - Compute Information Matrix,"currently im working RGB-D SLAM Kinect v1 Camera. In front-end SLAM estimates pose Ransac initial guess ICP. With pose estimation transform pointcloud pointcloud-scene represents map. To smooth map im trying implement graph optimizing algorithm (g2o). Until now, graph representation frontend, started integrate that. Im trying build .g2o file following fromat: VERTEX_SE3 x z qx qy qz qw x, y, z translation qx, qy, qz, qw ist Rotation respect initial coordinate system. And, EDGE_SE3 observed_vertex_id observing_vertex_id x z qx, qy, qz, qw inf_11 inf_12 .. inf_16 inf_22 .. inf_66 Translation rotation edge pose estimate compute Ransac ICP (visual odometry). Now im getting stuck information matrix. I read chapter 3.4 THE INFORMATION FILTER Thrun's Probabolistic Robotics several threads forum, as: The relationship point cloud maps graph maps information filter instead kalman filter approach From second link, got here. The covariance update $$P_{+} = (I-KH)P$$ expanded definition K $$ P_{+} = P - KHP$$ $$ P_{+} = P - PH^T (HPH^T+R)^{-1} HP$$ Now apply matrix inversion lemma, have: $$P_{+} = P - PH^T (HPH^T+R)^{-1} HP$$ $$ P_{+} = (P^{-1} + H^TR^{-1}H)^{-1}$$ Which implies: $$ P_{+}^{-1} = P^{-1} + H^TR^{-1}H$$ The term $P^{-1}$ called prior information,$$H^TR^{-1}H$$ sensor information (inverse sensor variance), gives us $P^{-1}_+$, posterior information. Could please point me. What data need compute information matrix?",slam kinect matlab
6896,Jacobian transpose: calculate orientation error,"I'm confused compute error orientation. All documents I've read don't explain it. The error position simply difference points. Let's assume orientation along effector axis, represent rotation quaternions. I two questions: Is describing orientation quaternions good approach? How compute error orientation quaternions use jacobian transpose?",inverse-kinematics jacobian
6900,Low power motors -- motor power jumper issue,"I'm currently working first robotics project using Initio kit 4tronix powered Raspberry Pi. The setup fairly simple, I've testing last couple days. All sensors work expected; however, motor tests failing. When I input commands actually move robot, I hear DC motors running they're getting enough power anything. In instructions, says issue encountered, power selection jumper might set correctly provides diagram: For comparison, here's I wiring motors setup: I'm entirely sure means power selection jumper set incorrectly would greatly appreciate someone could explain point see anything wrong setup.",mobile-robot motor raspberry-pi first-robotics
6905,"SLAM noob here, questions regarding EKF-SLAM","I've recently learning SLAM attempting implement EKF-SLAM python. I've using great article guide. Some progress made, I'm still confused certain stages. Firstly, inverse sensor model compute range bearing, opposed cartesian coordinates? Why approach used? Secondly, format robot provide heading in? Currently I use running offset origin angle (0), without wrapping 0 360. Turning right yields positive degrees, left negative. I ask I assume sensor model expects certain format. Thirdly, computing jacobians adding new landmarks, (page 35) Jz simply absolute rotation robot (-540 degrees example) plus bearing landmark detected at? And finally, what's best approach managing huge covariance matrix? I'm currently thinking good way 'expand' P adding new landmarks. Here's current implementation: Any help would much appreciated! Thanks.",slam ekf python
6906,Quadcopter Propeller size + Motor,"would like build quad uses bigger propellers like 15"" . My question kind motor shall use ? Low high KV? Do motors support kind propellers ? Will burn ?I found say CW CCW motors mean can't set way spin ? I'm totally new thank answer . okey given one able hold 15"" prob since it's description shall get 12A ESC since 15 size prob used max 8.8 shall get 25A ESC cause max continous 20 ?",quadcopter brushless-motor
6908,"EKF-SLAM, best manage 'P' covariance matrix, programatically","I've recently learning SLAM EKF-SLAM. I've began implementation python, trouble managing updating P, especially comes adding new landmarks. Currently 'P' separate matrices I stitch together needed. My implementation seen here: How best I manage large covariance matrix, I using one matrix, like algorithm suggests? Thanks advance.",slam ekf python
6909,EKF-SLAM Computing jacobians landmark updates,"I've working informative guide EKF-SLAM I'm difficulty understanding jacobians required 'landmark update', page 35. What exactly Jxr Jz taking input? Is taking current rotation robot, plus addition odometry update? IE, rotation stored 'X' state vector. Or taking angle Inverse Sensor Model, so, what's 'delta' angle from? Thanks.",slam ekf python
6910,How find theta1 theta5 D-H parameter,"I confused right way look theta1-theta5. Probably offset limit angles calculation x0 x5 angle rotation atan2(x,y).",robotic-arm dh-parameters
6913,What reduced form block diagram?,What reduced form block diagram? I can't see solution way :(,control
6918,How I work kinematic solution robot arm?,"I draw robotic arm Solidworks, I'm sure find DOF, forward backward kinematic. Could anyone help understand work kinematic solution robot arm?",robotic-arm kinematics automatic matlab
6922,How possible maintain total thrust controlling yaw quadcopter?,"I'm working control quadcopter I'd like understand come controlling yaw increase overall thrust. My understanding control carried 2 PIDs per axis (roll, pitch yaw). The output last PID sent PWM signal correct rotor speeds propellers. The mixing looks something like that: $T_{FrontLeft} = thrust + roll_{pid} + pitch_{pid} + yaw_{pid}$ $T_{FrontRight} = thrust - roll_{pid} + pitch_{pid} - yaw_{pid}$ $T_{RearLeft} = thrust + roll_{pid} - pitch_{pid} - yaw_{pid}$ $T_{RearRight} = thrust - roll_{pid} - pitch_{pid} + yaw_{pid}$ All quadcopter controls seem work way I could gather. So basic idea control yaw add $yaw_{pid}$ clockwise motors substract amount $yaw_{pid}$ counterclockwise motors make quadcopter turns clockwise. Which translates increase speed clockwise motors decrease speed counterclockwise motors amount. But know motor produces thrust torque according equations: $T = C_T\rho n^2 D^4$ $Q = C_Q\rho n^2 D^5$ $T$ thrust, $Q$ torque, $C_T$ $C_Q$ system dependent constants, $ρ$ air density, $n$ rotor speed, $D$ rotor diameter. Which means thrust produced motor proportional propeller speed squared. So $n$ speed propellers correction, thrust clockwise propellers correction proportional $(n+\Delta)^2$ thrust produced counterclockwise propellers $(n-\Delta)^2$. The total thrust 2 propellers proportional to: $(n+\Delta)^2 + (n-\Delta)^2 = 2n^2 + 2\Delta^2$ As see, increase $2\Delta^2$ overall thrust produced 2 propellers (and $4\Delta^2$ take 4 propellers account). Of course, real life, control yaw quadcopter go up. So I missing? (the stands roll pitch control since quadcopter turns around roll pitch axis, total thrust longer entirely vertical axis I could imagine projection vertical axis increasing, work yaw)",control quadcopter torque
6927,"How important events like ""Robocup"" advancement Robotics general?",Are events like Robocup advantageous development robotic advancement? Or merely entertainment advances robotics allowing entry level participation helps maintain interest? Do DARPA Grand's provide better vehicle advancement? (pun intended),design
6929,How send commands create 2 Bluetooth,I'm new create 2. I want send commands using Bluetooth. I already bought bluetooth USB radio. What devices I need get I set sending commands bluetooth. Any help appreciated. Thanks.,irobot-create
6931,Simulate IMU (2D gyro accelerometer) data,"If I robot path 2D space, i.e. vector (x,y) locations, I need generate artificial IMU data (simulate them), would I go it? How I model equations generate values given time frame positions? I've come across imusim I'd like know model generate using Matlab something similar.",imu accelerometer gyroscope simulation
6934,Glasses eye sensors,"Someone could tell wearable devices glasses, sensors detect eye movement? In particular, I would need device like google glass, sensor camera facing eye, capture movement, possibly interfaced mobile device. Alternatively, micro-cameras market, connected via Bluetooth USB mobile device?",sensors motion
6936,joint positions robot,"I would likte find joints positions using joint angles, link lengths etc. How I define position joint using DH parameters?",robotic-arm joint dh-parameters
6942,How set binocular cameras car?,"I trying set stereo vision system car. However, I meet several problems know solve them. How select baseline? I want distance measurement far 30 50 meters near around 5-10m. Is possible choose baseline meets requirement? I tried stereo calibration two cameras also learned compute depth value disparity map. However I don't know compute depth value focal lengths two cameras different. It seems theorems I find Web concern cameras focal length.",stereo-vision
6944,Dynamically detect changing obstacles,"So idea would one robot acting overwatch, would detect obstacles area (which necessarily static), send data obstacles' positions another robot would navigate around obstacles goal. My initial thought overwatch robot elevated position centre area, sweep around using ultrasonic sensor. This way, could keep track obstacles set polar coordinates (distance, angle). But I realised method doesn't account collinear obstacles. So question is, best way detect bunch non-static obstacles within area? As side note, I seen system similar this, robot detecting obstacles (in case, crowd people) another robot pathfinding around obstacles (the people), I'm unsure exactly system detecting obstacles.",sensors computer-vision sonar ultrasonic-sensors
6945,Help dimension right controller following Tranfer Function,"I generic problem create controller following system: $$\ddot{x}(t) = y(t)$$ $a$ constant real value. The system could seen equivalent mass-spring-damper system, damper spring removed. Also $x(t)$ $x$ dimension $y$ simply force moving mass. BUT case I need drive force using $x(t)$ contrary. Transforming according Laplace I get: $$ y(t) = \frac{1}{a}\ddot{x}(t)$$ $$ Y(s) = \frac{1}{a}s^{2}X(s)$$ $$ G(s) = \frac{Y(s)}{X(s)} = \frac{s^{2}}{a}$$ Considering $a = 1$ I implemented possible example Simulink. Please I put output given scope showing resulting answer system. So I 2 questions: Is possible develop system? As far I know degree numerator $=<$ degree denominator. So system possible? Is possible create PID PD controller stabilize output system? Regards",control pid matlab
6946,Square hinge four sides,"I want make component square plate behave like motorized hinge four sides. That is, ""open"" pivoting around one four sides. I want pivot 45 degrees. I thought designing 3 hinges could detached one pivots, I wonder there's simpler way this.",design motion
6952,Using Bitmap maze image navigate maze,"I'm working robot would able navigate maze, avoid obstacles identify objects it. I monochromatic bitmap maze, supposed used robot navigation. I first year electrical engineering student, need help I use bmp image. I making robot using Arduino mega microcontroller. So I get started it. If need elaborate anything kindly say so. Link:",arduino control localization
6953,How calculate Euler Angles gyroscope output?,I using tri-axis accelerometer tri-axis gyroscope measure linear acceleration body. I need get orientation body euler form order rotate accelerometer readings body frame earth frame. Please help I'm stuck,accelerometer gyroscope frame
6955,make robot move using arduino timing predefined locations?,make robot move using arduino timing predefined locations? without use sensors?? I want make car move different loactions board..want know possible options without using sensors encoders?? And cartesian robot work predefined locations..does require sensor too?,arduino navigation
6956,using range-only sensors mapping SLAM,"SLAM noob trying implement algorithm fuses odometry data mapping based wifi signal strengths 2D robot. 1) After various readings different resources, I came across - explained sensors used mapping categorized. There range-bearing sensors (stereo cameras,RGB-d cameras) provide distance angle (range bearing), easy locate (x,y) coordinates landmarks ---> I develop map. But case I'm using wifi signal strengths (Received signal strengths) etc, case range-only (meaning, I establish robot pose(x,y,theta) far signal coming from), I developing map all? My question similar - What algorithm I use constructing map explored area using number ultrasound sensors? quite same. Even I using IMU/GPS, I using GPS develop map? What state space there? If I getting GPS signals / wifi signals/ radio signals, I estimating transmitter/AP's location map? walls room I'm navigating in, map? A lot SLAM literature talks motion model measurement model, former gives pose robot quite easily odometry imu. The latter though development map. Am I right understanding this? If yes, say a] I walls room I'm using Lidar scanner - still gives location wall using number beams give bearing, average distance beams. b] Or I single laser scanner, I still use camera (distance) heading robot calculate location wall (the map). But If I wireless signal strengths, I distance (distance transmitter I'm getting RSS, distance wall) coming from. But I estimating location walls here? 2) What term ""correspondences"" mean SLAM literature?",localization slam artificial-intelligence mapping wireless
6957,Micro Quadcopter PID problem,"I designed mini quadcopter 4.5x4.5cm(Main Body). The main body PCB. ![enter image description here][1] It weighs ~20 grams battery. I'm using MPU6050 DMP using i2cDevLib. I using raw radians pitch, roll, yaw measures read MPU6050's DMP. The motors attached body using electrical tape(Black thing around motors). The motors 8.5mm diameter driven n-channel mosfet. The mode control right bluetooth(HC-05 module). The code used own. I control loop axes, pitch roll values since quadcopter symmetrical. The problem I PID tuning next impossible, best I got ~2 second flight ([Video slow-motion][2]). At first I using code control loop, wasn't effective Arduino PID library. The output PID loops mapped -90 90 axes. This seen code My full code below, think problem is? Code",arduino quadcopter pid
6969,Shallow underwater wireless sensor network,"I need make shallow (max 2m) underwater wireless sensor network. Data payload 10kB/s. I know VLF band (~3-30kHz)could best solutions that, cause time-to-market I cannot make hardware software ground. Maybe someone could share own-self experience filed. If band 100-900MHz could enough send 10kB/s one device another - 2m underwater dozen cm water surface? Maybe IC ultrasonic communication exist? Another ideas?",sensors wireless communication
6979,Question dynamic window approach?,"I mobile robot plan use dynamic window approach collision avoidance. I read paper ,but one inequality can't derive it. could tell me? thanks!",navigation motion-planning
6980,Beaglebone accessible LAN?,"Since day I bought I always use ethernet USB connection, I need use RJ45 LAN cable connect Beaglebone laptop, laptop can't even detect LAN connection it, could go wrong? Do I need straight crossover cable? Do I need configure something first BeagleBone? UPDATE: Managed connect Crossover cable assign IP address running DHCP server laptop. As seen laptop assign IP 169.254.223.76, I tried connect IP using puTTY gives connection refused. Please help.",beagle-bone
6982,EKF over-correcting?,"I've implementing extended kalman filter, following Thrun's Probabilistic Robotics implementation. I believe correct step may wrong, state appears corrected far much. Here's screen capture showing issue Note, bottom status reading 'corrected' pose coordinates. This correct step: h = The range bearing state landmark. q = (landmark.x - self.X[0])^2 + (landmark.y - self.X[1])^2 My sensor covariance errors 1cm per meter, pi/180 bearing. My assumption correction relative size robot's pose error. Which small example, moved forward less 30cm. Is kalman gain applied correctly here, yes, factors would result 'over-correcting'? Thanks.",slam ekf python
6984,Mapping algorithm without noise,"I simulated robot moving discretized 2D grid world (for various simplification time-restriction reasons) noise. The problem robot creates initial map world. Algorithms like SLAM occupancy grid mapping based uncertainty, case uncertainty. So I'm wondering relatively simple algorithm mapping environment noiseless position.",mapping
6985,Enable Bluetooth Adapter BeagleBone Black,"I recently bought USB 2.0 Bluetooth Adapter. It claims support Linux kernels versions 3.4 higher. I BeagleBone Black Debian GNU/Linux 7 image kernel 3.8. I developing BeagleBone Black hosting USB . I tried hot plugging plugging boot failed. Then, I tried tutorial. However, I cannot find connman directory BeagleBone Black device. I looked assumed I needed install connman package, BeagleBone Black internet access. I also tried lsusb -v, suggested answer similar question this, luck. The weird thing is, lsusb prints Bus 001 Device 001: ID 1d6b:0002 Linux Foundation 2.0 root hub Bus 002 Device 001: ID 1d6b:0002 Linux Foundation 2.0 root hub lsusb -v prints Bus 001 Device 001: ID 1d6b:0002 Linux Foundation 2.0 root hub hangs. Information regarding bus 002, I believe device connected to, printed. I restart ssh connection get back work. How I approach get dongle work BeagleBone Black? If connman package sufficient, I install BeagleBone Black without internet access. Why lsusb -v hang? Any help appreciated!",beagle-bone
6987,Calculating thrust generated electric engines,I wanted calculate amount thrust generated engines. I using blade 180 cfx model. After research I found way calculate thrust using: T = ( pi D^2 rho P^2)/2 P Power multiplier calculated using: P= prop constant * (rpm/100)^power factor I unable find values Prop constant power factor. Is way I get information? Or alternative way calculate thrust generated?,power
6990,Detect polyethylene,"First all, I high school[to tell I newbie lack knowledge] What I want achieve thing differentiate poly bags[polyethylene] stuffs. Or thing could detect polyethylene. I built robot therefore method accessible. Anyway knowledge suggestion external links provided you, topic would welcomed me.",mobile-robot sensors
6992,My PID Controller Java operating correctly,"I looking implementation PID controller Java I found one: So, I could understand I using way: But never stabilizes. He doesn't behave like PID all... This output I get: Input: 30.0 | Output: 100.0 | Error: 90.0 Input: 130.0 | Output: 50.0 | Error: -10.0 Input: 80.0 | Output: 100.0 | Error: 40.0 Input: 130.0 | Output: 50.0 | Error: -10.0 Input: 80.0 | Output: 100.0 | Error: 40.0 Input: 130.0 | Output: 50.0 | Error: -10.0 Input: 80.0 | Output: 100.0 | Error: 40.0 Input: 130.0 | Output: 50.0 | Error: -10.0 Input: 80.0 | Output: 100.0 | Error: 40.0 Input: 130.0 | Output: 50.0 | Error: -10.0 Input: 80.0 | Output: 100.0 | Error: 40.0 Input: 130.0 | Output: 50.0 | Error: -10.0 Input: 80.0 | Output: 100.0 | Error: 40.0 Input: 130.0 | Output: 50.0 | Error: -10.0 Input: 80.0 | Output: 100.0 | Error: 40.0 Input: 130.0 | Output: 50.0 | Error: -10.0 Input: 80.0 | Output: 100.0 | Error: 40.0 Input: 130.0 | Output: 50.0 | Error: -10.0 Input: 80.0 | Output: 100.0 | Error: 40.0 Input: 130.0 | Output: 50.0 | Error: -10.0 Input: 80.0 | Output: 100.0 | Error: 40.0 Input: 130.0 | Output: 50.0 | Error: -10.0 Input: 80.0 | Output: 100.0 | Error: 40.0 Input: 130.0 | Output: 50.0 | Error: -10.0 Input: 80.0 | Output: 100.0 | Error: 40.0 Input: 130.0 | Output: 50.0 | Error: -10.0 Input: 80.0 | Output: 100.0 | Error: 40.0 Input: 130.0 | Output: 50.0 | Error: -10.0 Input: 80.0 | Output: 100.0 | Error: 40.0 Input: 130.0 | Output: 50.0 | Error: -10.0 Input: 80.0 | Output: 100.0 | Error: 40.0 Input: 130.0 | Output: 50.0 | Error: -10.0 Input: 80.0 | Output: 100.0 | Error: 40.0 Input: 130.0 | Output: 50.0 | Error: -10.0 Input: 80.0 | Output: 100.0 | Error: 40.0 Input: 130.0 | Output: 50.0 | Error: -10.0 Input: 80.0 | Output: 100.0 | Error: 40.0 Input: 130.0 | Output: 50.0 | Error: -10.0 Input: 80.0 | Output: 100.0 | Error: 40.0 Input: 130.0 | Output: 50.0 | Error: -10.0 Input: 80.0 | Output: 100.0 | Error: 40.0 Input: 130.0 | Output: 50.0 | Error: -10.0 Input: 80.0 | Output: 100.0 | Error: 40.0 Input: 130.0 | Output: 50.0 | Error: -10.0 Input: 80.0 | Output: 100.0 | Error: 40.0 Input: 130.0 | Output: 50.0 | Error: -10.0 Input: 80.0 | Output: 100.0 | Error: 40.0 Input: 130.0 | Output: 50.0 | Error: -10.0 Input: 80.0 | Output: 100.0 | Error: 40.0 Input: 130.0 | Output: 50.0 | Error: -10.0 Input: 80.0 | Output: 100.0 | Error: 40.0 Input: 130.0 | Output: 50.0 | Error: -10.0 Input: 80.0 | Output: 100.0 | Error: 40.0 Input: 130.0 | Output: 50.0 | Error: -10.0 Input: 80.0 | Output: 100.0 | Error: 40.0 Input: 130.0 | Output: 50.0 | Error: -10.0 Input: 80.0 | Output: 100.0 | Error: 40.0 Input: 130.0 | Output: 50.0 | Error: -10.0 Input: 80.0 | Output: 100.0 | Error: 40.0 Input: 130.0 | Output: 50.0 | Error: -10.0 Input: 80.0 | Output: 100.0 | Error: 40.0 Input: 130.0 | Output: 50.0 | Error: -10.0 Input: 80.0 | Output: 100.0 | Error: 40.0 Input: 130.0 | Output: 50.0 | Error: -10.0 Input: 80.0 | Output: 100.0 | Error: 40.0 Input: 130.0 | Output: 50.0 | Error: -10.0 Input: 80.0 | Output: 100.0 | Error: 40.0 Input: 130.0 | Output: 50.0 | Error: -10.0 Input: 80.0 | Output: 100.0 | Error: 40.0 Input: 130.0 | Output: 50.0 | Error: -10.0 Input: 80.0 | Output: 100.0 | Error: 40.0 Input: 130.0 | Output: 50.0 | Error: -10.0 Input: 80.0 | Output: 100.0 | Error: 40.0 Input: 130.0 | Output: 50.0 | Error: -10.0 Input: 80.0 | Output: 100.0 | Error: 40.0 Input: 130.0 | Output: 50.0 | Error: -10.0 Input: 80.0 | Output: 100.0 | Error: 40.0 Input: 130.0 | Output: 50.0 | Error: -10.0 Input: 80.0 | Output: 100.0 | Error: 40.0 Input: 130.0 | Output: 50.0 | Error: -10.0 Input: 80.0 | Output: 100.0 | Error: 40.0 Input: 130.0 | Output: 50.0 | Error: -10.0 Input: 80.0 | Output: 100.0 | Error: 40.0 Input: 130.0 | Output: 50.0 | Error: -10.0 Input: 80.0 | Output: 100.0 | Error: 40.0 Input: 130.0 | Output: 50.0 | Error: -10.0 Input: 80.0 | Output: 100.0 | Error: 40.0 Input: 130.0 | Output: 50.0 | Error: -10.0 Input: 80.0 | Output: 100.0 | Error: 40.0 Input: 130.0 | Output: 50.0 | Error: -10.0 Input: 80.0 | Output: 100.0 | Error: 40.0 Input: 130.0 | Output: 50.0 | Error: -10.0 Can someone help tell I missing? Thank you!",control pid
6999,Quadcopter frame design,"Quadcopter frames seem consistently follow X design. For example: I'm curious know is. It certainly seems like efficient way use space frame design would work quadcopters? For instance, would design like work? Why not?",quadcopter design frame
7002,Easiest way submit longer non standard character string via MAVLink,"I want submit gains PID regulator via MAVLink. Unfortunately, I used MAVLink several functions may used purpose (I think). My string currently JSON formatted I directly sending serial port before. Is straight forward way submit data like (see below) MAVLink, better transfer JSON string MAVLink submit single value? If yes, function choice. So far I noticed sensors, already MAVLink function defined. For PID gains I found much.",c++ mavlink
7004,Euler’s Method Or ode45 solving ODE control systems,"The dominant approach solving ODE control systems books since majority books use Matlab. I'm acquainted ode45 works lately I started reading Euler's method book Numerical Methods Engineers. If step size small, results satisfactory. For simulation, one actually set step size small value. I've used ode45 regulation tracking problems. I faced difficulties using ode45 tracking problem since step size fixed. Now experiment, I've used Euler's method step size 0.001 sec. The results amazing friendly comparison ode45. This snapshot result And code clear all; clc; dt = 0.001; = 0; % initial values system = 0; % angular displacement da = 0; % angular velocity % PID tuning Kp = 50; Kd = 18.0; Ki = 0.08; error = 0; %System Parameters: = 0.5; % mass (Kg) = 0.0023e-6; % viscous friction coefficient L = 1; % arm length (m) I = 1/3*m*L^2; % inertia seen rotation axis. (Kg.m^2) g = 9.81; % acceleration due gravity m/s^2 % Generate Desired Trajectory = 0:dt:(3*pi)/2; AngDes = y; % Ang: angle , Des: desired AngDesPrev = 0; = 1:numel(y) % get first derviative desired angle using Euler method. dAngDes = ( AngDes(i) - AngDesPrev )/ dt; AngDesPrev = AngDes(i); % torque input u = Kp*( AngDes(i) - ) + Kd*( dAngDes - da ) + Ki*error; % accumulated error error = error + ( AngDes(i) - ); %store erro E(i) = ( - AngDes(i) ); T(i) = t; dda = 1/I*(u - d*da - m*g*L*sin(a)); % get function first dervative da = da + dda*dt; = + da*dt; %store data furhter investigation A(i) = a; dA(i) = da; = + dt; end plot(T, AngDes, 'b', T, A, 'g', 'LineWidth', 1.0) h = legend('$\theta_{d}(t)$', '$\theta(t)$'); set(h, 'Interpreter','LaTex') My question ode45 preferred many control books assuming step size small.",control
7008,How decide LiPo LiFePo robot battery,"When choosing battery robot, use LiPo LiFePo? For LiFePo, pros: deliver higher sustained amps many built drop-in replacements lead-acid batteries use charger The cons: enormously expensive (about $1/watt*hour/kg) lower energy density LiPo (around 110 watt*hour/kg) For LiPo batteries, pros: cheaper (about $0.2/watt*hour/kg) twice energy density LiFePo (around 250 watt*hour/kg) The cons: complicated unsafe charge (see videos LiPos catching fire) can't safely deliver high amps Is anything I'm missing? I see LiFePo batteries used lot larger platforms, probably due higher continuous amp rating. I see Ebay flooded tons cheap high-capacity Chinese LiPos, almost none documentation, probably means they're junk. When I use LiFePo vs LiPo?",battery
7012,algorithm Simple Stereo Vision,"I'm working project implementing vision system. I'm student first time I'm something like this, challenge. I'm using controller (Netduino+2, .Net MicroFramework) camera (CmuCam5 - Pixy) it's working well. I'm communicating robot(Fanuc M430iA) using Modbus, aquiring data camera using I2C. But, next challenge using 2 cameras implement stereo vision I'm shure achieve that. I'm reading lot I understand process generally works, I think case specific. My cameras detect center object give coordinates, so, I that, that's good. What think it's reasonable approach? (sorry english, let know I'm explicit, I'll edit question I see there's enough information)",microcontroller robotic-arm cameras stereo-vision
7014,What main factors/features explain high price industrial computer vision hardware?,"I student currently working computer science project require soon computer vision specifically stereoscopy (for close depth detection). I looking great camera job I found several interesting options: 1- A custom built set two cheap cameras (i.e. webcam); 2- The old, classic, economic proven Kinect; 3- Specialized stereo sensors. I found couple months ago sensor: I tought interesting small, stereoscopic brand new (encouraging fresh USA company). However, take apart additional APIs come it, I don't understand would buy Kinect (or ""cheap"" cameras) least 4-5 times less expensive still great better specifications. Same applies one: Can someone please explain I would need device not, needed some?",sensors computer-vision kinect
7016,Simple way 3d perception,"I wonder simple (can computed microcontroller level) option suitable 3d object perception (depth, position, pose coordinate estimation) flying robots except LIDAR, stereovision, omnidirectional camera, laser scanner machine vision based techniques",mobile-robot sensors cameras stereo-vision lidar
7018,Irobot create 2 C# connection,My department recently purchased Irobot create 2. We want recreate code Csharp create 2 driving Tether program use base intro computer science course. Currently code using talk Irobot . Not sure irobot getting commands well serial port making connection. We using Visual Studio 2012 programming environment. Any recommendation input would appreciated. Thank,irobot-create roomba
7024,ROVER 5 2 encoders help,"2 weeks old arduino projects..i using timing control rover...now, wanted shift using encoders..am facing quite problems..am using arduino uno two amp motor shield..this code trying use..am using 8V Li-po battery (link rover) (link motoshield) question four pins coming encoders side...what connected red black 5V GND respectively white yellow first encoder pin 2 white yellow second encoder pin 3...is correct?? sometimes use code, motorshield green red light starts thereby stalling motor..why happen? anyone suggest link simple encoder code make motors move forward straight using feedback.. thanks // interupt 0 -> pin 2 // interupt 1 -> pin 3 volatile unsigned long positionL = 0; //vehicle position count left encoder volatile unsigned long positionR = 0; //vehicle position count right encoder int motorLa = 5; int dirLa = 4; int motorRa = 7; int dirRa = 6; void setup() { pinMode (motorLa, OUTPUT); pinMode (dirLa, OUTPUT); pinMode (motorRa, OUTPUT); pinMode (dirRa, OUTPUT); Serial.begin(9600); } void loop() { moveFWD(5300); delay(2000); moveREV(3000); delay(2000); while(1); } void encoder1() { positionR++; } void encoder2() { positionL++; } void moveFWD(unsigned int x) { positionL=0; positionR=0; attachInterrupt(0, encoder1, CHANGE); attachInterrupt(1, encoder2, CHANGE); digitalWrite(dirLa, LOW); // Left Forward digitalWrite(dirRa, HIGH); //Right Forward while((positionL <= x) || (positionR <= x)) { } // Stop motors analogWrite(motorLa, 0); analogWrite(motorRa, 0); // Disables encoders interrupt detachInterrupt(0); detachInterrupt(1); } void moveREV(unsigned int x) { positionL=0; positionR=0; attachInterrupt(0, encoder1, CHANGE); attachInterrupt(1, encoder2, CHANGE); digitalWrite(dirLa, HIGH); // Left Forward digitalWrite(dirRa, LOW); //Right Forward while((positionL <= x) || (positionR <= x)) { (positionL > positionR) { analogWrite(motorLa, 20); analogWrite(motorRa, 200); } else (positionR > positionL) { analogWrite(motorRa, 20); analogWrite(motorLa, 200); // Sets motor speed value 180 } else { analogWrite(motorLa, 200); // Sets motor speed value 180 analogWrite(motorRa, 200); } Serial.print(positionL); // This prints current value positionL serial monitor computer. Serial.print(""\t""); // This creates tab monitor Serial.print(positionR); Serial.println(); // This creates new line print } // Stop motors analogWrite(motorLa, 0); analogWrite(motorRa, 0); // Disables encoders interrupt detachInterrupt(0); detachInterrupt(1); }",arduino sensors
7040,How get projection matrix odometry/tf data?,"I would like compare results visual Odometry groundtruth provided KITTI dataset. For frame groundthruth, projection matrix. For example: Here instructions provided readme: Row represents i'th pose left camera coordinate system (i.e., z pointing forwards) via 3x4 transformation matrix. The matrices stored row aligned order (the first entries correspond first row), take point i'th coordinate system project first (=0th) coordinate system. Hence, translational part (3x1 vector column 4) corresponds pose left camera coordinate system i'th frame respect first (=0th) frame But I don't know produce kind data me. What I frame case: The Tf transformation init_camera (the fix one (0,0,0)) left camera moving. So I translation vector quaternion rotation. The odometry data: pose twist Camera calibration parameters With data, How I compare groundtruth ? So I need find projection matrix data don't know it. Can someone help ? Thank",mobile-robot odometry stereo-vision
7043,How tune two PIDs quadrotor,"I'm trying implement two PIDs stabilizing quadrotor position tracking. The inputs $x_{d}(t), y_{d}(t), z_{d}(t)$ $\psi_{d}(t)$. For position tracking, usually small angle assumption assumed. This assumption allows acquiring $\theta_{d}$ $\phi_{d}$. These results The x-axis position driving crazy. After alot attempts tuning PIDs, I felt something wrong going on. Is normal behavior PID controller? Also, I've noticed $\psi$ reaches zero, platform starts oscillating (after 1.5 second figure). For solving ODEs computing derivatives velocities, I use Euler methods. It simulation Matlab.",pid quadcopter
7048,Depth view hypercatadioptric camera,"I trying determine depth view hypercatadioptric camera (camera lens system hyperbolic mirror) based 1. The following illustration seems pretty clear. For image point $p$, looking virtual point $p_u$, given parameters optical system. I troubles finding right equations paper, though. There seems connected $p_u$, defined anywhere. My goal replicate diagrams later paper, like e.g. one: Which mirror (blue) gives virtual image points scene (red). I would like calculate depth view, area image blur threshold. 1 Zhang, S., Zenou, E.: Optical approach hypercatadioptric system depth field. In: 10th International Conference Information Sciences, Signal Processing Applications",computer-vision cameras
7050,Questions regarding 3D scanning camera choice,"A days ago, I shared concerns price computer vision hardware exact forum (see What main factors/features explain high price industrial computer vision hardware?) I think new related post needed. So go. Here details consider regarding overall scanner I want build: Restricted space: overall scanner can't larger 3 feet cube. Small objects: objects I scanning shouldn't larger 1 foot cube. Close range: camera would positioned approximately 1 foot object. Indoor: I could dedicated light source attached camera (which might fixed dark box) Here stereo cameras/sensors I looking (ordered price): Two Logitech webcams (no model particular) Cheap Harder setup calibrate Need create API Built for: want achieve Intel RealSense: $100 High resolution: 1080p (maybe depth sensing) Workable minimum range: 0.2 Unspecified FOV Built for: hands fingers tracking Kinect 2.0: $150 Low resolution (for depth sensing): 512 x 424 Unworkable minimum range: 0.5 Excellent FOV: 70° horizontal, 60° vertical Built for: body tracking Structure Sensor $380 Normal resolution high FPS capability: 640 x 480 @ 60 FPS Unspecified minimum range Good FOV: 58° horizontal, 45° vertical Built for: 3D scanning (tablets mobile devices) ZED Camera: $450 Extreme resolution high FPS capability: 2.2K @ 15 FPS (even depth sensing) 720p @ 60 fps Unviable minimum range: 1.5 Outstanding FOV: 110° Built for: human vision simulation DUO Mini LX: $595 Normal resolution high FPS capability: 640 x 480 @ 60 FPS Workable minimum range: 0.25 (see ) Phenomenal FOV: 170° (with low distortion) Built for: general engineering Bumblebee2: Too much expensive (not even worth mentioning) Note: All prices date April 18th 2015 might change overtime. As see, really goods pros, none seems perfect task. In fact, ZED seems best specifications overall, lacks minimum range (since large baselined camera designed long range applications). Also, DUO Mini LX seems best situation, unlike ZED generates really accurate depth maps, one seems lack precision (lower resolution). It might good proximity detection, 3D scanning (in opinion). I could also try build experimental stereo camera two simple webcams, I don't know start I don't think I enough time deal problems I would face so. I stuck great dilemma. Here questions: What good resources internet give good introduction 3D scanning concepts (theoretically programmatically)? I using C++ OpenCV (I already worked lot) and/or API provided chosen camera (if applies). Should static camera capturing moving object moving camera capturing static object? Should I use something conjunction stereo camera (like lasers)? Is profitable use two cameras/sensors? Are resolution, FPS global shuttering really important 3D scanning? What camera I get (it also something I didn't mention, range $500 maximum possible)? My main criteria camera would able generate accurate depth map close range points. Thanks help!",sensors computer-vision kinect
7052,How select parameters Sliding Mode Control Robotic Arm?,"I working sliding mode control (SMC) 4 DoF manipulator, I don't know select discontinuity gain matrix, $ K$ , surface constant (the diagonal gain matrix $\Lambda$ components).",control robotic-arm industrial-robot
7056,Locating Omni-Directional Robot,"I omni-directional robot, X-Drive mecanum Drive I need track position of. I put encoders wheels, I terms sensors. I external beacons I link to. The issue I needed keep track X-Y position, including strafing, heading. Does anyone resources could help this.",localization
7057,How control Brushless Motor+ESC BeagleBone?,"I can't really find real straightforward tutorial that. There lot Arduino I original beaglebone, ESC, brushless motor me. Please help.",brushless-motor beagle-bone
7059,How approach object,"My question basic/conceptual level. I'm looking way approach object map, I detected earlier. My robot localized map using SLAM. And object position 2D point I recieve algorithm. (Object actually face picture wall). Is smart way approach point ""look"" it?",mobile-robot mapping
7062,create2 angle (packet ID 20),convert value get angle (packet ID 20) degrees? using create2 robot I understand data I getting back. The documentation says it's degrees I get back huge number like 4864 I turned robot 45 degrees.,irobot-create
7066,What technology used no-resistance robot arms?,"I saw high end robot arm I could move bend form I wanted resistance, robot arm didn't weight. I'd like know them. What class robot arm design called? Where I get information design applications?",control robotic-arm joint
7067,How I communicate wirelessly RasPi servo?,"I want use Raspberry Pi pan camera mounted servo wirelessly ~100 feet away. What good servos transceivers this? To clarify, physical connection RasPi servo. Do I need additional RasPi servo end?",motor raspberry-pi wireless
7068,How strategy changes RobCup soccer competition without connection outside?,"How new team strategy robocup competition sent player robot team? Robots Standard Platform League (i.e. SPL), example, fully autonomous connection non-team members (except pulling GameControl).",soccer
7069,Is GMIS really breakthrough?,The GMIS (General Machine Intelligence System) new article posted codeproject.com looks interesting. Do think could breakthrough field robotics,mobile-robot robotic-arm
7070,Jacobian point robotic arm,"currently programming robotic simulation. I Endeffector aproaches target, way target Obstacle. Now redirect Endeffector, hit target. When want whole arm want push arm away Obstacle well. Now working far redirect arm. But calculation Jacobian seems faulty. For setup, need that. I robotic arm, 7DOF. Let $x_0$ closest point arm obstacle. And $J_0$ corresponding Jacobian. Also given following term: $\dot{x_0} = J_0 * \dot{\theta}$ $\theta$ joint angles. I calculate Jacobian EndEffector, know calculate point ob arm. Does anybody Idea calculate corresponding Jacobian. Cheers",robotic-arm jacobian
7073,make hc-sr04 receive another one,"I 3 ultrasonic Sensor (HC-SR04), want use one transmitter, receiver, want let first one send ultra Sonic waves receive waves transmitter. ? tried send trigger ultrasonic connect different pins PIC, work. something like project using HC-SR04",microcontroller ultrasonic-sensors
7080,building quadcopter using STM32F3 Discovery board,calculate PID values stabilise quadcopter using board sensors The gyro accelerometer magnetometer,sensors
7089,Programable Drone robotic arm hand?,"I wondering possible buy build programmable drone robotic arm,hand, knife. I want program drone harvest crops. -object recognition live video stream server -identify grab objects arm, make cut necessary -transport produce collection site I know would take much knowlege many fields forsight limitations energy power. Estimates cost hardware?",robotic-arm design quadcopter dynamic-programming
7091,"Design construction universal robotic arm (5kg, 1m)","working master's thesis design construction universal robotic arm. Goal work design 5 DOF robotic arm. Something like picture: I need able lift weight 5kg. It move ""action radius"" 1m. Rotation speed 1m/s. The conclusion work like: ""You buy ABB robotic arm this..it lift much, turn speed weighs much"". Basic construction done too. Maybe simulation. First - picked really bad master's thesis me, know know. Second - like month finish it. I would like ask someone proceed. I know first step pick servos/actuators/gearboxes, one? What realistic weight whole arm lift another 5 kg weight? How strong motors pick gearboxes? Is anyone able help via maybe emails?",robotic-arm servos actuator arm
7095,Depth image sensor integration robot,"I know lots consumer depth image sensors: kinect, primesense, structure.io, leap motion, ... But I'm looking something suitable integration robot, something without case proper mount, compact available least next five years robot going production. Something similar sensors used drone",sensors kinect
7097,Connecting USB Xbox Controller National Instruments cRIO,"I FIRST Robotics spec National Instruments cRIO. I would like connect USB wireless Xbox controller order control distance minimal extra hardware (which I using traditional WiFi radio method). To point I able find either A. A sidecar cRIO allows act USB host B. A method use NI specific hardware connect two together If someone knowledgeable subjects industrial system robot control could provide assistance would greatly appreciated, thanks!",control industrial-robot wireless usb first-robotics
7099,Got Difficulty reading Specification?,Guys I making home automation system simple one infrared remote ccontrol tv remote Now problem I wanna buy relays switch 230V AC using arduino board can't understand one buy I don't want buy relay module I wanna buy relay.,arduino
7105,Is possible use ROS RPI controller like MultiWii similar?,I quadcopter using MultiWii(Arduino Mega) controller. I curious way connect ROS capable RPI. (That I could add quad itself).,arduino ros quadcopter
7109,Building industrial-like robotic arm,"I would like build 70cm articulated robotic arm (not scara one) lift 10kg 15kg (10kg would awesome already, payload includes weight arm+gripper) moves 1 m/s (dreaming :)). The goal make similar human arm since I want control ""remotely"", joint able rotate arm ^^ So I know I cannot uses servos available (like overpriced dynamixel ones..) payload. I also already excluded common linear actuators less common ones like pneumatic actuators (because latency). From I read arms like baxter ones uses elastic series actuators, I guess I go way, aren't lot details works (getting lot 100x100 photos see nothing) I lot questions. The thing I could understand uses 2 motors spring. Do use brushed brushless motors? DC motors steppers ? I read steppers aren't good handle collisions difficulties used limits. Also, spring mounted motor ? To sum up, I'm collecting experience, diagrams, intel, documents topic :) PS : budget can't exceed +/- 1500$ arm.",motor robotic-arm stepper-motor servomotor actuator
7110,read Ultrasonic HC-SR04,want run two HC-SR04 one PIC16F877A send value mesured two ultrasonic serial port. code using PIC C Compiler : computer received random values ! problem ?,microcontroller programming-languages ultrasonic-sensors
7111,DH Forward Kinematics Cartesian Robot (CNC Mill),"I implementing Denavit-Hartenberg forward transform 3-axes CNC mill. I know kinematic machine trivial doesn't need DH, I need make appliable robots too. My implementation math correctly(I've verified another tool), transformation doesn't give results I would expect. I assume 3-axes cartesian robot orthogonal prismatic joints(=CNC mill) resulting transformation matrix give input parameters(d1-d3) back translation vector, somehow doesn't. Also, resulting orientation matrix ""nice"" values(90, 180, 270, etc.) odd ones(0.0528, 0.5987, etc,.). Is assumption wrong?",forward-kinematics cnc dh-parameters
7112,What RobotC type motors?,"I'm trying create function allows easily start motor, I'm running problem, I don't know type use argument. I'm using VEX 269 Motor. Here's function. void runMotor(MotorTypeHere motorName, int speed, int time) { startMotor(motorName, speed); wait(time); } I don't know type put motorName argument. What type would be?",robotc vex
7116,accelerate stepper using arduino AccelStepper starting pre-defined speed,"I've read AccelStepper documentation airspayce.com seems possible accelerate stepper starting speed greater 0. Acceleration always starts speed=0, I tried several variations code below... I also tried set speed library's method void AccelStepper::computeNewSpeed() directly, I'm good c++ don't get work. Anybody ideas? UPDATE I tried write custom code AccelStepper.cpp's method void AccelStepper::computeNewSpeed() My idea set speed manually acceleration/deceleration speed intended value. At first I thought couldn't big deal, I see cpp skills seems good enough I don't understand library quite well. I tried void AccelStepper::computeNewSpeed() { long distanceTo = distanceToGo(); // +ve clockwise curent location long stepsToStop = (long)((_speed * _speed) / (2.0 * _acceleration)); // Equation 16 //now goes modification (_speed < 200.0 && _speed >= 0 ){ setSpeed(200.0); } //I modification comment This results slow stepper movement..",arduino control stepper-motor c++
7120,Measuring angular displacement using TI-SensorTag,"I've looked around can't find answer, I hope simple question. I'm working TI-SensorTag, I want able measure rotation around unit's Z-axis. Basically I want attach tag clock pendulum, lie clock table tag clock face point up, measure angular displacement pendulum swings back forth. I'm hoping mental image translated well! My understanding I solve displacement multiplying gyroscope readings sampling period, I'm sure compensate drift. So questions are: approach sound, answer drift use changing x accelerations? Or would I need somehow incorporate magnetometer readings? Thanks!",sensors kinematics gyroscope
7121,iRobot Create 2: Angle Measurement,"I working trying get angle Create 2. I trying use angle heading, I eventually use control robot. I explain procedure highlight problem. I Create tethered computer. I reset Create sending Op code [7] using RealTerm. The output is: bl-start STR730 bootloader id: #x47175347 4C636FFF bootloader info rev: #xF000 bootloader rev: #x0001 2007-05-14-1715-L Roomba iRobot! str730 2012-03-22-1549-L battery-current-zero 252 (The firmware version somewhere here, I clue look for--let know see it!) I mark robot I know true angle change been. I send following codes [128 131 145 0x00 0x0B 0xFF 0xF5 142 6]. This code starts robot spinning slowly circle request sensor data sensors group Packet ID 2. The output Create seen RealTerm 0x000000000000, makes sense. I wait robot rotated known 360 degrees, I send [142 2] request angle difference. The output 0x00000000005B. The OI specs say angle measurement degrees turned since last time angle sent; converting 0x5B decimal 91, certainly 360 expected. What I wrong here? Is iRobot Create 2 angle measurement atrocious, scaling factor I unaware of? better ways get angle measurement?",irobot-create roomba
7124,"Using accelorometer gyroscope get velocity, spin & flightpath ball projectile motion","I'm working project make SmartBall detect velocity(km/h) , spin(degrees per second) flightpath(trajectory) ball using Intel Edison 9DOF block (LSM9DS0 : 3-axis accelerometer, 3-axis gyroscope, 3-axis magnetometer) & battery block, I'm reading values 9DOF block RTIMULib(Library IMU chips). I've working integrating acceleration data accelorometer get velocity get position, I know method really accurate integration error cumulate fast I rely calculations done short time (about 3 seconds) re-calculate beginning every kick error doesn't cumulate hardly, Also need acceptable accuracy high one. I discovered i'm dealing projectile motion(ball kicking), considering & searching projectile motion equations found must know initial velocity angle projection(theta) able get requirements. problem I don't know get , I tried different approaches like getting horizontal distance & getting height get resultant(using pythagoras) get angle(assuming it's right angle) small time beggining projection , still couldn't get height. The gyroscope outputs roll, pitch & yaw angles related sensor orientation i'm still using i'm assuming sensor fixed inside ball it's orientation projection angle.Now What I really want approach/idea get velocity & flightPath projectile using accelorometer gyroscope data. Hope I made clear , Any help get requirements really appreciated, Thanks much.",gyroscope
7125,keeping 2 motors common three circuits,"I beginner robotics I want create line follower+ obstacle avoider+ remote controlled robot I using drive differential algorithm I want keep 2 common motors three circuits, I got three circuits ready I want switch among 3 circuits wirelessly. Please tell solution.",motor wireless line-following circuit
7128,Determining robot's distance certain point robot's position constantly changing,I wondering I could determine robot's distance fixed point robot constantly changing positions. I keep encoders wheels also get data gyroscope accelerometer.,localization
7129,(Dynamixel) Inverse rotation direction,"I'm wondering there's feature ""flip"" rotation direction Dynamixel (I'm using MX-106). For example, I give +1.57 motor, interprets . And way around. I'm using ROS driver package doesn't seem explicitly claim there's feature this, although question user reported able source code. But I failed replicate. So I first wanted ask capability device since I don't know limitation comes Dynamixel device ROS driver. Thank you. (UPDATE) Usecase mine I multiple robots direction Dynamixel attached different per robot, ideally like flip motor's direction driver's level I keep using controller software.",servomotor dynamixel
7137,Understanding various attitude estimation methods,"I building quadcopter using Arduino Uno 6dof accelerometer gyro. I adding separate 3 axis magnetometer soon heading. I successfully implemented code reads data coming sensors prints out. I also checked bias averaging 100 measurements. My code calculates pitch accel pitch gyro respectively: pitchAccel = atan2((accelResult[1] - biasAccelY) / 256, (accelResult[2] - biasAccelZ) / 256)*180.0 / (PI); pitchGyro +=((gyroResult[0] - biasGyroX) / 14.375)*dt; I using complementary filter fuse two readings together like this: pitchComp = (0.98*pitchGyro) + (pitchAccel*0.02); I stuck proceed here. I using procedure roll, I readings pitch roll respective complementary filter outputs. I read lot articles DCM algorithm relates angles body reference frame earth reference frame. Should next step here? Taking pitch roll readings body reference frame transforming earth reference frame? Repeat entire procedure yaw using magnetometer? If yes, I go transformations? I understand math behind it, I hard time understanding actual implementation DCM algorithm code-wise. Any help appreciated!",arduino quadcopter accelerometer gyroscope
7138,Pins OpenROV control motors?,"I'm working ROV project, I find OpenROV ready use image BB want use instead making program, I already deployed image, I can't find three pins find send PWM signal ESC's? Please help.",mobile-robot beagle-bone
7139,Determining transfer function PTU visual tracking,"I PTU system whose transfer function I need determine. The unit receives velocity position, move towards position given velocity. What kind test would one perform determining transfer function... I know Matlab provides method. The problem, though, I bit confused kind test I perform, I use Matlab determine transfer function. The unit used Flir PTU D48E ---> More system The input system pixel displacement object center frame. The controller I using converts pixel distances angular distances multiplied gain $K_p$. This works fine. However, I can't seem prove works well, I mean, I know servo motors cannot modeled like that. The controller fed angular displacement position => added together give angular position I go to. The angular displacement used speed move with, since huge displacement gives huge velocity. By updating elements different frequency I'm able step velocity overshoot gets minimized. The problem is: I prove transfer function I found fits system, I tests somehow using function Matlab, I'm quite unsure that. I'm also bit unsure whether PTU already controller within it, since moves well, I mean, it's simple math, makes sense I'll convert like that.",control
7140,What difference SAM SLAM?,What difference Smoothing Mapping (SAM) Simultaneous Localization Mapping (SLAM)? These general approaches seem closely related. Can someone describe differences?,slam
7146,Estimating angular speed position control purpose,"I new robotics, however I designing PID control angular velocity (azimuth, elevation) couple Faulhaber motors. The input PID control actual angular velocity, observed though, since derived position motor time $t$. The PID sample period aprox. , whereas input data rate joystick aprox. 300 samples/s, corresponding sample period 3.33 ms. The joystick input gets transformed desired angle speed, PID control. I initially filtering position data using normal 2D linear Kalman Filter, angular velocity linear (by formula), hence I switched Extended Kalman filtering. My questions following: Is latter approach makes use EKF correct? Which parameters I check order properly set update rate PID loop? Thx advance!",pid ekf
7148,An easy way exert desired load motor shaft?,"I trying exert desired load 0.07 N.m BLDC motor shaft whose length 0.750in diameter 0.3125in (0.008m). I go machine shop get small adjustable cylindrical coupling made shaft. But I need exert close desired torque speed 2100 rpm (220 rad/s). I tried calculations, according formula Torque = speed * mass * (radius)^2 If I solve equation T = 0.07 N.m, speed = 220 rad/sec, radius = 0.004 m, I get around 20 kg mass, huge!!!. It mass motor. Can please suggest convenient way load motor. Thank you.",motor brushless-motor
7153,Is possible A/V feed serial communication RF transceiver time Arduino?,"Is possible transmit live audio/video feed time, receive commands UART using 1 RF transceiver connected Arduino board? I want control Arduino serial communication (UART) accomplished using RF connection control remote. I also want transmit live audio video feed Arduino using RF transceiver. Is possible? I found AVCTP, I'm sure enables serial communication. Also, I don't like use Bluetooth reasons. Thanks advance!",arduino microcontroller radio-control serial communication
7156,STM32F3 timers & computing,"I STM32F3 discovery board. I want go next step I want try use timers configurations. How I calculate variables (such prescaler, period)? I looked datasheets, manuals didn't find anything describe values - Input capture mode, OP, PWM, etc. I think prescaler downgrading frequency 1-65575. So I fcpu=72MHz want generate signal frequency=40kHz, I supposed do: 72MHz/40kHz=1800? Now I subtract prescaler -1?",microcontroller
7158,C++ Create 2,I trying use C++ talk Create 2 robot. Does anyone basic code write/read Create 2 using C++ C? I trouble converting Create 2 commands (like ) one char.,irobot-create c c++
7159,Do structured light camera sensors work outdoors?,"Do structured light camera sensors like structure.io, Intel RealSense Microsoft Kinect work outdoors? I read sensors wont work outdoors ambient IR light. Can someone provide proper references/tests? I mean degree IR illumination needed sensor stop working etc. There videos YouTube show Microsoft Kinect working outdoors: Prairie Dog II: UGV Kinect Sensor Outside - limited outdoors range Outdoor Kinect Data Collection - heavy interference direct sunlight However, (not yet released) new Intel RealSence R200 specification says ""range 3-4 meters indoors, longer range outdoors"" older F200 says ""0.2 meters - 1.2 meters, indoors only"". I really interested seeing R200 really work outdoors.",kinect cameras
7161,ODroid XU3 speed issue image processing,"Currently working UAV using ODroid XU3 Lite center core running out-of-box SD card image Ubuntu. This (supposedly) upgrade previous XU running. We're using OpenCV functions HoughCircles, Lines, RGB color detection, searching shapes color blobs 3 different colors (white, Red, Green) competition. This running lag time little 2 seconds OpenCV playback frame output every second terminal that's off. The XU3 running even slower, though, despite better machine. What could I improve speed XU3 fitting power requirements? One thing I think issue could stock Ubuntu version bloated I've looking around images, I'd like avoid using Android.",computer-vision software uav c++ linux
7163,Hand Eye Calibration,"I'm trying use dual quaternion Hand Eye Calibration Algorithm Header Implementation, I'm getting values way off. I'm using robot arm optical tracker, aka camera, plus fiducial attached end effector. In case camera hand, instead sitting side looking arm. The transforms I are: Robot Base -> End Effector Optical Tracker Base -> Fiducial The transform I need is: Fiducial -> End Effector I'm moving arm series 36 points path (blue line), near point I'm taking position (xyz) orientation (angle axis theta magnitude) Camera->Fiducial Base->EndEffector, putting vectors required HandEyeCalibration Algorithm. I also make sure vary orientation +-30 degrees roll pitch yaw. I run estimateHandEyeScrew, I get following results, see position order magnitude. [-0.0583, 0.0387, -0.0373] Real [-0.185, -0.404, -0.59] Estimated HandEyeCalib Here full transforms debug output: Am I perhaps using wrong way? Is advice give?",robotic-arm stereo-vision calibration
7165,How implement PID control robotic arm?,"I'm wondering that, PID control linear control technique robot manipulator nonlinear system, possible apply PID control, case. I found paper named: PID control dynamics robotic arm manipulator two degrees freedom. slide share page, use PID control robotic arm, name approach? remove ambiguity PID linear control technique robot nonlinear system. Any suggestions?",control pid robotic-arm industrial-robot dynamics
7167,Is rubber/PVC coupling good enough small torque (0.1 N.m),"I working project involves speed regulation BLDC motor no-load load conditions. I wish use another machine operated generator, acting load motor, shown video. The coupling used motor/generator arrangement looks handmade rubber tube somethhing. I considering using alternative flexible coupling. Purchasing actual flexible coupling option me. Moreover, I need coupling urgent basis. My question is, arrangement (or something similar) used couple 15W motor similar rating machine, rated torque exceeding 0.1 N.m?",control brushless-motor
7175,Need suggestion microcontroller/processor language used project,I new robotics. I writing algorithm robot move around gather information surroundings process it. It also process audio-visual signals. I confusion micro-controller use would performance efficient consumes less power. The controller also capable communication wireless network (internet wi-fi) also support memory integration. Also I know program Java C. please suggest would best language use programming. Thanks. P.S. I would really like use microprocessor highly customizable. Please suggest best use,artificial-intelligence
7176,"Using 20 Servos once, raspberry pi","I recently asked review raspberry pi hat (from programming view) allow PWM control upto 16 servos, however I hoping use time work hexapod idea I thinking while, requires minimum 18 servo's, preferably 20 (camera/sensor pan tilt). My question is: What relatively cheap uncomplicated way extending control extra 4 servo's? It would appear servo controller hat/shiels arduino raspi upto 16 servos, extended buying another shield, options? Any advice subject would greatly appreciated, preferably dumbed bit, I don't know great deal micro controller hardware (more software guy)",raspberry-pi servomotor rcservo
7177,How test GAZEBO works properly. Save windows don't show component,"How I test whether gazebo installation works properly not? I'm trying ""save myworld"" ""save as"" options window shown.",gazebo
7178,Is ROS (Robot Operating System) mandatory?,Do build ROS robotic researchs/applications? What main advantage? When situations ROS mandatory?,ros
7181,"Is geometric inverse problem's solution ""continuous"" redundant robot?","Let's say redundant robot operationnal position $x$. Is set possible joint configuration ""continuous"", would mean possible explore possible configurations without moving end effector. Is way show true false? I using Kuka LBR robot 7 dof maybe specific answer one. I searching find result I gladly accept link answer may have.",control inverse-kinematics
7186,What would I need control DC servo using 4-20ma linear analog signal?,"I'm looking find way operate small servo using 4-20ma linear analog signal generated PLC industrial setting. The purpose allow automation task currently done manually turning adjusting potentiometer removable dial. Basically, I'm trying ghetto together oldschool Motor Operated Potentiometer (MOP) removed quickly easily without affecting operation original process. I've spent hours looking servo controllers/encoders capable this, I haven't able find any. Any way I could get pointed right direction would fantastic. Surely thing must exist! Thanks much!",rcservo
7188,Can Jacobian matrix used derive joint angles end-effector linear rotational velocity (without filter)?,"I 2-link, 2 degree freedom robotic arm, measures linear acceleration link(through accelerometer), rotational velocity joint (through gyroscope). I know using Jacobian matrix, I compute link velocity acceleration joint angles, inverse matrix I compute joint velocities joint angles link acceleration. However, I sure I compute joint angles using link linear rotational acceleration? I aware joint angle could estimated integrating joint velocities (and applying sort filter), algebraic way computed? It doesn't seem likely me.",robotic-arm accelerometer gyroscope jacobian
7189,create2 reading sensor date always work,"I noticed create2 always provide sensor data it's moving. Am I supposed stop robot, request sensor data start again? I missing something? seems work time I get data back. I trying make move one point another starting reading distance see far travels every .1 seconds sometimes I keeping getting data. I noticed using python C code well. I using USB port bit rate recommend (115200).",irobot-create
7190,Cheap efficient 3D sensor?,"I'm searching cheap (under 100$) efficient 3D sensor, detects obstacles moving objects, robot applications like quadrotor navigation, swarm robotics, etc. Can suggest sensor either commercial product ""do yourself"" project?",mobile-robot sensors swarm
7194,Beginner question software calculations,"I'm complete beginner robotics background programming... I started thinking robot project yesterday want order motors test with. I saw specs motors, torque etc, I think I remember enough physics high school simple calculations. For example, motor rotates arm, given torque length arm, much could lift? Also, doesn't lift straight up, angle, I could bit thinking tweak calculations bit... If would several joints attached other, calculations would complex, I could probably create program node.js, example, able experiment different values. However, I would assume kinds calculations would common designing robots. So I would assume already programs types calculations created. I don't know exactly I mean ""these types calculations"", I don't know yet I don't know, would like ask programs guys use making calculations design robots? Preferable open source...",robotic-arm mechanism software
7198,Dynamic model tank like robot,"I planning tank like robot hobby purpose. I control engineering background, however I never applied robotics. I would like test different control theory, namely MPC. I saw lot publications regarding kinematics inverse kinematics robot, however I wondering somebody point regarding dynamics modelling system,taking account forces, mass etc?",wheeled-robot
7199,Pole placement gains tuning,"given control system I found region complex space satisfies specifications, determining poles position 0.5 +- 0.2i. Now I want find gains fix desider pole (with matlab), I understand well it: anyone suggest example that, without matlab? Thanks Edit: first image sum blocks +-, ++",control pid tuning matlab
7203,Education sources robot building?,"I teach FTC robotics high school students, I'm proficient programmer teach coding fairly well, mechanical skills bit soft. I'm looking good sources students go gets little depth ""this gear, chain, gear ratio, etc.,"" maybe quite level building professional / industrial robots. I've used Vex Robotics Curriculum starting reference - - doesn't go advanced topics (for example, drive single gear / drive shaft multiple motors achieve power without gear lose speed.) Are good intermediate sources like this? Do I need bit bullet get college level mechanics text?",mechanism
7206,Building first quadcopter,"I trying build quadcopter scratch. I selected parts I idea whether quadcopter come together fly. I would appreciate feedback whether parts I selected compatible (UBEC, Motor). If not, I would appreciate suggestions. The frame quadcopter X configuration I making own. I expecting average weight quad around 800g. I hope motors prop combination hover well.",multi-rotor
7210,recommendation robot special education,"I saw video robot used special education children autism spectrum (). My son isn't autistic, Tourette Syndrome, ADHD, executive function problems, OCD. A robot could quite helpful him. Where I buy one? I don't need look like human being. It needs interactive reasonable cute. As son getting ready bed, needs someone talk steps, give positive feedback, ask questions like ""Okay, you're pajamas. Great! What else need get ready bed?"" And robot would mental list (preprogrammed) everything that's needed (brush teeth, wash face, put eczema ointment, put dirty clothes hamper). My son 12 would like get ready -- without Mama Papa -- gets sidetracked he's room own. The robot doesn't need able ""see"" brushing teeth. He needs able hear son saying, ""I brushed teeth."" Because two together decide made routine, call in, I'll check, we'll bedtime reading. That's example I mind. There situations I could imagine robot helpful him.",artificial-intelligence
7212,estimate transfer function stepper motor?,"I stepper motor internal controller. I would like determine both, don't know approach problem. system receives input velocity position, moves toward position using velocity. The input could also velocity. The plant Pan tilt unit, 2 stepper motors. I Tried ident got fit 5 %... My input noisy signal, output position writes out.",control
7215,Arduino-Create 2: Reading Sensor Values,"Over past weeks, I attempting interface iRobot Create 2 Arduino Uno. As yet, I unable read sensor values back Arduino. I describe hardware setup Arduino code, ask several questions; hopefully, answers questions helpful future work Create 2. Hardware: The iRobot Create 2 connected Arduino Uno according suggestions given iRobot. Instead diodes, DC buck converter used, transistor used software serial port used instead UART port. Software: The following code I implementing Arduino. The overall function stop spinning robot angle robot exceeds threshold. A software serial port used, runs default Create 2 Baud rate. Questions: Am I loading sensor values array correctly? This code works bump run program implemented, requires knowing one bit rather two bytes. How many bytes read serial connection time? A previous post (Help sending serial command Roomba) highlights one byte sent time. Does imply reverse true? If so, would solution use char array read values instead append two chars form signed int? Is serial communication synchronization problem? I assuming synchronization problem, possible bytes split nibble boundaries? This would present problem nibble datatype.",arduino irobot-create roomba
7216,What different ways control distance covered robot?,I want move robot certain distance say 1 meter. What different ways implement so? For example I measure circumference wheel assign time rotation move it. techniques achieve this?,wheeled-robot movement
7219,Issue multiple bytes Irobot Create 2,"I problems reading sensor information Irobot Create 2 sent email asking help Irobot staff. They super helpful gave answer(the next day!!!) helped push along project. I requesting data create2 print screen I could figure write code would read data. I started section code working (I trimmed code controlled functions): They told code actually working fine I trying print value sensor packet without parsing way. They recommended I change code program2 this: True: def toHexFromByte(val): return hex(ord(val))[2:}.rjust(2, '0').upper() x = connection.read() b x: print toHexFromByte(b) works beautifully prints screen bumper pressed wheel drops. My question deal responses longer one byte (ie Packet ID: 22 voltage)? When I try Packet ID: 22 prints screen sends high byte 3F low byte D7. I manually combine get 3FD7 convert decimal 16.343 Volts I would like figure way print screen voltage program me. Many sensors send data 2 bytes I need way make sure combined automatically. Robb",irobot-create python roomba
7221,What difference Positioning Localization Systems,I would like know differences Positioning Localization Systems. In review papers used interchangeably. Are same? For example: GPS(Global Positioning system): gives coordinates receiver SLAM(Simultaneous localization mapping): constructing updating map unknown environment Is difference : Positioning: gives information receiver coordinates.No information enviorement Localization: gives information receiver coordinates also enviorement. positioning subtopic localization,localization slam gps
7225,Robotic winch force sensor,"I requirement motor pulls piece rope rope taught. However I'm loss achieve this, I'm sure must've done I'm sure best describe way would get results. I wondered sensors pre-established methods sensing resistance motion electrical motors?",motor
7226,At frequency I input read values?,"I moment trying identify system using frequency sweep. I using Mathematica created frequency sweep such. The max frequency 10 Hz, I sample data using 1000 Hz. But rate I input system, rate I read it?",control
7227,Building micro cnc machine,"I building micro cnc machine, probably 2 cd roms x axis floppy drive z, 1 hard drive x, 1 cd drive 1 floppy z, I sure I wire work EMC2, linux cnc program works parrallel port. Do I connect steppers directly control drivers(the board I buy ebay right?) connect pc?Or I need interface board instead go driver parralel port? I also wondering people opt x/y bottom z top, put x/y/z stacked, could place upside top view?(I would might done accuracy,3 layers potential failure.",driver stepper-motor cnc
7229,iRobot Create 2: Encoder Counts,"This post follows earlier post (iRobot Create 2: Angle Measurement). I trying use wheel encoders calculate angle Create 2. I using Arduino Uno interface robot. I use following code obtain encoder values. A serial monitor used view encoder counts. The code prints encoder counts; however, wheels spun backwards, count increases never decrement. Tethered connection Create 2 using RealTerm exhibits behavior; suggests encoders keep track direction spin. Is true?",irobot-create roomba
7230,System identification physical system constrains,What kind input output test peformed physical system constraints identify transfer function. The system discussed pan/tilt unit.. The input receives either position velocity velocity..,input
7234,Are LiPo really 100 times energy dense model rockets?,"Lately I've interested comparing energy density model rocket engines lithium polymer batteries (attached motors propellers) propelling things upwards. To get feel this, I decided compare Estes C6-5 motor 3DR Iris + quadcopter. Estes C6-5 initial mass 25.8g, produces 10 N total impulse. So, ""Impulse density"" 10 N / 25.8g = 0.38 N g^-1. 3DR Iris+ weighs 1282g without battery. 3.5ah battery weighs 250g power hover 20 minutes (so 10.5a draw). Thrust produced hover Earth 9.8N kg^-1 * 1.532 kg = 14.7N. ""Impulse density"" 14.7N * 1200s / 250g = 70.6 N g^-1 . So, according math here, LiPo 0.38/70.6 = 186 times energy dense model rocket engine. Of course, model rocket engine lose 12.48g propellant end flight effectively little lighter, that's going affect things factor 100. Does seem right you? Am I missing anything?",quadcopter rocket lithium-polymer
7235,implement code inner outer PD controllers quadrotor position tracking,"The quadrotor system multi-ODEs equations. The linearized model usually used especially position tracking, therefore one determine desired x-y positions based roll pitch angles. As result, one nested loop inner outer controllers needed controlling quadrotor. For implementation, I put inside ode45 inner attitude controller? I'm asking I've read paper inner attitude controller must run faster (i.e. 1kHz) position controller (i.e. 100-200 Hz). In code, loops run 1kHz, therefore inside ode45 while-loop. Is correct position tracking? If not, I insert while-loop inside ode45 running inner loop? Could please suggest pseudocode position tracking? To thorough, dynamics equations nonlinear model quadrotor provided here, assume small angles, model reduced following equations $$ \begin{align} \ddot{x} &= \frac{U_{1}}{m} ( \theta \cos\psi + \phi \sin\psi) \\ \ddot{y} &= \frac{U_{1}}{m} ( \theta \sin\psi - \phi \cos\psi) \\ \ddot{z} &= \frac{U_{1}}{m} - g \\ \ddot{\phi} &= \frac{l}{I_{x}} U_{2} \\ \ddot{\theta} &= \frac{l}{I_{y}} U_{3} \\ \ddot{\psi} &= \frac{1}{I_{z}} U_{4} \\ \end{align} $$ The aforementioned equations linear. For position tracking, need control $x,y,$ $z$, therefore choose desired roll pitch (i.e. $\phi^{d} \ \text{and} \ \theta^{d}$) $$ \begin{align} \ddot{x}^{d} &= \frac{U_{1}}{m} ( \theta^{d} \cos\psi + \phi^{d} \sin\psi) \\ \ddot{y}^{d} &= \frac{U_{1}}{m} ( \theta^{d} \sin\psi - \phi^{d} \cos\psi) \\ \end{align} $$ Therefore, closed form desired angles obtained follows $$ \begin{bmatrix} \phi_{d} \\ \theta_{d} \end{bmatrix} = \begin{bmatrix} \sin\psi & \cos\psi \\ -\cos\psi & \sin\psi \end{bmatrix}^{-1} \left( \frac{m}{U_{1}}\right) \begin{bmatrix} \ddot{x}^{d} \\ \ddot{y}^{d} \end{bmatrix} $$ My desired trajectory shown The results And actual trajectory vs desired one My code experiment %% %######################( Position Controller )%%%%%%%%%%%%%%%%%%%%%%%%%%%%% clear all; clc; dt = 0.001; = 0; % initial values system x = 0; dx = 0; = 0; dy = 0; z = 0; dz = 0; Phi = 0; dPhi = 0; Theta = 0; dTheta = 0; Psi = pi/3; dPsi = 0; %System Parameters: = 0.75; % mass (Kg) L = 0.25; % arm length (m) Jx = 0.019688; % inertia seen rotation axis. (Kg.m^2) Jy = 0.019688; % inertia seen rotation axis. (Kg.m^2) Jz = 0.039380; % inertia seen rotation axis. (Kg.m^2) g = 9.81; % acceleration due gravity m/s^2 errorSumX = 0; errorSumY = 0; errorSumZ = 0; errorSumPhi = 0; errorSumTheta = 0; pose = load('xyTrajectory.txt'); DesiredX = pose(:,1); DesiredY = pose(:,2); DesiredZ = pose(:,3); dDesiredX = 0; dDesiredY = 0; dDesiredZ = 0; DesiredXpre = 0; DesiredYpre = 0; DesiredZpre = 0; dDesiredPhi = 0; dDesiredTheta = 0; DesiredPhipre = 0; DesiredThetapre = 0; = 1:6000 % torque input %&&&&&&&&&&&&( Ux )&&&&&&&&&&&&&&&&&& Kpx = 50; Kdx = 8; Kix = 0; Ux = Kpx*( DesiredX(i) - x ) + Kdx*( dDesiredX - dx ) + Kix*errorSumX; errorSumX = errorSumX + ( DesiredX(i) - x ); dDesiredX = ( DesiredX(i) - DesiredXpre ) / dt; DesiredXpre = DesiredX(i); %&&&&&&&&&&&&( Uy )&&&&&&&&&&&&&&&&&& Kpy = 100; Kdy = 10; Kiy = 0; Uy = Kpy*( DesiredY(i) - ) + Kdy*( dDesiredY - dy ) + Kiy*errorSumY; errorSumY = errorSumY + ( DesiredY(i) - ); dDesiredY = ( DesiredY(i) - DesiredYpre ) / dt; DesiredYpre = DesiredY(i); %&&&&&&&&&&&&( U1 )&&&&&&&&&&&&&&&&&& Kpz = 100; Kdz = 20; Kiz = 0; U1 = Kpz*( DesiredZ(i) - z ) + Kdz*( dDesiredZ - dz ) + Kiz*errorSumZ; errorSumZ = errorSumZ + ( DesiredZ(i) - z ); dDesiredZ = ( DesiredZ(i) - DesiredZpre ) / dt; DesiredZpre = DesiredZ(i); %####################################################################### %####################################################################### %####################################################################### % Desired Phi Theta R = [ sin(Psi),cos(Psi); -cos(Psi),sin(Psi)]; DAngles = R\( (m/U1)*[Ux; Uy]); %Wrap angles DesiredPhi = wrapToPi( DAngles(1) ) /2; DesiredTheta = wrapToPi( DAngles(2) ); %&&&&&&&&&&&&( U2 )&&&&&&&&&&&&&&&&&& KpP = 100; KdP = 10; KiP = 0; U2 = KpP*( DesiredPhi - Phi ) + KdP*( dDesiredPhi - dPhi ) + KiP*errorSumPhi; errorSumPhi = errorSumPhi + ( DesiredPhi - Phi ); dDesiredPhi = ( DesiredPhi - DesiredPhipre ) / dt; DesiredPhipre = DesiredPhi; %-------------------------------------- %&&&&&&&&&&&&( U3 )&&&&&&&&&&&&&&&&&& KpT = 100; KdT = 10; KiT = 0; U3 = KpT*( DesiredTheta - Theta ) + KdP*( dDesiredTheta - dTheta ) + KiT*errorSumTheta; errorSumTheta = errorSumTheta + ( DesiredTheta - Theta ); dDesiredTheta = ( DesiredTheta - DesiredThetapre ) / dt; DesiredThetapre = DesiredTheta; %-------------------------------------- %&&&&&&&&&&&&( U4 )&&&&&&&&&&&&&&&&&& KpS = 80; KdS = 20.0; KiS = 0.08; U4 = KpS*( 0 - Psi ) + KdS*( 0 - dPsi ); %###################( ODE Equations Quadrotor )################### %===================( X )===================== ddx = (U1/m)*( Theta*cos(Psi) + Phi*sin(Psi) ); dx = dx + ddx*dt; x = x + dx*dt; %===================( Y )===================== ddy = (U1/m)*( Theta*sin(Psi) - Phi*cos(Psi) ); dy = dy + ddy*dt; = + dy*dt; %===================( Z )===================== ddz = (U1/m) - g; dz = dz + ddz*dt; z = z + dz*dt; %===================( Phi )===================== ddPhi = ( L/Jx )*U2; dPhi = dPhi + ddPhi*dt; Phi = Phi + dPhi*dt; %===================( Theta )===================== ddTheta = ( L/Jy )*U3; dTheta = dTheta + ddTheta*dt; Theta = Theta + dTheta*dt; %===================( Psi )===================== ddPsi = (1/Jz)*U4; dPsi = dPsi + ddPsi*dt; Psi = Psi + dPsi*dt; %store erro ErrorX(i) = ( x - DesiredX(i) ); ErrorY(i) = ( - DesiredY(i) ); ErrorZ(i) = ( z - DesiredZ(i) ); % ErrorPhi(i) = ( Phi - pi/4 ); % ErrorTheta(i) = ( Theta - pi/4 ); ErrorPsi(i) = ( Psi - 0 ); X(i) = x; Y(i) = y; Z(i) = z; T(i) = t; % drawnow % plot3(DesiredX, DesiredY, DesiredZ, 'r') % hold % plot3(X, Y, Z, 'b') = + dt; end Figure1 = figure(1); set(Figure1,'defaulttextinterpreter','latex'); %set(Figure1,'units','normalized','outerposition',[0 0 1 1]); subplot(2,2,1) plot(T, ErrorX, 'LineWidth', 2) title('Error $x$-axis Position (m)') xlabel('time (sec)') ylabel('$x_{d}(t) - x(t)$', 'LineWidth', 2) subplot(2,2,2) plot(T, ErrorY, 'LineWidth', 2) title('Error $y$-axis Position (m)') xlabel('time (sec)') ylabel('$y_{d}(t) - y(t)$', 'LineWidth', 2) subplot(2,2,3) plot(T, ErrorZ, 'LineWidth', 2) title('Error $z$-axis Position (m)') xlabel('time (sec)') ylabel('$z_{d} - z(t)$', 'LineWidth', 2) subplot(2,2,4) plot(T, ErrorPsi, 'LineWidth', 2) title('Error $\psi$ (m)') xlabel('time (sec)') ylabel('$\psi_{d} - \psi(t)$','FontSize',12); grid Figure2 = figure(2); set(Figure2,'units','normalized','outerposition',[0 0 1 1]); figure(2) plot3(X,Y,Z, 'b') grid hold plot3(DesiredX, DesiredY, DesiredZ, 'r') pos = get(Figure2,'Position'); set(Figure2,'PaperPositionMode','Auto','PaperUnits','Inches','PaperSize',[pos(3),pos(4)]); print(Figure2,'output2','-dpdf','-r0'); legend('actual', 'desired') The code desired trajectory clear all; clc; fileID = fopen('xyTrajectory.txt','w'); angle = -pi; radius = 5; z = 0; = 0; = 1:6000 ( z < 2 ) z = z + 0.1; x = 0; = 0; end ( z >= 2 ) angle = angle + 0.1; angle = wrapToPi(angle); x = radius * cos(angle); = radius * sin(angle); z = 2; end X(i) = x; Y(i) = y; Z(i) = z; fprintf(fileID,'%f \t %f \t %f\n',x, y, z); end fclose(fileID); plot3(X,Y,Z) grid",quadcopter matlab microcontroller
7242,Underwater ROV Variable Ballast,How would guys recommend making variable ballast system underwater robot? I thinking problem earlier I trying figure way make one didn't require tank compressed air.,underwater
7243,Fast C++ library stereo vision/disparity computation,"I looking library disparity map / stereo vision computation. These requirements: C++ Multi-platform (Linux, Windows, OSX) (preferrable mandatory) CUDA based Suited robotics (e.g. work even images perfectly rectified cameras perfectly calibrated) Suitable tracking purposes (20fps more) Performing even low-res images (e.g. 320x240px) Open Source",computer-vision stereo-vision
7244,Conceptual problem regarding electronic shutters,"I looking CCD CMOS sensors cameras decide one use process automatic control printing process. By I getting grips almost essential numbers abbreviations remains problem shutters. I understand different types shutters, mechanical electronic, I understand work. My problem concerns shutter speed. If I use mechanical shutter, well maximum shutter speed depends particular element assembly, work electronic shutters? I never read ""Max shutter speed"" specs. The thing I usually see floating around frames per second. But usally pass limit 120 fps. Depending sensor built one could think maximum shutter speed therefore 1/120 1/240 uses half frames. Can right? It seems really slow. I faced task recording crisp clear images paper moves 17 m/s. That never possible shutter speeds slow. Will I forced use mechanical shutter I misunderstanding something?",computer-vision cameras
7245,How many quadcopters would take lift burrito?,"I investigating possible business opportunity quadcopters perform high-precision nutritional delivery via burrito medium. I never used burrito, I read internet typically weigh 600-700 grams (1). This much heavy commercially available platforms. How many quadcopters would take lift single burrito? (1):",quadcopter distributed-systems
7249,Quadcopter - iPhone ultimate flight controller?,"iPhone contains Gyroscope GPS Two photo video cameras Self-sufficient battery outlives motor battery Wifi Backup connectivity (cellular, bluetooth) Programmable computer Real-time image processing capabilities face detection General purpose IO (with something like this) old models available cheap. What main benefit separate dedicated flight controller camera hobbyist rotorcraft rather general purpose device like iPhone?",quadcopter
7251,Is bug Encoder Counts packets 43&44?,I think I found another bug - one mentioned another post angle distance. This one reading encoder's counts. I using workaround bugs I found one instance counts I reading right encoder incorrect. I reading loop sleeping 100msec turning create2. Here part counts definitely shows problem: This kept going I stopped. It seems problem reaches max. Has anyone else ran explain provide another workaround?,irobot-create
7254,Cool robotics projects,I'm robotics student new field. Can suggest websites provide projects/helpful info I learn from? Thanks,mobile-robot
7256,Sensing level liquid tube,"I'm looking build sensor detect level liquid tube. It precisely accurate, detect whether level approximately certain height. The liquid level seen red oval I thought monitoring webcam using opencv detect liquid level. seemed bit overkill. Especially I dedicated PC process images. Surely there's simpler solution. Perhaps component I attach raspberry PI arduino board ... I'm familiar laser sensors I don't know suitable. As long it's reliable ... EDIT I add tube contains toluene flammable, vacuum sealed. So can't drill it. Some kind optical/laser sensor might OK, long recognise clear liquid.",arduino sensors raspberry-pi laser
7265,PID another module implements PID control?,"I'm charge module control smoothness platform move; platform already implements closed-loop control firmware closed I access source code. It therefore requested closed loop control implemented top PID, superior layer, module already implements closed loop control, several question: It's conceptually correct implement PID control upper layer closed loop control implements it? What features may loose lower close loop? Maybe loop control closed negatively influenced PID implements top layer? Estimate The angular speed, yaw pitch, based position motors using Kalman filters generate values far actual values reported",pid
7266,How I make quadcopter avoid obstacles using infrared?,"I quadcopter built, I need able make autonomously follow route avoid obstacles possible. My general plan array sensors pre-defined ""front"". The quadcopter go forward. Generally I'd like make sensors pointing higher angle detect something getting closer bot moves forward, quadcopter stop, descend distance detected object decreases, continues forward. Similarly, I'd like opposite event happen sensors pointing lower angle detect something getting closer quadcopter. I'm thinking something like 9 small infrared distance detectors (pointing up, forward, || left, forward, right), basically 3x3 matrix. Would anyone ideas feasibility this? I'd like use raspberry pi, probably also need additional board read values sensors. In addition, I idea sensors use, infrared even work. Any suggestions welcome. I also thinking ultrasonic sensors, 9 could get cluttered, I'd worry short range crash means death quadcopter. I also fear would cause interference other.",mobile-robot quadcopter sensors
7270,What load current load speed? Which battery best suitable motor?,"These specifications motor: 25000RPM load speed 12V No Load Current - 1A, Stall Current - 10A 0.36Kgcm torque What definition load current load speed? Which battery would suitable power motor?",motor
7271,How would I implement following drone camera using GPS?,"As title states, way make following drone tracks GPS unit, follows/orients camera that? Similar",cameras gps line-following
7277,"Assuming I angle respect two beacons, know distance them, I localize myself?","Let's assume I following situation, need find (x,y). Is possible? There appear one solution system, trigonometry bit rusty. I feel like I need one distance.",kinematics inverse-kinematics
7278,Adding Actuator Force (Featherstone) Articulated Rigid Body Model,"I'm working project I need model system essentially comprised series ball-and-socket joints attached base, attached turn prismatic joint (rail). I've read Roy Featherstone's Rigid Body Dynamics Algorithms cover-to-cover, I've also read Dynamics section Springer Handbook Robotics (also written Featherstone). It took long time get acclimated using ""spatial vector"" ""spatial matrix"" notation, re-creating notation hand exercise works nice way concatenating 3x3 3x1 matrices vectors 6x6 6x1 matrices vectors. The maths invents perform operations bit tedious read hijacks standard notation, overall everything compact, easy implement MATLAB. My problem this: How I add actuators model? He walks explicitly configuring joint definitions, link definitions, etc., comes actuators applied forces says something like, ""Just add $\tau_a$ Bob's uncle!"" - it's discussed all. In Handbook Robotics suggests introducing false acceleration fixed base add gravitational force term, doesn't show add local coordinates mention add actuator input. Any help would greatly appreciated. I've considered starting different book, it's going great expense time re-acclimate different set notation. I'd like move forward this, I feel like I'm inches shy finish line.",actuator dynamics joint
7287,Odometry vs dead-reckoning,"In terms robotics, differences odometry dead-reckoning? I read odometry uses wheel sensors estimate position, dead-reckoning also uses wheel sensors, ""heading sensors"" well. Can someone please elaborate point me? Thanks",odometry deduced-reckoning
7288,Linear Motion Control quadrotor (clarification),"I've posted question regarding matter I couldn't solve. I'm reading paper, authors state Linear $x$ $y$ Motion Control: From mathematical model one see motion axes $x$ $y$ depends $U_{1}$. In fact $U_{1}$ total thrust vector oriented obtain desired linear motion. If consider $U_{x}$ $U_{y}$ orientations $U_{1}$ responsible motion x axis respectively, extract formula (18) roll pitch angles necessary compute controls $U_{x}$ $U_{y}$ ensuring Lyapunov function negative semi-definite ( see Fig. 2). The paper clear except linear motion control. They didn't explicitly state equations extracting angles. The confusing part say extract formula (18) roll pitch angles necessary compute controls $U_{x}$ $U_{y}$ formula (18) $$ U_{x} = \frac{m}{U_{1}} (\cos\phi \sin\theta \cos\psi + \sin\phi \sin\psi) \\ U_{y} = \frac{m}{U_{1}} (\cos\phi \sin\theta \sin\psi - \cos\phi \cos\psi) \\ $$ It seems roll pitch angles depend $U_{x}$ $U_{y}$, therefore compute roll pitch angles based $U_{x}$ $U_{y}$ control linear motion.",control quadcopter
7291,Stereo vision Matlab,I working project robot soccer vision. How I utilize two webcams stereo vision matlab robot soccer matters?,stereo-vision matlab soccer
7294,Dispensing precise quantities liquid powder,"I've toying around idea automating process testing aquarium water certain chemicals. Very briefly, salt water aquariums (reefs, specifically) require almost-daily testing 3-4 chemicals (calcium, alkalinity, ammonia, phosphate). This typically done hand, using various kits. There two main types combine several powders fixed amount aquarium water, compare color mixture turns chart combine several liquids together aquarium water, add another liquid mixture turns color. record much final liquid add color change occur (titration). Both methods straightforward, tedious. To maintain aquarium well, really need daily readings metrics, easily adds 30 minutes+ daily. So - I'd like able automate process. The biggest question is, I reliably dispense materials needed? We're talking gram milliliter UoM here. The kits come plastic syringes spoons correct volume powders. I need way measure dispense these, way queue several days worth (refilling daily defeats purpose). Any ideas? Edit different How measure dispense finite amount powder liquid units measure involved. I need able reliably dispense ~ 1g +/- 5% powder, 1ml +/- 5% liquid.",electronics
7295,Help ultrasonic sensors obstacles avoiding robot,"Well, I start directly problem. I'm working project I 10 days left. The idea simple, wheeled robot 3 ultrasonic sensors avoid obstacles. I've developed code it's working fine. I'm using: Arduino Uno, L293D driver 2 dc motors, 3 HC-SR04 ultrasonic sensors Newping library. I've made kind shield I soldered common points gnd 5V order connect L293 ic sensors pins easily. The problem ultrasonic sensors functioned expected behavior! After always sending zero result sometimes number showed disconnect sensor! Is power problem? I'm using usb cable power arduino sensors (motors powered using 2 Li-po batteries) kindly provide guidance",arduino power ultrasonic-sensors
7297,Arm disassemble assemble notebook home?,"Suppose I perfect AI control robotic arm. What characteristics fulfill able take common tools screwdriver linesman's disassemble assemble conventional notebook computer? Are models available? Is seems me, arms OWI-535 toys, i.e. relocate lightweight objects that's all. Am I right? UPDATE Also suppose AI look assembly area multiple HD cameras perfectly ""understand"" sees.",robotic-arm
7308,How control dc motor,"I 2 12v motors 12v battery I would like know best solution controlling motor Arduino Uno would be. Does motor controller need maximum current 100A? I though 100A transistor connected pwm pin arduino, then, control motor pwm. Is voltage regulator better pwm?",motor esc pwm microcontroller
7311,How make compact soft robot,I want make compact (actuators motors sensors one) soft robot. Actuators pneumatic dielectric. I need suggestions manufacturating. I'm open new ideas.,actuator manufacturing
7315,2Nm small motor,"Currently designing spherical wrist, I want manipulate 300gr payload. design 200mm span, I'm guessing 1.1Nm (considering weight structure & motors). I've looked Maxon, Faulhaber, can't find motor+gearbox+encoder 100gr. Any suggestion ?",motor actuator torque
7316,How I make motion tracking camera?,"I'm looking CCTV, interested minimising costs motion tracking camera cover area would otherwise utilise multiple cameras. There already something like market manufactured company called NightWatcher (I think). However, track, merely senses using 3 PIR's points camera 1 3 positions. Ping ponging subject sensors. I like idea this, drawbacks, wondering anything I could arduino similar achieve better result. I stumbled across this, entirely sure it. Also outside application, thread indoor (if makes difference). Edit... Just case I mislead you, I want unit sensors detect movement camera face position.",cameras
7317,Vacuum Lifter: Moving Playing Cards,"I'd like buy small Vacuum Lifter I move playing cards around robotics. But ""google-fu"" failing me. I don't really know search terms look for... webpages look find kind component. In essence, I want electronic version Vacuum Pen. I don't really know search kind component. I've found pneumatic valves complicated machinery... ideally I'd want self-contained electronic vacuum pen. Since I'm planning move playing cards around. Anyone idea look something like this? Thanks.",robotic-arm actuator
7320,Position estimation photo fingerprinting,want make 3d position position change estimation photos taken flying robot. I need suggestions fast photo matching.,localization
7327,How transfer signed integers libusb?,"Folks programmers stack exchange asked ask here: I want communicate arduino sent integers it. I code program C++. I initialy used bulk_transfer(), sends char data. This API reference libusb: Here prototype bulk_transfer() int libusb_bulk_transfer (struct libusb_device_handle *dev_handle, unsigned char endpoint, unsigned char *data, int length, int *transferred, unsigned int timeout) As see, data unsigned char pointer, is, pointer buffer containing length unsigned chars. I successfully transcieve strings. How I transfer integers sign? Currently I thinking system arduino asks digit sending character program sends number reply followed sign, requested next. Is solution viable? Or I transfer integer string? Is better way?",arduino communication usb c++
7331,position control linear model quadrotor (problem tracking task),"Lately, notice I posted questions regarding position tracking nonlinear model. I couldn't it. I've switched linear model, hope I it. For regulation problem, position control seems working I switch tracking, system starts oscillating. I don't know why. I stated I've done hope someone guides correct path. The linear model quadrotor provided $$ \begin{align} \ddot{x} &= g \theta \ \ \ \ \ \ \ \ \ \ (1)\\ \ddot{y} &= - g \phi \ \ \ \ \ \ \ \ \ \ (2)\\ \ddot{z} &= \frac{U_{1}}{m} - g \\ \ddot{\phi} &= \frac{L}{J_{x}} U_{2} \\ \ddot{\theta} &= \frac{L}{J_{y}} U_{2} \\ \ddot{\psi} &= \frac{1}{J_{z}} U_{2} \\ \end{align} $$ In paper, position control based PD provided. In aforementioned paper, (1) (2) desired angles $\phi^{d}$ $\theta^{d}$ obtained, therefore, $$ \begin{align} \theta^{d} &= \frac{\ddot{x}^{d}}{g} \\ \phi^{d} &= - \frac{\ddot{y}^{d}}{g} \end{align} $$ $$ \begin{align} \ddot{x}^{d} &= Kp(x^{d} - x) + Kd( \dot{x}^{d} - \dot{x} ) \\ \ddot{y}^{d} &= Kp(y^{d} - y) + Kd( \dot{y}^{d} - \dot{y} ) \\ U_{1} &= Kp(z^{d} - z) + Kd( \dot{z}^{d} - \dot{z} ) \\ U_{2} &= Kp(\phi^{d} - \phi) + Kd( \dot{\phi}^{d} - \dot{\phi} ) \\ U_{3} &= Kp(\theta^{d} - \theta) + Kd( \dot{\theta}^{d} - \dot{\theta} ) \\ U_{4} &= Kp(\psi^{d} - \psi) + Kd( \dot{\psi}^{d} - \dot{\psi} ) \\ \end{align} $$ regulation problem $x^{d} = 2.5 m, \ y^{d} = 3.5 m$ $z^{d} = 4.5 m$, results Now I change problem tracking one, results messed up. In last paper, state A saturation function needed ensure reference roll pitch angles within specified limits Unfortunately, max value $\phi$ $\theta$ stated paper since use Euler angles, I believe $\phi$ range $(-\frac{\pi}{2},\frac{\pi}{2})$ $\theta$ range $[-\pi, \pi]$ I'm using Euler method ODE solver step size fixed. For derivative, Euler method used. This code For trajectory code clear all; clc; fileID = fopen('xyTrajectory.txt','w'); angle = -pi; radius = 3; z = 0; = 0; = 1:6000 ( z < 2 ) z = z + 0.1; x = 0; = 0; end ( z >= 2 ) angle = angle + 0.1; angle = wrapToPi(angle); x = radius * cos(angle); = radius * sin(angle); z = 2; end X(i) = x; Y(i) = y; Z(i) = z; fprintf(fileID,'%f \t %f \t %f\n',x, y, z); end fclose(fileID); plot3(X,Y,Z) grid",control quadcopter matlab
7333,Why ESCs stop working?,"I'm new robotics first time building quadcopter. I'm unable work I keep losing ESCs. Most recently testing, I've managed calibrate 4 ESCs accurately control speed 4 motors. But neatly securing frame, 1 motor didn't work. I recalibrated ESCs and, running again, motor still didn't work. However, 3 motors continued run first, also suddenly stopped altogether. Research suggested ESCs cut-off voltage, indicating battery might flat, I immediately looked recharging it. To surprise, (still new) battery appeared bulged out, indicating damaged. Further research suggested size battery I using insufficient amount current drawn motors. So, without PWM applied, I reconnected new fully charged battery hope listening beeps diagnose, one ESC immediately coughed huge puff smoke. Before happened, I managed get 2 ESCs run motors. Despite several attempts tweaking PWM signals calibrating them, I ended replacing 2. Unless there's obvious reason ESCs keep dying me, I assume specific ESCs badly made I ask money back. These components I'm using: Raspberry Pi 2 Model B Adafruit 16-Channel 12-bit PWM/Servo Driver - I2C interface - PCA9685 RCTimer Mini ESC 40A OPTO BLHeli Firmware (Oneshot125, Support 2-6S) RCTimer 2208-8 2600kV Outrunner Brushless Motor Gens ace 2200mAh 11.1V 25C 3S1P Lipo Battery Pack The Raspberry Pi powered micro USB interface 5V Step-Up Voltage Regulator connected 5000mAh 3.7V LiPo battery. The PWM Controller powered Vcc pin GPIO1 (3.3V) pin Raspberry Pi, also happens power sensors. At time (when 4 motors worked), I able accurately control either 50Hz 400Hz 1-2 millisecond duty cycles.",quadcopter power esc pwm
7334,Mechanical design base robotic arm,"I using DC motors build robotic arm. I want make base shoulder (which rotates lifts) stable stronger. How I design using DC motors? Also I would like put motor elbow base efficiency. Which design best suits this? UPDATE I building robotic arm payload approx. 1-2 kg using DC high torque motors. In model, I using shoulder gripper. The gripper self made weighing approximately 400 grams. I want proper design material choice shoulder part remains less heavy stable. In addition I want operate movement gripper, i.e. motion, using motor base part. What design better alternative?",robotic-arm design
7339,Driving non-circular timing belt,"I'd like create camera slider similar one. The part I'm sure setup camera drive. It looks like I buy similar timing belt here, I'm sure set servo drive slider. Particularly keep belt contact drive pulley. My fabrication skills limited I need simple box solution.",servos
7344,Image based 3d position estimation one camera,There many 2d position estimation one camera. Is 3d position estimation application technique one camera? If application technique why?,localization
7349,Arduino triggers camera start recording,"I've already made Arduino device detects trigger event, I want trigger recording storage video event occurs. If camera could wirelessly triggered feet away Arduino unit, would optimal, I settle running wires need be. I'm looking suggestions I'm limited budget project. I want avoid reinventing wheel ordering parts I can't get work Arduino. I'm considering use camera. This first Arduino project. Any help welcome.",arduino wireless
7358,Suggestion camera,"Are good low cost cameras frequently used robotics? I assuming cameras good fit robotics ... Works well OpenCV PC Windows support - USB2/USB3 (GigE, USB3 vision cameras seem pricey) Good image sensing performance Adjustable focus - manual motorized (fine focus control would great) Do IP cameras make good cameras Robotic vision projects?",computer-vision cameras
7359,Interfacing GPU image processing motor control 30+Hz,"I would like make robotic system takes input video feed, runs GPU-based image recognition video, outputs commands set motors. The goal motors react video little latency possible, hopefully order 10s ms. Currently I GTX 770m laptop running Ubuntu 14.04, connected camera heavy image processing. This takes frames 30Hz output motor commands frequency. After days looking around web design system, I'm still loose end whether (a) even feasible (b) so, best approach interface laptop motors? The image processing must run Linux, leeway change part things.",control real-time
7361,idea web application robotics,"I learning I interested robotics, also I need update web development skills question - idea good web application could connected robotics - service robots, industrial robots etc. Maybe already open source ongoing web application projects robotics I make contribution. Thanks!",design software
7363,What difference Multiple robots swarm robots?,What difference Multiple robots swarm robots? What key point? Also multi agent systems? Do multi agent systems works computer simulations games? These terms used similar applications.,simulation multi-agent swarm
7378,Electric piston (longitudinal electric motor)?,"Are electric motors, apply force rotational motion, longitudinal motion? They electromagnetic design gears worms. Such motors would great linear actuators. They could transfer force feedback. What name devices?",motor actuator
7383,Determine configuration space robotic arm,"I'm working 4DOF Parallel-Mechanism arm. I'm interested writing planners arm (PRM RRT) configuration space, I'm sure identify obstacles/collisions. When writing planners mobile robots 2d workspace, easy define visualize workspace obstacles planner/robot operating. This website (link) shows great example visualizing workspace configuration space 2DOF arm, I higher dimensions?",robotic-arm motion-planning
7384,How memory alloy used alternative compressor found refrigerator?,"I'm curious alloy say used alternative traditional compressor. Can anyone explain would work? My goal understand use case I adapt alloys robotic projects. My gut tells perfect kinematics, mechanisms, I'm missing pieces puzzle (how would work?)",kinematics mechanism
7385,3D scanner Phone Camera,"123D software construct 3D model photos taken phone. It doesn't process photos phone. Instead, sends cloud create 3d model. How construct 3d model like (only one camera)? I searched find information laser/procetor scanners (simple desktop use only). I think 123D uses IMU sensors camera use cloud? Can beaglebone rasperry pi create 3d models like this?",computer-vision 3d-printing 3d-reconstruction 3d-model
7386,"Introduction Robotics Mechanics & Control, John J Craig., 3rd Ed., Forward transformation problem Examples 2.2 2.4","I reading book ""Introduction Robotics Mechanics & Control"", John J Craig., 3rd Ed., Forward transformation problem Examples 2.2 2.4. Ex. 2.2 (Page 29): Frame {B} rotated relative frame {A} X axis 60 degrees clockwise, translated 20 units along Y axis 15 units along z axis. Find P frame {A} P frame {b} = [0 8 7] The book's answer [0.18.062 3.572]. But answer [0 30.062 11.572]. Ex. 2.4 (Page 33): Vector P1 rotated 60 degrees clockwise, X axis translated 20 units along Y axis, 15 units along Z axis. If P1 given [0 8 7], find P2. Essentially Ex.2.2 2.4 problem. However, Transformation matrix Ex 2.4, [0 8 7] translation vector (The 4th column T) instead [0 20 15]. And, given answer [0.18.062 3.572]. I sure typo, I missing genuine operation. Please let know opinion. Thanks.",forward-kinematics books
7387,"Hector SLAM, Matching algorithm","I'm trying understand scan-matching part Hector SLAM (PPT summary). It seems little difficult understand, cases, possible actually perform alignment scans. Can anyone explain it? In case, I'm working simulation. I'm moving robot corridor-like featureless environment (only two walls) I don't get map. Nevertheless, I move sinewave motion, I'm able get map. Moreover, I additional feature, algorithm even shows real path long feature seen (right part image), otherwise shows weird-looking oscillatory path resemble sinewave all. Something important notice width map pretty accurate (real=4m, map's=4.014m), length movement also somehow accurate (real=15m, map's= 15.47). I'm using Hokuyo URG-04LX laser range finder, odometry, IMU. I'm running Ubuntu 14.04 using ROS Indigo. I less understand Hector works, I idea I'm getting map specially trajectory. Thank you.",localization slam ros mapping rangefinder
7388,Fingerprinting/ model matching algorithms localization,This paper mentioned fingerprinting/model matching case. But I could find image based algorithm. Any suggestion image based localization,mobile-robot localization
7389,ROBOTIC arm playing chess,"I wish build chess playing robot robot arm shown youtube, anyone please tell robot arm would suit purpose whether bought second hand alternatively anybody willing sell used chess arm robot? Please help out.",robotic-arm
7395,Simple wireless connection two circuits,"I'm relatively new robotics, I'm building project I need simple wireless connection two circuits first circuit switched on, circuit gets switched too. I'm looking preferably build something like own, I idea wireless connections. I know basic wired robotics. I also know C++ programming helps. Apologies question already asked. Regards, Hanit Banga",wireless
7397,Selecting hardware: stereo camera beginners,"I'm looking cheap hardware would offer results decent enough continue experimentation. I've looking obtain hardware learning stereo vision 3D reconstruction, I found two basic ways: - buy 2 cheap webcams DIY - buy stereo camera For I understood little variations distance inclination easily compromise diff map DIY version might end requiring constant calibrations, however end, buying ""professional"" stereo camera range 500 euro infinite. For moment I trying something between, like minoru 3d, however overall performance camera looks bit poor also it's 2009 product, however I can't find recent product offering similar solution. Can suggest would best way/product/guide archive decent results without spending fortune ? Thank much :)",stereo-vision
7398,Matlab toolbox (Windows) Sick lasers?,"Does anybody know I get matlab toolbox functions work SICK laser-scanner (Windows OS)? I'm using SICK-LDRS2110 ethernet cable, SOPAS software allow program recording times specific tasks. Any tips welcome! Thanks!",laser matlab
7400,Quadcopter force/torques duty cycle conversion,"determined control loops quadcopter project, I'm going determine motor commands (PWM duty cycle) motor forces/torques. I following guidelines document I trying inverse matrix M (page 17) determinant equal 0. The procedure correct? Anyone suggest link conversion? I searched Internet I haven't found much that. Thanks The part document I'm referring following:",control quadcopter pwm
7403,EKF SLAM C++ code openslam.org,I recently working code robot maze solver using laser sensors odometry data. I went pdf available online $\textbf{'SLAM Dummies'}$ understand process conceptually. I master's student control part wasn't hard writing code C++ difficult task. The EKF SLAM codes available site $\textbf{openslam.org}$ seem bit advanced since I beginner. I couldn't find site (maybe missed) simplest EKF SLAM algorithm 2D implementation. Could anyone guide open source code C++ 2D implementation I build suit robot I working on?,slam
7406,How I Program Create 2,I un-boxed set Create 2 charge night. How I program it? Where software? Daniel,irobot-create programming-languages
7409,Libusb arduino communication working,"I line following robot based opencv. I onboard computer(an old pandaboard) running opencv. It calculate offset required path communicate arduino via USB. Then PID optimisation data, adjust speed left right motors. To dismay communication part working, I've tried hard day fix result. Here relavent code running pandaboard: imgvalue data send. This code running Arduino: void loop() { Serial.write('s'); if(Serial.available()>0) Input_tmp = Serial.read(); if(Serial.available()>0) Input_tmp = Input_tmp | (Serial.read() << 8); Input=Input_tmp; myPID.Compute(); // adjust motor speed } What happens I run pause libusb read operation timeout zero(infinity). At point I've tried resetting arduino, doesn't help. So I make program respond start byte send Arduino? Where I go wrong?",arduino communication usb
7411,What cheapest way detect identify vehicles entering gate real time?,"I want detect identify vehicles passing gate. I live video feed gate I initially thought process detect number plates help OpenCV graphics library freely available. The problem is, size number plates may vary widely, language number plates written with(Bengali) good OCR performance all. The next idea put QR code windshield vehicles. (Yes vehicles supposed enter area private enlisted vehicles). But I confident I able detect identify QR codes real time 100% accuracy, QR codes might get pixelated due low resolution video. So anyone suggest cheap way adopt detect identify vehicles? Can NFC cheap sensors used purpose?",sensors design computer-vision
7415,Quadcopter PID output duty cycle conversion,"I'm trying design two PD controllers control roll pitch angle quadcopter P controller control yaw rate. I give system reference roll, pitch yaw rate smartphone controller (with WiFi).In case roll pitch feedback outer 'P' loop given attitude estimation algorithm, inner 'D' loop reference angle rate, feedback provived filtered version gyroscope data. As far yaw rate concerned, P controller, reference yaw rate given smartphone, feedback loop provived smartphone. This illustrate situation. My sampling frequency 100hz (imposed attitude estimation algorithm, Kalman Filter, I'm using). I tuned controller gains matlab, imposing rise time 0.1 seconds maximum percent overshoot 2% root locus. Matlab able found solution, large gains (like 8000 P 100 D). I tuning, using quadcopter model (for euler angle) based linearized model quadcopter instance : $$\ddot \tau_\Phi = I_x\ddot \Phi -> G_\Phi(s) = \frac{I_x }{ s^2} $$ order 'reasoned' starting point gains, re-tune reality. (The transfer function continous, model I obliviously used discrete version 100hz sampling rate). This premise following questions. Now, I map controller outputs duty cycle. Since I'm using PWM 25Khz frequency, period (in TIM channel configuration) 2879. I checked activation threshold (after motor starts move) threshold stops increasing speeds, first 202 second 2389. I following good answer Quadcopter PID output I still questions. 1) As far throttle mapping concerned, I map way values coming smartphone controller (in interval [0, 100]) mapped whole [202, 2389] interval, I 'reserve' speed order allow quadcopter angular movement exploiting differences 4 motor speeds even 100% throttle? 2) Coming back fact matlab propose huge gains controllers, leads fact I cannot directly sum controller output duty cycle stated metioned answer (because I certainly go [202, 2389] bound TIM pulse). Doing proportion result altering gains systems, placing somewhere else poles systems procedure done matlab became useless, right? So, I'm wrong? I tried enforce matlab bound gainsm instance [0,100] interval, case cannot find gains constraints verified. Thank",control quadcopter pid matlab
7416,"Artificial Intelligence Software Packages: Professionals, University education oft' step behind. What's actually used?","Currently using Windows 8, software packages artificial intelligence programming (robotics branch) used today's professional environment standard. Lots internet suggestions, companies seem keep closely guarded secret. And internet rumors true? Would switching Ubuntu offer terms depth. Context: Educational field: Computer Science Artificial Intelligence, current focus (though obviously experience others) programming languages stands c++, C Python. Looking build, program develop human-like bot (NOT aiming singularity point ;))and asking question order build toolbox little.",design software artificial-intelligence programming-languages
7423,Many One Bluetooth Communication Link,"I application requires data streamed multiple Bluetooth modules one host controller. Somewhat like multiple Clients one Server. The throughput looking around 1920-bits per second per module. The SPBT2632C2A.AT2 module supports SPP profile single link (One Client One Server). My application needs multiple modules ( Max 5) send information one server. Is way One Receiving Station multiple transmitting module using SPP? (All modules SPBT2632C2A), need Different higher end module server side supports multiple SPP Links? It advisable look module like BCM2070 driver run system?",electronics
7429,Is ROS hard real time safe?,"I know question asked many times, still clear me. I read online isn't people say control robots ROS applications hard real time constraints. So, I need technical arguments (rather plain ""ros real time"") I specific (suppose ROS RTOS): I read ROS uses TCP/IP-based communication ROS topics I know TCP/IP reliable. That means I cannot use topics real time loop? For instance send control signal system publishing topic, system sending feedback via topic? If I RTOS (eg Linux+Xenomai) I build real time control loop robot using ROS, ROS bottleneck? Maybe naive I lack knowledge, please enlighten me! Note: I define hard real time system (eg 1KHz), system guarantee miss thing (if control loop fails run every 1ms system fails).",ros real-time
7434,"What achievable stiffness impedance/admittance controlled robot (incl. haptic devices), given structural control stiffnesses?","EDIT: I realised I missed point paper completely (thanks very-skim reading ;) ). So, part I'm relating much damping - much stiffness - display obtain stability, given structural stiffness. I changed question accordingly - achievable stiffness impedance/admittance controlled robot, given structural control stiffnesses? (Stiffness/compliance is, course, mathematically one terms total impedance/admittance) Let us consider haptic device mechanical control parts, mechanical part infinitely rigid (compliant). Basically, would robot impedance admittance control. I thought perceivable stiffness simple serial connection two stiffnesses - stiffer mechanical structure is, better display control stiffness: $k = \frac{k_e k_c}{k_e + k_c}$ $k_c$ stiffness control. Still, I cannot find confirmation this, although something similar stated Samur's ""Performance Metrics Haptic Interfaces"". I would grateful could refer sources plain prove wrong right (: In paper (here, p. 728) I found stability condition virtual damping value relation virtual stiffness, given structural stiffness.",control mechanism reference-request
7438,How make directed graph?,"I'm working robot would able navigate maze, avoid obstacles identify objects it. I monochromatic bitmap maze, supposed used robot navigation. Up till now, I converted/read bitmap image maze 2D array bits. However, I need guidance use array plan path robot. I would appreciate could share links well, I new stuff (I 1st year BS electrical engineering student) would happy detailed explanation. If need elaborate anything kindly say so. I would grateful! Here's image maze. This sample image; robot able work maze (image) similar dimensions. And welcome! Thank Chuck! UPDATE Heres code sub2ind c++. Kindly see output correct:- Heres Link output file.",arduino mobile-robot localization mapping planning
7440,Matlab Control Toolbox root locus,"I'm using control system toolbox provided matlab estimate gains controller: using root locus design I get graph like one . My question is: x x-axis? maybe pole position previous iteration optimization procedure I run find gain value satisfies requirements? It shouldn't open loop pole position, system formed two integrators multiplied constant (1/inertia). Thanks Edit: I add requested details: I start following simulink diagram: trasfer function $$G_\Theta(s) = \frac{Y(s)}{U(s)} = \frac{\Theta(s)}{\tau_\Theta} = \frac{1}{I_y s^2}$$ Iy = 0.0054 (another little question, point I'm taking torque correct?) I select analysis , control design, compensator design. I select Kp Kd gains tuned, I use root locus specifying constraints. Then I click SISO Design Task, automated tuning, optimize compensator, automatically tries find gain values satisfy constraints. The white area satisfies constraints, I think pink squares poles position completed optimization procedure. This correct? But case, x(pole) shown? Thanks",control matlab
7445,Why PD controllers quadcopter angles control?,question is: lot cases possible find Internet PD (instead PID) control euler angles quadcopter? Why integral part often neglected kind applications? thanks,control quadcopter pid
7449,Changing behaviour Roomba 880,I've seen possible use micro controller send commands Roomba SCI interested changing behavior roomba operation (e.g: change priority behaviours) Is IDE roomba? Regards,roomba
7450,Which math course beneficial?,"Let know Academia instead, I posted get responses specifically people active robotics development. I'm currently undergraduate student completing majors mechanical engineering computer science. I'm still fairly new field, interest firmly electronic mechanical systems. Next year I take one courses below: I want take three likely eventually, time schedule allows one. Therefore, I wondering could explain little bit applied robotics field believe helpful learn now.Thanks advance!",beginner theory
7454,How use IMU hover fixed location quadcopter presence gravity?,"There's accelerometer IMU. The output integrated estimate position, least theory. But practice, there's huge acceleration gravity, varies rather randomly across locations. Vibrations etc filtered low-pass filters, filter gravity? Is simply case vertical vector ignored calculations? My application is, I want build quadcopter could hover one place even presence (reasonable) winds: quadcopter ideally would tilt towards random gusts maintain certain position. Every single tutorial I could find Internet uses accelerometer estimate stationary, simply assumes using gyroscope hold quadcopter level enough. I also want use IMU estimate altitude possible, course input something like Kalman filter conjunction sonar system. Obviously, application GPS far slow.",quadcopter imu
7456,Human arm inverse kinematics,Hi I want implement human arm robot task moving glass two points using Robotic Toolbox Matlab Peter Coorke. I'm student I'm newbie kind things I would find good reference solving inverse kinematics human arm algorithm implements kind obstacle avoidance exploiting redundancy manipulator (7dof) using null space motion. Anyone suggest good reference follow implementation toolbox? Thanks,robotic-arm inverse-kinematics manipulator matlab
7457,Cognitive Architectures: perform qualitative quantitative comparisons?,"I couldn't find sub stackexchange artificial intelligence, I think robotics comes close, I'm posting here. I recently saw TED talks AI Google car, interesting me: Hod Lipson - Building ""self-aware"" robots Juan Enriquez - The next species human Ray Kurzweil - Get ready hybrid thinking The third one led 'criticism' section (labeled wiki article, though certainly least partially reads criticism section well) Kurzweil 'theory' brain, namely ""Pattern Recognition Theory Mind"" (PRTM). After link surfing people performed analysis PRTM respective academic contributions, I came learn Cognitive Architecture: ""A cognitive architecture refer theory structure human mind. One main goals cognitive architecture summarize various results cognitive psychology comprehensive computer model. However, results need formalized form far basis computer program. By combining individual results comprehensive theory cognition commercially usable model arise. Successful cognitive architectures include ACT-R (Adaptive Control Thought, ACT), SOAR OpenCog."" It appears several interesting architectures, including 3 mentioned above. I read bit ACT-R, SOAR, OpenCog, DUAL, CHREST, CLARION. The list comprehensive. It also appears two main types architectures: Connectionism Symbolic. Though I many questions, main question this: What quantitative metrics qualitative properties measure compare two architecture types? Other questions Can architectures categorized one, other, combination two, third, fourth, etc? How two main types alike? How different? What recommended readings topic. What centres organizations leading development this? What computer programming languages, related skill-sets, cross-domain knowledge set utilized R&D product offerings systems?",artificial-intelligence
7460,How calculate quadcopter lift capabilities?,I'm looking equation (or set equations) would allow predict (with fair accuracy) heavy payload quadcopter capable lifting. I assume main variables would weight copter well size + power 4 rotors. What general approach one use make determination?,quadcopter
7462,How safety cages around quadcopter rotors/blades affect lift capabilities?,"I interested building quadcopter scratch. Because I like err side caution, I'm considering adding ""safety cages"" around propeller/rotor, hopefully prevent (at least minimize) chance spinning rotor blades coming contact someone. Without knowing much physics behind ""lift"" works, I would imagine cages present two main problems rotors: They add weight copter making harder lift payload; They're sheer presence/surface area makes harder spinning rotor generate lift push away ground The former problem obvious self-evident. For latter problem, I mean ""surface area"" I imagine caging around spinning rotor, difficult lift effectively. For instance, spinning rotor might ability generate enough power lift, say, 2kg. But construct entire box (not cage) around entire rotors, 6 sides openings, I would imagine lift capability would drop 0kg. So obviously, I'm interested cage design provides adequate safety doesn't ""box in"" rotor much causes rotor ineffective incapable providing lift. So I'm looking optimal tradeoff safety (boxing/caging around spinning rotor) lift performance. I would imagine calculating designing pretty huge undertaking lot math behind it. I'm wondering anyone already figured stuff out, anyone knows way model safety-vs-lift-performance trade way.",quadcopter
7463,Stewart platform robotic wrist joint,"I'm planning design wrist humanoid robot. I would like choose design sturdy allowing dexterity comparable human wrist. One option presented use Stewart platform. This setup appears correctly recreate possible movements human hand. My immediate concern platform use total six actuators require additional power computational requirements. I don't want commit design I certain isn't better alternative. Is Stewart platform good choice replicating dexterousness human wrist? If not, better solution?",robotic-arm design actuator joint humanoid
7470,7DOF inverse kinematics spherical wrist,"Is possible apply kinematic decoupling 7 DOF 7R manipulator spherical wrist? If possible, anyone suggest reference apply approach redundant manipulator spherical wrist, explain possible? I'm working Robotic Toolbox (matlab) numeric algorithm find inverse kinematics solution without problem I don't specify orientation. And I thinking solving problem second time considering spherical wrist. Will approach work?",inverse-kinematics manipulator matlab
7472,Wiring & driving TowerPro SG90 servos,"I got hands Tower Pro SG90 9G servos cannot find schematics datasheet anywhere (besides link). I following concerns: Looks like they're rated 4.8V, tolerate 5V supply? How I determine current require, amps, mA, etc.? There's 3 wires: brown, red & yellow-orange, guys do? If I guess I'd say red power, another one direction, another one position rotate",rcservo wiring
7474,How I accurately calculate speed rotary encoder high sample rate?,"I'm aiming control motorized joint specific speed. To this, I'm planning attaching rotary encoder this. I'll controlling motor PID controller. With PID controller, I need control joints based velocity. Since: It would make sense something like this: double getCurrentSpeed() { return (currentAngle - lastAngle) / samplingRate; } However, there's issue; encoder doesn't provide high enough resolution accurately calculate speed (the sample rate high). I want updated data every 5-15 ms (somewhere range current motors seem able respond change range) Some information: 14 bit precision (roughly 0.0219726562 degrees per ""step"" encoder I'd like able calculate small speed differences possible As motors going fairly fast (120+ degrees/second highly variable speeds directions), feedback accurate delayed So, couple ideas: I find encoders I sample high rate. I thinking sampling time changes encoder's value. However, seems finicky likely noise-prone I could sort rolling average, would cause data values ""lag"" previous values would ""hold back"" output calculations somewhat would play PID loop Noise filter sort, although I don't know would work given rapidly changing values application However, none seem ideal. Is option get 16 bit (or higher!) encoder? Or another method/combination methods I could use get data I need?",motor pid algorithm
7475,Can I control 18 servo motor Raspberry Pi,"I'm trying make hexapod 18 servo motors i'm asking control Raspberry Pi. (Never used it). I saw lot's stuff control 1, 18, 20... Currently I'm working Arduino Mega, SSC-32 board, I found result slow jerky. At end, I want add camera processing image, I know Arduino can't handle process Raspberry Pi ? Thank information subject :)",arduino raspberry-pi cameras servomotor
7483,How transform x z coordinates Tx Ty Tz?,"I need get coordinates specific points 2D CAD file transform I could use move robotic arm points. The problem I get x z coordinates robotic arm needs x z Tx Ty Tz coordinates move certain position. Any suggestions? Edited: My task: I need robotic arm go certain points PCB board heat soldering paste. I could manually setting points pendant. But much easier way would get coordinates points CAD file write code using PC. code linear motion certain point looks like I could find manual. This pendant manual maybe helpful. I second year student ""Robotics mechatronics"". I'm currently internship scientific research institution. I really appreciate help!",robotic-arm
7485,Matlab: System simulation dynamic state matrix / input matrix,"I following system: $$\dot{x} = A(t)x+B(t)u$$ $$y = x$$ $A(t)$ $B(t)$ actually scalar, time-dependent. If would constant, I could simulate system Matlab using: lsim(sys,u,t,x0); However, would nice simulate system dynamic state input matrix. The matrices based measurement data, means I would discrete time step $t_i$ another matrix $A(t_i)$. Any suggestions that?",dynamics matlab simulation
7486,How determine long battery power robotic circuit for?,"Obviously robotic circuits draw different amounts power/current. So given battery, say, 9V, connecting 2 different circuits deplete two different rates. Robot/Circuit #1 might drain battery 5 minutes. Robot/Circuit #2 might drain battery 20 minutes. What ratings batteries allows us figure long power circuit for? Bonus points: rating uphold solar panels and, deed, power supplies (not batteries)?",power battery circuit
7489,Understanding solar panels supply power robotic circuits,"Say I solar panel outputs 6V 330mA, ~1.98 Watts. If I connect Arduino, expects 5V supply (roughly) 50mA, Arduino whole requires 5V * .05A = 0.25 Watts power it. To me, I understand correctly, perfect weather/sunlight, solar panel power Arduino day long, problem. Now let's say wire 4 motors Arduino, draw 250 Watts. Now Arduino + 4 motors drawing ~1.25 Watts. But since panels still outputting 1.98 Watts, I would think (again, perfect sunlight) panel would power Arduino motors day long, problem. Now add 4 motors Arduino circuit, total 8 motors. The circuit drawing 1.25 Watts + 1 W = 2.25 Watts. I would expect solar panel longer capable powering circuit, least properly. My first concern is: I understanding 3 scenarios correctly? If not, understanding going awry? Assuming I'm less track, next question is: solar panels ""daisy chained"" together increase total power output? In third case above, way add second solar panel mix, effectively making two panels output 1.98 Watts * 2 = 3.96 Watts, would make capable powering Arduino 8 motors (yet again, assuming perfect weather/sunlight conditions)?",power circuit
7491,Wiring necessary route power one several rechargeable batteries,"I'm looking robotics project draw power one 3 rechargeable batteries; basically whichever ""juice"" it. From initial research I've already done, I believe I could connect rechargeable battery (probably LiPo) diode, wire 3 diodes series. However, new robotics/electronics, I guess I wanted bounce community sanity check, see better way achieving this. Again, I looking way circuit automagically detect battery #1 power battery #2, ""decides"" draw power #1. The instant #1 depleted deemed ""less powerful"" #2, #2 battery takes over. Thoughts/criticisms?",power battery wiring
7493,Discover vector/angle stereo camera pose vehicle body,"I calibrated stereo camera system mounted passenger car means I able retrieve point cloud stereo image. However, I need find well camera aligned vehicle - read: camera perfectly facing forwards not. I guess never perfectly face forwards I need get angle (or rather 3D vector) ""perfect forwards"" ""actual camera pose"". What came mind drive vehicle possibly perfectly forwards use stereo visual odometry detect angle vehicle movement seen camera (which vector I looking for). The LIBVISO library visual odometry output 3D vector movement change one stereo frame another could used detect needed vector. The problem may actually able drive perfectly forward car. Maybe RTK GPS could used check correction. Will anyone suggestion proceed? The stereo camera I use consists 2 separate Point Grey USB cameras. Each camera mounted windshield inside car mount like one. The cameras calibrated mounting. The stereo baseline (distance cameras) 50 cm.",stereo-vision odometry
7494,Spring electronically adjustable stiffness,"I would like build mechanical module acts like spring electronically controllable stiffness (spring rate). For instance, let's imagine solid, metallic cube, 0.5 side. On top side cube, chair sitting top solid mechanical spring. When sit chair, would go proportionally weight, inversely proportional spring's rate. What I want spring's rate electronically adjustable real time, instance microcontroller system might increase spring's rate detects larger weight. I'm using example best describe I want achieve I'm robotics specialist I don't know inside terms. Is already electro-mechanic module one I'm describing? (obviously nevermind cube chair, it's spring I'm interested in).",actuator
7497,Torque coreless DC micro motor,"I would like build small two-wheeled robot similar one shown here. In order keep robot small, I intend use two coreless micro motors like one shown bellow. The power source would 2 AAA AA batteries, order reach 3 V. These batteries would represent bulk weight robot. The rest robot would virtually weightless. The specifications one motor are: My question small DC motors type enough torque even make robot start moving. I unable find torque info kind motors I suspect weight robot could much handle. Do know typical torque motor? Is another type (cheap) motor appropriate project?",mobile-robot motor wheeled-robot torque
7498,Measurement physics model fusion,"I combining two position measurements ball two sensors real time obtain one triangulated position x,y,z coordinates. As data exchange measurements carries latency, data extrapolated able obtain current position. Due extrapolation error appears triangulated data. I know ball air, velocity ball constant x directions velocity z direction decay g. The velocities x however oscillate function time around mean value actual x respectively velocity. The goes I compute acceleration z direction. It oscillates function time around g. Given I know ball behave, i.e. vx vy constant acceleration z direction z, I impose conditions better estimate triangulated position?",sensor-fusion
7499,Can I use Bipolar stepper motor driver drive Unipolar motor Unipolar configuration?,Can I use Bipolar stepper motor driver drive Unipolar motor Unipolar configuration ?,stepper-motor stepper-driver
7502,Control Velocity Position (Linear actuator),"I trying control velocity+position linear actuator. At moment I able control position velocity. But I'm trying control both. What control do: Let linear actuator drive position i.e. 0 100 cm constant velocity 1cm/s. I control actuator using PWM signal. And I measure velocity position using position sensor shaft. What kind control preferred, PID cascade? If so,what would code look like. Any kind control would function better? Thanks advance! EDIT: A describing picture. I want Velocity controlled Position controller. Hopefully make clear EDIT My first try trapezoid wave. Maybe easy way without much calculation power change s-curbe. Then accelartion/jerk alot smoother. I let microcontroller calculate 3 different formulas afterwards calculate using loop iteration. This way I use one PID position. The parameters following code fictional: A big problem code amount accelartion loops constant. It changed except already know amount loops take. I using two separate arduinos, connected using CAN-bus connection. Anyway, won't communicate unless load becomes high. This make Master/Slave impossible. Also system modular: adding another actuator circuit won't problem. The actuator speed controlled using PWM signal. The linear sensor deliver 0-10v signal reduce 0-5v simple voltage divider. The loop around 5 10 ms, depend maximum looptime. Arduino 10-bit(1023) ADC use oversampling I probably try increase 12-bit. To decrease reading speed I decrease prescaler ADC. The PWM output 8-bit(255), I trying find way increase. Because I think 255 steps low application. Because Arduino limit internal memory, pre calculating positions impossible. Thank help far!",arduino pid microcontroller
7506,Converting 2D array bits connectivity map (Code Debugging),"I'm working robot would able navigate maze, avoid obstacles identify objects (Boxes pot balls) it. I monochromatic bitmap maze, supposed used robot navigation. Up till now, I converted/read bitmap image maze 2D array bits. Right I writing code convert 2D array (that represents maze) connectivity map I could apply path planning algorithm it. Mr. @Chuck helped providing code MATLAB. converted code C++, however code isn't providing right output. Kindly see code tell I wrong. I sharing link 2D array made, MATLAB code, code C++ convert array connectivity map. Link 2D array:- MATLAB CODE:- Code C++:- int **digraph = NULL; digraph = new int *[6144]; (int = 0; < 6144; i++) { digraph[i] = new int[6144]; } (j = 0; j < 96; j++) { (z = 0; z < 64; z++) { currentPos = sub2ind[j][z]; digraph[currentPos][currentPos] = 0; //------NEW ADDITION----------- ((z - 1) >= 0) { destPos = sub2ind[j][z - 1]; digraph[currentPos][destPos] = bitarray[j][z] * bitarray[j][z - 1]; } ((z + 1) < 64) { destPos = sub2ind[j][z + 1]; digraph[currentPos][destPos] = bitarray[j][z] * bitarray[j][z + 1]; } ((j - 1) >= 0) { destPos = sub2ind[j - 1][z]; digraph[currentPos][destPos] = bitarray[j][z] * bitarray[j - 1][z]; } ((j + 1) < 96) { destPos = sub2ind[j + 1][z]; digraph[currentPos][destPos] = bitarray[j][z] * bitarray[j + 1][z]; } } } ofstream connectivityMap; connectivityMap.open(""diGraph.txt""); (int l = 0; j < 100; l++) // printing 100 elements { (int k = 0; k < 100; k++) { connectivityMap << digraph[l][k] << "" ""; } }",mobile-robot localization mapping planning
7507,Circuit Design Simulation,I want design circuits own. My area expertise Computer Science Engineering. I listed components essential circuit. I want software used design simulate circuits real time projects. Please suggest best among them. Thank you. @AkhilRajagopal,software electronics
7510,Improving Velocity estimation,"I sensor reduction model gives velocity estimate suspension system(velocity 1) . This suspension system estimate velocity used calculate another velocity(velocity 2) via transfer function/plant model. Can I use velocity 2 improve velocity estimate (velocity 1) Kalman filtering feedback system.?? V1 ""estimated"" using two sensors.That fed geroter pump (Fs diagram) pumps fluid manupulate damper viscous fluid thereby applying resistance forces applied car body. There problem I velocity sensor spring.I could measure accurately I estimate. I trying make estimate better.Assume I model/plant transfer function already gives V2 given V1.",control sensors pid kalman-filter
7513,What frequencies used within drones?,"What frequencies used within drone technology, values? 35 MHz 433 MHz 868 MHz 2.4 GHz 5.8 GHz",quadcopter wireless radio-control
7517,Need help regarding EKF MonoSLAM,"I trying understand implementation Extended Kalman Filter SLAM using single, agile RGB camera. The vector describing camera pose $$ \begin{pmatrix} r^W \\ q^W \\ V^W \\ \omega^R \\ a^W \\ \alpha^R \end{pmatrix} $$ where: $r^W$ : 3D coordinates camera w.r.t world $q^W$ : unit quaternion describing camera pose w.r.t world $V^W$ : linear velocity along three coordinate frames, w.r.t world $\omega$ : angular velocity w.r.t body frame camera The feature vector set described $$ \begin{pmatrix} y_1 \\ y_2 \\ \vdots \\ y_n \end{pmatrix} $$ where, feature point described using XYZ parameters. For EKF acting unknown linear angular acceleration $[A^W,\psi^R] $ , process model used predicting next state is: $$ \begin{pmatrix} r^W + V^W\Delta + \frac{1}{2}\bigl(a^W + A^W\bigr)\Delta t^2 \\ q^W \bigotimes q^W\bigl(\omega^R\Delta + \frac{1}{2}\bigl(\alpha^R + \psi^R\bigr)\Delta t^2\bigr) \\ V^W + \bigl(a^W + A^W\bigr)\Delta t\\ \omega^R + \bigl(\alpha^R + \psi^R\bigr)\Delta \\ a^W + A^W \\ \alpha^R + \psi^R \end{pmatrix} $$ So far, I'm clear EKF steps. Post prediction step, I'm clear perform measurement update system state. From slide, I impression need initialize random depth particles 0.5m 5m camera. But, point, camera pose feature depth unknown. I understand running particle filter estimating feature depth camera pose known. I tried implement concept project: I read camera pose ground truth file keep triangulating depth features w.r.t world reference frame I also comprehend running particle filter estimating camera pose feature depths known. But parameters unknown. How I perform measurement update? I understand narrowing active search region feature matching based predicted next state camera. But features matched using RANSAC (or algorithm), I find updated camera pose? We estimating homography, we? If idea regarding MonoSLAM (or RGB-D SLAM), please help understanding EKF steps. To specific: homography estimation step algorithm? project epipolar line (inverse depth OR XYZ) next frame estimate camera motion?",slam ekf
7519,Structuring EKF estimate pose velocity odometry inputs,"I differential drive robot I'm building EKF localization system. I would like able estimate state robot $\left[ x, y, \theta, v, \omega \right]$ $x, y, \theta$ represent pose robot global coordinates, $v, \omega$ translational rotational velocities. Every mobile robot Kalman filter example I've seen uses velocities inputs prediction phase, provide filtered estimate them. Q: What best way structure filter I estimate velocities use measured odometry, gyroscope, possibly accelerometers (adding $\dot{v}$ $\dot{\omega}$ state) inputs? My intuition tells use prediction step pure feedforward (i.e. integrates predicted velocities positions), separate updates odometry, gyro, accelerometer, I never seen anyone before. Does seem like reasonable approach?",localization kalman-filter gyroscope odometry
7521,Calculate required motor torque Harmonic Drive,"I term project controlling two-link manipulator harmonic drive installed joint. To control, used Computed control method determine torque needed joints based formula: $$\tau_i =M(\theta)(\ddot{\theta_i}+K_d\dot{e}+K_pe)+V+G $$ To calculate torque motor needs produce harmonic drive, use: $$\tau_{motor} =(J_m+J_g)\rho\ddot{\theta_i}+\frac{\tau_i}{\rho\eta_g}$$ where: $\rho$ $\eta_g$ gear ratio efficiency harmonic drive. $J_m$ $J_g$ motor gear inertia, respectively. calculation, see effect harmonic drive system comparing input torque motor model harmonic drive ($\tau_{motor}$) torque model without harmonic drive ($\tau_i$) But professor doesn't agree formula $\tau_{motor}$ used. He want include stiffness $k$ harmonic drive. This done P/S: This model consists two-link manipulator+harmonic drive joint built MATLAB. Can anyone suggest formula it? Thank much.",actuator manipulator
7522,Highspeed gearbox low speed brushless motor?,"I'm attempting control small vehicle relatively slow (.5 m/s - 1 m/s) speeds, extreme accuracy (1mm). For drive system, I'm considering using brushless motors much greater power / volume ratio I able find brushed motors, especially small size. I using wheels 1"" 2"" diameter, RPM I looking 150 - 500 RPM max. This would suggest either driving motors low speed directly, driving high speed gearing down. As I understand it, setups give high torques, brushless motors decrease torque speed. With brushed motors, it's quite obvious gearbox necessary otherwise torque system, choice isn't clear, I asking. tl;dr Use brushless motors high speed gearbox low speed (ungeared) high torque / low speed / high precision application?",motor brushless-motor
7533,Which middleware IPC multi-threading autonomous robot?,"Aim: To use multi-threading inter-process communication(IPC) coding autonomous robot. Platform: Embedded Linux (Yocto) Constraints : Limited CPU power. We building Autonomous Underwater Vehicle, compete RoboSub competition. This first time I something like this. I intent use middleware like ROS, MIRA, YART, MOOS etc. The purpose using one I want modularise tasks, divide core components subsystems, run parallel(by multi-threading). But I limited computational power (a dual core omap SoC), middleware, robust also efficient. I need use middleware, I don't want program run single thread. My CPU two cores, would great I could multi-threading improve performance program. The middleware provide communication layer, I don't worry data races, problems associated parallel processing. Also I prior experience writing multi-threaded programs, using parallel processing libraries directly would difficult. Hence IMO, middlewares excellent choices. In experience, best one suited task. I don't really want use ROS, lot features, I wont using them. I computer science student(under graduate freshman, actually) don't mind getting hands dirty one much features. That's true take less toll CPU.",ros communication underwater operating-systems
7534,On-board monocular odometry quadcopter stabilization,Has anyone done EKF/PID small microcontroller? Or know code snippets help implementing this?,quadcopter odometry stability
7535,Detecting presence person room,"I working first hobby project I'm familiar sensors yet. I trying build system detects presence person small room single entrance/exit door. The idea first person enters room, lights turn following person doesn't affect state lights. After last person leaves, lights turn off. In programmatic sense, lights turn present person count greater 0. I explored options found infrared sensors usually used type problem. What I sure detect whether person entered left, I would like ask help this.",sensors
7537,Inverting transform (Reading J Craig's book Robotics),"From Introduction Robotics J.J. Craig, chapter 2, Page no. 36: Could anyone explain equation derived/formed? I stuck page due failing understand equation came from. Thank you.",design theory books
7542,Starter Looking For Advice,"I'm professional. At 29 I became seriously interested robotics months ago researching everything I since. Now I've come understand far robotics truly come I desire try make own. Granted, I know nothing coding programming. I idea begin. And I know it'll probably, first time least, something small rather huge life altering project. Thus, anyone could suggest good resources beginner I'd massively appreciate it.",beginner
7547,Lagging sensor data PID,"Let's say PID implemented errors calculated using sensor data, sensor data lags certain amount time overhead. And lag time smaller sampling period, well PID performs? What I thinking PID calculate errors based past data, use control. How using Kalman filter estimate actual sensor data help?",pid kalman-filter
7549,"Question experience using stereo cameras/module (e.g. ZED, DUO M, Bumblebee, etc.)","This question experience using stereo cameras/modules like ZED, DUO M, Bumblebee cameras, etc. (not TOF cameras). I can't find sample disparity outputs internet, I can't find information perform. Basically things I'd like know used cameras mentioned (and others) What resolution no. disparities work with? How framerate? On hardware? Did camera ASIC sort produce disparity maps, require host? How quality? For used ZED camera, promotional video youtube. Are disparity maps really good?",cameras stereo-vision
7552,Pull-down resistor inter-chip sensor-to-chip communication,"I understand concept using pull-up/pull-down resistor implementing button/switch Arduino avoid floating state, fact I implemented quite often. But I sure pull-down resistor necessary chip-chip chip-sensor communication. I connecting coin acceptor Arduino (common ground). The coin acceptor's output pin gives short pulse time coin inserted. So far I connecting output pin coin acceptor directly Arduino pin works without problem. Is pull-down resistor (on line) usually required precaution case? Also I question connecting 2 pins 2 separate Arduino's (also common ground) one Arduino read pulses other. Thanks advance experience shared! Dave",arduino
7556,Mini Recorder RC Heli Parts,"I RC Helicopter (with video,picture, audio taking capabilities) recently ""died"" (unrelated short circuit). The reciever board short circuted, board sent data micro-sd card camera+mic fine. I access data micro-sd card circuit, USB cable. The reciever board sent data via 4 wire bundle camera board make take pictures/record audio. Is way still computer (from USB), turn mini spy camera? (Not remotely, jst cable) I got heli back I don't heli number camera board number , reciever board number 3319B rev.a Reciever Board Image Camera/Data Board Image",control cameras circuit
7557,Troubleshooting Xbox Kinect 360,"I recently got libfreenect running mac able test uses 3D capabilities depth sensor. I noticed Kinect would respond / pick movement happened within range 3-6 inches front sensor. I thought may lights I turned off. It seemed get little better still ""works"" something block sensor almost completely. Does anyone know something solved? I know it's old sensor I got $20 I could prototyping it. Notes: laser project ON light starts blinking goes solid green level light goes red RGB camera works little choppy sometimes shows tears picture. freenect-glcplview output (snippet): [Stream 80] Expected 1908 data bytes, got 948 [Stream 80] Expected 1908 data bytes, got 948 [Stream 80] Expected 1908 data bytes, got 948 [Stream 80] Expected 1908 data bytes, got 948 [Stream 80] Expected 1908 data bytes, got 948 [Stream 80] Expected 1908 data bytes, got 948 [Stream 70] Expected 1748 data bytes, got 948 [Stream 70] Expected max 1748 data bytes, got 1908. Dropping... [Stream 70] Expected max 1748 data bytes, got 1908. Dropping... [Stream 80] Expected 1908 data bytes, got 948 [Stream 80] Expected 1908 data bytes, got 948 [Stream 80] Expected 1908 data bytes, got 948 [Stream 80] Expected 1908 data bytes, got 948 [Stream 80] Expected 1908 data bytes, got 948 [Stream 80] Expected 1908 data bytes, got 948 [Stream 80] Expected 1908 data bytes, got 948 [Stream 80] Expected 1908 data bytes, got 948 [Stream 80] Expected 1908 data bytes, got 948 [Stream 80] Expected 1908 data bytes, got 948 [Stream 80] Expected 1908 data bytes, got 948 [Stream 80] Expected 1908 data bytes, got 948 [Stream 80] Expected 1908 data bytes, got 948 freenect-regview output (snippet) [Stream 70] Invalid magic 2dc5 [Stream 70] Invalid magic aaf5 [Stream 70] Invalid magic dddb [Stream 70] Invalid magic 9272 [Stream 70] Invalid magic 9873 [Stream 70] Invalid magic 9b8b [Stream 70] Invalid magic 59eb [Stream 70] Invalid magic 88f1 [Stream 70] Invalid magic 75ee [Stream 70] Invalid magic ffff [Stream 80] Expected 1908 data bytes, got 948 [Stream 80] Expected 1908 data bytes, got 948 [Stream 80] Expected 1908 data bytes, got 948 [Stream 80] Lost 1 packets [Stream 80] Lost 15244 total packets 514 frames (29.657587 lppf) [Stream 80] Expected 1908 data bytes, got 948 [Stream 80] Expected 1908 data bytes, got 948 [Stream 80] Expected 1908 data bytes, got 948 [Stream 80] Expected 1908 data bytes, got 948 [Stream 80] Expected 1908 data bytes, got 948 [Stream 80] Invalid magic 3b46 [Stream 80] Lost 1 packets Found gives idea may USB issue: Regular receipt undersized packet.",kinect
7558,Problems Complementary Filter IMU tuning,"I'm developing project consists IMU controlled Arduino send via radio module, data PC three Euler angles raw data sensors. For filtering I used code made available SparkFun: Razor AHRS 9 dof The code provide radio transmissions tuned 50 Hz sampling rate, fact parameters are: project data read every 20ms (50Hz) records sensors set accelerometer odr 50hz 25 bandwidth. gyroscope 50 Hz odr. In project I used gyroscope different, namely I used L3G4200D frequency odr starting 100Hz, I set registers 100Hz. My global data rate 33Hz max, beacouse use radio, read complete date frequency 33Hz. How tune Ki Kp setup? Kp period, I consider frequency odr I set register individual sensors set global system sample rate limited 33Hz radio transmission?",arduino imu gyroscope sensor-fusion
7560,Digital Controller Design System variable sample time,"Basically I got system sensor output. I want apply digital implemented feedback controller. The problem setup sensor. The specifications module says sampletime sensor change wide range, depending usecase; 1.3 second 10 second. But stays constant system disabled. My first approach tuning digital PID-Controller longest sampletime. This works fine. Even I change sampletime shortest system stays stable, expected I'm still ROC. The problem system's response pretty slow. If I design controller fastest samplingrate results satisfying become instable slowest samplerate, explained ROC I could use kind adaptive predefined gains I change depending samplerate I wondering control strategies able handle sampletime changes? EDIT: To give better overview I add details: I'm talking heating system heats radiation. As sensor I use pyrometer module samplingrate 1kHz. The problem is, pyrometer able produce reasonable readings whenever radiator turned on. (Yes alternatives pyrometer, start $50k expensive). The radiator pulsed operate it. So maintain decent heat time steady-state temperature ""duty-cycle"" decent rate(target 95%). The minimum ""off-time"" radiator 0.2 seconds measured values reasonable. So end sensor got effective sampletime 1-10seconds (by varying duty cycle). The hardware hard change, radiator sensor evaluted months right now. Therefore I try improve results ""just"" changing control algorithm.",control
7564,How localise underwater robot?,"I building autonomous underwater robot. It used swimming pools. It capable running normal sized pool, pool I test. So I cannot rely particular design feature. It know it's position pool, either respect initial position respect pool. I IMU, Pololu MiniIMU finding displacement IMU near impossible task. What sensor I use task? It expensive. (below 200$) Tank size: 25x20x2.5 meters",sensors localization sensor-fusion underwater
7565,How determine trajectory reference real robot trajectory tracking,"I know use algorithms like LQR, MPC, even PID make robot follows trajectory references. In simulation like MATLAB, I usually specify trajectory reference function. Let say, given sequence points generated path planning algorithm, I want real experiment trajectory tracking sequence points. My question is: - How specify errors towards path real situation. My impression generated path path planning algorithm uncertain due error robot sensing. And unlike line following robot real physical line reference, generated path path planning virtual, e.g. exist real world. I really confused matter.",mobile-robot control
7570,Homogenous Transformation Matrix DH parameters,"I'm studying Introduction robotic found different equations determine position orientation end effector robot using DH parameters transformation matrix, : Example: Puma 560, All joints revolute Forward Kinematics: Given :The manipulator geometrical parameters. Specify: The position orientation manipulator. Solution: For Step 4: step 3 :Here I'm confused Here calculate transformation matrix link multiply get position orientation end effector. I've seen different articles using one equations get step robot(puma 560) What difference them? Will result different? Which one I use calculating position orientation?",dh-parameters
7575,DH-Parameters Forward Kinematics Translatory Motion,"I fairly new DH-transformation I difficulties understand works. Why coordinates (X+Y+Z) incorporated parameters? It seems least one information useless/goes trash, since a, (translatory information) alpha, theta(rotatory information). Example: The transition two coordinate systems identical orientation(alpha=0, theta=0) different coordinates(x1!=x2, y1!=y2, z1!=z2). DH makes use maximum two information. Please enlighten me! Greetings :EDIT: To clarify part DH-Transform I don't understand, example. Imagine CNC-Mill(COS1) stand(COS0) without variable length(=no motion) COS0-COS1. For reason I need incorporate transformation COS0-COS1(=T0-1) forward transformation CNC-Mill. DH-Parameters T0-1 would a=5mm, alpha=90°, d=2mm theta=90°. Assuming correct, dX=10mm information lost process? If I recreate relation COS0 COS1 according DH-Parameters, I end like this: As far I understand, non parallel axis information lost measurement a/d would diagonal, therefore include either dX/dY, dX/dZ dY/dZ(pythagorean theorem) one parameter. Where flaw logic?",forward-kinematics dh-parameters
7578,Orientation parameter quadcopter madgwick fusion algorithm,"I recently decided build quadricopter scratch using Arduino I'm faced orientation estimation problem. I bought cheap 10DOF sensor 3 axis magnetometer, 3 axis accelerometer, 3 axis gyro barometer complementary filter I use get orientation returns usable noisy values. I tried Madgwick fusion filter too, returns unstable values diverges ones I get complementary filter. Given Madgwick filter implementation correct, I pass acceleration values measured Gs, gyro values measured rps (radians per second) Magnetometer values measured uT, sampling time loop cycle. Is anything I missed? Is advantage using Kalman filter? EDIT1: My problem due wrong choice sampling time seems work, convergence slow (i.e. takes 3 seconds reach right value quick flip IMU). Rising value Kp adds much noise. I also tried repeat filter update step per cycle requires much time exceeding sampling time. Here graphs, top bottom Complementary filter, Madgwick filter Madgwick filter high Kp: EDIT2: Different values probably caused cable plug unplug. Anyway raw data example sensor downloaded",arduino quadcopter kalman-filter imu
7580,Sensors' field view car driving,"I want develop autonomous driving RC car. For detecting obstacles, I plan mount 3-5 ultrasonic sensors front back car. What minimum necessary combined field view sensors car never hits obstacle? I.e. minimum angle detection combined sensors car detect obstacle path? Some data car: (I don't know whether data relevant) Separation right left wheel : 19,5 cm Wheelbase (distance front back wheels): 31,3cm Steering axle: front. Maximum angle steering: around 30 degrees. The car uses Ackermann steering",mobile-robot sensors wheeled-robot
7588,Is Lego Mindstorm good start?,I would like start experimenting Robots. Is Lego Mindstorm good start? Should I consider platforms?,platform
7592,"IMU rotate one axis, two angles change","I trying use Invensense's MPU9250. I using provided library read euler angle. When IMU rotates one axis, angles two axes change too. What could potential cause it?",imu
7595,STM32_OC_Timing IRQHandler,"I created program simple time base delay (in seconds). I problem: How read interrupt flag channel 1 etc.? When I use error occurs. When interrupt occurred , uC clear flag set Blue LED Discovery Board. Here program: Main.c /* Includes #include ""stm32f3xx_hal.h"" /* Private variables <br /> **TIM_HandleTypeDef htim2;** /* Private function prototypes <br /> void SystemClock_Config(void);<br /> static void MX_GPIO_Init(void);<br /> static void MX_TIM2_Init(void);<br /> int main(void) { /* MCU Configuration----------------------------------------------------------*/<br /> /* Reset peripherals, Initializes Flash interface Systick. */<br /> HAL_Init(); /* Configure system clock */<br /> SystemClock_Config();<br /> /* Initialize configured peripherals */<br /> MX_GPIO_Init();<br /> MX_TIM2_Init();<br /> /* Infinite loop */ (1) { HAL_GPIO_WritePin(GPIOE,GPIO_PIN_11,GPIO_PIN_RESET); } } /** System Clock Configuration*/ void SystemClock_Config(void) { RCC_OscInitTypeDef RCC_OscInitStruct;<br /> RCC_ClkInitTypeDef RCC_ClkInitStruct;<br /> RCC_OscInitStruct.OscillatorType = RCC_OSCILLATORTYPE_HSE;<br /> RCC_OscInitStruct.HSEState = RCC_HSE_ON;<br /> RCC_OscInitStruct.HSEPredivValue = RCC_HSE_PREDIV_DIV1;<br /> RCC_OscInitStruct.PLL.PLLState = RCC_PLL_ON;<br /> RCC_OscInitStruct.PLL.PLLSource = RCC_PLLSOURCE_HSE;<br /> RCC_OscInitStruct.PLL.PLLMUL = RCC_PLL_MUL9;<br /> HAL_RCC_OscConfig(&RCC_OscInitStruct);<br /> RCC_ClkInitStruct.ClockType = RCC_CLOCKTYPE_SYSCLK|RCC_CLOCKTYPE_PCLK1;<br /> RCC_ClkInitStruct.SYSCLKSource = RCC_SYSCLKSOURCE_PLLCLK;<br /> RCC_ClkInitStruct.AHBCLKDivider = RCC_SYSCLK_DIV1;<br /> RCC_ClkInitStruct.APB1CLKDivider = RCC_HCLK_DIV2;<br /> RCC_ClkInitStruct.APB2CLKDivider = RCC_HCLK_DIV1;<br /> HAL_RCC_ClockConfig(&RCC_ClkInitStruct, FLASH_LATENCY_2);<br /> HAL_SYSTICK_Config(HAL_RCC_GetHCLKFreq()/1000);<br /> HAL_SYSTICK_CLKSourceConfig(SYSTICK_CLKSOURCE_HCLK);<br /> } /* TIM2 init function */<br /> void MX_TIM2_Init(void) { TIM_ClockConfigTypeDef sClockSourceConfig;<br /> TIM_MasterConfigTypeDef sMasterConfig;<br /> TIM_OC_InitTypeDef sConfigOC;<br /> htim2.Instance = TIM2;<br /> htim2.Init.Prescaler = 7199; //72Mhz/7200 <br /> htim2.Init.CounterMode = TIM_COUNTERMODE_UP;<br /> htim2.Init.Period = 65535;<br /> htim2.Init.ClockDivision = TIM_CLOCKDIVISION_DIV1;<br /> HAL_TIM_Base_Init(&htim2);<br /> sClockSourceConfig.ClockSource = TIM_CLOCKSOURCE_INTERNAL;<br /> HAL_TIM_ConfigClockSource(&htim2, &sClockSourceConfig);<br /> HAL_TIM_OC_Init(&htim2);<br /> sMasterConfig.MasterOutputTrigger = TIM_TRGO_RESET;<br /> sMasterConfig.MasterSlaveMode = TIM_MASTERSLAVEMODE_DISABLE;<br /> HAL_TIMEx_MasterConfigSynchronization(&htim2, &sMasterConfig);<br /> sConfigOC.OCMode = TIM_OCMODE_TIMING;<br /> sConfigOC.Pulse = 20000; //0.0001[s] * 20000 = 2 [s] DELAY <br /> sConfigOC.OCPolarity = TIM_OCPOLARITY_HIGH;<br /> sConfigOC.OCFastMode = TIM_OCFAST_DISABLE;<br /> HAL_TIM_OC_ConfigChannel(&htim2, &sConfigOC, TIM_CHANNEL_1);<br /> sConfigOC.OCMode = TIM_OCMODE_TIMING;<br /> sConfigOC.Pulse = 30000;<br /> sConfigOC.OCPolarity = TIM_OCPOLARITY_HIGH;<br /> sConfigOC.OCFastMode = TIM_OCFAST_DISABLE;<br /> HAL_TIM_OC_ConfigChannel(&htim2, &sConfigOC, TIM_CHANNEL_2);<br /> HAL_TIM_Base_Start_IT(&htim2);<br /> HAL_TIM_OC_Start_IT(&htim2,TIM_CHANNEL_1 );<br /> //HAL_TIM_OC_Start_IT(&htim2,TIM_CHANNEL_2 );<br /> } /** Configure pins <br /> * Analog <br /> * Input <br /> * Output<br /> * EVENT_OUT<br /> * EXTI<br /> PC9 ------> I2S_CKIN<br /> */ void MX_GPIO_Init(void)<br /> { <br /> GPIO_InitTypeDef GPIO_InitStruct;<br /> /* GPIO Ports Clock Enable */<br /> __GPIOF_CLK_ENABLE();<br /> __GPIOC_CLK_ENABLE();<br /> __GPIOE_CLK_ENABLE();<br /> /*Configure GPIO pin : PC9 */<br /> GPIO_InitStruct.Pin = GPIO_PIN_9;<br /> GPIO_InitStruct.Mode = GPIO_MODE_AF_PP;<br /> GPIO_InitStruct.Pull = GPIO_NOPULL;<br /> GPIO_InitStruct.Speed = GPIO_SPEED_HIGH;<br /> GPIO_InitStruct.Alternate = GPIO_AF5_SPI1;<br /> HAL_GPIO_Init(GPIOC, &GPIO_InitStruct);<br /> <br /> /* * Configure GPIO pin : PE8 BLUE LED */ <br /> GPIO_InitStruct.Pin=GPIO_PIN_8;<br /> GPIO_InitStruct.Mode=GPIO_MODE_OUTPUT_PP;<br /> GPIO_InitStruct.Pull=GPIO_NOPULL;<br /> GPIO_InitStruct.Speed=GPIO_SPEED_HIGH;<br /> HAL_GPIO_Init(GPIOE,&GPIO_InitStruct);<br /> GPIO_InitStruct.Pin=GPIO_PIN_12;<br /> GPIO_InitStruct.Mode=GPIO_MODE_OUTPUT_PP;<br /> GPIO_InitStruct.Pull=GPIO_NOPULL;<br /> GPIO_InitStruct.Speed=GPIO_SPEED_HIGH;<br /> HAL_GPIO_Init(GPIOE,&GPIO_InitStruct);<br /> <br /> /* * COnfigure GPIO pin : PE11 GREEN LED */ <br /> GPIO_InitStruct.Pin=GPIO_PIN_11;<br /> GPIO_InitStruct.Mode=GPIO_MODE_OUTPUT_PP;<br /> GPIO_InitStruct.Pull=GPIO_NOPULL;<br /> GPIO_InitStruct.Speed=GPIO_SPEED_HIGH;<br /> HAL_GPIO_Init(GPIOE,&GPIO_InitStruct); } low level implementation :<br /> void HAL_TIM_Base_MspInit(TIM_HandleTypeDef* htim_base)<br /> { <br /> if(htim_base->Instance==TIM2)<br /> { <br /> /* Peripheral clock enable */<br /> __TIM2_CLK_ENABLE();<br /> /* Peripheral interrupt init*/<br /> HAL_NVIC_SetPriority(TIM2_IRQn, 0, 0);<br /> HAL_NVIC_EnableIRQ(TIM2_IRQn);<br /> } } void TIM2_IRQHandler(void) { <br /> /* USER CODE BEGIN TIM2_IRQn 0 */<br /> HAL_GPIO_WritePin(GPIOE,GPIO_PIN_8,GPIO_PIN_SET);<br /> // HAL_GPIO_TogglePin(GPIOE,GPIO_PIN_12);<br /> HAL_TIM_IRQHandler(&htim2);<br /> //THis function implemented StmCubeMX , WHAT IS THIS? } So TIM2_IRQHandler look like? Each channel generate delay +1 sec. When I debugging program, LED set period equal 1s (time set LED).",microcontroller
7598,Extend robotic arm wrist rotation,"I got OWI Robotic arm, slightly disappointed horizontal position gripper. What would easiest way extend gripper/wrist rotation, i.e. 6th degree freedom?",robotic-arm
7600,KUKA Robotics API IDE,"I've got Robotics API library, demo-program robot. I want develop app it. The best solution offline development kind simulator. I'm completely new tasks - IDE this? Or way deliver byte-code machine? Thanks advance!",robotic-arm dynamic-programming
7607,Can ESC programmed run full throttle one side quadcopter?,"Can ESC quads programmed way one side throttle throttle other? This would cause quad flip I suppose? With that, way program controller like trigger switch want quad flip? Because I thinking waterproof quad. So initially, flies air normally 4 channel, I set float water. After that, I thinking maybe triggering switch controller time it's going flip nothing else. After flips, I would trigger switch back normal operation. Is possible?",quadcopter
7612,"Raspberry Pi Hexapod 18DOF, Best servo control board?","Recently I've bought hexapod kit 18 TowerPro MG995 servos. My objective apply also Pi camera, sensors perhaps claw... So I've researching I haven't found clear answer comes servo control board. Which servo controller board shall I choose complete project?",mobile-robot raspberry-pi servomotor rcservo hexapod
7613,How efficiently 3D mapping area MAV?,"I researching cost-effective way scan area MAV (exploraton) later use CAD/civil purposes(use point cloud data CAD) major sensors available problems. kinect - can't use outside,high computation power stereo - high computation power,somewhat expensive lidar - expensive + real time + heavy I need system(on MAV/quadrotor) work wifi/wireless, scan outdoors , expensive gives data real-time.Please suggest system close requirements. Also stereo operated wifi?",kinect mapping stereo-vision 3d-reconstruction
7615,Problem acceleration sensor,"I’m using BMA020 (from ELV) Arduino Mega2560 trying read acceleration values doesn’t confuse me. First I connected sensor SPI-4 mode. Means CSB <-> PB0 (SS) SCK <-> PB1 (SCK) SDI <-> PB2 (MOSI) SDO <-> PB3 (MISO) Also GND UIN connected GND 5V Pins Arduino board. Here self-written code I use And really confuses me. I got 5 sensors. One working code perfectly fine. The Data I get I expect. I measure earth gravity z-component Iay sensor table, I start turning I measure earth gravity component wise x-, y- z- direction depending angle I turn sensor. From 4 sensors I receive data different. The values jump -314 (about -1.2 g) +160 (about 0.5g). With code, wires Arduino. I checked register settings sensors, same. I checked wire connection first component sensors, around 0.3 Ohm. I used Oscilloscope made sure CSB, SCK MOSI work properly. Am I missing something? What causes similar wrong behavior 4 5 sensors?",arduino accelerometer
7617,Using 2x UARTs STM32F072RB,"I trying use 2x UARTs ChibiOS STM32F072RB Nucleo Board. I initialized UART2 I still getting output UART1 pins, totally weird. The line uartStartSend(&UARTD2, 7, ""Soom!\r\n""); gives output UART1. Is anything else I need do? mcuconfig.h reads #define STM32_UART_USE_USART1 TRUE #define STM32_UART_USE_USART2 TRUE #define STM32_UART_USART1_IRQ_PRIORITY 3 #define STM32_UART_USART2_IRQ_PRIORITY 3 #define STM32_UART_USART1_DMA_PRIORITY 0 #define STM32_UART_USART2_DMA_PRIORITY 0",microcontroller serial c
7622,Virtual model PLC discrete / continuous,"How one implement virtual model (continuous) control system discrete (PLC)? I've done practice theory, one explain topic stranger? (lets say myself)",control
7626,methods compare PID controller performance?,If input sensor measured outputs. What objective methods compare performance besides looking inputs outputs matching not?,pid
7632,Project - building Electric skateboard,"During vacation wa thinking could fun make electric skateboard/longboard... I haven't decided Longboard want use, nearly done selecting parts. The board driven one runner [Turnigy Aerodrive SK3 - 6374-149kv][1] And mount motor use [kit][2] As ESC recommended [this][3], [this][4] battery. Which seems like good seem ok setup application. The problem bit I don't reason chosen ESC battery pack. Surely deliver needed amps ESC withstand max current that, I don't see couldn't buy set.. especially cheaper... cheaper alternative have, drawbacks",brushless-motor battery esc
7633,Brushless DC motor - Electronic Speed Control - Quadcopter,"I'm student electrical electronics engineering. I'm currently final project quadcopter. One objectives make Electronic Speed Controller (ESC) brushless motors used. I made design ESC using proteus I made PCB also. I attached schematic. I used PIC16F628A ESC wrote small code mikroC ESC work powered up. Unfortunately didn't work properly. I tried sensorless control brushless motors without getting feedback. Can I know much current I provide motor? According articles I read brushless DC (BLDC) motor requires around 10A startup around 20 ms. I posted code also. I used two codes run motor. One PWM without PWM (100% duty cycle). I rookie subject BLDC motor controlling. I grateful anybody help clear doubts figure mistakes design make work properly. Below given code I tried. Please help figure right way program chip. When I uploaded given code I set delay around 3000 μs, motor spun time one MOSFETs got heated I cannot touch anymore. Here video scenario. This code (PWM); const delay1 = 2000; const delay2 = 1000; int count = 0; int cnt; int arr[6] = {0x24, 0x36, 0x12, 0x1B, 0x09, 0x2D}; int = 0; int x = 0x32; void init(void) { TRISB = 0x00; PORTB = 0x00; //OPTION_REG = 0x87; //INTCON = 0xA0; CCP1CON = 0; CMCON = 0x07; } void main() { init(); while(1){ (cnt = 0; cnt < 10; cnt++) { PORTB = arr[i]; delay_us(2); PORTB = 0x07; delay_us(2); } i++; (i == 6) { =0; } }; }",quadcopter brushless-motor esc
7634,Arduino original generic beginner?,"I'm new robotics electronics world, I'm willing dive it. I'm software developer I want create project uses GPS Accelerometer data show layer Google Maps transferred PC. My doubt controller get. In country, generic controllers based Atmega328 sold massive difference price original Arduino (talking UNO model). Should I start original model? Should I expect break controller, fry it, break components connecting wrong? Would experience generic controller less exciting original Arduino one?",arduino beginner
7640,PID gains motor position velocity control,"I servo motor quad optical encoder I'm trying control position velocity. By controlling I meant I input motor reach 90° 200rpm should. How I that? I using Arduino Uno. Kindly share code possible. Though I implemented PID, I don't think correct I didn't implement feedforward controller (because I idea is) I able find suitable gains PID. The gains I find small steps (or say degree rotation) work well large steps vice versa. I also used limit integral sum (because I don't much be). I using Pittman motor.",robotic-arm
7641,Mapping formats small autonomous robots,"I robot software I'm working (Java Android) needs store pre-designed map playing field able navigate around. The field's got fancy 3d structure, map 2d. I've trying find good format store maps in. I've looked SVGs DXFs, neither one really designed purpose. Is file format specifically designed small, geometric, robotics-oriented maps? The field I'd modelling one:",mapping
7644,How use POMDP-based planner top probabilistic filter,"POMDPs extend MDPs conceiling state adding observation model. A POMDP controller processes either action/observation histories bayesian belief state, computed observations (belief-MDP transformation) In complex, real-world system like robot, one usually preprocesses sensory readings using filters (Kalmann, HMM, whatever). The result belief-state. I looking publications discuss problem fitting (probably abstract) POMDP model top existing filter-bank. Do stick belief-MDP, hand filtered belief-state controller? Is way using history-based POMDP controllers, like MCTS? How construct/find abstract observations need formulate POMDP model?",kalman-filter particle-filter planning filter
7645,How I choose best filter dead reckoning IMU?,I'm searching filter reduce noise smooth signal dead reckoning IMU (6dof gyro+accelerometer). What differences/advantages/disadvantages following filters: Kalman Complementary moving average Mahony I applied kalman complementary filters IMU gives time lag actions respect filter parameters. Also kalman filter works slower moving average complementary. How I choose right filter filter parameters?,mobile-robot localization kalman-filter imu
7647,ROS Calibration Camera Problems,"I trying calibrate monocular camera using ROS help website: How Calibrate Monocular Camera. When I run , I get: /left /right /rosout /rosout_agg /usb_cam/image When I run rosservice list, I get: /cameracalibrator/get_loggers /cameracalibrator/set_logger_level /rosout/get_loggers /rosout/set_logger_level Finally, I run: rosrun camera_calibration cameracalibrator.py --size 10x7 --square 0.025 image:=/usb_cam/image camera:=/usb_cam It says: ('Waiting service', '/usb_cam/set_camera_info', '...') Service found I even added parameter end, --no-service-check, makes terminal stall indefinitely. Could someone please help figure going wrong I fix it? Also important, usb_cam saved catkin_ws/src/usb_cam.",ros cameras calibration
7648,iRobot Create 2 sensors,"Can someone please provide list sensors create 2? I hoping get one soon, want sure ultrasonic sensors bump sensors I do.",irobot-create roomba
7652,How I control robotic arm motion?,"I Robotic arm mounted car. There's camera attached it. Suppose camera takes image room, finds there's something, say object, picked up. Say it's 50 feet away robot. My question robot reach object first place, secondly, reached object, know real world co-ordinates object, pick object up, using inverse kinematic equations. Any help would appreciated. Thanks",mobile-robot robotic-arm
7656,How cliff sensors ROOMBA work glass wall?,"I want use IR sensors detect whether dustbin full I want protect outside dust. I planning use IR sensors Roomba. How working despite plastic wall? Also, range sensor? Can detect obstacle 25 cm? Why wall IR sensors? Is reason positioned certain angle?",sensors roomba
7659,PTAM CameraCalibrator error,"I trying run using PTAM according Camera Calibration tutorial. However, I so, I get following error: ERROR: cannot launch node type [ptam/cameracalibrator]: can't locate node [cameracalibrator] package [ptam] I source devel/setup.bash I run code well still work. Here launch file: <launch> <node name=""cameracalibrator"" pkg=""ptam"" type=""cameracalibrator"" clear_params=""true"" output=""screen""> <remap from=""image_raw"" usb_cam/image_raw"" /> <remap from=""pose"" to=""pose""/> <rosparam file=""$(find ptam)/PtamFixParams.yaml""/> </node> </launch> Here I get rostopic list: /rosout /rosout_agg /svo/dense_input /svo/image /svo/image/compressed /svo/image/compressed/parameter_descriptions ... /tf /usb_cam/camera_info /usb_cam/image_raw /usb_cam/image_raw/compressed ... /usb_cam/image_raw/theora /usb_cam/image_raw/parameter_descriptions /usb_cam/image_raw/parameter_updates The path cameracalibration.launch file catkin_ws/src/ethzasl_ptam/ptam/launch. I sure error keeps coming I run roslaunch ptam cameracalibrator.launch, says: NODES / cameracalibrator (ptam/cameracalibrator) So I'm thinking PTAM include cameracalibrator. If someone could please point error, would really helpful. I've using post guide, it's helping much: Ros Dynamic Config file. As says link, I tried find . -executable I could find cameracalibrator. I could find below. How I proceed? ./include ./include/ptam ./cfg ... ./launch ./src ./src/ptam ./src/ptam/cfg ...",ros cameras calibration
7660,Implementing boustrophedon algorithm given room obstacles,"I mobile robot navigating around room, I already map room. I using navigation_stack ROS. I using rotary encoders odometry. I fusing data Rotary encoders IMU using robot_pose_ekf. I using amcl localization move_base planning. Now, I write Complete coverage Path planning algorithm I following paper I would like ask best way generate Boustrophedon path (simple forward backward motions) cell (can rectangular, trapezium, etc.) obstacles? I read paper use different templates combine certain way come Boustrophedon path. Is way generate boustrophedon path? If someone suggest implement ROS, great. Please let know need information me. Any help appreciated.",ros navigation motion-planning coverage
7662,How I work specifications motors propellers quadcopter?,"What specifications motors propellers approx produce thrust 100kg quadcopter? We planning lift total weight 50 Kg along 20 Kg weight quadcopter itself. So 50% throttle total thrust produced 150 Kg per motor total thrust 37.5 kg. I looked answer How calculate quadcopter lift capabilities? don't understand use information work specifications motor propeller required application. The answer given previous question limited small quad & I require specifications BLDC motor Kv,torque,Imax,V,Power,etc Propeller suitable motor.",quadcopter
7664,What actuator types exist remain locked last position like hydraulic piston?,"I would like find electronic actuator mimics characteristics hydraulic actuator, position remains fixed without power drain actuator moving. Which actuators exist match criteria?",electronics actuator
7666,"get reference Kalman filter, technical report","I'm sorry question might fit however, I would like give shot. I've chosen stack since question somehow related mobile robots. I've came across paper Mobile Robot Localization cited following reference, C. Brown, H. Durrant-Whyte, J. Leonard, B. Rao, B. Steer. Kalman filter algorithms, applications, utilities. Technical Report OUEL-1765/89, Oxford U. Robotics Research Group, 1989. I couldn't find reference. Nothing show Google even Google Scholar. In university allows access massive database, also nothing show up. Since technical report, I'm interested read appreciation Kalman Filter. Has anyone came across reference?",mobile-robot localization kalman-filter
7670,Kinect v1 VS Kinect v2,From technical standpoint differences Kinect v1 Kinect v2 ? I'm interested hardware equipment format data.,kinect
7671,Kinect VS Stereo cameras,"As I'm advancing project I realized I need better hardware, particularly video input processing. From intuitive feeling sounds like stereo cameras offers powerful flexible solution, hand Kinect looks like great out-of-the-box solution depth sensing also takes away lot computational complexity output directly depth. So I would like know upsides downsides 2 solutions well known limitation and/or field application why. Thank",kinect cameras stereo-vision
7672,Extending iCreate battery power auxilliary equipment,"I plan use icreate platform carry tablet, notebook PC want power time I need 3000 mAh battery. I want powered battery system use charging source. So I need info wire additional 14.4V NiMH batteries parallel existing deal additional temperature sensors (I could ignore course but...). Can built power control deal this? Do I need upgrade somehow? I would appreciate suggestions I want completely separate power system aux devices. Charging standard home base goal even though take longer. I deal adapting 14.4V whatever aux devices I add. Thanks.",power battery roomba
7678,How reduce battery power 10v 1.5A 6v 1.5A,What's least complex way reduce power 10V 1.5A battery 6V 1.5A Thank you!,battery
7680,Arduino compatible sensor motion detection positioning,"I working project requires motion detection positioning. I've worked substantially camera issue I need something sleek, small heavy all. Cameras also tend rely luminosity don't work well poorly lit spaces. I need someone who's worked something like knows best sensor purpose.",arduino
7682,Object Grasping Robot Arm Control,"I 2 DOF Robot Arm camera attached it. It takes Image there's object image, say glass. Of course, order move arm required position grasp object, I solve inverse kinematic equations. In order solve them, I need x y, coordinates arm reach grasp object. My question I find x say midpoint object image. Thanks",mobile-robot robotic-arm
7685,What required build simple XY-stage?,"In scope PhD, I would like build automated microscopy set-up take images sample 2cm 2cm. This done taking pictures 500 micrometers 500 micrometers. Therefore I need design XY-stage moving sample optical setup. I would use Raspberry Pi steer hardware. Could direct material best make XY-stage ? My questions types motors use (stepper?), many, create good sliding mechanism avoid jerky steps, etc. Simple links basic engineering set-ups would enough start, I complete layman field. EDIT: I found blogpost. It I require, I get small enough angle step stepper motors. EDIT2: I need maximal range motion 10 cm directions. The overall size exceed 30x30 cm^2. Step sizes exceed 10 microns. I care moving speed. Based upon design link, buying stepper motor 100:1 gear box could allow small radial steps (<0.05 deg) would result 5 micron steps, assuming rotor radius 1cm. As far price goes, exceed commercially available options start 5k USD",raspberry-pi stepper-motor
7691,Is anybody using robot simulators?,"Do use simulators developing robot algorithms test directly robot? I would like get introduced simulators world, don't know start... recommend one? Regards",simulator
7694,Degree Freedom,"A robotic arm pick cuboid table, rotate around vertical axis put possible positions. How many degrees freedom least necessary? (All coordinates, reached robotic arm, workspace. It allowed put cuboid pick up, robot ) The answer 4 (3 translatory 1 rotatory). But I don’t understand why. I thouhgt 3. 2 prismatic joints: 1 pick cuboid up, another one move anywhere table. 1 revolute joint rotate cuboid around vertical axis. => 2 translatory 1 rotatory.",robotic-arm
7698,Voltage rpm relation,I measure voltage ESC drawing increasing dc motor speed. Multimeter shows long speed increases voltage value decreases. Can anybody explain happening?,brushless-motor electronics esc
7703,increase PID sampling rate embedded system,"robotic project running every 1ms processes taking 0.9ms. I running PID max clock rate 1kHz. About half processing time taken SPI peripherals, IMU encoders. Is recommendation I run faster PID sampling rate?",pid embedded-systems
7705,Low variance resampling algorithm particle filter,"For particle filter, I decided try using low variance resampling algorithm suggested Probabilistic Robotics. The algorithm implements systematic resampling still considering relative particle weights. I implemented algorithm Matlab, almost word-for-word text: As would expected given loop structure, I getting error accessing weight(i), exceeds array dimensions. To solve this, I considering circularly shifting weight array (putting first index used first value weight, I never exceed matrix dimensions). However, I wasn't sure would negatively impact rest algorithm, seeing I'm trouble understanding purpose U calculation loop. Could anyone help clarify purpose U loop, whether circular shift acceptable fix?",mobile-robot algorithm particle-filter probability
7708,How make door opening top,"I need make construction (door closed default, door opened top). This scheme: Red rectangle picture aperture, blue rectangle door (weight 0.5 kg), moves top door need opened. Green stripe picture rail door. Which electrical engine I use? Estimated time door opening 10 seconds, I want send signal door, drop power lost I send signal drop down.",design electronics actuator
7710,Formationing Algorithm Multiple Robots,"I'm looking algorithm formationing multiple robots 2D simulation. Can suggest resources topic. Also I need suggestions comments topics: Can I recruit algorithm optimization algorithms like particle ant? Is way except ""go goal"" robot Is patter formationing algorithms feasible? Suggestions fast way formationing/ aligning Notes: Im using robotics simulator physics engine this. Robots represented dots. multi robot system homogeneous every robot sense obstacles robots sense range circle around robot. number obstacles robots vary 2 100 multi robot system central",mobile-robot multi-agent swarm
7712,Prototyping IRobot roomba,"For project I building Tele-Op Robot using IRobot's Roomba drivetrain. In order robot work, I need extra castor. IRobot provides .stl .stp files use I used printed files. (The file I printed link: Create® 2 Bin Modification. This file new part drivetrain allow another caster. And I downloaded first link called ""Full bin bottom caster mount"" The piece great made castor different height wheels. I wondering anyone file saved something different I edit preferably Solidworks. I phone IRobot 2 hours today told post here. So please help!!!! :)",irobot-create roomba
7718,Optimal hardware linear algebra operations,I've working lately SLAM algorithms implementing extended kalman filtering brush localisation techniques I thinking forward hardware side things. Are embedded chips microcontroller optimised large linear algebra operations? What sort embedded options best processing sorts operations?,slam kalman-filter
7720,Reading crazy large numbers Naze32,"I hope someone help here. I reading large numbers naze32. What max min values pitch, roll yaw? would I convert degrees radians?",quadcopter
7722,"What type control law used ""Reaction Control System"" Apollo Lunar Module Space Shuttle?","Reaction Control Systems (RCS) vehicles implemented using small rocket thrusters. For looks like thrusters work kind ""pulse"" mode. And I can't understand - use optimal control calculate advance required impulse reach new desired state system OR use ""pulse"" mode precise magnitude variation provided thrust (like average voltage PWM(pulse-width modulation)) classic PID control loop?",control automatic rocket
7723,MATLAB 3D Simulation SOLIDWORKS model,"I'm learning make 3D simulation MATLAB based model designed SOLIDWORKS. There example: SIMULINK+SOLIDWORKS The way used is: Create 3D model SOLIDWORKS Create xml file applicable import MATLAB via SimMechanics Link Import model MATLAB/SIMULINK. A simulink system created. After steps, controlling system implemented SIMULINK. But I feel simulink kind strict control. I want flexible, apply algorithm model. And using matlab *.m file control efficient way. So question this: Is way 3D simulation (MATLAB+SOLIDWORKS) using *.m file control, SIMULINK anymore? All model information contained *m.file. Maybe step 1 2 inherited, step 3 different.",matlab simulation
7724,Determine rotation axis given rotation matrix,"How I find around axis coordinate system rotate, rotation matrix given? $ {^{a}R_{b} } $ = $ \left(\begin{matrix} 0 & 1 & 0 \\ -1 & 0 & 0 \\ 0 & 0 & 1 \\\end{matrix}\right)$ $ {^{a}R_{c} } $ = $ \left(\begin{matrix} 0 & 0 & 1 \\ 1 & 0 & 0 \\ 0 & 1 & 0 \\\end{matrix}\right)$ For $ {^{a}R_{b} } $ I thought, rotation around z-axis, $R(z,\theta) = \left(\begin{matrix} cos(\theta) & -sin(\theta) & 0 \\ sin(\theta) & cos(\theta) & 0 \\ 0 & 0 & 1 \\\end{matrix}\right)$ values positions $a_{13}, a_{23},a_{33},a_{32},a_{31}$ $ {^{a}R_{b} } $ $R(z,\theta)$ identical. So I solved $cos(\theta) = 0$ =>$\theta = 90° $ => 90° rotation around z-axis. But I solve it, 1 rotation, like $ {^{a}R_{c} } $?",joint
7728,Where make changes simulation project Bullet/Gazebo/ROS/Orocos,"I starting develop robotics project involves simulation (and maybe real world programs) soft-body dynamics (for food processing) clothes/garment handling (for textile industry home service robots). It known soft-body dynamics garment handling two less explored areas robotics simulation, therefore I hope make development (contribution to) projects involved. The following projects involed: Bullet physics engine - dynamics Gazebo - simulation environment ROS - robot OS, I hope use Universal Robot UR5 UR10 arms grippers (not decided yet) Orocos - control algorithms Initially I hope use ""ROS INDIGO IGLOO PREINSTALLED VIRTUAL MACHINE"" (from nootrix.com), apparently I make updates Bullet, Gazeboo, add new ROS stacks on. The question - organize project? E.g. If I updating Bullet physics engine new soft-body dynamics algorithm executable (so) files I produce put virtual machine? The similar question asked I need update Gazebo. There seems incredibly large number files. Is right change them. Sorry questions, sofware stack seems complex robotics itself.",ros software programming-languages dynamics gazebo
7729,Is possible simulate vision (perception) Gazebo (or simulators),"Vision important part robotics frequently unavoidable component control loop. E.g. many clothes/garment handling algorithms rely visual cues deciding proceed. The question - simulation environments (Gazebo others) allow one design world robot garment simulate garment dynamics simulate also robot sees, robot perceives garment simulation step? If possible simulate vision simulate algorithms vision component control loop? Maybe simulation vision good research theme? Are trend good articles it? Some initial projects could expanded? Actually - stated general question - possible simulate sensors Gazebo? E.g. food handling (soft-body handling) involve tactile sensors. In principle Gazebo calculate deformation forces soft-body format data simulated values sensor readings. Maybe similar mechanism used simulation vision well?",computer-vision simulator research simulation gazebo
7731,Comparing industrial robot arms,"I'd like study capabilities industrial robot arms. For example, answer question price vary precision, speed, reach strength? Is database industrial robot arms including information like price, precision, speed, reach strength model?",robotic-arm industrial-robot
7735,Estimation Battery Life Time From PWM Signals Quadrotor,"Is way estimation battery life pwm outputs goes motors microcontroller level. I'm planning estimate path range this. Microcontroller, sensor electronic device neglected.",quadcopter battery
7737,"Building parts, keeping laser alignment steady","I building laser gun pentathlon targets (also one). I would like know build part gun I count steady laser attached motor. The question laser. I want maybe attached small-(servo)motor try implement cheat fun. Assuming motor good torque, I assume laser move (not sightliest bit) motor turned off? (I don't test) This precision shooting, small vibrations moving pointer would really prejudicial. In case does, I minimize problem? Is ordering motor highest torque? I also second question slightly off-topic, yet related, robotics people usually solutions problems. I also need build sights. Here's gun: As tell, sights fixed plastic point front, adjustable large back. There two bolts, one side. One makes sight higher lower, makes point right left. How part built simple tools? Thanls",motor stability laser
7739,Navigating Maze using path-planning (Dijkstra),"I'm working robot would able navigate maze, avoid obstacles identify objects it. I monochromatic bitmap maze, supposed used robot navigation. Up till I processed bitmap image, converted adjacency list. I use dijkstra's algorithm plan path. However problem I extract entrance point/node exit node bmp image dijkstra's algorithm plan path. The robots starting position slightly different (inch two entrance point) entrance point maze, I supposed move entrance point using ""arbitrary method"" apply dijkstra algorithm plan path maze's entrance exit. On way I also stop ""X's"" marked bmp file I attached below. These X's basically boxes I pot balls. I plan path entrance point exit point , entrance 1st box, second, exit point; I think boxes always placed shortest path. Since starting position different entrance point, I match robot's physical location coordinates program move accordingly. Even entrance position would starting position may error. How I deal it? Should I navigate bases coordinates provided dijkstra use ultrasonics well prevent collisions? And yes, give idea I use (ultrasonics, coordinates)?",arduino mobile-robot localization motion-planning mapping
7741,Mathematical Moddeling Elastic Robots,"We easily compute rigid robot kinematics dynamics. There many resources, simulators modelling tools it. But couldnt find elastic robots. Can suggest resources modelling tools?",kinematics simulator dynamics
7757,Calculus robotics,"I still high school part robotics club competes FTC (First Tech Challenge). I finishing first Calculus class (Calc 1), would ecstatic able apply someway real world example robotics. [Besides PID. It seems like approximations anyways] So far, I've working ""fabricated"" math problems. Would deriving equation real life situations complicated? Thank you!",control software
7760,Create simple C++ client Application control KUKA's Robot-arm LBR iiwa via FRI,"Until I programming robot using Java KUKA's IDE ""KUKA Sunrise.Workbench"", I want control robot arm via C++.Net application (I would use camera Kinect get commands). I'm reading documents provided Kuka, I'm bit hurry, I want understand C++ client application (running laptop) send/receive information to/from robot's controller ""KUKA Sunrise Cabinet"" (running server application) via FRI. I still issues grasping whole mechanism. A simple application (Server/Client) source code explanation (or schematic) would helpful .",robotic-arm c++
7763,Why generally prefer DH parameters kinematic representations robot arms?,"I specifically interested DH parameters versus representations terms kinematic calibration. The best (clearest) source information I could find kinematic calibration book ""Robotics: Modelling, Planning Control"" Bruno Siciliano, Lorenzo Sciavicco, Luigi Villani, Giuseppe Oriolo, chapter 2.11. Which requires description arm DH parameters, multiplying kinematics equation, partial differentiation w.r.t. DH parameter, least-squares fit (with left pseudo-inverse), iterate. Is fundamental reason DH parameters used instead different representation (like xyz + euler angles). I understand fewer parameters (4 versus 6 more), calibration procedure like I taking much data unknowns anyway. All robotics textbooks read present DH parameters say ""this use"", don't really go why. Presumably argument found original paper Denavit, I can't track down.",robotic-arm kinematics calibration dh-parameters
7764,Blade 180QX :What red wire do?,"I Blade 180QX quadrotor / quadcopter I move red wire shoved circuit board I fixed broken power wire. Now red wire shown straight circuit board right configuration - least was. If I understood I might know place it. Is horizon sensor (temperature)? Ever since I move wire, quadrotor goes unstable flying. The appreciable change wire POSITION. The red wire attached anywhere else board. It shoved circuit board inside battery holder.",quadcopter
7765,Drone Battery Question,"Background: 6 propeller drone w 20C 3s 6400 mAh 11.1 liPO battery 4 propeller drone w 25C 2s 5000 mAh 7.40 liPO battery Behavior: Drone 1 flies ease Drone 2 struggles hover 2-3 inches ground Question: The microcontroller, props, ESCs, motors same. I'm thinking reason drones flying differently difference batteries. IF batteries reason, would property responsible difference flight?",battery
7766,Duty cycle mapping,I need build conversion/mapping algorithm controller (PID etc.) output duty cycle order command bldc motor via esc. I couldn't yet l think l dont know meaning controller output. Anybody highlights way?,arduino motor esc microcontroller
7772,How cut throttle signal ESC properly?,"I 16 Channel Servo Driver board Adafruit (see here), I communicate via I2C using Raspberry Pi. The servo board controlling Qbrain sending PWM pulse 1ms 2ms works great. Problem is, I'm trying create kill switch signal servo board would cease, ESC would stop detects PWM signal. I placed toggle switch cuts VCC servo board, technically longer produce PWM signal, however power cut, ESC jumps 100% throttle, I assume ESC believes signal 100% duty cycle, I solve this?",raspberry-pi esc
7774,Modeling robot find position,"The task robot follows. My robot catch another robot arena, trying escape. The exact position robot sent robot 5Hz. Other I use sonsor identify robot. Is possible estimate next position robot using mathematical model. If so, anyone recommend tutorials books refer..?",arduino kalman-filter automatic probability
7778,Electric Motor Speed Control - PWM vs analog voltage?,"I'm working 2-wheeled robot connected raspberry pi L298N motor driver. I'm sending enable pin particular motor software-generated PWM signal 100Hz 50% duty cycle. I observe osciloscope: fairly clean square wave going enable pin expected. fairly dirty square wave across output motor terminals. The motor turns 50% speed/torque expected. I find wondering would better control speed motor placing flat lower constant voltage across terminals, rather oscillating square wave. ie 50% speed/torque - instead oscilating 0V 5V - put constant 2.5V across motor terminals. I wonder oscillation waste power/energy. Is true? Or doesn't make difference? Do high-end motor drivers use variable flat analog voltage control speed/torque, use PWM? If PWM, frequency make difference?",motor
7781,How I decide size time steps sensing control actuation?,"My Background: My experience solid mechanics FEA. So I zero experience robotics/controls. Problem Description I'm developing control strategy stabilize complicated 6-legged dynamical system. Torques Ti leg's joints used create net moment M body, stabilizing system. This moment M known pre-determined control strategy. (Side note: dynamical solver nonlinear computational type) Due lack background, I fundamental confusion dynamical system. I want use joint torques Ti create known net moment M body. This moment M function current positions/angles leg segments reaction forces moments (that cannot controlled) leg controllable joint torques Ti leg time $(*)$ At given time $(n-1)\Delta$t: --From control strategy, desired net moment M computed/known --One read/sense legs' positions, angles, reaction forces, reaction moments (say, well placed sensors), time $t = (n-1)\Delta$t. --From information, vector algebra easily yields desired joint torques Ti required create net moment M $(**)$ At time $(n)\Delta$t: --one applies previously determined joint torques Ti (determined $t=(n-1)\Delta$t) create desired moment M --of course torques Ti applied immediate proceeding time step cannot applied instantaneously So exactly fundamental confusion exists. The torques Ti calculated $(*)$, based data angles/positions/reactions $(*)$, objective create moment M. However, torques Ti applied $(**)$, data (angles/positions/reactions) different - thus desired net moment M never created (unless magically apply actuation instantaneous time sensing). Am I understanding controls problem correctly? Questions Am I understanding robotics problem correctly? What terms strategies around dilemma? Of course I could create time steps sensing actuation infinitely small, would unrealistic/dishonest. What balance realistic time step, also performs task well?",control actuator stability legged
7782,Is possible SLAM IR sensors like Buddy?,"I saw Buddy's page want purchase SLAM research. However, I wonder possible program Buddy SLAM? According Buddy's spec, they're IR's, sonars camera. As I know, SLAM algorithms implemented powerful sensors RGBD/stereo camera, even laser range finder. Are pepers mention IR-based SLAM?",mobile-robot localization slam mapping rangefinder
7786,Which joints discretize IK,"I using ikfast OpenRave inverse kinematics. This analytical solver, robot's DOF matches IK type's DOF, get possible solutions. But robot DOFs, need pick joints constant value. (However, use OpenRave's Python interface discretize joint you. i.e. give set solutions every 0.1 radians joint. But question holds either interface.) I 7 DOF anthropomorphic arm joints: Roll-Pitch-Roll-Pitch-Roll-Pitch-Yaw seen image: The discretized joints call ""free joints"" OpenRave's terminology. If I let ikfast decide, picks joint 3 (upper arm roll) free joint. However, I using joint 4 (elbow) free joint easier think about. But I realized perhaps joint 5, 6, 7 would better discretize closer end chain. Won't IK solutions suffer joints closer start chain large discretization? Or OpenRave picking optimal joint discretize? I wondering standard practices known conventions sort thing. Put simply: I want set IK solutions end-effector pose. I fix joint either near start end kinematic chain. And set isn't going perfect. Lets say ""ideal"" position epsilon. Now imagine want hand in-front robot, I pick bad angle shoulder (like straight example), rest joints hard time getting end-effector target pose, all. But If I fix wrist awkward angle, still good chance getting end-effector there, lease close. What kind trade-offs there? Which ""better"" set solutions?",inverse-kinematics
7790,How control motor speed via neural network dsPIC?,"I would like seek advise I go implementing neural network dsPIC control motor speed robot (if feasible). Currently, I deploying typical PID control loop control speed motors encoders attached them. Here thoughts I think set-up like: Inputs -> Desired Speed, Current Speed Output -> PWM Hidden -> Not sure many nodes needed many layers I also face contradiction supervised learning this. Assuming I pass desired speed current speed, output,if using sigmoid function, would 0-1. I would take multiply maximum PWM value compare PWM value required generate speed. Is correct way determine error? I little unclear part. Technically, I could manually determine PWM values required certain speeds, would result small data set training. Alternatively, I considered passing PWM values motor function, wait short period, capture current speed motor compare desired speed get error. I started coding basic neural nets I hope get ideas. Thanks!",motor pid pwm
7791,thrust measurement,I try find relation rpm vs. thrust battery+motor+propeller combination. image shows setup also measurement result. Can anyone explain l use datas (I know Kv.v gives rpm voltage values decreasing P=V.I relation etc.),quadcopter brushless-motor esc
7794,robot working,I spektrum dx5e transmitter ar610 receiver. I believe paired I turn transmitter receiver's light turns on. However I lost bind plug I somehow managed bind them. I plugged servos batteries correct slots nothing happens I move sticks. What I wrong? I Y splitter two power hd servos (contentious rotation) another power hd micro servo steering none responding.,wheeled-robot
7795,Can I connect UDOO PC using straight-through ethernet cable I need cross over?,"Can I connect UDOO board PC using straight-through ethernet cable? Or I need cross-over cable? As far I know, modern devices use two interchangeably. However, I sure UDOO that. Anyone experience? Thank help. (PS: I don't UDOO moment, I can't test myself. Couldn't find information documentation either).",embedded-systems
7796,Calculating Required Torque,"Say I object 4 motors/wheels attached (in fairly standard arrangement). I need calculate amount torque required motors able move object x kilograms consistently (without skipping steps) velocity y, travelling slope angle z. I'm guessing would also depend factors like grip tyre such? Fairly straightforward question (I hope answer way too). Thanks advance.",motor motion torque wheel
7802,EKF-SLAM initialize new landmark covariance matrix,"I trying implement EKF-SLAM using algorithm unknown correspondences proposed book ""Probalistic Robotics"" Sebastian Thrun Table 10.2 . By I understand actually algorithm except initialization new landmarks covariance matrix $ P_{new} $. In algorithm new landmark detected procedure normal measurment update already observed landmark done: Kalman gain $ K $ calculated new landmark covariance updated Kalman gain jacobian $ H $ new landmark like $ P_{new}= (I - K * H) * P$ . In understanding new observed landmark would effect rows columns correspond already mapped landmarks robot pose covariance matrix. Instead I think two rows columns x created uncertainity like proposed here: uncertainty initializing new landmark EKF-SLAM . I tried split calculation $ P_{new}$ via claculating blockwise see I could somehow come initialization shown link above. But I end different covariance matrix apparently new landmark effecting rows columns parts old covariance, view can't right. I hope I don't understand pseudo code book wrong I mistake try come initialization. Any advice initialization new lnndmarks work code actually link appreciated. Edit So basically I asking is: would normal Kalman update covariance matrix line 24 table 10.2 new observed landmark? Why explicit case initialization new rows/columns new observed landmarks covariance matrix? It seems like normal measurement update even newly observed landmark.",mobile-robot slam ekf
7803,Gyroscope - How I remove low frequency component high pass filter only?,"I'm using Matlab suppress low frequency components high pass filter. Objective Filter angular velocity measurements affected high frequency noise bias order get best estimate angular position. The output gyroscope still looks like this. First Approach The easiest way remove baseline remove average achieved Matlab using one line code. Second Approach We design high pass filter attenuate low frequency components. If analyze frequency components signal see one peak low frequency ""infinite"" small components frequencies due Noise. With second order ButterWorth filter normalized cutoff freq Wn = 0.2 get looking for. Filtered data Tilting Gyro When tilt gyroscope situation changes. With sampling frequency 300Hz get following plot. The first half dft shown normalized scale. You find sample.mat file The first approach works great. I would like apply second one particular case low frequency components make job harder. How I apply second approach based High Pass filter remove bias? EDIT 1 You find information EDIT 2 How filter signal remove bias keeping angular velocity information (from 110-th 300-th sample) intact? If gyroscopes bias problem experiencing rotation, offset present first ~110 samples. If hypothesis correct, maybe apply high pass filtering first 110 samples desactivate filter rotations gyro, estimated angular position accurate.",gyroscope matlab filter
7809,Robot structure kit materials,"I arduino, wires, resistors, good stuff. However, I don't materials build structure robot. What guys recommend? I don't place solder yet I can't solder kit material guys recommend? Will work well motors stuff? Thanks! P.S. I plan building standard driving robot, I want able make robots materials/kit. I don't want kit makes one robot, I want Lego-esque approach building structure I build whatever I want it. (Bump2)",arduino beginner
7815,"Are shelf solutions GPS+INS (accelerometer,gyro,magneto) sensor fusion getting filtered/fused location speed output?","I working project needs tracking location speed pedestrians/runners/athletes (so really robotics, I see lot related usage posts robotics domain, answer question could help follower robots). I'm interested 2D location (latitude-longitude). Using GPS position noisy/jump samples also degradation due multi-path near trees etc. From reading filtering solutions, I understand sensor fusion fuses GPS data inertial sensors (INS) helps improve lot issues. Also, kind sensor fusion seems used lot places -- robotics, wearables, drones etc. Hence I think might shelf chips/modules/solutions this, I couldn't find any. I found sensor hub Invensense integrates 9 dof inertial sensors comes fusion firmware, doesn't seem hookups firmware fusing GPS providing filtered latitude-logitude. So, I looking for? Are shelf chips/modules/solutions come built sensor fusion Software/firmware GPS+INS fusion? I understand still need tuning params well calibration.",localization kalman-filter sensor-fusion gps
7816,Displacement accelerometer,I want use sensor find displacement accelerometer. How I use accelerometer find displacement? I want use quadcopter.,quadcopter imu accelerometer uav
7819,Deciding length quadcopter arms,How quadcopter's arm length affect stability? As per view I'll better control copter longer arms stresses arms also doesn't affect lift capabilities.,control quadcopter stability
7823,Which sensor type accurately measures position?,"We're building 6dof joystick, need accurately measure displacement central device. We easily use mechanical connection edges, discussion best way achieve is. The range motion fairly small, accuracy incredibly important us. Which sensors easily accurately measured? My impulse response rotational linear potentiometers reliable, others arguing using gyros/accelerometers. I've also heard hall effect sensors used great effect.",control sensors accelerometer
7825,What device I need project laser point specific location?,"I'm searching (commercial) projector projects single laser point world (e.g. using two moving mirrors). However, I'm struggling I'm sure thing called. I either find area projectors use lasers, party equipment laser pointers. What name device?",laser
7828,How brushless gimbal motor different regular brushless motor?,"How brushless motors gimbal assembly designed? Obviously doesn't need continual rotation, need accurate control precise position. I've noticed motors gimbal don't usual magnetic 'snap' positions motors do. What primary design differences kinds motor, any?",motor
7829,How To Program Three Wheel Omni,"I created three wheeled omni robot like diagram below. Now I unsure program it. I want use single joystick one x one value. The values x -1 1, also motors set anywhere -1 1. How I use data make robot move based joystick without changing orientations? After initial research seems like complex problem, I hoping formula I can.",wheeled-robot
7831,Complementary Kalman filter don't work Y angle,"I'm working Python script reads data MPU6050 IMU returns angles using sensor fusion algorithms: Kalman Complementary filter. Here implementation: Class MPU6050 reads data sensor, processes it. Class Kalman implementation Kalman filter. The problem next: None Kalman, neither Complementary filter returns appropriate angle values Y angle. The filters work fine X angle, Y angle values make sense. See graphs below. I've checked code million times, still can't figure problem is. EDIT: I've added information based @Chuck's answer: self.result_list[3] contains temperature In opinion compl. filter implemented correctly: gyro_x_scaled gyro_y_scaled angular velocities, multiplied dt, give angle. acc_?_scaled accelerations, acc_x_angle acc_x_angle angles. Check comment, Complementary filter tutorial is. Yes, something missing Kalman filer, I've corrected it. I totally agree you, sleep(dt) best solution. I've measured much time calculation takes, 0.003 seconds. The Y angle filters return incorrect values, even sleep(0.007) sleep(calculatedTimeDifference) used. The Y angle filters still return incorrect values.",kalman-filter
7832,Kalman filter estimating position “direction” measurements,"I currently working pose estimation problem I would like use filtering. To explain system briefly, consists two cameras GPS/IMU module. The main assumption Camera1 fixed stable, whereas camera2 noisy pose 3D. I using computer vision obtain pose (metric translation rotation) camera2 w.r.t. camera1, I improve upon inherent noise GPS/IMU modules. The problem translation obtained vision method arbitrary scale, i.e. given instant, I obtain unit vector specifies ""direction"" translation absolute metric translation. The camera based estimation, although accurate, idea much actual distance cameras, I GPS, gives position data noise. Example: camera 2 5 east camera 1, pose vision algorithm would say [1, 0, 0] ; 1 north-east camera 1, would something like [0.7, 0.7, 0] Hence, would possible consider GPS estimate metric translation well covariance ellipse, somehow link normalized camera measurements obtain final, accurate estimate metric translation? I sure kind filters would happy use measurement absolute value it. Thanks!",kalman-filter cameras pose
7837,Type servo torque calculation required 2axis robot arm,I trying build 2-axis robot arm pan tilt mechanism. The gripper/holder hold object weighing 300 grams. The total weight arm including motors around 2 kg. I decided use 180 degree servo motors. The maximum arm reach 340 mm. I want ask is: What kind servos (analog/digital) suitable support total weight (2 kg) object weight (300 g)? How I calculate required torque? How many servos I use make sure arm doesn't flip over? Please suggest better approach designing robot. I fairly new electronics first time I building robot. Thanks advance.,robotic-arm design servos
7838,MCU architecture design,"Are standards regarding single vs multiple MCU robotic system? More specifically, single MCU handle sensor data actuator controls, better use single MCU multiple MCUs hierarchical manner? Are references/papers regarding topic? What arguments towards one other? I looking facts, personal opinions, pros, cons, standards such.",design
7841,Real-time camera localisation known environment,"I young researcher/developer coming different (non-robotic) background I research camera localisation I came point, I say I lost I would need help. I discovered lot SLAM algorithms used robots etc. As far I know unknown environments. But situation different. My problems idea time is: I placed known room/indoor environment (dimensions would known) I would like use handheld camera I use predefined landmarks would help. In case, I put "" unique stickers"" walls predefined positions would help way faster localisation. I would like get camera position (with orientation etc) realtime(30 Hz faster). For beginning I would like ask SLAM algorithm right one situation start. Or suggestions get real time camera positions inside known room/environment. It must really fast must allow fast camera movements. Camera would person robot. thank advance.",localization slam real-time
7850,EMAX ESC Simon Series arduino,"I want control brushless motor ""EMAX Simon Series 30amp ESC"" Arduino (Leonardo) board. I really confused that. I can't understand beep sounds mean what. I tested many code examples weren't useful.",arduino brushless-motor esc
7852,Olf Futaba Rx & Tx APM micro 2.7.2?,Hi I found old Rx & Tx loft need know weather compatible APM micro 2.7.2. I already telemetry give manual control. My guess I need new Rx current one make hash electronics APM. Thanks advance[![enter image description here][1]][1] [![enter image descriptere][2]][2],quadcopter
7853,How tune PID Y(t) = k*X(t) system?,"Could I opinions PID type selection? System description Here comes simple system: $\mbox{Output}(t) = k * (\mbox{Input}(t) + \mbox{systemVariable}(t))$. $k$ constant $\mbox{systemVariable}(t)$ system variable may change according time. The goal whole system maintain system output $0$. It close zero possible. The controller compensate $\mbox{systemVariable}$. The change ($\mbox{systemVariable}$ ) modeled slow ramp. Controller description The controller's input output system. However, measurements always noisy, I modeled Band-Limited White Noise measurements. After PID controller, output goes integrator, since PID controller always calculates ""change"" plant input. Questions My original thoughts: Add PID controller P=1/k enough. Since every time controller gets error $e$, calculated back compensation controller output shall $e/k$. However, Matlab auto-tuning always give PID. Why that? What relation P PID measurement noises? If P large, system tend rambling largely, due noises. If P small, system tend converge correct value slow. How make trade-offs? Or prevent system rambling largely get quick system responses? Thanks lot!",control pid
7855,How absolute flash size calculated microcontroller?,"I working STM32F103C8 flash size 64kBytes. Now using ChibiOS 2.6 build file binary file 82kBytes. Using ST-Link Utility, program getting dumped microcontroller's flash. My question come 82kB code fits 64kB Flash? How size .bin calculated? I attaching picture display. I compare ch.bin device memory doesn't report errors found. All parts code work fine, don't see problems anywhere tried features code, nothing breaks behaves abnormally. Could someone please explain this? Thanks!",microcontroller
7860,iRobot Create Serial Cable Turtlebot I,I need iRobot Create Serial Cable (one end 7-pin Mini-DIN Connector end USB) Turtlebot I. How I connect bot PC?,mobile-robot irobot-create serial roomba
7864,Can RC servo motors continually rotate?,"I know RC servo motors designed precise movement, rather D.C. motors' continual rotation. Are RC servo motors limited movement within one rotation actually made continually rotate? That say, movement limited specific arc? Or depend type RC servo motor? I seen videos industrial size steppers rotating constantly, but, specifically, I wondering whether MG995 can. I don't RC servo motors yet, I can't actually test myself. I want make sure I make purchase. I keep seeing conflicting information, example instructable, How modify RC servo motor continuous rotation (One motor walker robot), implies RC servo motor continually rotate, else otherwise, would need modify it? Addendum I realised, digging google, HighVoltage points answer, I confused steppers servos. In addition, I found hack TowerPro MG995 Servo continuous rotation.",stepper-motor rcservo
7870,Simple Sensor Fusion pose estimation,"I currently working balancing robot project, features fairly low-cost sensors 9-Dof IMU measurement states $\textbf{x}_\text{IMU} = \left[a_x, a_y, a_z, g_x, g_y, g_z, m_x,m_y,m_z \right]^\text{T}$. Currently I use accelerometer gyroscope readings, fused complimentary filter get angular deviation robot's upright (stable) position. The magnetometer values tilt-compensated yield robots orientation respect earth-magnetic field (awful close magnetic distortion). Furthermore I pretty decent rotational encoders mounted wheels deliver information wheel's velocity. $\textbf{x}_\text{ENC} = \left[v_l,v_r\right]^\text{T}$. Given measurements want try get robots pose (position + heading). $\textbf{x}_\text{ROB} = \left[x,y,\theta\right]^\text{T}$ I minor theoretical knowledge EKF KF, sufficient actually derive practical implementation. Note computational resources fairly limited (Raspberry Pi B+ RTOS) I want avoid using ROS non-std libs. Can anybody help actually approach kind problem?",sensors kalman-filter imu sensor-fusion odometry
7872,Simulation environment conducting visual servoing experiment,"I want conduct following experiment: I want set scene kuka lwr4+ arm, 3D model object camera overlooking them. I want find pose object using pose estimation algorithm move arm towards object. In general I want piece software combination cooperating software without reinvent wheel. Is anything available?",software simulation visual-servoing
7874,What commands make irobot create 2 go left right forwards backwards?,"I new create 2 I downloaded real term program, opened interface robot send numbers robot. I get drive command work. I know make robot go faster, turning around slower. I would like know make commands work along making go left right.",irobot-create
7877,Original paper Kalman filter,"Recently we've encountered Kalman filter algorithm state estimation course Probabilistic Robotics. After taking several days try read Kalman's original paper published 1960, ""A New Approach Linear Filtering Prediction Problems"", firstly feel bit difficulty read, seems majority show orthogonal projection optimal estimation certain conditions solutions Wiener's problem. But I find exact algorithm original paper one textbook. For example, explanation ""Kalman gain"" paper ? Does Kalman's paper provide mathematical derivation Kalman filter algorithm?",kalman-filter
7879,Forward kinematics: Why ω remain same?,"Can anyone please explain lines found page 5 Kinematics Equations Differential Drive Articulated Steering Thomas Hellström? Note plugging $r$ $v$ left right wheel result $\omega $ (otherwise wheels would move relative other). Hence, following equations hold: $$ \begin{align} \omega~ \left(R+\frac{l}{2}\right) &= v_r\\ \omega~ \left(R-\frac{l}{2}\right) &= v_l\\ \end{align}$$ $R$ distance ICC midpoint wheel axis, $l$ length wheel axis (see Figure 6). Figure 6 . When left right wheel rotate different speeds, robot rotates around common point denoted ICC My questions are: How equations come be? Why $\omega$ want analyse behavior changing wheel velocity relative other? How know circle, robot rotates variations one wheel velocity, surely passes center point two wheels.",mobile-robot
7881,How I dispense greasy fluid?,"I'm agricultural engineering student complete newbie trying build simple mechanism attached drone dispenses grease-type fluid. However, since I'm familiar field, I'm hard time googling I don't know correct terms search for. I'm looking mechanism remotely push grease out. The problem carrying necessary weight hectare (300g 1,5kg fluid) dispenser mechanism within drone. So I'm looking lightweight dispenser mechanism capable deliver small amounts fluid (3g) distributed trees canopy. The grease need heated flows naturally normal temperatures (like toothpaste). Both pump syringe-type arrangement would fine long I control remotely.",motor quadcopter design battery actuator
7882,How determine x-axis two z-axis intersecting Denavit Hartenberg representation,"Suppose I 3 link(1 dimensional) chain joints revolutes, axis first revolute joint along Z-axis(global) axis second joint along X-axis(global). The first link along X-axis(global) second link along Z-axis(global). Now order use DH representation I introduced local frame link 1 joint 1(z axis along Z x axis along X) another frame joint 2.Here z-axis along axis rotation(global X) I clueless determine x-axis joint 2 two z axis intersecting.(standard procedure find common normal two z axis) Thanks time.",robotic-arm dh-parameters
7883,How I get values IMU serial message received Simulink via UART?,"I try read IMU sensor data Arduino mega 2560 UART serial receive block Arduino support package simulink. The IMU send binary packets also nmea packets I configure output. When serial recieve block output directly used, displays numbers 0-255. l need help parse coming data contains euler angles I want use. Here binary structure ; ""s"",""n"",""p"",packet type(PT),Address,Data Bytes (D0...DN-1),Checksum 1,Checksum 0 The PT byte specifies whether packet read write operation, whether batch operation, length batch operation (when applicable). The PT byte also used UM7 respond commands. The specific meaning bit PT byte given below. Packet Type (PT) byte; 7 Has Data, 6 Is Batch, 5 BL3, 4 BL2, 3 BL1, 2 BL0, 1 Hidden, 0 CF Packet Type (PT) Bit Descriptions; 7...Has Data: If packet contains data, bit set (1). If not, bit cleared (0). 6...Is Batch: If packet batch operation, bit set (1). If not, bit cleared (0) 5:2..Batch Length (BL): Four bits specifying length batch operation. Unused bit 7 cleared. The maximum batch length therefore 2^4 = 16 1...Hidden: If set, packet address specified “Address” field “hidden” address. Hidden registers used store factory calibration filter tuning coefficients typically need viewed modified user. This bit always set 0 avoid altering factory configuration. 0...Command Failed (CF): Used autopilot report command failed. Must set zero packets written UM7. The address byte specifies register involved operation. During read operation (Has Data = 0), address specifies register read. During write operation (Has Data = 1), address specifies place data contained data section packet. For batch read/write operation, address byte specifies starting address operation. The ""Data Bytes"" section packet contains data written one registers. There byte packet explicitly states many bytes section possible determine number data bytes packet evaluating PT byte. If Has Data bit PT byte cleared (Has Data = 0), data bytes packet Checksum immediately follows address. If, hand, Has Data bit set (Has Data = 1) number bytes data section depends value Is Batch Batch Length portions PT byte. For batch operation (Is Batch = 1), length packet data section equal 4*(Batch Length). Note batch length refers number registers batch, NOT number bytes. Registers 4 bytes long. For non-batch operation (Is Batch = 0), length data section equal 4 bytes (one register). The data section lengths total packet lengths different PT configurations shown below. The two checksum bytes consist unsigned 16-bit sum preceding bytes packet, including packet header. Read Operations; To initiate serial read one registers aboard sensor, packet sent UM7 ""Has Data"" bit cleared. This tells device read operation address specified packet's ""Address"" byte. If ""Is Batch"" bit set, packet trigger batch read ""Address"" byte specifies address first register read. In response read packet, UM7 send packet ""Has Data"" bit set, ""Is Batch"" ""Batch Length"" bits equivalent packet triggered read operation. The register data contained ""Data Bytes"" section packet. Example Binary Communication Code;",arduino electronics embedded-systems matlab
7884,Using Blob detection V-Rep,"I trying reproduce youtube tutorial V-rep I came across problems concerning blob detection. There complaints matter video. I don't believe blob detection stopped working recent v-rep versions, I unable make work (as new v-rep user myself). Has anyone idea properly implement it? More specifically, I vision sensor named I want follow red ball. The vision sensor detect position ball I use control joints steer sensor (yaw pitch). My script follows threadFunction=function() yaw=simGetObjectHandle(""yaw"") pitch=simGetObjectHandle(""pitch"") cam=simGetObjectHandle(""cam"") simGetSimulationState()~=sim_simulation_advancing_abouttostop result,pack1,pack2=simReadVisionSensor(cam) result>0 xtarget=pack2[5] ytarget=pack2[6] simAuxiliaryConsolePrint(out,string.format(""\n x: %0.2f, y: %0.2f"",xtarget,ytarget)) simSetJointTargetVelocity(yaw,1*(0.5-xtarget)) simSetJointTargetVelocity(pitch,1*(0.5-ytarget)) end end end simSetThreadSwitchTiming(2) = simAuxiliaryConsoleOpen(""Debug"",8,1) res,err=xpcall(threadFunction,function(err) return debug.traceback(err) end) res simAddStatusbarMessage('Lua runtime error: '..err) end When I run simulation I see sensor sees red ball point result always 0 meaning detection takes place. Here scene",simulator visual-servoing
7886,How numerically calculate Jacobian?,"I'm trying calculate Jacobian days now. But first details. Within Master's Thesis I numerically calculate Jacobian tendon-driven continuum Robot. I homogeneous transformation matrices I already implemented kinematics Robot. Due it's new structure discrete joint variables anymore rather continuous parameters. Therefore I want compute Jacobian numerically. It'd awesome someone could provide detailed way compute numerical Jacobian 6-DoF rigid-link robot (only rotational joints => RRRRRR). From I transfer continuum robot. I've already started computing it. Let T homogeneous transformation matrix Endeffector (Tip) $$T=\begin{bmatrix}R & r \\ 0 & 1 \end{bmatrix} $$ R = rotational matrix (contains orientation) $ r = \begin{bmatrix} x & & z \end{bmatrix}^T$ endeffector position. My approach compute first three rows J successively increasing joints, computing difference ""original"" joint values dividing increment delta, joint-space $ q = \begin{bmatrix} q_1 & q_2 & q_3 & ... &q_6 \end{bmatrix}T $ $q_1 = q_1 + \delta$ => $J(1,1) = (X_{increment} - X_{orig})/\delta$ $q_2 = q_2 + \delta$ => $J(1,2) = (X_{increment} - X_{orig})/\delta$ on. I z coordinates. So I get first 3 rows J. Now I don't know compute last three rows refer rotational Matrix R. Since it's 3x3 matrix scalar value I don't know handle it.",jacobian
7889,Forward kinematics constrained double pendulum,"I wondering whether maybe could help problem. I double pendulum. I set origin cartesian coordinates ""head"" first arm, fixed. The end second arm attached block slides along x-axis. What I want derive equations relating pendulum's angles distance origin block. Now, I know I could go deriving equations without constraint. $$x_1 = L_1cos(a_1)$$ $$y_1 = L_1sin(a_1)$$ Where $x_1$ $y_1$ first arm joins second arm $a_1$ angle horizontal first arm. Similarly, I derive equations end second arm $x_2 = x_1 + L_2 cos(a_2)$ $y_2 = y_1 - L_2 sin(a_2)$ Now then, I attach sliding block end second arm, I don't know whether equation $x_2$ would change all. I don't think would would I somehow restrict swing angles block moves along x direction? Well, basically problem finding equation $x_2$ it's attached block moves along x- direction.",forward-kinematics
7894,Beginner Soldering question,"So, I need know couple things soldering. My primary workspace, robotics otherwise desk computer little bit free space (4ft. 6 in.). I wondering safe solder small area. Also, level ventilation I need solder safely? My desk normal house room desk write next air vent. My house heating A/C? Do I need fan fume sucker thing? I plan solder little get things stay solder less bread board (soldering header pins onto wires such). So, basically, minimum requirements soldering safely (space ventilation). Also, anyone could point hobby/beginner level soldering must-haves amazon would great, thanks.",beginner
7895,IRobot Create 2: Powering Up Sleep,I've notice IRobot Create 2 respond app's commands sleeping. If I press Clean button re-run app robot responsive commands. My initialization sequence (Android/Java) using usb-serial-for-android: The physical architecture IRobot Create 2 connected IRobot Serial Cable Google Project Tango Tablet. How app wake Roomba it's sleep?,irobot-create
7896,How rotate dc motor fixed rpm,"I using 8051 microcontroller dc motor.What rotate motor fixed rpm. Let's say 120rpm. And possible generating pwm,how calculations relation duty cycle rpm?",control motor microcontroller
7903,How I tell servo motor capable controlled degree degree?,"I want create rotating control mechanism turn surface face direction sphere. My dad (an electrical engineer) said I probably connecting two servo motors together. I looking servo motor I want do, moving sphere decent precision (within ~1 degree) I don't know kinds motors able handle precision. Another challenge one servo hold second servo top. As I understand it, torque rating determines maximum amount force servo exert load I figure servo strong enough math?",control servos
7910,How I recognize animals video stream static images openCV library/software?,"I'm software developer experienced AI machine learning, I'm interested developing kind software. I want develop software recognizes specific objects, specifically, animals video stream (or sequence static images). I saw there's library called openCV often commented forum, I saw far library helper working images, I didn't find object recognition self learning part. Is openCV good starting point? better go theory first? already developed libraries frameworks aimed object recognition? EDIT To give context: I ona camera checking landscape, mostly static leaves may move wind person may step in, I want get alert animal view, I reduce ""animals"" birds (not always I nice bird/sky contrast). I work supervised neural networks 15 years ago studied AI machine learning theory, I guess things improved way much since then, that's I asking practical first steps. Thank",computer-vision
7912,Powering Project Tango Tablet iRobot Create 2,"Project Tango Development Kits come mini-dock (see picture below). I controlling iRobot Create 2 mounted Tablet using USB cable provided plugged mini-dock. (see docs). The USB 3.0 port mini-dock functional tablet docked. The port used attach external memory drive standard peripherals tablet. I wish recharge tablet using power iRobot. The mini dock comes port external charging: The mini-dock accepts power adapter faster charging (not provided). The power adapter output must 12V, 2A, connector must barrel plug 5.5mm outer diameter, 2.1mm inner diameter, center positive. Ideally charging would happen iRobot also charging, charging time acceptable. Is possible? If so, how?",irobot-create
7913,Non linear control system?,"I dual (sequential) loop control system controlling angle rotational joint robot using absolute encoder. I tuned inner control loop (for motor) working tuning outer loop (for joint). Example dual loop controller When I disturb system response isn't I would expect. Kp = 0.4 Kp = 0.1 Kd = 0.001 I didn't add Ki term I don't steady state error. I'm confused fact second overshoot first plot larger first one. No matter I adjust parameters I can't seem get rid oscillation velocity joint (seen second plot). One limitation I I increase Kp Kd high gearbox becomes noisy noise encoder signal creates larger adjustments position motor. I'm working adding filter output using method described here. The code I'm using outer loop is: I'm beginning think system might able modeled first order equation, would change implementation control loop all? Any advice appreciated! Ben",pid
7915,Arduino mega shield v2.0 compatibility arduino due,Like title says.. Will work? I know due 3.3 volt limitations. I want build hexapod 18 servo's. The shield I looking at: If isn't compatible. Is alternative shield work? I can't seem find much due.,arduino
7919,Telemetry APM 2.6 XBee,"The transmission telemetry data ground base station APM 2.x (Arducopter), using XBee, well documented. The documentation Telemetry-XBee, specify XBee version used. I checking I guess version 1 (this one P2P link others not), I sure. I would like know, XBee modules people use flying drones? Do problems APM connection? How I control drone remotely using XBee link Mavlink protocol?",quadcopter radio-control mavlink
7920,Inverse kinematics solution 6DOF serial arm,"My 6 joint robot arm structure doesn't meet requirements closed form solution (no 3 consecutive axes intersecting point 3 parallel axes...). What would best method adopt get solution 1ms less? Estimation accuracy 1mm. I'm assuming computation done average laptop Intel Core i3, 1.7GHz, 4GB RAM",inverse-kinematics
7921,Robot localization without sensors,"Is possible localize robot without sensors, odometer servo motors? Assume robot dc motors obstacles.",localization mapping
7925,Positioning Sensor,I would like locate position stationary autonomous robot x-y-z axis relative fixed starting point. Could someone suggest sensors would suitable application? I hoping move robot 3D space able locate it's position wirelessly. The rate position update important I would like stop robot moving relay information wirelessly. The range I looking roughly 2 KM + (the better) accuracy +/- 1 CM. Is system could this? Thanks help.,sensors imu
7928,Robot path planning,"My goal move robot certain points shown figure. It's initial position (x0,y0) move along coordinates. I able track robot position using camera connected pc camera located top arena. I've mounted ir beacon robot, camera find beacon locates it's coordinate(in cm) arena. Using coordinate I move robot another position, say new position (x1,y1) My robot arduino mega 2560 two DC motors, communication pc robot done using bluetooth Update: Thanks @Chuck answer, however I still doubts regarding turning angle. My robot position setup shown image. (xc, yc) current position (xt, yt) target position. If I want align robot direction target coordinates, I've calculate atan2 target current coordinates. But angle remains since it's current position changing respect target point. I assume robot simply makes 360' rotation current position? Update: The path points show image, initial heading angle assumption correct? '1' starting point. Update Thank patience time, I'm still struck turning, code goes like Since angle always -90' robot makes right turn loop current point, since angle changing. I think I'm missing something here.",arduino navigation
7930,Can charge lipo nano tech battery imax b3 charger,Can charge lipo nano tech battery imax b3 charger. 2650mah 35/70c 3s battery,battery lithium-polymer
7937,Multiple EKFs one big,"Let's say I would like use EKF track position moving robot. The EKF would estimate position also variables affecting position estimate, example IMU biases, wheel radius, wheel slip on. My question is, better use one big EKF (state vector containing estimated variables) multiple smaller EKFs (each one responsible tracking subset variables estimated)? Or difference? As example above, EKF could split one tracking position, one estimating wheel radius slip one estimating IMU biases. The position EKF would course use estimations output concurrent EKFs vice versa. To seems would easier tune test multiple smaller EKFs rather one big. Are advantages/disadvantages (execution time, ease debugging etc.) assuming resulting estimates equal two approaches (or close enough least)? Thanks, Michael",kalman-filter ekf
7940,recommendation really high precision attitude measurement sensors,"I new field, I looking high precision gyroscopes accelerometers attitude measurements.The precision requirement around 0.2~0.5 deg/s dynamic. I done digging myself, single integrated MEMS sensor without costing much. So heavy math needed that's fine.I need make sure prefect sensors chosen, budget less 100USD. one help, thanks advanced.",sensors research
7942,Wall following using hokuyo lidar sharp IR sensors,"I mobile robot I would like follow walls room. I have: A map room. Wheel encoders odometry. A Kalman filter fusing data wheel encoders IMU. A Hokuyo lidar localization obstacle avoidance A Kinect see obstacles seen Hokuyo. Amcl localization. A couple sharp sensors side wall following. I planning use global local costmap localization robot perfect robot might think closer (or away) wall actually therefore, wall following might fail. So, I planning use data Hokuyo lidar sharp sensors wall following maintain constant distance wall (say 10 cm). Now, I would like know best technique wall following manner? Also, one deal issue open gaps wall (like open doors, etc..) wall following using approach? I know general question suggestions regarding appreciated. Please let know need information me. Update: I trying wall following given room (I vertices room global reference frame) For example, Lets say I map room (shown below). I want make robot follow wall closely (say 10 cm wall). Also, open space (on bottom left), robot go adjacent room keep wall following given room (For this, I boundary limits room I use make sure robot within given room). The approach I thinking come initial global path (set points close wall) wall following make sure robot goes one point next making sure always maintains certain distance wall. If wall, robot follow global path (assuming localization good). I sure implementation complexity whether better algorithm/ approach something like this.",sensors localization navigation
7944,Compatibilty setup?,"I'm building first quadcopter, components I intend buy: Motor: EMAX BL2212 1400 KV Brushless Outrunner Motor around 0.9 kg thrust: Flight Controller: Multiwii V2.5 Flight Controller Propellers: I don't know one get: fut-electronics propellers collection GPS: Skylab UART GPS Module SKM58 (Small Form Factor) Radio Communication: Radio Telemetry 915 Mhz (3DR), affordable alternative buying radio telemetry maybe using Wi-Fi? ESCs: 4x1 ESC (4x25A) - Speed Controller Quadcopter Battery: I don't know one choose My questions are: Are components compatible? What battery choose? If I'm planning GPS planned missions, would GPS important anything else? By way I intend attach camera smart-phone video capturing I think extra 200 grams.",quadcopter multi-rotor uav
7945,"Why name ""combinatorial""?","Why 'cell decomposition' methods motion planning given name, ""combinatorial"" motion planning?",motion-planning
7950,Axis rotation via IMU,"Using IMU (gyro, accelerometer magnetometer), found smartphones, I detect differences tilting device, say forward, along different (parallel) axis positions? To clarify, axis rotation far sensor, motion contains translational component. Can distance position axis extracted IMU data how? Is data fusion algorithm this?",imu accelerometer gyroscope magnetometer
7953,Hand Eye Calibration Solver,"I rig I pretty good estimate static transformation camera joint based CAD. It errors though I hoping fix hand eye calibration. So, I started generating data based transformation I already. From papers I reading, want solve $$AX = XB$$ problem either converting $A$, $B$ dual quaternions simplifying equation something like $$ n_A = Xn_B $$ $n_A$, $n_B$ eigenvectors corresponding eigenvalue 1 $A$ $B$ rotations. After generating data, I tested data collection correct I validated checking $AX = XB$ $A$s $B$s I generated. I used CamOdoCal library try solve problem I got - The actual transform one I based $A$ $B$ data on. Then I tried implementing Tsai-Lenz Horaud Dornaika's Nonlinear optimization techniques using LM solver avail. I get correct transformation solvers. So, I wondering could point hand eye calibration library paper worked.",kinematics calibration
7954,Book mechanisms,I wanted know sort archive mechanisms contains brief description mechanisms like type motion forces involved. Not lengthy derivations stuff.,mobile-robot mechanism
7959,Tuning PD line follower,"I trying make line following robot. I using atmega328p mcu, pololu 10:1 motors, pololu qtr6-rc sensor, 2s li-po. Here code: And qtr library: #ifndef QTRRCSensors #define QTRRCSensors #define SLOW 1 #define FAST 0 static inline void initQTRs(void) { TCCR1B = (1 << CS11); } uint16_t QTRtime[QTRCNT], QTRmax[QTRCNT], QTRmin[QTRCNT]; static inline void readQTRs(uint8_t forceSlow) { uint8_t lastPin, i, done = 0; (i = 0; < QTRCNT; i++) // clear previous times QTRtime[i] = 0; READDDR |= 0b00111111; // set pins output READPORT |= 0b00111111; // drive high _delay_us(10); // wait 10us charge capacitors READDDR &= 0b11000000; // set pins input READPORT &= 0b11000000; // turn pull-up registers TCNT1 = 0; // start 16bit timer 0 lastPin = READPIN; ((TCNT1 < MAXTICKS) && ((done < QTRCNT) || forceSlow)) // forceSlow, always take MAXTICKS time { (lastPin != READPIN) // pins changed { lastPin = READPIN; (i = 0; < QTRCNT; i++) { ((QTRtime[i] == 0) && (!(lastPin & (1<<i)))) // pin go low first time { QTRtime[i] = TCNT1; done++; } } } } (done < QTRCNT) // timed out, set pins didn't go low max (i = 0; < QTRCNT; i++) (QTRtime[i] == 0) QTRtime[i] = MAXTICKS; } void calibrateQTRs(void) { uint8_t i, j; (j = 0; j < 10; j++) { // take 10 readings find min max values readQTRs(SLOW); (i = 0; < QTRCNT; i++) { (QTRtime[i] > QTRmax[i]) QTRmax[i] = QTRtime[i]; (QTRtime[i] < QTRmin[i]) QTRmin[i] = QTRtime[i]; } } } void readCalibrated(void) { uint8_t i; uint16_t range; readQTRs(FAST); (i = 0; < QTRCNT; i++) { // normalize readings 0-1000 relative min & max (QTRtime[i] < QTRmin[i]) // check reading within calibrated reading QTRtime[i] = 0; else (QTRtime[i] > QTRmax[i]) QTRtime[i] = 1000; else { range = QTRmax[i] - QTRmin[i]; (!range) // avoid div zero min & max equal (broken sensor) QTRtime[i] = 0; else QTRtime[i] = ((int32_t)(QTRtime[i]) - QTRmin[i]) * 1000 / range; } } } uint16_t readLine(void) { uint8_t i, onLine = 0; uint32_t avg; // weighted total, long division uint16_t sum; // total values (used division) static uint16_t lastValue = 0; // assume line initially way left (arbitrary) readCalibrated(); avg = 0; sum = 0; (i = 0; < QTRCNT; i++) { // following white line, set QTRtime[i] = 1000 - QTRtime[i] (QTRtime[i] > 50) { // average values noise threshold avg += (uint32_t)(QTRtime[i]) * (i * 1000); sum += QTRtime[i]; (QTRtime[i] > 200) // see we're line onLine = 1; } } (!onLine) { // If last read left center, return 0. if(lastValue < (QTRCNT-1)*1000/2) return 0; // If last read right center, return max. else return (QTRCNT-1)*1000; } lastValue = avg/sum; // chance div zero since onLine true return lastValue; } #endif I trying find Kp constant it's 7 robot turns line always spot. When Kp 8 follows staright line wobbles lot can't take corners. I also tried increase Kd 10 20 times Kp 8 didn't change much. How I get working? Here robot track I want follow.",pid line-following avr tuning
7964,Total Hand calculations procedure & formulaes Mega-Quadcopter,"I student BE taking Mega-Quadcopter final year project.Can u please help total hand calculations mega-copter i.e procedure formulaes? . I wanted know calculate dimensions frame,specifications motor propeller,the rating ESC's power rating batteries total no.s.I want direct answers procedure formulaes.I want lift aload around 20-30 kgs .Please feel free help.",quadcopter
7966,Orthogonal projection laserscanner data,"I recently discovered ROS-package: . Which basically exactly I need. However I using ROS, I need done package myself. Basically information I range measurement r angle theta every measurement point 360 degree laserscan + I orientation roll, pitch, yaw angles laserscanner. However yaw important could ignored. I really can't get head around project points ground plane. I mean easy measurement point align roll pitch axes, I don't know points :D One solution I thought this: Convert measurement point (r, theta) cartesian coordinates (x,y,z) - vector Use rotations matrices: create rotation matrix rotation around roll axis roll angle, adequately pitch axis. Multiplay bot matrices multiply (x,y,z) - vector. Now orthogonal projection measurement would (x,y,z) - vector z=0. Convert (x,y) - vector back polar coordinates (r, theta). However, especially step 2 complicated, rotation matrices change according sign roll pitch angles, right? I would like note absolute value role pitch angles always < 90°, unambiguity rotations.. Is easier (or maybe elegant) way solve problem? My guess is, problem must solved basically every robot application uses 2D-laserscanner fixed one axis. But I find solution anywhere. So I would glad anyone could point right direction. Kind regards",quadcopter slam
7968,What PID values keep,"I built quadcopter problem balancing. It doesnt goes up. I using PID techniqe balancing. But finding suitable values PID tuning. I using mpu6050 sensor. I get accelerometer values x axis find error them. That lets say accel x zero error cause zero balanced. I using +-2g sensitivity scale accelerometer. The motors using dji 920 kva. What values kp, ki kd set. I cant set flight cause completely balance. This design. Completely home made. I modified little photo. Accelerometer 2g balance z 32768/2 . There also questions, scale error pid output, error ranging 0 16380 2g setting, scaling 0 42. So divide error pid value?",quadcopter pid balance
7969,What erector sets function normal servo motors?,"I need basic erector set parts fit servo motors dc motors. Preferably $100. I've looked Minds-i basic set looks good except I don't know function servos without hot glue extensive modifications. If matters, I making bipedal robot I don't require wheels anything pre-built. I need basic set I add build whole bunch different robots.",mobile-robot rcservo
7970,Firmware upgrade iRobot Create 2,Is firmware upgrade available Create 2? I issues March using assigning University Tennessee programming project. We getting ready use (we 10 now) I'd like get updated latest firmware.,irobot-create
7972,Air hockey robot opponent,"I'm sure right place post goes. So, title states, I'm planning building desk doubles air hockey table robot side. The robot would mounted rail able go left right using linear actuator. It able ""attack"" puck using two servos. The real problem I detect puck's location? My idea: Since table would tiny holes corners every square(0.5inx0.5in), I could fit laser bottom part table, laser ever 1in 1inx1in square, location would reflected ""ceiling"" table instead laser diodes, would replaced ldr. So I'm planning matrix reading signals ldr's columns rows performing logic locate center puck. PROBLEMS: While I don't see performance flaws plan, I see tons flaws done imperfectly even tiniest bit. I exactly accurate regarding laser diode's position, center holes, right z-axis. This easy I'm going place 4 5. But I'm not. According estimations, I'm going use 300-700 laser diodes, depending I'm planning putting lasers opponent's side entire board. It would definitely costly. Imagine 300... This isn't really huge problem, like hassle. Wiring 300 these. Forget pcbs, project area large. I thought numerous way lessen these, like using color sensor get x-axis location laser situated negative x-axis pointing positive x-axis locate puck's location, I'm still comparing ideas. Advantages: I could get 3d-like graphical representation 3d-like controls (3d-like reality technically 2d since lasers plotted x axis though facing z-axis). Since project going room desk, situated automated room, I thinking making ""desk modes"" toggle game takes advantage lasers controls, A control desk room, ordinary desk mode, air hockey mode. My question: (More like request) Does anyone another idea regarding I able locate puck's x location accurately real time? EDIT: The table roll-able stored underneath loft bed under-area height 5'4"". Which means I can't go grande vertical solution. EDIT #2: Thanks helpful people here, I come conclusion using camera. The camera smartphone's, I'll create app tracks object color fixed size comparison identify distance robot puck. The phone process send signals via bluetooth. The phone anchored end robot's moving part camera reminiscent games first-person view. Incoming problems: I'm looking forward delay, given delay processing.",sensors microcontroller design electronics laser
7983,"Magnetic, low insertion force connector","I'm building robotic tea-maker/watchdog robot power problem. I would like able robot approach socket insert power cord cheap immersion heater (120V, 300W, see links below) turn heater on. However, power precision required plug wall beyond capabilities stepper motors/Arduino. My solution magnetic breakaway power cord like charger Mac higher voltage. Deep fat fryers suitable ones (120V, high power, see links below). However, problem I need sides connector, I find magnetic breakaway power cord, opposite side, would normally built deep fat fryer. I don't fancy buying whole fryer get one little part... Any ideas? Alternatives breakaway cord? Anyone know (cheap) 120V induction chargers? I'll resort mechanical on/off switch leave robot plugged I to, I hoping something bit sleeker. Links: Immersion heater Fryer cord",untagged
7992,How calculate vehicle detection distance,I would like know calculate distance car I run application autonomous vehicle real time. In addition I want know implement calculation C++. You see images know distance vehicle I don't know code I use make calculations every vehicle . Please check photo understand I'm trying achieve.,control sensors localization ros cameras
7993,Why two Series 1 XBees talk X-CTU?,I two Series 1 XBees won't transparent mode AT command mode I'm X-CTU. I asked help elsewhere one answer except telling flow control. The XBees configured properly MY DL settings. I'm thinking maybe I shorten timeout supposedly get AT command mode stay AT command mode. The time I get two Series 1 XBees talk X-CTU. I need two Series 1 XBees automatically transparent mode powered on.,wireless
7995,Ceiling depth monocular camera,"Having camera mounted robot looking upwards, I want estimate distance ceiling robot moves also position landmarks observed ceiling (lamps example). I know structure motion problem I confused implement it. This case much simpler case bundle adjustment intrinsic calibration camera existing, camera pose changes x directions, observed thing planar ceiling. Odometry might also available I would like start solving without. Do know libraries offer good simple API thing? preferably based levenberg-marquardt similar optimization algorithms taking two observations. (Python bindings would nice have)",cameras 3d-reconstruction
7997,Why can't buy continuous servos absolute positioning?,"I've looking parts beginners robotics kit (I teach museum) wondering servos. You buy continuous servos relative position encoders. But I can't find continuous rotation servos absolute position encoders. Do exist? If not, not? I understand forums don't like shopping questions, I suspect part doesn't exist I'd like understand why. Also, I understand servos use potentiometer position encoder don't turn 1 rotation, types encoders seem like would job. Thanks help!",servos quadrature-encoder
7998,Weave Weld Lincoln Electric Mig Robot,This simple question I can't seem find answer setting weave function exactly frequency (Hz) determine fast moves back forth? In words I raise frequency move quicker slower factors must I consider?,robotic-arm industrial-robot
8001,Add hardware reset button Create2,Is way add reset button Create2 would equivalent temporarily disconnecting battery?,irobot-create
8006,Quadcopter accelerating,"I project quadcopter. So use PID stabalizing it. I think going wrong adding pid output motors thrust. While motors thrust means acceleraTion. The reason previous statment quad static air(not goin below), time thrust enough cancel gravity, means thrust negative gravity, acceleration. So add pid output thrust acceleration motors, wrong. I add pid speed motors, visible. My quad stabalizing reason see this, adding pid acc, added speed(virtually). What do. Should derivate pid output add thrust? This drawing circuit. I giving current one esc whole circuit. Other esc's pwm wire connected circuit.",quadcopter pid
8008,Image Based Visual Servoing algorithm MATLAB,"I trying implement IBVS algorithm (the one explained Introduction here) MATLAB myself, I facing following problem : The algorithm seems work cases camera change orientation respect world frame.For example, I try make one vertex initial (almost) square go closer opposite vertex, algorithm work, seen following image The red x desired projections, blue circles initial ones green ones ones I get algorithm. Also errors exponentially dereasing should. What I wrong? I attaching MATLAB code fully runable. If anyone could take look, I would really grateful. I took code performing plotting. I hope readable now. Visual servoing performed least 4 target points, else problem unique solution. If willing help, I would suggest take look function check rotation matrix properly calculated, verify line ds = vc; euler_ode correct. The camera orientation expressed Euler angles according convention. Finally, one could check interaction matrix L properly calculated. function VisualServo() global A3D B3D C3D D3D A B C D Ad Bd Cd Dd %coordinates 4 points wrt camera frame A3D = [-0.2633;0.27547;0.8956]; B3D = [0.2863;-0.2749;0.8937]; C3D = [-0.2637;-0.2746;0.8977]; D3D = [0.2866;0.2751;0.8916]; %initial projections (computed show relation desired ones) A=A3D(1:2)/A3D(3); B=B3D(1:2)/B3D(3); C=C3D(1:2)/C3D(3); D=D3D(1:2)/D3D(3); %initial camera position orientation %orientation expressed Euler angles (X-Y-Z around inertial frame %of reference) cam=[0;0;0;0;0;0]; %desired projections Ad=A+[0.1;0]; Bd=B; Cd=C+[0.1;0]; Dd=D; t0 = 0; tf = 50; s0 = cam; %time step dt=0.01; = euler_ode(t0, tf, dt, s0); end function ts = euler_ode(t0,tf,dt,s0) global A3D B3D C3D D3D Ad Bd Cd Dd = s0; ts=[]; t=t0:dt:tf ts(end+1)=t; cam = s; % rotation matrix R_WCS_CCS R = calc_Rotation_matrix(cam(4),cam(5),cam(6)); r = cam(1:3); % 3D coordinates 4 points wrt NEW camera frame A3D_cam = R'*(A3D-r); B3D_cam = R'*(B3D-r); C3D_cam = R'*(C3D-r); D3D_cam = R'*(D3D-r); % NEW projections A=A3D_cam(1:2)/A3D_cam(3); B=B3D_cam(1:2)/B3D_cam(3); C=C3D_cam(1:2)/C3D_cam(3); D=D3D_cam(1:2)/D3D_cam(3); % computing L matrices L1 = L_matrix(A(1),A(2),A3D_cam(3)); L2 = L_matrix(B(1),B(2),B3D_cam(3)); L3 = L_matrix(C(1),C(2),C3D_cam(3)); L4 = L_matrix(D(1),D(2),D3D_cam(3)); L = [L1;L2;L3;L4]; %updating projection errors e = [A-Ad;B-Bd;C-Cd;D-Dd]; %compute camera velocity vc = -0.5*pinv(L)*e; %change camera position orientation ds = vc; %update camera position orientation = + ds*dt; end ts(end+1)=tf+dt; end function R = calc_Rotation_matrix(theta_x, theta_y, theta_z) Rx = [1 0 0; 0 cos(theta_x) -sin(theta_x); 0 sin(theta_x) cos(theta_x)]; Ry = [cos(theta_y) 0 sin(theta_y); 0 1 0; -sin(theta_y) 0 cos(theta_y)]; Rz = [cos(theta_z) -sin(theta_z) 0; sin(theta_z) cos(theta_z) 0; 0 0 1]; R = Rx*Ry*Rz; end function L = L_matrix(x,y,z) L = [-1/z,0,x/z,x*y,-(1+x^2),y; 0,-1/z,y/z,1+y^2,-x*y,-x]; end Cases work: A2=2*A; B2=2*B; C2=2*C; D2=2*D; A2=A+1; B2=B+1; C2=C+1; D2=D+1; A2=2*A+1; B2=2*B+1; C2=2*C+1; D2=2*D+1; Cases NOT work: Rotation 90 degrees zoom (zoom alone works, I better visualization) A2=2*D; B2=2*C; C2=2*A; D2=2*B;",control algorithm matlab visual-servoing
8014,Arduino mobile robot,Is way I control arduino robot anywhere world. The robot goes range home wifi wifi shield can't help. Is way make sure robot always Internet matter goes?,arduino mobile-robot raspberry-pi
8018,Complete Quadrotor Tutorial (Text)Book?,"I'm looking complete tutorial textbook build control quadrotor (dynamics, control, etc.). I'm engineer broad background programming, mechanics, control it's several years I'm rusty. I wondering anyone knew great ""from ground up"" tutorial quadrotors? I found book looks interesting thought I'd ask too. Thanks! EDIT So, assume I've taken formal course necessary topics: system modeling, mechanics, control theory, state estimation, programming, etc. I'm looking book assumes reader familiar topics also goes step-by-step. For example, instead stating ""here system equations"" I'm looking ""let's derive system equations"" (but assumes familiar modeling/kinematics). I'd like start quadcopter side project precious spare time I'd prefer single good reference instead jumping individual topic textbook; maybe I'm greedy :)",quadcopter
8019,indoor positioning system: better?,"Which method better, term accuracy, detection indoor localization drone. Camera based system wireless techniques like WLAN Bluetooth?",slam
8024,PID quaternion contoller,"I want control attitude(roll, pitch, yaw) vehicle capable pitching rolling. To I created quaternion PID controller. First I take current attitude vehicle converting quaternion Qc desired attitude quaternion Qd. I calculate input PID controller Qr = Qc' x Qd. The imaginary parts quaternions fed force requests roll, pitch, yaw axes vehicle. I test simulator control works becomes unstable cases (request R: 60 P: 60 Y:60). I also want work around singularities (i.e. pitch 90) Does anyone know I get behavior explain (thoroughly) I'm wrong?",control pid stability
8027,How sumarize Kalman filter covariances display?,"I'm implementing extended Kalman filter I'm facing problem showing covariances user. The covariance matrix estimate contains information current value estimate, much display. I would like single number says ""our estimate really good"" close 0 ""our estimate worth much"" large. My intuitive simple solution would average values covariance estimate matrix (or maybe diagonal), except case values different units different ranges. Is possible something like this?",kalman-filter
8028,What I need learn build robots,What subjects involved robotics. If I want build robots necessary things I need learn consecutively beginner.,artificial-intelligence embedded-systems first-robotics
8033,continuous vs discrete simulation robotics,"As far I know, robot sends orders discrete signals. However, isn't computer simulation based continuous simulation? Do know may happen important difference comparing reality simulation cases? I heard cable-driven robots quite sensitive.",control simulation
8038,Raspberry pi quadcopter drifts like crazy,"I recently built raspberry pi based quadcopter communicates tablet wifi. The problem drifts lot. At first I thought problem vibration, I mounted MPU-6050 securely frame. That seemed help bit, still drifts. I tried tuning PID, tuning complementary filter, installing real time OS. Nothing seems help much. Below code written completely java. Any suggestions appreciated. QuadServer.java: Sensor.java: package com.zachary.quadserver; import com.pi4j.io.gpio.GpioController; import com.pi4j.io.gpio.GpioFactory; import com.pi4j.io.gpio.GpioPinDigitalOutput; import com.pi4j.io.gpio.PinState; import com.pi4j.io.gpio.RaspiPin; import com.pi4j.io.i2c.*; import java.net.*; import java.io.*; public class Sensor { static I2CDevice sensor; static I2CBus bus; static byte[] accelData, gyroData; static long accelCalib[] = {0, 0, 0}; static long gyroCalib[] = {0, 0, 0}; static double gyroX; static double gyroY; static double gyroZ; static double smoothedGyroX; static double smoothedGyroY; static double smoothedGyroZ; static double accelX; static double accelY; static double accelZ; static double accelAngleX; static double accelAngleY; static double smoothedAccelAngleX; static double smoothedAccelAngleY; static double angleX; static double angleY; static double angleZ; static boolean init = true; static double accelSmoothing = 1; static double gyroSmoothing = 1; public Sensor() { try { bus = I2CFactory.getInstance(I2CBus.BUS_1); sensor = bus.getDevice(0x68); sensor.write(0x6B, (byte) 0x0); sensor.write(0x6C, (byte) 0x0); System.out.println(""Calibrating...""); calibrate(); Thread sensors = new Thread(){ public void run(){ try { readSensors(); } catch (IOException e) { e.printStackTrace(); } } }; sensors.start(); } catch (IOException e) { System.out.println(e.getMessage()); } } private static void readSensors() throws IOException { long time = System.currentTimeMillis(); long sendTime = System.currentTimeMillis(); (true) { accelData = new byte[6]; gyroData = new byte[6]; int r = sensor.read(0x3B, accelData, 0, 6); accelX = (((accelData[0] << 8)+accelData[1]-accelCalib[0])/16384.0)*9.8; accelY = (((accelData[2] << 8)+accelData[3]-accelCalib[1])/16384.0)*9.8; accelZ = ((((accelData[4] << 8)+accelData[5]-accelCalib[2])/16384.0)*9.8)+9.8; accelZ = 9.8-Math.abs(accelZ-9.8); double hypotX = Math.sqrt(Math.pow(accelX, 2)+Math.pow(accelZ, 2)); double hypotY = Math.sqrt(Math.pow(accelY, 2)+Math.pow(accelZ, 2)); accelAngleX = Math.toDegrees(Math.asin(accelY/hypotY)); accelAngleY = Math.toDegrees(Math.asin(accelX/hypotX)); //System.out.println(accelAngleX[0]+"" ""+accelAngleX[1]+"" ""+accelAngleX[2]+"" ""+accelAngleX[3]); //System.out.println(""accelX: "" + accelX+"" accelY: "" + accelY+"" accelZ: "" + accelZ); r = sensor.read(0x43, gyroData, 0, 6); gyroX = (((gyroData[0] << 8)+gyroData[1]-gyroCalib[0])/131.0); gyroY = (((gyroData[2] << 8)+gyroData[3]-gyroCalib[1])/131.0); gyroZ = (((gyroData[4] << 8)+gyroData[5]-gyroCalib[2])/131.0); if(init) { smoothedAccelAngleX = accelAngleX; smoothedAccelAngleY = accelAngleY; smoothedGyroX = gyroX; smoothedGyroY = gyroY; smoothedGyroZ = gyroZ; init = false; } else { smoothedAccelAngleX = smoothedAccelAngleX+(accelSmoothing*(accelAngleX-smoothedAccelAngleX)); smoothedAccelAngleY = smoothedAccelAngleY+(accelSmoothing*(accelAngleY-smoothedAccelAngleY)); smoothedGyroX = smoothedGyroX+(gyroSmoothing*(gyroX-smoothedGyroX)); smoothedGyroY = smoothedGyroY+(gyroSmoothing*(gyroY-smoothedGyroY)); smoothedGyroZ = smoothedGyroZ+(gyroSmoothing*(gyroZ-smoothedGyroZ)); /*smoothedAccelAngleX = accelAngleX; smoothedAccelAngleY = accelAngleY; smoothedGyroX = gyroX; smoothedGyroY = gyroY; smoothedGyroY = gyroY;*/ /*smoothedAccelAngleX += (accelAngleX-smoothedAccelAngleX)/accelSmoothing; smoothedAccelAngleY += (accelAngleY-smoothedAccelAngleY)/accelSmoothing; smoothedGyroX += (gyroX-smoothedGyroX)/gyroSmoothing; smoothedGyroY += (gyroY-smoothedGyroY)/gyroSmoothing; smoothedGyroZ += (gyroZ-smoothedGyroZ)/gyroSmoothing;*/ } angleX += smoothedGyroX*(System.currentTimeMillis()-time)/1000; angleY += smoothedGyroY*(System.currentTimeMillis()-time)/1000; angleZ += smoothedGyroZ; angleX = 0.95*angleX + 0.05*smoothedAccelAngleX; angleY = 0.95*angleY + 0.05*smoothedAccelAngleY; time = System.currentTimeMillis(); //System.out.println((int)angleX+"" ""+(int)angleY); //System.out.println((int)accelAngleX+"", ""+(int)accelAngleY); } } public static void calibrate() throws IOException { int i; for(i = 0; < 100; i++) { accelData = new byte[6]; gyroData = new byte[6]; int r = sensor.read(0x3B, accelData, 0, 6); accelCalib[0] += (accelData[0] << 8)+accelData[1]; accelCalib[1] += (accelData[2] << 8)+accelData[3]; accelCalib[2] += (accelData[4] << 8)+accelData[5]; r = sensor.read(0x43, gyroData, 0, 6); gyroCalib[0] += (gyroData[0] << 8)+gyroData[1]; gyroCalib[1] += (gyroData[2] << 8)+gyroData[3]; gyroCalib[2] += (gyroData[4] << 8)+gyroData[5]; try { Thread.sleep(1); } catch (Exception e){ e.printStackTrace(); } } gyroCalib[0] /= i; gyroCalib[1] /= i; gyroCalib[2] /= i; accelCalib[0] /= i; accelCalib[1] /= i; accelCalib[2] /= i; System.out.println(gyroCalib[0]+"", ""+gyroCalib[1]+"", ""+gyroCalib[2]); System.out.println(accelCalib[0]+"", ""+accelCalib[1]+"", ""+accelCalib[2]); } public double readAngle(int axis) { switch (axis) { case 0: return angleX; case 1: return angleY; case 2: return angleZ; } return 0; } public double readGyro(int axis) { switch (axis) { case 0: return smoothedGyroX; case 1: return smoothedGyroY; case 2: return smoothedGyroZ; } return 0; } public double readAccel(int axis) { switch (axis) { case 0: return accelX; case 1: return accelY; case 2: return accelZ; } return 0; } public double readAccelAngle(int axis) { switch (axis) { case 0: return smoothedAccelAngleX; case 1: return smoothedAccelAngleY; } return 0; } public void setSmoothing(double gyro, double accel) { gyroSmoothing = gyro; accelSmoothing = accel; } }",pid raspberry-pi quadcopter
8043,How convert classic modified DH parameters?,"I currently description 22 joint robot ""classic"" DH parameters. However, I would like ""modified"" parameters. Is conversion simple shifting $a$ $alpha$ columns parameter table one row? As imagine, 22 joints lot, I'd rather re-derive parameters I don't to. (Actually, classic parameters pulled OpenRave command: .",kinematics dh-parameters
8044,What best ways transmit force air efficiently?,"I taking part robotics competition, challenge create pair robots successfully navigate series obstacles. However, rules state two robots, one must driving actuator. The must somehow moved robot, WITHOUT PHYSICAL CONTACT. I could think either sails non-driving robot, moving fans driving one OR electromangnets driving one permanent magnets opposite polarity non-driving one. However problem efficiency falls drastically distance. Thus, I looking possible ways overcome problem. Thanks :) Also, driving robot cable power supply, non-driving one may batteries. Rulebook:",force
8045,composition rotation matrices,"I moment learning rotation matrices. It seems confusing could $R_A^C=R_A^BR_B^C$ rotation coordinate frame A C C A, A,B,C different coordinate frames. $R_A^C$ must 2x2 matrix defined $$ R_A^C= \left( \begin{matrix} xa⋅xb & xa⋅xb \\ ya⋅yb & ya⋅yb \end{matrix} \right) $$ $x_a, y_a x_b,y_b$ coordinates points given different coordinate frame. I don't see how, using standard, multiplication stated give matrix $R_A^C$. Some form clarification would helpful here.",frame
8047,"kp,ki,kd keep","program quadcopter, tune PID values, kp, ki kd. accelome 2g. Please point wrong program, error signal appropriate? Please also give help choose correct pid tuning. limitation I always connect arduino pc change kp ki kd values, remote control available currently.",quadcopter pid
8050,iRobot Create 2 serial battery power,"I don's seem able get battery power Create 2. I spliced original cable came with, tried use power red/purple(+) yellow/orange(-) power Raspberry Pi2, luck. While serial-to-USB cable still works, I able command robot via Python, seems power coming red/purple cables. I tried multimeter luck, even I moved device passive/safe/full modes. There power even Create 2 charging/docked.",raspberry-pi irobot-create serial roomba
8051,Maximum ball screw speeds,"What maximum rotational velocity miniature ball-screw (diameters 12mm) approximately 1000 thrust cycles, type/brand would be, speed limited ball return mechanism? The fastest I could find 4000 rpm 3000 N thrust, datasheet big safety margin (millions cycles). I'm looking either experience data, general method/formula used find maximum velocity (and load) function cycles way round (similar ball bearings). Suggestions knowledge faster types brands ballscrews ones I able find welcome well. Some background information: Ball screws interesting transmissions electrically actuated legged robotics, since provide high-geared rotary-to-linear transmission accurate, precise, energy efficient possibly backlash-free. However, big downside limited rotational speed. The maximum rotational velocity limited resonance ball return mechanism. The former limit easy calculate (eigenfrequency calculation), mostly problematic small spindles. However, latter bigger problem. The balls ball screw roll threaded spindle recirculated end nut. The recirculation limits rotational velocity ballscrews. The corresponding maximum rotational velocities calculate-able (for far I know) provided manufacturers catalogues, either directly rpm via so-called $D_n$-value, rotational velocity rpm $n=D_n/d$ diameter ball screw. But even then, maximum rotational velocity ball screws capped 4000 rpm lower according datasheets (depending brand ball return mechanism). The highest permissible rotational velocities I found Steinmeyer ballscrews, 4000 rpm, using end-cap-return mechanism. Note electrical motors (up 200W) ideal (maximum power) velocities higher 4000 rpm, even twice high many brushless motors. It appears however ball screws run higher speeds specified reality, specifications hold many millions cycles. I find single unofficial source someone claims run ball-screws 6000 rpm, missiles (one-time-use) 7500 rpm. I'm interested theory experimental data backs up.",driver
8053,How use Homogeneous transformation matrix?,"I trying understand use, requires compute homogenous transformation matrix. I know 2 points 2 different frames, 2 origins corresponding frames. I transformation matrix looks like, whats confusing compute (3x1) position vector matrix needs. As understand is, vector origin old frame compared new frame. But calculate it, obvious answer (I think) would subtract ($O_{new} - O_{old}$ ), feel right. I know simple question head cannot get around issue, prove right way, information know?",kinematics frame
8054,Motor DIY Remote controlled shades,I'm currently undertaking project build remote controlled shades scratch. I currently every piece figured except I don't know know much motors involved something like this. I looking suggestions type motor search for. I imagine I need type go forward back well stop shade fully retracted. I don't know search though. Any help much appreciated.,motor
8056,What factors consider selecting motor free wheeled cart-pole balancing robot?,"I'm developing small scale cart-pole balancing robot consisting two wheels driven single motor base (essentially like unicycle, two wheels constrain balance one dimensional problem). I'm sure qualities look motor. I think motor able accelerate quickly directions opposite motion dictated control system. However, i'm sure rapid acceleration correlate higher torque motors faster speed motors. I think higher torque motors would slow react control commands. In contrast, fast speed motors may able overcome momentum cart. Are design equations calculations make based robot's dimensions weight determine right specs needed robot's motor? How determine right motor specs application without resorting brute-force trial & error experiments?",motor design balance
8058,Optimal-time acceleration sequence line-following robot following moving obstacle,"Say line-following robot moving obstacle front, one-dimensional problem. The moving obstacle defined initial state sequence (longitudinal) acceleration changes (the acceleration function piecewise constant). Let's say robot controlled specifying sequence acceleration changes initial state. However, robot maximum minimum acceleration maximum minimum velocity. How I calculate sequence accelerations minimizing time robot needs reach goal. Note final velocity must necessarily zero. Can briefly explain problem addressed point references algorithm described? Or point closely related problems? Furthermore, solution depend goal position could robot brake late possible time (avoiding collisions) still reach goal optimal time? A formal problem description: Given position obstacle $x_B(t) = x_{B,0} + \int_{t_0}^t v_B(t) dt$, velocity obstacle $v_B(t) = v_{B,0} + \int_{t_0}^t a_B(t) dt$, $a_B$ known piecewise constant function: $$a_B(t) = \begin{cases} a_{B,1} & \text{for } t_0 \leq < t_1 \\ a_{B,2} & \text{for } t_1 \leq < t_2 \\ \dots & \\ \end{cases}$$ given initial state line-follower $x_{A,0}, v_{A,0} \in \mathbb{R}$ search piecewise constant functions $a_A$, $a_{min} \leq a_A(t) \leq a_{max}$, $v_{min} \leq v_A(t) \leq v_{max}$ $x_A(t) \leq x_B(t)$ (collision freeness) holds times. Reasonable assumptions e.g. $v_B(t) \geq 0$ $x_{B,0} \geq x_{A,0}$. Among feasible solutions I would like pick minimizing $\int_{t_0}^{\infty} x_B(t) - x_A(t) dt$ similar objective. Approximation algorithms also ok. Some numbers would like test input:",mobile-robot control motion-planning line-following
8062,IR 40kHz receiver,These days I'm trying build IR 40kHz long range receiver. I use ir phototransistor. I don't want use components like TSOP... I need make daylight filter intensify filtred signal sensor I wanna use microcontroller. Can someone help me? Any idea? Thanks.,sensors
8065,Solution INS GPS integration,"I GPS module IMU (gyro, accelerometer magnetometer) I need build autonomous navigation system quadcopter. It must know position time track predefined path. I know that, order improve precision, I need merge sensors data Kalman Filter (or technique matter, thing Kalman Filter way common according research). The problem I seriously stuck I know might something simple I don't seem find solution least answer basic questions. As start, I know get position accelerometer readings. I filters help eliminate noise minimize integration errors. I also GPS readings latitude longitude. The first question is, sensor fusion, I make measurements compatible? The latitude longitude GPS won't simply mix displacement given accelerometer, starting point this? Should I calculate displacement GPS readings I assume starting latitude longitude update accelerometer prior applying filter? I developed simple Kalman Filter I could plug new reading values obtain next estimate position two wheeled car. Now I two sources inputs. How I merge two together? Will filter two inputs I find function somehow get best estimate (average, maybe?) accelerometer GPS? I really lost here. Do guys examples code I could use learn? It really easy find articles full boxes arrows pointing direction data must flow really long equations start get confusing soon presented article: (I problems equations, seriously) I never seen real life example implementation. Any help topic would deeply appreciated. Thank much.",kalman-filter sensor-fusion gps
8077,Mobile Robot path reconstruction using IMU acceleration Yaw angle,"I hope help project. I'm using skid-steering wheeled mobile robot autonomous navigation I'd like find way able perform path reconstruction Matlab. By using robot encoders (installed robot) yaw rate information (which come accurate IMU sensor mounted robot frame), I successfully path reconstruction. (I'm using XBOW-300CC sensor) The problem I would like try reconstruct path using IMU yaw rate IMU acceleration values X Y axis. I'm able obtain velocity distance integrating two times IMU acceleration values problem I don't know use data. Do I use rotation matrix pass IMU frame robot frame coordinates? I'm asking I use rotation matrix encoder values come robot encoder. At moment, I use equations robot encoders IMU yaw rate: Do I still use R2 matrix? Thank lot",mobile-robot kinematics imu navigation matlab
8080,"Could anyone tell things Roomba robot clean them, please?","I'm really doubt whether proper ask question here, I'm apologizing not, I'll delete it. I Roomba robot worked three years, working producing strange sounds, I've decided clean thoroughly. But I disassembled point: I got stuck sort glass things (marked red rectangles picture). They really filthy inside I cannot figure clean them. Does anyone know one remove dust inside things? May Roomba creators here. Thanks advance.",roomba
8082,Wifi module Zumo robot,"I'm CS student trying implement clustering algorithm would work set robots indoor controlled environment. I'm still starting Robotics don't much experiencing figuring work together. My plan get 6 Zumo robots plug wifi module like Wifi shield. Then, I would use inter communication execute algorithm. My question: Can wifi module plugged would work? If not, I go achieving task. I see lots Arduino boards different names I'm sure works which, whether plugged in. Any help would appreciated.",arduino wifi
8087,Is safe give 5v 5v pin arduino uno r3 usb cable inserted,Is safe give 5v 5v pin arduino uno r3 USB cable inserted? I ESCs connected aren't likely start cases. The 5v gnd coming BEC circuit connected ESC. Please help me. Thanks,arduino esc
8094,What learning (control) algorithm inside Cubli?,"As video: In new version (did see learning part past versions), three four trials, Cubli learn balance new surface.",control
8096,How I control fast real time sensor (250Hz) slow system display(60Hz),"We experiments real time representation sensor position TV. In experiments, used sensors collect real time position 3D 250Hz TV Display sensor position 60Hz. Also, used MATLAB C++ programming OpenGL platform. In programming, Every iteration dat display TV, erase draw circle (Object, represent real time position display). In program I collect 60 points loose 190 points every second, becuase, I think refresh rate TV 60Hz. I gone thread ""How I control fast (200Hz) realtime system slow (30Hz) system?""(How I control fast (200Hz) realtime system slow (30Hz) system?), don't understand, How implement two loop 200Hz 30Hz. My Question is, How implement MATLAB/C++? So I store 250 data sensors well 60 points real time display TV. If help pseudo code, I appreciate help. Thank You advance. Please help me. P.S. Code",design communication matlab c++
8100,Robotic legs technologies,"robotic leg technologies available. i'm sorry basic question software developer looking get field robotics. particularly interested robotic legs similar used Boston Dynamics ATLAS robot. mechanism required allows move joints quickly. see videos many Boston Dynamics robots make engine sound (presumably uses engine), cant find details configuration used.",legged
8103,Overheating/Jamming MG996R servo,"I recently purchased first ever servo, cheap unbranded Chinese MG996R servo, £3.20 eBay. I using conjunction Arduino Servo shield (see below): As soon arrived, even plugging in, I unscrewed back ensured shorter PCB, rather full length PCB found MG995 servos. So, seems reasonable facsimile bona-fide MG996R. I read somewhere (shame I lost link) limited life, due resistive arc potentiometer wearing out. So, test durability, I uploaded following code Arduino, constantly sweeps 0° 180° back 0°, left running 10 15 minutes, order perform simple soak test. When I returned, servo making grinding noise longer sweeping, rather seemed stuck 0° position (or 180°). I picked servo whilst hot, certainly quite warm. A quick sniff also revealed hot, burning motor windings smell. After switching external power supply allowing cool, servo began work again. However, issue occurred little later. Again, allowing rest, upon re-powering, servo continues work. However, I reluctant continue soak test, I don’t really want burn motor out, yet. Is common “no-no” making servos sweep extreme extreme, one “play nice” perform 60° sweeps, cheapness servo issue here? I powering servo external bench supply, capable 3A, lack current issue. Please note I also follow question, Should MG996R Servo's extreme position change time?",arduino rcservo
8104,Should MG996R Servo's extreme position change time?,"This question follow previous question, Overheating/Jamming MG996 servo. I recently purchased first ever servo, cheap unbranded Chinese MG996R servo, £3.20 eBay. After mounting servo horn bracket, I realised I mounted horn tout fait 0° orientation, rather angle bracket servo side approximately 20°. However, switching servo couple times, time allowing servo perform, say, 10 sweeps time, I quickly noted servo’s extreme positions changing time, initial extremes extremes 5 cycles, changed 15°, now, 0° 180° bracket parallel body servo. I quite surprised this, I assumed 0° 180° positions would fixed, change time, vary time switched off. Seeing stop peg gear connected potentiometer inside, even possible?",rcservo
8106,2D Positioning mobile robot,"I starting explore idea I somewhat novice robotics. I looking position mobile robot accurately possible concrete slab. This would new construction building probably many walls vertical points reference. basic premise behind robot print floor plans straight slab. I access BIM (building information models, CAD, Revit) files building. I want robot position accurately possible blank slab using BIM files map. What would best avenue track adjust positioning robot open space slab? Low frequency, Lidar, wifi? Lastly sensors would best?",mobile-robot sensors localization
8107,Are systematic ways tune Kalman filter engineering practice?,"Including Q, R, initial states x P.",kalman-filter
8108,"How use specific ESC,BLDC motor Arduino Uno R3?","Attempt clean up: I'm trying use motor ESC Arduino Uno R3. Typically, I used PWM pins I use Arduino ESC, I can't control motor even I use servo library, I've also tried sample code different websites. The ESC beep I can't understand. Sometimes it's high-low-high high 4 seconds, I can't find anything Google. Sometimes motor spins periodically short time, I don't know why. Some sites recommend using flash bootloader, I'd prefer use Arduino PWM servo library. Original post Specific ESC Rctimer Mini ESC16A OPTO SimonK Firmware SN16A ESC.. I using ESC(Discussed above..) RCTimer 1806-1450KV Multi-Rotor BLDC Motor. Typically, I used PWM pins(3, 9, 10, 11-because similar Signal frequency) using Arduino-ESC.. but, I control BLDC Motor even used Servo library.. I've used usual websites example code. Just ESC unknowable beep .. sometime di-ri-di di(for 4 seconds).. I couldn't find way.. google (or country websites) Sometimes, The Motor spins(In certain value, periodically) short time I don't know The motor spins In google sites, using flash Bootloader, I'll use Arduino PWM Servo.. So.. Please! would please help me? Thank reading thread.",arduino brushless-motor esc pwm
8111,Multiple control loops overlapping effects,"I'm familiar using PID perform closed loop control single output single error signal well output achieving desired set-point. Suppose, however, multiple control loops, one output one error signal, loops fully independent. In particular, one loop increases actuator signal, changes impact output loops system. For concrete example, imagine voltage source series resistor, applying voltage across system six adjustable resistors parallel. We measure current resistor want control current resistor independently adjusting resistance. Of course, trick adjust one resistor's resistance, changes overall resistance parallel set, means changes voltage drop due divider voltage source's resistance hence changes current resistors. Now, clearly ideal model system, predict resistance use resistors simultaneously solving set linear equations. However, whole point closed loop control want correct various unknown errors/biases system deviate ideal model. The question then: what's good way implement closed loop control model kind cross-coupling?",control pid
8112,Do know get original iRobot Create?,"Does anyone know I get original iRobot Create? The company longer sells them. It 2 years ago sold. It white value physical design, large exposed deck mounting armatures. It preprogrammed operate different configurations, eg. spinning, figure 8, following outline wall, etc. I ongoing art project using model operation everyday, I eventually need replace new ones. To see video one projects go I currently working spinning motion.",irobot-create
8116,Covariance optimization,"I trying build map containing lamps landmarks. I drive around robot monocular camera looking ceiling. The first step detect edges observed rectangular lamp save position pixels also current position odometry robot. After lamp disappears field view, enough base-line 3D reconstruction based structure motion. Once reconstruction done uncertainty position lamps modelled covariance. Imagine robot driving while, position estimated odometry also relatively high incertitude, I integrate incertitudes together final covariance matrix position lamp? If I understand well would following covariances: noise camera Inaccurate camera calibration matrix inaccurate result optimization drift odometry My goal manually loop closure using example g2o (graph optimization) I think correct covariances needed point.",slam cameras 3d-reconstruction
8118,What sensors MCU VectorNav VN300 use internally?,"I'm hesitant open VectorNav VN300 see what's inside. Does anybody know underlying sensors uses? The accel, gyro, mag outputs low-noise compared ""high end"" 3-axis MEMs devices (ie Kionix KXR94, Maxim 21000, ST LIS3MDL). Everything fits small package I'm guessing they're using devices integrated axes ADC's, rather ""navigation grade"" devices tend analog, fewer three axes, enormous compared consumer-level MEMs. Likewise, automotive MEMs sensors (which mention using one web pages) tend single dual axis, necessarily less noisy consumer-grade sensors.",imu navigation
8120,Device generate screen tap response,"I extremely limited knowledge general topic robotics therefore question shot dark. Please let know topic unsuitable site. I interested creating device would generate touchscreen tap. In nutshell, I would like replicate touchscreen automated mouse functionality obtain software like AutoHotKey Windows. Since, without jailbreaking phone, software solution basically impossible, occurs one first components would physical device simulates tap. Do options component exist? I recognize philosophical implications creating device. I assuming entire conversation theoretical solely related hardware design. Thanks, Alex",automatic
8122,Powering robot 12V battery charged gas/petrol generator robot operating?,A designed robot perform tasks farms. But problem I'm sure best way supply continuous power robot. All motors rated 12V Arduino sensors work 5V less. Can I continuously charge 12V lead acid battery adapter (comes battery) plugged AC output generator robot operating? Do I worry overcharging battery? Or I use generator's DC output supply 12V 8.3Amp. Or suggestions? Some information adapter stated package: 1. Built-in over-charge protection device. 2. Built-in thermal protection device 3. Output: 6v/12v 2Amp This generator I have: This first robot quite big requires lot electrical/electronic knowledge power it. I lot experience field. So feedback greatly appreciated.,electronics power battery
8124,Two exclusive inputs control,I system two inputs (throttle brake) one output (speed). How one design controller way two outputs controller (throttle brake) never greater zero (so doesn't accelerate brake simultaneously)? Thanks,control automation
8127,Can connect arduino usb laptop arduino started,"I sensors attached arduino uno r3 esc. I start Motor attached esc ardiuno usb connected laptop. It starts correctly. There must start arduino non usb supply esc correctly started, means motor doesnt start usb connected pc. Now get sensor values laptop. If connect usb pc starting motor, work.",arduino esc
8128,How calculate current consumed brushless motor quadcopter,"I want create virtual quadcopter model, I struggling come satisfying model brushless motors & props. Let's take example, based great eCalc tool: Let's say I want know much current consumed motor hovering state. I know mass quad (1500g), I easily compute thrust produced motor: Thrust produced moving mass air average speed V: Thrust = 0.5 * rho * A * V² Where rho (air density) 1.225kg/m3 A (propeller disk area) PI * Radius² = 0.073m² (12"" props). So I compute V: V = sqrt(Thrust / 0.5 / rho / A) = 9.07 m/s All right, I calculate aerodynamic power created propeller: P = Thrust * V = 3.68 * 9.07 = 33.4 W All right, I calculate mechanical power actually produced motor. I use PConst efficiency term eCalc: Pmec = Paero * PConst = 33.4 * 1.18 = 39.4W Here, eCalc predicts 37.2W. It's far number, I imagine use sophisticated hypotheses... Fair enough. From post, I know power also equal to: Pmec = (Vin - Rm * Iin) * (Iin - Io) Where I know Rm (0.08 Ohms) Io (0.9 A). So, finally, question: How calculate Vin Iin here? Of course, I knew rotation speed engine I could get Vin from: n = Kv * Vin Where Kv = 680 rpm/V. But unfortunately I don't know rotation speed... (Note Vin assumed averaged pulse-width-modulated output produced ESC) Thanks help!",motor quadcopter brushless-motor electronics power
8129,Why bipedal robots difficult?,"Not sure asked, lots simulations bipedal locomotion algorithms online, evolutionary algorithms converge good solutions. So seems algorithm part bipedal locomotion well-understood. If well simulations, able well real world. You model delay noise, model servo's response curve. What I don't understand still difficult make walking robot? Even robot like Big Dog rare.",walk
8130,Line following robot path planning,"I built mobile robot several ultrasonic sensors detect obstacles infrared sensor track line path. I written simple algorithm follow line works fine, avoiding obstacles problem robot doesn't know layout path, even move around obstacle, guaranteed find path line again(unless line perfectly straight). Therefore, I think I may need use path/motion planning algorithm find way store layout path robot could predict move get back path line keep following overcoming obstacle. I would like hear suggestions types algorithms I focus specific problem. Picture might help specifying problem I'm facing. Thank you.",motion-planning
8133,"""Ambiguous scale"" , Explanation required","I reading ""Computer Vision: Models, Learning, Inference"" author writes several points (like page 428-429) although matrix A seems 'n' degree freedom since ambiguous scale 'n-1' degree freedom? Can anyone explain thing means? Why one degree freedom decreased?",computer-vision
8134,Interferences using two ToF cameras,"Im using two time-of-flight (ToF) cameras, DS325 SoftKinetic Creative Senz3D, time DepthSense-SDK Point-Cloud-Library (on Ubuntu 15.04). But I got strong interferences. Is possibility control laser (software side) either send light special frequency turn alternating? Or another way get rid interferences?",cameras laser 3d-reconstruction 3d-model
8140,"""Thermal Imaging"" Arduino and/or Lego Mindstorm NXT 2.0?","I'm trying build robot sent rooms/buildings detect people using nxt and/or Arduino. In addition I would like able view robot ""seeing"" real-time PC infrared image. The sensors I've shortlisted are: Thermal Infrared NXT Sensor Dexter industries - £44 RoBoard RM-G212 16X4 Thermal Array Sensor - £94 Omron D6T MEMS Thermal IR Sensor - £31 I believe RoBoard Omron sensors capable thermography, I wondering anyone experience sensors give advice. I also thinking using idea project: . In case I'd use data read sensor plot graph showing different temperatures.",mobile-robot sensors nxt
8142,High-traction thin tires vs Wide moderate-traction tires? [Sumo-bot],"I building sumo-bot competitors thin sticky tires, wider less sticky tires. The diameter same, gearbox/motor same. Who win? PS: Sticky tires: & wide tires: Thanks!",movement wheel two-wheeled
8144,Using DC motor generator recharge battery robot,"I trying recharge 12V lead acid battery 12V DC motor. I using battery power robot climbs. When descends, I notice I dont need apply reverse voltage dc motor backdrives instead. This act generator recharge back battery, I right? I know need step low voltage generated backdriven motor 12V needed recharge battery. This board I think job: Is I need make work? With method, I concerned 3 stages battery charging: bulk, absorption float? Please advise. Any feedbacks greatly appreciated.",mobile-robot battery
8146,Using SLAM create 2D topography,"I small mobile robot LidarLite laser range finder attached servo. As I range finder side-sweeping 30 degree arc, taking continuous distance readings side robot (perpendicular robots forward motion). My goal robot drive roughly parallel wall, side-scanning entire time, create 2D map wall moving past. The 2D topography map created post processing (I use R much data processing, I don't know popular kind work). From I know it, SLAM sounds like great tool I want do. But I two issues: 1: I know robot consistent speed, I way predict measure speed robot. So I way estimate odometry robot. 2: The robot also move closer wall proceeds it's path. So I depend steady plane travel robot. So given I don't odometry data, realtive distance wall changes course run, possible use SLAM create 2D maps? I'm looking stitching algorithms used applications, handle variances relative distance, I hoping SLAM algorithm could use here.",slam servos laser rangefinder
8150,Sensor orientation external magnetometer,"On many drones already external magnetometers. Unfortunately, orientation sensors sometimes unknown. E.g. sensor tilted 180° (pitch/roll) X° yaw. I wondering, whether one could calculate rotation sensor relative vehicle application accelerometer gyrometer? Theoretically, accelerometer yields vector used calculation coordinate system. The discrepancy magnetometer gyrometer then, may used calculation correct orientation compass. Later compass used yaw calculation. Below starting orientation sensors (just example, orientation compass anything). Does someone know good way figure rotation compass?",magnetometer orientation
8152,"How Should I tie My quadcopter thing, adjust pid one axis","I stuck adjusting PID quadcopter, I cant adjust fly get control. I adjusting attaching quadcopter something. Is method correct. Will pid values required different fly same. Please suggest attach quad thing.",quadcopter pid balance
8153,Can someone explaine code?,,c++
8160,Implement vocal interface arducopter,"I'm student working robotics project, I'm complete beginner robotics. I'm working ArduCopter structure, using ArduPilot Mega associated Ardupilot IMU autopilot board. I EasyVR module Arduino UNO vocal recognition stuff. I don't know give order autopilot board vocal module. Do I need change ArduCopter source code? Do I use Mission Planner software? The final aim this.",arduino quadcopter ardupilot
8162,When use multiple batteries vs UBEC,"When use multiple separate batteries vs single battery multiple UBECs? I'm trying design power system small 2-wheeled robot. Aside 2 main drive motors, also power Arduino, Raspberry Pi couple small servos actuate sensors. motors rated 6V peak stall current 2.2A Arduino uses 5V@100mA Raspberry Pi uses 5V@700mA servos use 6V peak stall current 1.2A. So theoretical max current draw would = 7.6A. Originally I planning use three separate Lipo batteries: one 12V using step-down converter power main drive motors 6V@4.4A peak two 3.7V lipos step-up converter (rated 5v@3A) handle servos logic separately Then I discovered UBECs, sound good true, seem cheap (<$10) efficient (>90%) able handle exact volt/current requirements. Should I instead use single high-current 12V lipo three UBECs independently power drive motors, sensor motors logic? Or still suffer brown-out power irregularities motor draws much current? What I missing?",battery bec
8165,what's confidence level? use vehicle detection using OpenCV?,"I'm working project Autonomous vehicle, want know what's confidence level means use confidence level vehicle detection OpenCV ?",opencv statistics
8168,How much offset speed motors axis required adjusting pid,"For adjusting pid quadcopter, much speed motors required adjusting pid. Do need give much offset speed cancels weight? I sure cant start adjusting pid zero speed motors initially.",quadcopter pid
8171,Robot arm reachability pose Cartesian space,"Given set robot joint angles (i.e. 7DoF) $\textbf{q} = [q_1, ... , q_n]$ one calculate resulting end-effector pose (denoted $\textbf{x}_\text{EEF}$), using foward kinematic map. Let's consider vice-versa problem now, calculating possible joint configurations $\textbf{q}_i$ desired end-effector pose $\textbf{x}_\text{EEF,des}$. The inverse kinematics could potentially yield infinitely many solutions (and comes I interested in) solution (meaning pose reachable robot). Is mathematical method distinguish whether pose Cartesian space reachable? (Maybe rank Jacobian) Furthermore still find reachability test case certain joint angle limitations?",mobile-robot robotic-arm kinematics inverse-kinematics jacobian
8181,Can digital servo motors modified continuous rotation?,"In autonomous mobile robot, we're planning using digital servo motors drive wheels. Servo motors usually don't rotate continuously. However, modified based many tutorials online mention modifying [analog] servo motors. My question is, method(s) ones used modify digital servo motors? Thanks",mobile-robot rcservo
8182,image processing,"I making Robot goalie, robot supposed detect whether ball thrown direction , sense direction ball stop entering goal post. A webcam mounted top goal post. The robot required move horizontally (left right), shouldn't move forwards backwards. The robot wheels, image processing performed raspberry pi send required information micro controller responsible moving robot required direction(using servo motors). Which image processing algorithm best implement scenario?",mobile-robot computer-vision algorithm beagle-bone first-robotics
8184,What difference CNC router versus CNC mill?,"People RepRap 3d-printing project often mention CNC routers CNC mills. Both kinds machines almost always motorized spindle stepper motors move spindle X, Y, Z directions. What difference CNC router versus CNC mill? (Is better place sort question -- perhaps Woodworking Stack Exchange?)",industrial-robot
8186,Robot wire follower + position wire,"I'm designing lawn mower robot, I perimeter stage. The electronic part done, works quite good, comes software. I need advice deal problem line following. I mean, robot line, parallel line, that's relatively easy. But manage situation robot driving around approaches line (wire)? I two sensors, left right, turned 45° respect forward direction. The robot could arrive angle, signal amplitude read sensor could completely random.. So I don't understand order move right position wire... What's usual approach? The idea here: The wire around yard. mower 2 sensors, left right, sense signal emitted wire, square wave signal 34 KHz. The signal amplitude read sensors mower 2 V it's wire.",line-following magnetometer
8187,Is simpler way ROS 5 DOF Dynamixel arm control,"I 5 6 DOF arm build Dynamixel HerculeX smart servos. I need move gripper along Cartesian trajectory, I calculate C++ application. I looked ROS, learning curve pretty steep looks like major overkill use case. I don't need distributed system complexity brings. Preferably, I would like call standalone C++ library libraries get arm actuated. What options? What limitations using full blown robotics framework like ROS YARP case. EDIT Here I would like code it: The last line spread several library function calls intermediate data structures, needed. The end result gripper physically following Cartesian trajectory given way_points way_poses.",robotic-arm ros motion-planning c++
8188,How I avoid Roomba Error 10 Code?,"I trying run 600 series Roomba large, open space (1700+sf) recognize large, open space throws Error 10 code. It recognize edge 2 12""-3"" either; fall edge become stuck. Any suggestions?",mobile-robot irobot-create roomba
8191,rotation matrix euler angles gimbal lock,"How determine angle negate gimbal lock occurs. As i've understood gimbal lock remove one degree freedom, determine degree removed value R[1][3] rotation matrix (size 3x3) value 1. Is Roll, Pitch yaw taken equation?",motion-planning
8194,Choosing motors quadcopter frame,I bought drone frame : q450 glass fiber quadcopter frame 450mm I'm considering buying 4 AX-4005-650kv Brushless Quadcopter Motor's Will motor's fit frame ? How I determine motor's fit frame ?,quadcopter
8196,Camera Calibration fails run ROS,"I running ROS Indigo Ubuntu 14.04. I mono-camera calibration trying follow camera calibration tutorial ROS Wiki. I give following command: rosrun camera_calibration cameracalibrator.py --size 8x6 --square 0.108 image:=/my_camera/image camera:=/my_camera I get following error: ImportError: numpy.core.multiarray failed import Traceback (most recent call last): File ""/opt/ros/indigo/lib/camera_calibration/cameracalibrator.py"", line 47, import cv2 ImportError: numpy.core.multiarray failed import I thought updating rosdep update difference. What possible way solve problem? UPDATE: I uninstalled reinstalled ROS completely scratch. I still get error. Should I look somewhere outside ROS?",ros cameras calibration
8199,Wires columns contract passing electricity,"Background: Introductory robotics competition college freshmen; Bot open 8 jars (with two balls them) ten minutes load balls shooting mechanism. So, project hit upon challenge jar opening like originally intended to. So decided get rack-pinion mechanism use unscrewing lid. However, large unable fit bot required dimensions The actual question: Are wires rigid columns/things contract ~1 cm electricity passed it? And would price range be? Our budget also list constraints bot Edit: We include wire length <1m column length <30 cm. Also, wire needs contract 7mm",mechanism
8202,EKF-SLAM: Shrink covariance matrix one direction,"I implemented EKF mobile robot (x,y,theta coordinates), I've problem. When I detect landmark, I would like correct estimate defined direction. As example, robot travelling plane, meets landmark orientation 0 degrees, I want correct position estimate direction perpendicular landmark (i.e. 90 degrees). This I'm position estimate: I update x_posterior normal case, store x_temp. I calculate error x_temp - x_prior. I project error vector direction perpendicular landmark. I add projected quantity x_prior. This working quite well, I covariance matrix? Basically, I want shrink covariance direction perpendicular landmark. Thank help.",mobile-robot slam kalman-filter ekf
8204,velocity end-effector,The joint velocities constant equal $\dot{\theta}_{2}$ = 1 $\dot{\theta}_{1}$ = 1. How Compute velocity end-effector $\theta_{2} =\pi/2$ $\theta_{1} = \pi/6$,robotic-arm
8207,Quadcopter stability vs (PID error signal lag sample time),"The question I asking that, effect stability increasing decreasing sample time lagging error signal PID. Does helps stability degrade it?",quadcopter pid stability
8209,Two DC motors single output?,"I saw one old industrial robot(Year 1988) end effector 2 DC motor roll drive. After roll drive, yaw pitch drives connected dc motors separately. But roll drive two DC motors. Why used like this? single higher torque. All roll, pitch yaw motors spec. Total 4 DC motors. Two DC motor connected single shaft using gears roll.",industrial-robot
8212,UWSim Pressure Sensor Units,"I attempting use data Underwater Simulator (UWSim) provides ROS interface simulate number sensors running physical aquatic robot. One sensors detects current depth robot so, I want simulate data provided UWSim simulated pressure sensor. The Problem nowhere UWSim wiki source code I find reference units UWSim uses measure pressure. That said, units UWSim use measure pressure? Additionally, I would appreciate general information units UWSim uses data provided it's virtual sensors.",ros simulation underwater
8213,Balancing Robot Control Model,"I trying find control model system balancing robot. The purpose project control $\theta_2$ 2 motors wheels i.e. torque $τ$ I started dynamic equations went find transfer function. Then I find PID gains control robot keep balanced optimum response. For time I interested finding transfer function dynamic model only. Here example: However, I sure result.Here free body diagrams wheels inverted pendulum (robot body) calculations below: Dynamic Equations: $$ \begin{array}{lcr} m_1 \ddot{x}_1 = F_r - F_{12} & \rightarrow & (1)& \\ m_2 \ddot{x}_2 = F_{12} & \rightarrow & (2) &\\ J_1 \ddot{\theta}_1 = F_r r - \tau & \rightarrow & (3) &\\ J_2 \ddot{\theta}_2 = \tau - mgl\theta & \rightarrow & (4) & \mbox{(linearized pendulum)}\\ \end{array} $$ Kinematics: $$ x_1 = r\theta_1 \\ x_2 = r\theta_1 + l\theta_2 \\ $$ Equating (1) (3): $$ m_1 \ddot{x}_1 + F_{12} = F_r \\ \frac{J_1 \ddot{\theta}_1}{r} + \frac{\tau}{r} = F_r $$ Yields: $$ \frac{J_1 \ddot{\theta}_1}{r} - m_1 \ddot{x}_1 + \frac{\tau}{r} = F_{12} \rightarrow (5) $$ Equating (5) (2): $$ \frac{J_1 \ddot{\theta}_1}{r} - m_1 \ddot{x}_1 + \frac{\tau}{r} - m_2 \ddot{x}_2 = 0 \rightarrow (6) \\ $$ Using Kinematic equations (6): $$ (J_1 - m_1 r^2 - m_2 r^2) \ddot{\theta}_1 + m_2 l r \ddot{\theta}_2 = -\tau \rightarrow (7) \\ $$ Equating (7) (4): $$ \begin{array}{ccc} \underbrace{(J_1 - m_1 r^2 - m_2 r^2) }\ddot{\theta}_1 &+& \underbrace{(m_2 l r + J_2 ) }\ddot{\theta}_2 &+& \underbrace{m_2 gl}\theta &= 0 \rightarrow (8) \\ A & &B & & C & \\ \end{array} $$ Using Laplace transform finding transfer function: $$ \frac{\theta_1}{\theta_2} = -\frac{Bs^2 + C}{As^2} \\ $$ Substituting transfer function equation (7): $$ (J_1 - m_1 r^2 - m_2 r^2) \frac{\theta_1}{\theta_2}\theta_2 s^2 + m_2 lr\theta_2 s^2 = -\tau \\ $$ Yields: $$ \frac{θ_2}{τ} = \frac{-1}{(mlr-B) s^2+C} $$ Simplifying: $$ \frac{θ_2}{τ}= \frac{1}{J_2 s^2-m_2 gl} $$ Comments: -This expresses pendulum without wheel i.e. dependent pendulums properties. -Poles real verify instability.",arduino control pid wheeled-robot
8220,Balancing plate IMU offset center,I recently bought IMU . I new this. My question: Does positioning IMU matter? Are differences placing center plate offset center? I still learning topic. So help would greatly appreciated. Thanks.,control sensors imu sensor-fusion
8222,3D Angular velocity 3D velocity predict next state,"I sensor gives R, Theta, Phi (Range, Azimuth Elevation) As such: I need predict next state object given roll, pitch yaw angular velocities given information. But math really confusing me. So far I've gotten this: worked trigonometry, far seems predict pitching x axis yawing axis (sorry use camera axis) But dont know involve roll (AngularZVel)",kalman-filter
8223,Determining pose ar_track_alvar message ROS,"I using ar_track_alvar package Indigo detect AR Tags determine respective poses. I able run tracker successfully I visualize markers RViz. I give following command print pose values rostopic echo /ar_pose_marker I get following output indicating poses determined. Now I want use poses another ROS node hence I need subscribe appropriate ROS message('ar_pose_marker""). But I unable get enough information web header files functions use order extract data published message. It would great somebody point reference implementation documentation handling messages. It might useful note ar_track_alvar ROS wrapper hence people used ALVAR outside ROSmay also give inputs. UPDATE: I tried write code task suggested @Ben comments I get error. The code follows #include <ros/ros.h> #include <ar_track_alvar_msgs/AlvarMarker.h> #include <tf/tf.h> #include <tf/transform_datatypes.h> void printPose(const ar_track_alvar_msgs::AlvarMarker::ConstPtr& msg) { tf::Pose marker_pose_in_camera_; marker_pose_in_camera_.setOrigin(tf::Vector3(msg.pose.pose.position.x, msg.pose.pose.position.y, msg.pose.pose.position.z)); } int main(int argc, char **argv) { ros::init(argc, argv, ""pose_subscriber""); ros::NodeHandle nh; ros::Subscriber pose_sub = nh.subscribe(""ar_pose_marker"", 1000, printPose); ros::spin(); return 0; } And I get following error /home/karthik/ws_ros/src/auto_land/src/pose_subscriber.cpp: In function ‘void printPose(const ConstPtr&)’: /home/karthik/ws_ros/src/auto_land/src/pose_subscriber.cpp:17:53: error: ‘const ConstPtr’ member named ‘pose’ marker_pose_in_camera_.setOrigin(tf::Vector3(msg.pose.pose)); ^ make[2]: *** [auto_land/CMakeFiles/pose_subscriber.dir/src/pose_subscriber.cpp.o] Error 1 make[1]: *** [auto_land/CMakeFiles/pose_subscriber.dir/all] Error 2 make: *** [all] Error 2 Any suggestions?",ros pose
8225,choice camera sensor used LiDAR,I research autonomous car looking sensor used along LiDAR laser scanner. Ladybug could good option cost!! expensive. Could please suggest options camera sensors good FOV cost around $1000. Thank much!! -CHIANG CHEN,computer-vision
8226,How would I replicate tank/zero-turn steering system small robotic vehicle?,"I'm working project requires build small vehicle (footprint ~ 14 x 14 inches, less 6.5 pounds) traverse sand. For steering system, I thinking replicating way tanks lawn mowers navigate (ability zero-point turns), I want four wheels instead tracks like tank. I need help implementing idea. My preliminary thoughts two motors motor power wheels one side vehicle (I think would require gearing system) motor power individual wheel I'd rather avoid.",mobile-robot motor wheeled-robot
8228,Quad Copter flight module replace smart phone?,"I want replace flight module smart phone sensors required, like gyroscope, magnetometer, etc. Is possible? I using Google Nexus 4 Android (OS model 5.1). I control using another mobile, I able write app, Arduino acting bridge smartphone copter. I using flight controller OpenPilot CC3D CopterControl.",arduino quadcopter
8229,4dof 5dof robot arm stepper motors tool-chain hobbyist,"In past I built simple robot arms home, using RC servo motors stepper motors (till 3dof). I would like build new arm 4dof 5dof steppers. Until I used Arduino A4988 stepper drivers Gcode. For calculating inverse kinematics real time 4dof 5dof I think Arduino enough powerful. So I'm searching new tool-chain Gcode Interpreter + inverse kinematics calculation + stepper controller. I see LinuxCNC + beaglebone black + cnc cape. Not expensive hobbyist. But possibility I found. There possibilities hobbyist implement 4dof 5dof robot arm working stepper motors?",stepper-motor arm
8231,quadcopter settling time large,"quadcopter's settling time large, sets setpoint large amount time, covered large distance. But settle point, gives jerk push returns settle normal duration. doesnt shoots(little). The problem settling time move stick front back takes huge amount time. could wrong. tried giving P value I value PID overshoots get unstable. This PID program. PID values given. I read 6 channels remote using command pulsein(). guess taking upto 20ms per command. pidy added subtracted esc speeds respectively.",arduino quadcopter pid
8234,For quadcopter: Premade flight controller custom made?,"I'm interested building quadcopter. The result I'd like obtain autonomous drone. I'd interested GPS allow remain stationary air, also fly checkpoints. Can done flight controller, need programmed? I'm sure flight controllers really are. Could someone offer materials help get towards goal. Thanks, Jacob",arduino quadcopter
8239,Embedded frame grabber machine vision fusion,"Looking find solution save stills three cameras. Communication protocol camera link Gige, looking lightweight solution save stills (don't require video) system tested multirotor application. Frames saved every 3 seconds don't require lot bandwidth. We don't require anything frames store them. Thanks",sensor-fusion uav embedded-systems
8241,Linear actuators cartesian robots,"I would like make Cartesian robot maximum speed $1ms^{-1}$ x/y plane, acceleration $2ms^{-2}$ accuracy least 0.1mm. Expected loads: 3kg Y axis, 4kg X axis. Expected reliability: 5000 work hours. From I seen 3D printers, belt drive seems precise enough (too much backlash), screw drive rather slow. What types linear actuators available? What used commercial grade robots, i.e.",actuator industrial-robot cnc
8244,How connect ethernet based Hokuyo scanner?,"This basic beginner question, I know, I trouble connecting Hokuyo UST-10LX sensor haven't really found much terms helpful documentation online. I tried connecting Hokuyo UST-10LX directly ethernet port Lubuntu 15.04 machine. The default settings Hokuyo UST-10LX apparently: ip addr: 192.168.0.10 netmask: 255.255.255.0 gateway: 192.168.0.1 So, I tried going network manager setting IPv4 settings manually, ip addr 192.168.0.9, netmask 255.255.255.0, gateway 192.168.0.1. I also route set settings scanner. I go terminal run: get output: [ERROR] [1444754011.353035050]: [setParam] Failed contact master [localhost:11311]. Retrying... How might I fix this? I figure it's simple misunderstanding end, searching I couldn't find anything get running :( Thank help! :) EDIT: HighVoltage pointed I wasn't running roscore indeed case. I actually running problems I still roscore up, I tried again, output rosrun command: [ERROR] [1444828808.364581810]: Error connecting Hokuyo: Could open network Hokuyo: 192.168.0.10:10940 could open ethernet port. Thanks again!",sensors ros rangefinder linux
8245,Aligning datasets drift,"I dataset contains position information tracking robot environment. The position data comes accurate optical tracking system (Vicon similar) IMU. I need compare position data (either integrating IMU differentiating optical tracking data). The main problem systems different reference frames, order compare I first need align reference frames. I found several solutions; general problem aligning two datasets seems called ""the absolute orientation problem"". My concern I use methods I get rotation translation aligns datasets minimizing error whole dataset, means also compensate extent IMU's drift. But I especially interested getting feeling much IMU drifts, solution seem applicable. Anyone pointer solve absolute orientation problem want correct drift? Thanks",sensors localization imu calibration
8247,Angular velocities rotation matrices,"Let us assume I object O axis $x_{O}$, $y_{O}$, $z_{O}$, different orientation global frame S $x_{S}$, $y_{S}$, $z_{S}$ (I don't care position). Now I know 3 instantaneous angular velocities object O respect O frame, $\omega_O^O = [\omega_{Ox}^O \omega_{Oy}^O \omega_{Oz}^O]$. How I obtain angular velocity respect global frame (that $\omega_O^S$)? Thank you!",mobile-robot imu gyroscope
8250,Gyro measurement absolute angles,"Let us assume gyro perfectly aligned global frame ($X,Y,Z$). From I know gyro data give angular rate respect gyro axis ($x,y,z$). So let's say I got $\omega_x,\omega_y,\omega_z$. Since I know 2 frames perfectly aligned I perform following operations: $\theta_X = dt * \omega_x$ $\theta_Y = dt * \omega_y$ $\theta_Z = dt * \omega_z$ $\theta_X$ rotation angle around $X$ on. My question is: update like following steps? Because time measurement I get directly related global frame (rotated respect gyro frame). Thank you!",imu gyroscope frame
8255,Accurate Wheeled Robot Odometry,"I'm looking ""good"" algorithm/model wheeled odometry estimation. We encoders two back wheels tricycle robot, IMU controller board. Currently use MEMS gyro angular velocity estimation encoders linear velocity, integrate get pose. But it's hard calibrate gyro properly drifts (due temperature imperfect initial calibration). How improve pose estimation? Should consider model incorporates encoders gyro heading estimation? Model slippage, sensor noise? Is nice standard model? Or use more/better gyro? Not considering visual odometry.",kalman-filter wheeled-robot odometry
8261,"Robotic arm [""FAiL""] error display. - Festo / Mitsubishi Melfa RV-2AJ (Controller CR1-571)","To avoid wasting time question, might want react knowledge industrial robotic arms specific. Common troubleshooting unlikely fix problem could take much time. We've started project Mitsubishi Melfa RV-2AJ robotic arm. Everything went fine moment replaced batteries. The controller displays: ""FAiL"" respond buttons commands sent serial connection. We replace batteries robot controller. As took time get batteries delivered, we've left robot (and controller) withouth power weekend. (Which might caused problem) Is anyone knowledge Mitsubishi Robotic arms around here? I'm kinda hoping would common problem/mistake anyone experience subject would know it?",robotic-arm
8262,Real-time video processing video feed drone's camera,"I working project I want run computer vision algorithms (e.g. face recognition) live video stream coming flying drone. There many commercial drones offer video streams, like etc.. But none seem give access video feed real-time processing. Another idea drone carry smartphone, processing phone phone's camera. Or use digital camera arduino attached drone. Although ideas feasible, I would rather access video-feed drone itself. So question drones offer feature? hacked somehow achieve this?",computer-vision cameras
8271,DC Motors ROV?,"I planning build homemade ROV, I wanted know couple things motors. First is: Will Ok, I use brushed DC motor, instead brushless motor, major disadvantages ? Second : What RPM DC motor I aim ? High RPM low RPM ? Will 600rpm enough ? The specific motor I talking Will good motor propellers ROV. I planning 4 motors / propellers. Two upward downward thrusting, 2 forward side thrusting. The propellers I plan use, basic plastic 3 blade propellers, diameter, 40mm 50mm. My main question is, RPM torque I aim choosing DC motor ?",motor
8272,"ROS MoveIt!, virtual joints, planar joints, prismatic joints","I robotic application, 7Dof robot arm mounted omnidirectional mobile platform. My overall goal get MoveIt! calculate sequence joint movements, robot EEF reaches desired goal Cartesian space. In order combine robot platform world, MoveIt! setup assistant lets assign virtual joints ""footprint"" platform world placed in. I two strategies. Either select planar joint virtual joint. (What degrees freedom respectively joint information I gather joint) select fixed joint add (prismatic-x -> prismatic-y -> revolute-z) chain robot model. Are significant differences (advantages/ disadvantages) either approaches?",mobile-robot robotic-arm ros motion-planning
8273,Where I put angle sensor cart-pole robot?,"I'm using accelerometer gyroscope detect angle tilt rate two-wheeled cart-pole robot. Is optimal height place sensors? Should I place closer bottom (near wheels), middle (near center mass), top? Justification optimal choice would appreciated.",sensors balance
8276,Should therotical parameters match physical setup constraints modeling robot?,"I'm working modeling simulation robotic arm, I obtained mathematical model robot, I used implement control techniques, control motion robot. The dimensions masses links taken available kit, basically, it's RA02 robot servo joint. After modeling, different parameters, plotted: like joint angles\speeds\torques ... etc. The point that, value obtained joint toque much higher torque limit servo, mean design\modeling realizable? Is necessarily get close (torque) value servo's torque? Any suggestion?",control robotic-arm servomotor dynamics torque
8277,What torque bandwidth actuated joints affect control systems?,"The rest student team I process redesigning exoskeleton building based existing one. From papers reading references low, high zero impedance torque bandwith. What that? Does control system? It measured Hz. Here table one papers:",control design mechanism joint
8279,Ways estimate drift rate gyrometer,"I found much literature topic, I ask here. Does someone know ways estimate drift rate gyrometer. I thinking basically two approaches. One would use low pass filter low cut-off frequency estimate drift angular velocity. Second would use accelerometer, calculate attitude dcm also angular velocity. The difference acc angular velocity gyrometer would maybe also drift rate. Nevertheless, I sure whether good way get reliable drift rates :D",sensors gyroscope
8286,How connect Arduino Uno Android phone via USB cable?,Is possible set communication Arduino Uno Android phone using wire directly connects Android phone Arduino?,arduino usb
8288,Sourcing motors physical dimensions,I 1inch square tube I would like place motor into. The motor I takes approximately 1/2 available space (roughly 3/4 inch I.D.) I would like find largest motor fit space without cobble much housing. Where/how find motors physical dimensions?,motor
8289,Crock Pot Knob Turner,I Crock Pot analog knob would like find way turn knob using appliance timer. I idea begin. I need help. Thanks,control sensors stepper-motor
8292,Are aerodynamics modeling/simulation software capable consume SolidWorks model interface MATLAB/Simulink?,"Currently I developing control system aircraft unique design (something helicopter dirigible). At moment I model dynamics vehicle without aerodynamic effects taken account. For I use following work-flow: Mechanical model SolidWorks -> MSC ADAMS (Dynamics) <--> MATLAB/Simulink (Control algorithms) Thus, dynamics vehicle modeled ADAMS control algorithms MATLAB/Simulink. Unfortunately, ADAMS simulate aerodynamic effects. As result, I design control system capable fight even small wind disturbances.",control simulator uav matlab simulation
8293,Advanced Line Following Robot Maze Solving,I know make line follower. But video done exactly? They giving source destination map robot moves based instruction given map? What procedure it? They mapped path. Please watch video.,wheeled-robot mapping line-following
8294,Need mobile robot simulator provides easier odometry funtions,"I want mobile robot go starting position goal position. But, I don't want calculate pose encoders. Instead I want know exist simulator provides pose function makes work easier, like go_to(x_coordinate, y_coordinate). That means, robot automatically calculate current position leads goal position.",mobile-robot odometry simulation
8296,Using Gazebo installed machine MATLAB,I planning use MATLAB Gazebo one course projects. However tutorials I seen till use Gazebo using virtual machine ROS Gazebo installed. I already installed ROS Gazebo machine (OS Ubuntu). I also MATLAB installed it. Is possible use Gazebo machine MATLAB toolbox? Thanks.,ros matlab gazebo
8302,What difference path planning motion planning?,What main differences motion planning path planning? Imagine objective algorithm find path humanoid soccer playing robot ball short possible yet satisfying specified safety path terms distance obstacles. Which better terminology? motion planning path planning?,mobile-robot motion-planning humanoid
8310,What required theory behind building robotic arm?,"I currently planning building robotic arm. The arm's specs follows: 3 'arms' two servos (to move next arm) single servo clamp mounted revolving turntable turntable rotated stepper motor turntable mounted baseplate ball bearings allow rotation baseplate mounted caterpillar track chassis baseplate smaller length width caterpillar chassis What required formulas determining much torque servo must produce, keeping mind arm must able lift weights 1 kilogram? Also, considering ball bearings take load arm, strong stepper (just formulas, answers)? As far overall dimensions concerned, entire assembly roughly 255mm x 205mm x 205mm (l x w x h). I finalized arm length, aforementioned dimensions give general estimate size.",arduino robotic-arm stepper-motor rcservo torque
8313,Is modelling robot deriving Equations Motions applicable system inherently unstable?,"As someone new still learning robotics, I hope help out. Let's say I two systems: (a) Inverted Pendulum (unstable system) (b) Pole Climbing Robot (stable system) For system (a), I would say generally, dynamic system produces fast motion. So, order effectively control it, I would derive Equations Motions (EOM) I supply sufficient input achieve desired output. Eventually, program implement EOM enables microcontroller produce right signal get desired output. However system (b), I assume stable system. Instead deriving EOM, cant I rely sensor determine whether output produced exactly I want achieve? For unstable system, controlling difficult moreover, tolerate erratic behavior well. The system get damaged, consequence. On contrary, stable system tolerant towards unpredictable behavior since fact stable. Am I right think perspective? What exactly need deriving EOM systems (a) (b) above? What advantages? How affect programming systems? Edited: Some examples climbing robot I'm talking about:",mobile-robot control
8319,Filtering angular velocity spikes cheap Gyroscope,"I would like filter angular velocity data ""cheap"" gyroscope (60$). These values used input nonlinear controller quadcopter application. I interested removing bias readings. Edit: I'm using l2g4200d gyroscope connected via i2c Arduino uno. The following samples acquired arduino, sent via serial plotted using matlab. When sensor steady, plot shows several undesired spikes. How I filter spikes? 1st approach: Spikes attenuated still present... Let's consider following samples couple fast rotations performed. Let's assume frequency components ""fast movement"" ones I deal final application. Below, discrete Fourier transform signal normalized frequency scale second order ButterWorth low pass filter. With filter, main components signal preserved. Although undesired spikes attenuated factor three plot shows slight phase shift... And spikes still present. How I improve result? Thanks. EDIT 2: 1./2. I using breakout board Sparkfun. You find circuit Arduino gyro post: Can roll L3G4200D gyroscope, Arduino Matlab? I added pullup resistors circuit. I would exclude option sensors connected via i2c interface working correctly. I haven't decoupling capacitors installed near integrated circuit gyro. The breakout board I'm using (0.1 uF). Please check left side schematic below, maybe I wrong. Motors separate circuit I soldered components protoboard. The gyro quadcopter body test motors turned off. That interesting. The sampling frequency used test 200Hz. Increasing update freq 200 400 hz doubled glitching. I found comments web breakout board topic. Open comments bottom page Ctrl-F",quadcopter gyroscope filter
8322,Need idea: automated sim card switcher,"First off, sorry question naive related forum (this best matching one I've found StackExchange). I amount SIM-cards. I programmatically access single SIM-card inserted USB-modem. I want able access specified card set. The best way achieve I think create device would somehow replace current card modem one set. I use several modems I don't really know amount cards I would like automate process anyway. I programmer engineer everything follows (including entire concept switching cards) looks pretty weird me. There probably better solution, best I've come with. For I consider building sort conveyor would move cards insert ones I need sort feed device. This looks like overkill would expensive build uneffective work with. I want idea device would replace SIM-cards modem (or maybe better solution problem). Any disassembly modem needed possible. This required automate receiving SMS clients different contact phones. Unfortunately, simple redirection SMS option.",automatic automation
8327,Transforming angular velocity?,"I following system here: Basically, I range finder gives $R_s$ 2D model. I also model rotate Centre Mass, I angular values velocities Beta ($\beta$) BetaDot ($\dot{\beta}$). I can't see, life me, figure formula angular velocity Range Finder frame. How I supposed this? I values listed variables. The object doesn't move vehicle/system pitches. It's stationary.",robotic-arm sensor-fusion
8329,Filtering IMU angle discontinuities,"I try measure Euler angles IMU, discontinuities happens measurement, even vibrationless environment, shown images below. Can someone explain type filter best choice filter type discontinuities?",sensors imu matlab noise filter
8331,Designing 5 bar linkage robot: Plot Clock,"I beginner robotics. I recently stumbled across robotic clock youtube. I electrical engineering student interested submitting minor project. I studied basics forward inverse kinematics, Greubler's Equation, four bar linkage robot seems 5 bar linkage. I want know implement 5 bar linkage. How use inverse kinematics solutions described Combined synthesis five-bar linkages non-circular gears precise path generation, make robot follow desired trajectory? I stuck days... sort help would appreciated.",robotic-arm beginner first-robotics
8333,Relation pole placement marginal stability?,"I'm given assignment I design full state feedback controller pole placement. The state space system fully controllable I've using Matlab/Simulink determine required feedback gain K using place() command several sets poles, however I use poles ""too negative"", example p=[-100,-200,-300,-400,-500], controlled system starts showing bounded oscillatory behaviour. Is possible negative poles cause marginal stability? And so, why? I've read possible real part one poles equals 0, certainly isn't case here.",control stability
8337,KUKA FRI program using JAVA,"I trying establish FRI connection KUKA LBR iiwa. I know configure FRI connection example programs available Sunrise.Workbench. A sample code given below. My question 'how pass' joint torque values (or joint position wrench) controller using 'torqueOverlay' mentioned code below. Since I could find documentation this, quite difficult figure out. Any sample code explanation clues would helpful. JAVA code:",robotic-arm programming-languages
8340,Trying calculate Thrust quadcopter motors,I trying Calculate thrust 4 quadcopter motors have. I sure it. Here parts I Using 4S 6600mAh 14.8V Lipo Pack 15x5.5 Prop 274KV motor max output 28A ESC 35 Amp Thank You,quadcopter
8343,How much pause messages? (IRobot Create-2),When I send several commands row don't get executed. For example I script starts roomba driving circle plays john cena theme song speakers sometimes play music drive. I noticed guides pauses every command. Is documentation describes pauses needed?,irobot-create
8345,Trying Figure parts buy Quadcopter,"So I building Quadcopter I already frame 39 inches(3.25 feet) 680 grams. I want run Multistar Elite 5010-274KV Multi-Rotor Motor. KV(RPM/V): 274KV Lipo cells: 6~8S Max current: 630W Max Amps: 28A No Load Current: 0.43A/10V Weight: 211g I want use Multistar High Capacity 4S 6600mAh Multi-Rotor Lipo Pack Minimum Capacity: 6600mAh Configuration: 4S1P / 14.8V / 4Cell Constant Discharge: 10C Peak Discharge (10sec): 20C Pack Weight: 537g The props I thinking using 15x5.5props. So anyone knows wrong setup, work, maybe even tips pointers since I beginner drone builder I really don't want spend $1,044 take build work advice appreciated. Total Estimated Weight = 1,919 Grams(4.23 Pounds) Also chart motor helpful. The chart near price files tab Multistar Elite 5010-274KV Multi-Rotor Motor Thanks In Advance",battery multi-rotor
8348,Changing STM32 Nucleo Board's Microcontroller,"I STM32F072RB Nucleo Board 64Pin Microcontroller. For application I chose sTM32F103RG bigger RAM size Flash size too. Can Remove F072R Nucleo board put F103R top it? I testing code F103C, flash ram size meeting requirement. I F072R Nucleo Board lying around quick developmental test could I swap 103R ? The R series Pin Compatible! Anyone Has done microcontroller swapping before?",microcontroller
8350,differences SCARA arm design,"I currently interested SCARA arm designs I few, beginner questions I didn't find answers yet. 1/ While comparing professional arms (made epson, staubli...) I noticed actuator used translation Z axis end arm. On ""hobby"" arms like makerarm project kickstarter use leadscrew actuator beginning arm. I thought smarter put actuator handling DoF begining arm (because weight) end, I assume companies experience company behind makerarm. So I'm probably wrong, I would like understand :) 2/ Also I would like understand kind actuators used arms. The flx.arm (also kickstarter project) seems using stepper motors also say using closed loop control, added encoder stepper motors right? Wouldn't better use stepper and, instance, use DC brushless motors servos instead ? 3/ I also saw arms using belts 2nd Z axis rotation, advantage ? allows put actuator begining arm ?",robotic-arm design actuator
8354,Need help quadcopter PID,"I'm trying make quadcopter Arduino. I already angles (roll pitch yaw) thanks IMU. They degrees filtered complementary filter. I want apply PID algorithm axis I dont know inputs angles (degrees) angular velocities degrees per second calculate errors respect referencies. Which difference? Which best way? Finally, another question PID code: I seen many people don't include time codes. For example, derivative term kd×(last error-actual error) instead kd×(last error-actual error)/looptime something similar integrative term. Which difference? Thank advanced.",quadcopter pid
8356,Very low output voltage output L298n?,"I using arduino L298n motor driving IC drive 4 12V dc motors (150rpm). Also I using 11.1V LiPo battery (3cell, 3300 mAh, 20C).I connected two PWM pins L298n digital HIGH arduino.Battery positive terminal connected 12V input IC.Battey negative terminal arduino ground connected ground input IC.Also 5V input given arduino IC ground arduino connected gnd pin adjacent INT3 pin.Motor1 pins L298n connected two motors (connected parallely right side bot) Motor2 pins connected two motors (connected parallely left side bot).Appropriate inputs given INT1,INT2,INT3,INT4 drive bot forward direction.But bot moving slowly.The voltage measured across motor1 pins 5V.I connected battery directly motors,then running fast.How run fast.Please help.....",arduino motor
8357,How drive robot without driving actuator?,"I participating robotics competition. I supposed design build two robots. Out these, one cannot driving actuator (it steering actuator though, fed line following circuit). The supposed drive non-driving robot obstacle course, without touching it. This kind driving crazy since one point separation two robots 60 cm (23 inches). Ways I've considered: Wind Energy (wont work, need huge sails) Magnetic Repulsion sort Now repulsion I've spent lot time studying. My solution use strong permanent magnets non-driving robot (Neodymium,N52) electromagnets driving robot. But, huge load calculations came conclusion enough force transmitted distance magnetic fields fall quick. Rulebook: I really looking even pointer here. Is trick somewhere I missing?",line-following
8361,6DOF robot arm: Velocity end effector vs. joint velocities,"I 6 DOF arm whose velocities I'm controlling function force applied end effector. The software robot allows input either desired end effector velocity desired joint angular velocities, I know found using inverse Jacobian. Are benefits using one scheme other? Would, example, one help avoid singularities better? Does one lead accurate control does?",robotic-arm jacobian force-sensor
8363,Cannot command irobot create 2,"This might dumb question. I started play robot raspberry pi two days ago. I simple stuff, like- move around sensor reading etc. But since yesterday night, It seems like I cannot send command. The built clean, dock functions working perfectly I cannot anything using python code I already used before. Its behaving like nothing going Rx. Can suggest might go wrong? Thanks",irobot-create
8365,using device os instead microcontrollers,Im working robot needs image processing analyze data recieves cameras. As searched ARM AVR libraries found dip library micros limited ram hard image data process. want know hardware connects win android or... devices make possible device connect actuators sensors? thank helping.,microcontroller
8367,ArDrone navdata reading error,"I trying read navdata ardrone using following callback function, But always returing 0 value, echo navdata linux terminal, topics publishing non-zero value. error? Edit: After debugging found callBack function called all. I wrote subscriber node like ros::Subscriber sub = ardrone.subscribe(""/ardrone/navdata"",1,callBack); What going wrong here?",quadcopter
8368,Solving DH Parameters,"Given three sets joint angles end effector position, possible find DH parameters? If robot 2 DOF shoulder, 2 DOF elbow, 1 dof wrist, DH parameters upper arm length, elbow offset 1 axis, lower arm length, solved, how? I tried iterating DH parameters minimize position end effector forward kinematics, doesnt seem work DH parameters 0 everything makes 0 minimal distance. Reason this; given physical robot, DH parameters known, measuring hand accurate.",dh-parameters
8369,Power iRobot Create 2 via serial port,"I Arduino talk Create 2 via serial interface. But sending commands robot, I power manually pushing power button robot. How make robot turned via mini din 7 port, instead pushing power button? I notice plugin iRobot serial-2-USB cable port robot, robot immediately turned on, ready received first command (command 128), apparently way turn robot via port.",irobot-create
8371,Switching scheme vector controlled pmac drive,"I 28 pmac motors (3-ph, 230 volt 0.5 kw, 1.05kw 1.21kw) motor control center. Please suggest time staggered switching scheme order avoid tripping due voltage sag, swell , flicker etc",power
8372,Denavit Hartenberg parameters,"Can anybody help figure HD parameters case two links revolute joint plane, thus variable angle 0, twist 0. This simple drawing. I think x-axis perpendicular z-axis, points away goes intercection z-axis. The link length 0, twist offset d. Whould correct? Thanks.",dh-parameters
8375,detects animals PIR(passive infrared sensors),dont know kind radiation animals emit. humans emit IR radiations PIR sensors help identify humans. pls suggest someone knowledge sensors detects animals.,arduino raspberry-pi first-robotics
8376,kk2.1.5 gyro bubble centre,"I quadcopter controlled KK2.1.5 flight controller. I flying without problems, facing problem. When start arm kk2.1.5, giving throttle starts turning towards direction acceleration. I double checked motor pins locations things, correct. When took look gyro bubble kk2.1.5 wasnt mid crosshair. I turned quad on. I check bubble centre. gave throttle started turning towards direction. I checked again, wasnt centre time too. So armed state gyro bubble moves away centre giving throttle. due quad overcorrects itself. Now understood gyro centre due vibration FC. What antivibrate it. What material keep vibrations almost zero.",quadcopter
8378,Torque control eye-in-hand visual servoing,"In papers IBVS camera velocity computed used pseudo-input manipulator. (e.g. one) Is work dynamic Lagrange model $H(q) \ddot q +C(q,\dot q)\dot q+g(q)=\tau$ manipulator taken consideration order compute torque required move joints accordingly?",dynamics torque visual-servoing
8382,How make stepper motor rotate come position certain degress (say 90 degrees) initial position?,"I tried coding working. But problem coding placed inside loop 'if loop', working. Can anyone help figuring problem. I using accelStepper library coding. void loop() { int dummy=1; if(dummy==1) { int = 104; int x2 = vertical2.currentPosition(); int z2 = y-x2; int x1 = horizontal2.currentPosition(); int z1 = y-x1; horizontal2.moveTo(z1); horizontal2.run(); vertical2.moveTo(z2); vertical2.run(); } }",arduino stepper-motor
8387,Optimal trajectory manipulators using optimal control,"I'm trying implement direct-multiple shooting method problem. As I understand theory, I divide variables state variables control variables. State variables are: q v Control variable is: tau In time interval I'll generate cubic splines q(t)=a_0+a_1*t+a_2*t^2+a_3*t^3 Could help I implement it? I don't understand ODE I construct algorithm? Are example it? edit make equations clear I'll rewrite again: based link state variables: x1(t) = (q1(t) , ··· ,qn(t))^T x2(t) = (q˙1(t) , ··· ,q˙n(t))^T. derivatives state variables equal x˙(t) = f(x(t) ,u(t)) f f(x(t), u(t)) = ((q˙1(t), . . . , q˙5(t))^T; M(x(t))−1· (u(t) − N(x(t))) I don't know insert cubic polynomials equation system solve ODE Will like [T,X]=ode45('f', [0 t_f], [q_0 q_f])",manipulator
8389,3 DOF Inverse Kinematics Implementation: What's wrong code?,"I currently trying implement Inverse Kinematics solver Baxter's arm using 3 pitch DOF (that yGoal value redundant, axis revolution). I part copied slide pseudocode page 26 . Here logic writing this: I first calculated Jacobian 3x3 matrix taking derivative equation seen forwardKinematics method, arriving at: [370cos(theta1) + 374cos(theta1+theta2) ..... 0 0 0 -370sin(theta1)-374sin(theta1+theta2)-...... ] In order arrive numerical values, I inputted delta theta change theta1,2 3 0.1 radians. I arrived Jacobian numbers: [0.954 0.586 .219 0.0000 0.000 0.0000 -.178 -.142 -0.0678] I input matrix pseudoinverse solver, came values see invJacob matrix code I posted. I multiplied difference goal end effector currently at. I applied tenth value joints, make small steps toward goal. However, goes infinite loop numbers way be. Where I go wrong? Is complete rewrite implementation necessary? Thank help.",inverse-kinematics python joint jacobian
8391,What easiest efficient way detect human close range distance make robot follow it?,I thesis right regarding robot. My research requires robot attached linear guide rail. A robot detect human close range (of 2 meters distance). What easiest efficient method components shall I use?,sensors wheeled-robot industrial-robot
8394,connecting MPU-9250 GY-9250 SENSOR MODULE arduino uno,"using sensor make self balancing robot.At first soldered header(only vcc,gnd,scl,sda ) imu borad opposite side component mounted.then connecting arduino uno r3(vcc vcc 3.3v/5v,gnd 1 3 gnd,scl scl sda sda(first time next AREF, second time A5,A4) ) uploaded sketch opened serial monitor got Accelerometer Test FF Ooops, ADXL345 detected ... Check wiring! thought may soldered header wrong direction(as picture videos internet,they so) desolder(with solder iron,no technique) header,but still solder around hole could remove.then checking continuity pins multimiter(in resistance mode) found resistance 20k(scl-sda),220k(scl-gnd),220k(sda-gnd),between vcc 3 pins multimieter shows 1(range 2000k). soldered opposit side(this time components mounted).the serial monitor still shows output,and muiltimeter.so problem? soldering ?do need disolder header clean left solder(with Chip Quik type desoldering technique ) opposite side(no component mounted)?is hope won't need buy again? picture opposite side component mounted desoldering resoldering",imu accelerometer gyroscope
8399,Updating firmware kk2,"I facing problems updating kk2 board. I used usbasp header connecting pc, kk2firmware software. But fails. It says valid vid pid values etc. Please help me. If idea updating firmware this. I used usbasp header connecting kk2 board pc.",arduino
8400,"Using RGB + Depth Camera locate X,Y,Z coordinates ball","I've recently trying use Gazebo modelling couple tasks. I robot that's effectively able locate ball get x,y coordinates terms pixels using simple RGB camera Kinect. I also point cloud generated Kinect, I hope find depth perception ball using X,Y coords sent circle recognition RGB camera. My plan earlier convert X,Y coordinates RGB camera meters using DPI Kinect, I can't find info it. It's much, much harder object recognition using Point Cloud, I'm hoping I stick using RGB camera recognition considering it's simple Hough Transform. Does anybody pointers me?",localization computer-vision kinect cameras gazebo
8403,How tilt camera 180 using mirrors,"How would vertically tilt camera 180 degrees using mirrors? I'm trying add pan/tilt mechanism Raspberry Pi's camera. The camera uses one flat cables unstranded wires, even strain gauge, I don't trust handle repeated bending, I'm trying design tilt mechanism allows camera rigidly mounted wires move. The tilting also happen quickly, I'm trying minimize amount mass I need move. Then I saw Oculus kit actuates mirror effectively tilt laptop's fixed webcam. I'm trying extend idea, I trouble working mechanics would allow tilt extend 180 degrees. The layout Oculus's mechanism supports tilt angle 90 degrees, mirrors relatively large. Is possible modify support 180 degrees? Are ways ""bend"" view camera without move actual camera?",mechanism cameras
8406,"Samsung IP camera, wifi direct feature","Can use wifi direct feature samsung IP cameras connect directly Laptop wifi adapter without need additional router? I working OpenCV project want read stream 3 cameras simultaneously, thinking could connect 3 usb wifi adapter laptop connect directly cameras. Is scenario possible?",opencv
8407,One propeller Drone?How well works?Hope,Can one propeller drone work efficiently good flight stable camera footage drone flight,quadcopter
8411,Joint Space Singularities,"I would like clarify self singularity configurations. If I moving robot joint space one joint time, I come singular configuration? If how? Thanks",joint jacobian
8417,Removing PCB Dynamixel RX-24F servo?,"For mod Dynamixel RX-24F I need remove enclosed PCB. I removed screws PCB doesn't come easily (without applying force I'm comfortable with). It seems stuck three large solder points white area. Has someone experience particular servo? It might glued/soldered case, I'm quite certain. Any help appreciated.",dynamixel
8418,How compute relative pose two robots?,"How compute relative pose two robots? I robots (matlab code): And corresponding covariance matrix probability distribution one (the movement robot asociate gaussian distribution) co1 = diag([0.08,0.6,0.02]); co2 = diag([0.20,0.09, 0.03]); AUXILIAR FUNCTIONS TO SOLVE Function compose two poses ([x ; ; theta]) function tac=tcomp(tab,tbc) %Composition transformations given poses ang = tab(3)+tbc(3); ang > pi | ang <= -pi ang = AngleWrap(ang); end = sin(tab(3)); c = cos(tab(3)); tac = [tab(1:2)+ [c -s; c]*tbc(1:2); Function get inverse pose pose function tba=tinv(tab) tba = zeros(size(tab)); t=1:3:size(tab,1), tba(t:t+2) = tinv1(tab(t:t+2)); end SOLUTION: To get relative pose, need compute two things: The pose composed poseR1 get poseR2. It means need get ""pose_inc"" satisfy equality tcomp(psoeR1,**pose_inc**) = poseR2 The next code compute relative pose allows poseR1 reach poseR2 % Computing relative pose R1 R2 % pose composed poseR1 reach poseR2 pose_inc = tcomp(tinv(poseR1),poseR2); The covariance matrix relative pose. The uncertainty R1 reach position poseR2 c = cos(poseR1(3)); = sin(poseR1(3)); x_1 = poseR1(1); y_1 = poseR1(2); x_2 = poseR2(1); y_2 = poseR2(2); % Jacobians compute covariance relative pose JacF_1 = [-c -s -(x_2-x_1)*s+(y_2-y_1)*c ; -c -(x_2-c_1)*c-(y_2-y_1)*s ; 0 0 -1]; JacF_2 = [c 0; -s c 0; 0 0 1]; % Computing covariance relative pose C_p12 = JacF_1*co1*JacF_1' + JacF_2*co2*JacF_2';` Roughly, JacF_1 jacobian define difference poseR1 pose_inc JacF_2 jacobian define difference poseR2 pose_inc C_p12 covariance matrix R1 move poseR2",sensors movement pose first-robotics
8419,"Running 3 DOF Inverse Kinematics Code: Works MATLAB, Python","I asked question similar earlier, I believe I new problem. I've working figuring inverse kinematics given x,y,z coordinate. I've adopted Jacobian method, taking derivative forward kinematics equations respect angles input Jacobian. I take inverse multiply step towards goal distance. For details, look page 21 onwards. For better picture, something: Below code MATLAB script, runs flawlessly gives solution 2 seconds: Below Python code, goes infinite loop gives results. I've looked differences MATLAB code, look exact me. I clue wrong. I would forever grateful somebody could take look point out. def sendArm(xGoal, yGoal, zGoal, right, lj): ycurrent = xcurrent = zcurrent = 0 theta1 = 0.1 theta2 = 0.1 theta3 = 0.1 xcurrent, zcurrent = forwardKinematics(theta1, theta2, theta3) xchange = xcurrent - xGoal zchange = zcurrent - zGoal ((xchange > 0.05 xchange < -0.05) (zchange < -0.05 zchange > 0.05)): in1 = 0.370*math.cos(theta1) #Equations in1-6 pdf I linked (inv kinematics section) in2 = 0.374*math.cos(theta1+theta2) in3 = 0.2295*math.cos(theta1+theta2+theta3) in4 = -0.370*math.sin(theta1) in5 = -0.374*math.sin(theta1+theta2) in6 = -0.2295*math.sin(theta1+theta2+theta3) jacob = matrix([[in1+in2+in3,in2+in3,in3],[in4+in5+in6,in5+in6,in6], [1,1,1]]) #Jacobian invJacob = inv(jacob) #inverse jacobian xcurrent, zcurrent = forwardKinematics(theta1, theta2, theta3) xIncrement = (xGoal - xcurrent)/100 #dx increment zIncrement = (zGoal - zcurrent)/100 #dz increment increMatrix = matrix([[xIncrement], [zIncrement], [1]]) change = invJacob*increMatrix #multiplying matrixes theta1 = theta1 + change.item(0) theta2 = theta2 + change.item(1) theta3 = theta3 + change.item(2) xcurrent, zcurrent = forwardKinematics(theta1, theta2, theta3) xchange = xcurrent - xGoal zchange = zcurrent - zGoal print ""Xchange: %f ZChange: %f"" % (xchange, zchange) print ""Goals %f %f %f"" % (theta1, theta2, theta3) right.set_joint_positions(theta1) #First pitch joint right.set_joint_positions(theta2) #Second pitch right.set_joint_positions(theta3) #Third Pitch joint def forwardKinematics(theta1, theta2, theta3): xcurrent = .3708 * math.sin(theta1) + .374 * math.sin(theta1+theta2) + .229 * math.sin(theta1+theta2+theta3) zcurrent = .3708 * math.cos(theta1) + .374 * math.cos(theta1+theta2) + .229 * math.cos(theta1+theta2+theta3) return xcurrent, zcurrent",kinematics inverse-kinematics matlab python jacobian
8420,Why require force turn servo electronically connected another servo?,"I two servo motors I rigged use telescope remote focuser. The idea turn one servo hand use power generated turn other, geared telescope focuser knob. I noticed two servos electrically connected, noticeably harder turn servo compared turning itself. I tried changing polarity connection hoping would help, still harder turn servo connected. Does anyone know is?",servos servomotor
8421,I can't get motors turn Raspberry pi,"I want turn motors using raspberry pi. I able turn LED using 3.3V GPIO pin. For motors, I tried using L293D chip per instructions link. What happened first time I set circuit one motor, worked perfectly. But then, I moved pi little motor since refused work. I even bought new pi still luck circuit. I bought L298N board fits smugly top GPIO pins pi followed instructions video Still luck, motor won't run either pi. I using four AA batteries power motor connecting pi power supply wall. What could possibly problem here?",motor raspberry-pi
8425,Relationship earth frame attitude acceleration quadcopter,"For quadcopter, relationship roll, pitch, yaw earth frame acceleration x, y, z dimensions earth frame? To concrete, suppose roll ($\theta$) rotation earth frame x-axis, pitch ($\phi$) rotation earth frame y-axis, yaw ($\psi$) rotation z-axis. Furthermore, suppose $a$ gives acceleration produced four rotors, i.e. acceleration normal plane quadcopter. Then $f, g, h$ $$a_x = f(a,\theta,\phi,\psi)$$ $$a_y = g(a,\theta,\phi,\psi)$$ $$a_z = h(a,\theta,\phi,\psi)$$ $a_x$, $a_y$, $a_z$ accelerations $x$, $y$, $z$ dimensions. I've seen number papers/articles giving relationship x,y,z accelerations attitude, it's never clear whether attitude angles rotations earth frame body frame.",quadcopter dynamics
8426,Denavit Hartenberg parameters - 3DOF articulated manipulator,I trying solve forward kynematics problem 3DOF manipulator. I working Robotics Toolbox MatLab created Peter Corke calculte DH parameters introduce MatLab compute fordward kynematics plotted robot be. I guess I made mistakes calculating DH parameters. Attached file see DH frames calculated joint DH parameters frame. Anyone could give clue whether correct answer? Here image frames calculated me. And robot I get Matlab (using Robotics Toolbox P.Corke),robotic-arm inverse-kinematics forward-kinematics
8427,What charger use ZIPPY Compact 6200mAh 4s 40c Lipo MultiRotor Battery,"Hello I trying build Quadcopter school project I need finish quick mission trip I asked finish I could take it. But I problem figuring charger would work ZIPPY Compact 6200mAh 4s 40c Lipo Pack Here specs battery Capacity: 6200mAh Voltage: 4S1P / 4 Cell / 14.8V Discharge: 40C Constant / 50C Burst Weight: 589g (including wire, plug & case) Dimensions: 158x46x41mm Balance Plug: JST-XH Discharge Plug: HXT4mm Also I running Tarot T4-3D Brushless Gimbal GoPro (3-Axis) anyone tell good battery run maybe would better run main battery. Thanks Advance",quadcopter battery lithium-polymer
8428,Moatech stepper motor salvage - unsure pinout,"I salvaged Moatech BL55K-M01 Stepper motor old printer I'd like play around it, I'm unsure use pinout listed board. Pinout reads: 24V 24V GND GND SGND 5V ST/SP RD CLK GAIN Which well good, I sure SGND, ST/SP, RD, GAIN used for. I understand CLK, also don't know frequency expects. Moatech e-mail bounced back, I hoping someone might coherent datasheet know designations mean.",stepper-motor
8432,How use SLAM simple sensors,"What 2D SLAM implementations (preferably included ROS) used simple distance sensors like IR ultrasonic rangefinders? I small mobile platform equipped three forward facing ultrasonic sensors (positioned 45 degrees, straight ahead, -45 degrees), well 6-DOF accel/gryo wheel encoders, I'd like use play around ""toy"" SLAM implementation. I don't want waste money Kinect, much less commercial laser rangefinder, methods require high-density laser measurements aren't applicable.",slam ros
8438,Solar panel set rotation: How achieve vertical horizontal rotation?,How achieve kind rotation enable maximum trapping solar rays day?,mobile-robot
8443,iRobot Create 2: Can I load code instead connecting cable? (new learner),"I new learner iRobot. I trying program control movement Create 2. After glancing existing project, I find based sending commands Roomba cable. Is anyway embed code let Roomba behave accordingly? If method, kind API tool think easiest beginner?",irobot-create
8444,Is way turn sound Roomba?,"I working iRobot Create 2 I work others around me. Whenever I turn robot on, send OI reset command, etc., makes various beeps noises. I would like happen since I find little annoying I'm sure work around would like things quiet concentrate work. Is way accomplish turning beeps (while still able easily re-enable them), I luck?",irobot-create roomba digital-audio
8448,"Quadrotor - Control system, begin?","I starting assemble quadrotor scratch. Currently, I this: Structure; IMU (accelerometer, gyro, compass); 4 ESCs DC motors; 4 propellers; Raspberry Pi control system, and; LiPo battery. I calibrated ESCs four motors already working ready. But I stuck. I guess next step dive deeply control system, I sure begin. I read articles control using PIDs, I don't know many I use, whether I need model quadrotor first compute kinematic dynamic quadrotor inside RPi. Sorry question basic! More details The structure kit. Well, I ESCs calibrated, although I documentation adjust cut voltage LiPo battery. I made tests Python code I found PWM outputs motors control I2C bus communicate IMU. One problems I need RPIO library PWM work I2C libraries MIT control IMU far I know RPIO works Python2 quick2wire works Python3 I don't know manage this. So actually, I code yet control four motors parallel, testing code test separately also IMU. About IMU, I still learning work use MIT library. The unit includes sensors: ADXL345 HMC5883L-FDS ITG3205 You see picture quadrotor below, So I said before, I would like know handle control system implemented inside Raspberry Pi, start work Python code assemble motors, IMU control.",control pid raspberry-pi quadcopter beginner
8450,Torque / Current control BLDC motors,"I working robotic application, I want control torque (or current) brushless DC motors. There many BLDC speed controllers I could find anything related torque current. Instead continuously spinning, motor actuating robotic joint, means I need control torque steady-state, low-speed, finite rotation. I looking low-cost, low weight solution, similar Texas Instruments DRV8833C Dual H-Bridge Motor Drivers brushed DC motors.",brushless-motor
8451,What hardware components build modular robot consists several 5x5x5cm modules?,"I computer science student I knowledge robotics. In project, I trying find controllers modular robots make specific tasks using evolutionary techniques. For moment I simulator, I want make physical robots I know priori components add robot, I place them, especially modules robot small (cubes 5*5*5cm)... So questions are: What must components make physical robot ? (arduino, batteries, sensors, ...) For small robot many batteries I need ? If modules communicate wifi, I put wifi card module? I want add IMU. Is position important, I mean I put middle robot ? Thank much.",arduino mechanism
8452,What easiest yet precise method one make track train,I would like put train track control movement high precision left right using wireless controller. What best way it?,arduino
8455,Small IR distance sensor works black surfaces,"Can anyone recommend IR distance sensor works black surfaces? I'm looking something use ""cliff"" sensor, help small mobile robot avoid falling stairs table, I thought Sharp GP2Y0D805Z0F would work. However, testing it, I found matte black surface register sensor, meaning sensor would falsely report dark carpet dropoff. Sharp models might better handle this, they're much larger expensive. What type sensor good detecting ledges dropoffs, small inexpensive works wide range surfaces?",sensors
8457,Create 2 CAD files,"I found CAD files Create ROS TurleBot download page (.zip), shells gazebo sim page. Any ideas files Create 2 could found?",design irobot-create
8461,Electronic circuit heating nylon fishing line muscle,"I'm trying make artificial muscles using nylon fishing lines (see ) So far, I've produced nicely coiled piece nylon fishing line, I'm little confused heat electrically. I've seen people say wrap muscle copper wire like, pass current wire, muscle acuates dissipated heat given wire resistance. I two questions regarding heating: 1) isn't copper wire resistance extremely low, thus generates little heat? metal I use? 2) circuit I build heat wire (and control heating)? Most examples ""attach battery"" wire, afaik simply short-circuiting battery, heating wire inneficiently (and also may damage battery could even dangerous). So what's safe efficient way produce heat necessary make nylon muscle react? (I've read 150 centigrads, could correct?) example arduino? simple circuit breadboard? thanks lot!",arduino electronics actuator
8462,Automatic sliding window shutter,"I want build automatic sliding window shutter need help part selection dimensioning. Some assumptions: window width 1.4 sliding shutter weight 25 kg max speed 0.07 m/s max acceleration 0.035 m/s^2 pulley diameter 0.04m. Leaving friction I need motor 0.02 Nm torque rated speed 33 rpm. What I would like use: motor controller soft-start jam protection, dc motor 24V, Pulleys timing belts. Would suggest components different setup? How I connect motor pulleys (clamping set?)? Do I need additional bearings radial load? (M motor, P pulley, B bearing, = shaft) If I extend motor shaft. What would I use (clamp collars, couplings?)? What width I need belts? Which belt profile (T, AT, HDT) I use? Update The construction I aiming resembles one seen page 6 (pdf numbering) here.",motor design microcontroller automation
8463,Angular velocity translational velocity,"I 3D point space it's XYZ Coordinates Frame A. I need calculate new XYZ coordinates, given angular velocities axis instant time Frame A I referring notes, I'm little confused. This notes say: As see, calculate angular velocity vector w given angular velocities. But I'm sure translates calculate new XYZ position! How calculate RPY values equation seems need XYZ, calculate new position",mobile-robot
8466,Sizing high current power supplies large robots,"I'm researcher lab that's starting work larger humanoid/quadruped robots well quadcopter. Currently, several power supplies max rating 30V/30A modified quadcopter easily maxes current limit half propellers running. It seems like power supplies meant small electronics work fairly low current limits. I think I want look power supplies able provide 24-48V higher 30A extended period time. 1.) Is unreasonable expensive? 2.) Do labs connect PSUs series get higher voltages? Thanks input.",quadcopter power humanoid
8470,Xaxxon Oculus Prime Platform: using different SBC one sold manufacturer,"I using kit version Oculus Prime Mobile Platform sold Xaxxon project planning use Odroid XU4 running ROS. But, problem I faced Odroid XU4 32bit processor whereas server application ROS packages written Oculus Prime run 64bit. Here links documentation server application. Could anyone tell if: There 32-bit variant way run server application ROS packages Odroid. Will single board computer 64-bit architecture able run required packages special configuration motherboard sell. (is case platforms general) Which single board computers would ideal situation I purchase them?",ros ugv platform
8471,Dynamic simulation compliant elements quadruped robot,"I preliminary design legged robot uses compliant elements legs parallel motors energy recovery impact well pair flywheels front back oscillate back forth generate angular momentum. I'd like create dynamic simulation robot order able test control strategies I build real model. What simulation package I using why? I heard good things MSC Adams, namely slow learn, lot capability, including integration matlab simulink. I also heard simmechanics toolbox matlab, would nice use since I already decent CAD know matlab language. I yet familiar simulink, used Labview before.",mobile-robot design dynamics matlab simulation
8474,Kinematic decoupling,"Is kinematic decoupling 5DOF revolute serial manipulator also valid? The three last joints spherical joint. Most literatures talks decoupling 6DOF manipulators. Thanks advance, Oswald",kinematics
8475,How I reduce motor's maximum current draw?,"I motor stall current 36A. I also motor controller peak current rating 30A. Is way I could reduce stall current otherwise protect motor controller? I realize ""right"" solution buy better motor controller, we're bit low funds right now. I thought putting resistor series motor came value 150mΩ, would reduce maximum current draw 25A (given 12V/36A=330mΩ maximum impedance motor). Is downside this? Would I harming performance motor beyond reducing stall torque?",motor microcontroller current
8480,What's difference feedback feedforward control?,"I'm reading Astrom & Murray (2008)'s Feedback Systems: An introduction scientists engineers difference feedback feedforward. The book states: Feedback reactive: must error corrective actions taken. However, circumstances, possible measure disturbance disturbance influenced system. The effect disturbance thus reduced measuring generating control signal counteracts it. This way controlling system called feedforward. The passage makes seem feedback reactive, feedforward not. I argue feedforward control still uses sensor values produce control signal, still reactive conditions system finds in. So, feedforward control possibly different feedback forms reactive control? What really separates two other? A illustrative example difference two would helpful.",control
8483,Powering 6 servomotors requiring 6V 2A,"The title pretty much says all. I'm team currently building robotic arm capstone project engineering degree, design similar Dobot (5 degrees freedom). We purchased 6 servomotors, one requires 2A 6V. From preliminary research, I haven't able find power source could satisfy this. We'd rather purchase six individual AC/DC power source servo, we've heard introduce problems, aren't necessarily voltage-regulated. Another suggestion we've received buy computer power source, modify output voltage amperage need. This raises concerns, since professor running course might find dangerous. We'd like input power servos effectively, without going overboard costs (we students, all). Thanks!",power servos servomotor arm
8486,How build fast quadcopter,"im currently (risky) proyect involves building fastest quad afford. Im trying get something close extremely fast warpquad After reading lot quadcopters, know buy fit together fly without problem. My questions are, first im wrong im missing something read (thinking common build racer quad). Then: Will overheat (bad consecuences) let drain full battery 100% throttle? Will fly least 4 minutes previous conditions? Should get higher C-rating battery? As can't find better motors size, way improve speed putting 6S battery? would happen it? Should put 6inch props 4inch? I know 4inch get faster rpm changes noticeable sizes? And general tips make faster welcome. Thanks.",quadcopter
8487,Is way disconnect reconnect Create 2 streaming sensor readings without unplug/replug USB-serial cable?,"I working Create 2 I executing simple sequence like (in pseudocode): The outcome I run program repeatedly works first time, I see sensor data (that seems change reactive) printing screen, future runs serial read program crashes (because I throwing exception I want get problem ironed getting far along things). If I unplug replug USB cable Macbook, program work another run, fall back faulty behavior. I experience issue things like driving robot, I able run programs similar simplicity repeatedly. If I mix driving sensor streaming, driving works program run program run, data streaming crashes program subsequent runs. I noticed I want query single sensor, I need pause stream get query response come serial port, resume it. That I inclined pause/restart stream. Am I something wrong, like pausing stream often? Are things I need take care starting/stopping stream? Any help would appreciated! EDIT: I note I using Python pyserial. I also note, future readers, iRobot pushes streamed data laptop every 15ms sits buffer, data sits call serial.read() serial.flushInput(). This seemed sensor values weren't updating I read/polled every half second, I reading old values current ones still buried back buffer. I worked around issue flushing buffer reading next data come in. EDIT 2: Sometimes workaround fails, I detect failure, I pause stream, re-initialize stream, read fresh data coming in. This seems work pretty well. It also seems solved issue I originally asked question about. I still don't know exactly works, I still accept @Jonathan 's answer since I think good practice introduced new issues, least added benefit robot letting know started/exited sounding tones.",mobile-robot irobot-create
8491,Relative orientation two robots,"Given two robot arms TCP (Tool Center Point) coordinates world frame is: $X_1 = [1, 1, 1, \pi/2, \pi/2, -\pi/2]$ $X_2 = [2, 1, 1, 0, -\pi/2, 0]$ The base robots at: $Base_{Rob1} = [0, 0, 0, 0, 0, 0]$ $Base_{Rob2} = [1, 0, 0, 0, 0, 0]$ (The coordinates expressed successive transformations, X-translation, Y-translation, Z-translation, X-rotation, Y-rotation, Z-rotation. None joint axes capable continuous rotations.) How many degrees TCP robot 2 rotate orientation TCP robot one? Is calculation $\sqrt{(\pi/2 - 0)^2 + (\pi/2 - (-\pi/2))^2 + (-\pi/2 - 0)^2}$ wrong? If yes, please specify why. UPDATED: relative orientation two robots [π/2,π/2,−π/2]−[0,−π/2,0]=[π/2,π,−π/2]? euclidean distance cannot applied calculate angular distance? In words: While programming robot, tool frame selected motion, match orientation one, would issue move_rel($0, 0, 0, \pi/2, \pi, -\pi/2$) command, executed motion would magnitude $\pi$? While programming robot, world frame selected motion, match orientation one, would issue move_rel($0, 0, 0, \pi, 0, 0$) command, executed motion would magnitude $\pi$?",robotic-arm kinematics geometry
8499,Mapping camera pose image features visual servoing,"I robotic arm camera eye-in-hand configuration. I know relationship body velocity $V$ camera velocities $\dot s$ image feature space $\dot s=L(z,s) V$ $L$ interaction matrix. I wondering one find mapping (a called diffeomorphism) connects image features' vector $s$ camera pose $X$. All I able find possible structured environment I don't fully understand is.",mapping visual-servoing
8500,Forward kinematic inverse kinematic... When use what?,"I quite sure I quite understand difference two concepts, difference two concept. Yesterday I trying compute jacobian needed inverse kinematics, usual input I provided transformation Forward kinematics Points P xyz could applied, The transformation matrix given state vector Q, Tool position could retrieved... I sure understand concept quite well, can't seem google topics, usually include terminologies makes concepts simple (Angle calc on.. ) I know might pretty much ask, form input needed compute jacobian ?, difference forward inverse kinematics?..",inverse-kinematics forward-kinematics jacobian
8501,Lifting robotic leg one servo,"Note I start: I actually put anything together yet, i'm still planning, changes require shape change anything like accepted. I'm working making walking robot arduino 3d printing pieces I need. It four legs, since needs mobile, I didn't want power supply huge. I've decided would best I get leg require 1 servo, 5V each. I know get leg move back forth, want able lift between; brings leg forward, needs lift foot. The thing I think rotation maybe locking sort gear. When motor begins rotating clockwise, I power short motion move object toward itself, begins moving counterclockwise power object short distance away itself? The servos I using 180* rotation, don't go way around loop. also: don't know important not, peculiar construction foot, would best lifted straight up, rather angle, isn't 100% necessary. Are robots already this? so, I'm unaware them. Thanks time.",mechanism motion-planning servomotor legged gearing
8510,What approaches indoor robot positioning?,I understand self-driving cars solutions based Lidar video SLAM. But robots reserved indoor usage? Like robot vacuums industrial AGVs? I see Lidar used iRobot latest version uses VSLAM. AGVs also seem use Lidar.,slam lidar
8511,What engineering problems needs solved build potato-peeling robot?,"OK, let's say tech request robotic system peeling potatoes, design follows: One ""arm"" picking potato holding it, rotating needed. Another ""arm"" holding knife-like something peel skin potato. Arm picks potato first container, holds trash bin peeling, puts peeled potato second container. For simplicity human rinses peeled potatoes, need build automatic system it. In first iteration even 100% spherical peeled potatoes OK, ideally would good peel little possible, minimize wastes. Question: I know we're very, far away building system. Nevertheless, purely technical difficulties needs solved robot built? EDIT Let's assume stick design invent something radically different, like solving problem chemistry dissolving skin something. I know problem peeling potatoes currently solved means - mainly applying friction lot water. This question it. I asking specifically problems solved two-arms setup using humanlike approach peeling.",robotic-arm
8512,How connect absolute encoder rotating shaft. Please see three options?,"Hi, Here I added 2 options connecting encoder shaft. Motor, gearhead shaft connected using coupling. But best place encoder (To avoid backlash coupling gearhead). whether hollow encoder available? (see option 1). I dont know one best kind system. Which one widely using arrangements? Options 3 Encoder placed motor.",motor
8516,"Getting pitch, yaw roll Rotation Matrix DH Parameter","I've calculated DH Parameter matrix, I know top 3x3 matrix Rotation matrix. The DH Parameter matrix I'm using below, Above I'm using. From I understand I'm rotating around Z-axis X-axis, explanations extracting Euler angles Rotation matrixes deal 3 rotations. Does anyone know equations? I'd thankful help.",kinematics forward-kinematics dh-parameters
8519,"Fanuc Robot ""Heat"" control","My work older Fanuc robot ( Arc Mate 100-iBe RJ3iB, Fanuc AWE2 teach pendant Powerwave 355M) old operator/programmer left. I taken job cant find turn voltage wire feed speed occasionally burns parts. I tried manually putting voltage wire feed speed seems accept previous weld schedules 1-8 mess affect programs using those. I need someone please point right direction. P.S. Typed phone , sorry sloppy.",industrial-robot
8522,Recommendation 3D mechanism modeling simulation software,"I'm working robotic hand I would like simulate different joints tendon insertion points starting actually build it. I've googling found things like Solidworks Autodesk, seem costly hobbyst like also I don't quite fully understand capabilities (just CAD? 3D modelling simulation? Simulation interactive?). I've also found things like FreeCAD seem somehow abandoned CAD simulation. Another requirement would interactivity simulation, rendering. I don't problem commercial software, I'm looking reasonable cost hobbyst, engineering company. Is software meets requirements? Or I use several programs specific purpose? Thanks!",design mechanism software simulator 3d-model
8525,Quadrocopter problem stability,"I'm building quadcopter scratch, software implemented STM32F4 microcontroller. Frequency main control loop equals 400Hz. I've though everything almost finished i've mounted everything started calibration PIDs faced problem. It impossible adjust PID parameters properly. So started test lower power (not enough fly) i've managed quite fast adjust PID roll i've increased power problems control came back. After i've done measurements. I didn't make test blades probably even worse cannot calibrate it. If problem due vibration fix it? If something else cause symptom, it? Can solve better controls data fusion algorithms? Now use complementary filter acc gyro sensors data fusion roll pitch.",control imu accelerometer gyroscope
8526,Which USB interface Android device I use motor driver,"I new robotics, I controlling DC motors Android device USB For I selected L298N motor controller(After watching YouTube videos ) And got DC motors I idea I connect Android device via USB cable Help appreciated Ref: PS: All I know programming android",motor usb
8527,Which brushless dc propeller choose?,I small bot(around 4-5kg wheels) pushed without contact another bot. I plan using bru propeller. I problems selecting right combination. Please help questions:- Should bldc high kv low kv(will need high rpm low rpm) What ideal propeller use motor create enough thrust get 'small' bot motion keep motion? What criteria keep mind selecting.,brushless-motor
8538,Setting gimbal Dji Wookong-M using separate transmitter receiver,I bought Wookng-M multi copter I wondering possible two man system one controls main craft one transmitter controls camera Gimbal another transmitter. I know set gimbal Wookong-M I wasn't could use separate transmitter control even control all. I also waiting 3-axis GoPro gimbal arrive I even control pan I control gimbal completely separate use Wookong-M gimbal camera. I beginner 1st time working Wookong-M please keep answers understandable. Thanks Advance,quadcopter
8539,How I increase resolution PWM signal?,Say I motor I want spin exactly 2042.8878 revolutions per minute. Say I precise sensor detect RPM motor resolution 1/1000th revolution per minute. Can I produce PWM signal match speed degree precision? What variables signal parameters would I adjust get precision possible? Would I use additional circuitry motor driver? Would I design signal/circuitry around specific specifications motor? Should I use stepper motor? This assuming I using microcontroller measure motor's speed adjust signal real-time maintain certain speed.,motor microcontroller stepper-motor pwm stepper-driver
8544,Pole-balancing / inverted-pendulum; need active control?,"Not sure I posting question correct community, relates primarily reinforcement learning. Apologies early so. In reinforcement learning many algorithms exist 'solving' cart-pole problem; balancing mass edge stick, connected cart hinge, 1 DoF. There TD learning, Q-learning many off-policy methods. There also recent, model-based policy search method PILCO. What I really wondering, I suppose physics question: need active control? Why possible find one point cart, prevents mass move, even incrementally, left right sits atop pole? Why always 'fall'?",control
8546,Modelling Point Clouds Collision Detection Gazebo,"I currently applying path planning robotic arm (in Gazebo) chosen use RRT. In order detect points collision, I thinking getting Point Cloud Kinect subscriber feeding something like Octomap collision map I could import Gazebo. However, Gazebo plugin import Octomap files I enough experience write own. The next idea would instead feed point cloud mesh generator (like Meshlab) turn URDF, starting I'd rather get input somebody far experienced. Is right way go? Keep mind environment static, things moving arms. Thank you. Below picture octomap.",robotic-arm localization slam kinect gazebo
8549,DH parameters Kinematic Decoupling,Is possible decouple 5DOF manipulator? This question I asked earlier I believe I got right answers I never show drawings manipulator I'm hesitating setup DH parameters Forward Kinematics. See drawing depicted here.,kinematics forward-kinematics dh-parameters
8555,Which trajectory planning algorithm minimizing jerk,"In order perform cyclic task, I need trajectory planning algorithm. This trajectory minimize jerk jounce. When I search trajectory planning algorithms, I get many different options, I haven't found one satisfies requirements terms values I specify. An extra complicating factor algorithm used online system without much computing power, mpc algorithms possible... The trajectory I planning 2D, stripped 2 trajectories 1 dimention each. There obstacles field, bounds field (minimum maximum values x y) Values I able specify: Total time needed (it reach destination specific time) Starting end position Starting end velocity Starting end acceleration Maximum values position. Ideally, I would also able specify bounds velocity, acceleration, jerk jounce, I comfortable generating trajectory, checking values exceeded. Which algorithm that? So far I used fifth order polynomials, checking limits velocity, acceleration, jerk jounce afterwards, I cannot set maximum values position, problem... Thank advance!",control algorithm
8556,Length Width Line Following Robot,"I'm building line following robot. I made different chassis designs. The main prototype I'm using rectangle base. At one side motors placed. On side rectangle caster wheel placed middle. Look following image. By varying values , I seen stability robot varying rapidly. I'm driving robot using PID. I seen chassis designs hard(sometimes impossible) calculate correct constant values. And chassis easy. By word stability I meant this. I feeling robot dimensions, distance values stability relationship.. Is equation something used estimate value distance width robot known..? Other relationship robot weight diameter wheel robot dimensions diameter..? Thanks attention!!",arduino motor pid line-following
8559,Is possible design robot software AI function different devices?,"i'm really interested robotics.. I'm really robot expert experience creating one. I like them. Anyway, I always wondering possible build robot transfer different devices still function. I mean, want robot transfer itself(THE DATA making function whatever call it) laptop still use away anything.. Does creating one require advanced computing knowledge? Is kind creating artificial intelligence?. When think would always thought J.A.R.V.I.S since go Stark Suit communicate him. Translated robotics terminology roboticist: Is possible create software controlling robot hardware transfer different devices still function. Could transfer laptop collaborate using information gathered it's robot body? Does creating software like require advanced knowledge computing? Is software like considered artificial intelligence? I serious question sorry bother anyone annoyed./",mobile-robot
8561,Is Venetian mirror possible Autodesk Inventor?,I see things like glass mirror Autodesk Inventor Professional 2016 possibility Venetian mirror? So one side would look like mirror side would look like transparent glass?,design mechanism 3d-printing 3d-model visualization
8562,Humanoid balancing,"I'm currently working Humanoid robot. I've solved Forward & Inverse Kinematic relations robot, turn fine. Now I want move onto Walking. I've seen tons algorithms & research papers none make idea clear. I understand concept ZMP & method tries do, I simply can't get head around details required implement real robot. Do I plan gait & generate trajectories beforehand, solve joint angles, store somewhere & feed motors real-time? Do I generate everything run-time(a bad Idea IMO)? Is step-by-step procedure I follow get job done? Do I crawl way Research papers, never make sense(at least me).",mobile-robot stability humanoid
8565,velocity link (i+1) respect frame (i+1),"I read several textbooks could find good explanation. Can anybody tell velocity link (i+1) respect frame (i+1) zero? My argument is: Since velocity link (i+1) velocity origin frame (i+1) zero respect itself. !from ""Introduction Robotics Mechanics Control""",kinematics forward-kinematics
8570,Calculate robot heading follow wall avoid obstacles,"I task involves implementing robot behaviour follow wall avoid obstacles along it's path. The robot must stay desired distance wall also stick loose sight it. Robot sensing it's surrounding ultrasonic sensor oscillating left right filling array small length (10 values) detected distances (every 10 degrees). From reading I would like calculate heading vector result robot path similar one shown bottom picture: Black(walls), red(obstacles), blue(robot), green(desired path)",wheeled-robot navigation
8575,PID tuning 6 dof robotic arm,"I'm currently developing 6 dof robotic arm. The arm vibrating stop moving I want reduce it. Another thing arm heavy (because projector inside it, lol) I use spring joints. So, anyone tell 1. select springs supervisor told proper selection springs reduce vibration? 2. I tune PID parameters? All joints dynamixel servos PID parameters tunable. I read article tuning single servo. How I tune parameters whole arm?",control pid robotic-arm
8579,Change PWM values according encoder output,"I motor encoder. When I set speed motor change speed encoder readings per second fit equation $y = ax^2 + bx + c$ speed value given motor encoder readings per second get motor. Encoder reading counted every 1ms equal value encoder output get motor (it calculated using equation), PWM input motor vary in-order get desired encoder output. I want control value using PID controller I'm confused writing equations. Any help would appreciated..",motor pid pwm
8580,Arduino Power Adapters,"I'm shopping first Arduino specific goal mind. I need attach 3 standard servo motors, ArduCam Mini 2MP camera, several LEDs. I'm trying figure power requirements. I assume USB power won't sufficient. I'm looking 12V AC-to-DC outlet adapters I noticed Amps vary ~500MA 5A. I don't want use batteries. What would recommend minimum amperage setup? Is maximum amperage Arduino boards? I don't want plug burn out. If I plug USB cable power adapter time, power drawn cables? Thanks!",arduino power
8585,ROS Kinect data without callbacks,"I'd like get rgb depth data kinect, I found little tutorial here: . It's fine, I'd like able get data demand, whenever callback triggered, assuming I won't try get data faster available. I'd appreciate help - go easy ROS jargon, I'm still learning...Thanks.",ros kinect
8586,How I measure actual speed distance traveled robot external setup?,"Good day all. First all, I'd like clarify intention question solve localization problem popular robotics. However, purpose gather feedbacks actually measure speed robot external setup. The purpose able compare speed robot detected encoder actual speed, detected external setup. I trying measure distance traveled speed robot, problem occasionally experiences slippage. Therefore encoder accurate kind application. I could mark distance measure time robot reach specified point, I would work stopwatch transfer data Excel analyzed. Are ways it? It would great external setup allow data automatically sent directly software like Matlab. My concern hardware side. Any external setup sensors devices help achieve this? Thanks.",mobile-robot control wheeled-robot
8590,How I measure height object single sharp sensor (GP2Y0A21YK0F)?,I one sharp sensor I use measure height block (6cm - 12 cm). How I accomplish ? Actually connected robot move near box determine height. About GP2Y0A21YK0F: The robot like this: If possible please suggest solution doesn't require moving sensor. But method fine.,mobile-robot first-robotics
8592,Manipulator end-effector orientation quaternions,"I following problem: Given 3 points surface, I adjust manipulator end-effector (i.e. pen) Baxter Robot, normal surface. From three points I easily get coordinate frame, well normal vector. My question now, I use tell manipulator supposed orientation. The Baxter Inverse Kinematics solver takes $(x,y,z)$-tuple Cartesian coordinates desired position, well $(x,y,z,w)$-quaternion desired orientation. What I set orientation to? My feeling would use normal vector $(n_1,n_2,n_3)$ $0$, I calculation?",inverse-kinematics orientation
8595,"In order integrate MCL Occupancy Grid implement Grid-based FastSLAM, record data?","It's unclear one goes integrating Occupancy Grid mapping Monte Carlo localization implement SLAM. Assuming Mapping one process, Localization another process, motion generating process called Exploration exist. Is necessary record data sequenced time stamps coherence? There's Motion: $U_t$, Map: $M_t$, Estimated State: $X_t$, Measurement: $Z_t$ so.. Estimated state, $X_t$, function current motion, $U_t$, current measurement, $Z_t$, previous map, $M_{t-1}$; confidence weight, $w_t$, estimated state function current measurement, $Z_t$, current estimate state, $X_t$, previous map, $M_{t-1}$; current map, $M_t$ function current measurement, $Z_t$, current estimated state, $X_t$, previous map, $M_{t-1}$. So question is, proper way integrating mapping localization processes? Is something record timestamp sequences? Are suppose record data, like FullSLAM, maintain full history. How verify sequenced time referred current (i.e. measurement) previous (measurement).",slam occupancygrid
8596,What picture/data tell?,"I've implemented model ball-on-plate plant controlling network. Below open loop output excited successive sinusoidal inputs increasing frequencies. I know plant open loop unstable, cool figure nicely captures instability. What I'd like know information I glean plant relationship input output state. (The state clipped 3.1 units.)",control balance distributed-systems
8598,Comparison lifting systems,"What kind systems used make torso lifting system like one used robot (the black part) : Rack pinion lead screw scissor lift triple tree help ? What pro cons system ? How ensure stability ? And finally, way draw current lowering instead drawing current lifting ?",mechanism
8600,ROS + kinect depth data duplication,"I trying get depth data Kinect ROS project. It currently looks like this: To arrive this, I've done: I also launch openni.launch openni_launch package, publishes depth data. I also get weird warning node (can seen image): ComplexWarning: Casting complex values real discards imaginary part. But I understand data type array 32-bit floats. Yet values appear nan. I would like depth image directly corresponds RGB image array size. I tracking RGB space, using tracked coordinates (X,Y) index depth array. Thanks. edit: Turns out, /camera/depth/image published array uint8s, actual data 32bit floats (which listed anywhere, hunt people's code). Thus array 480x640 uint8s, interpreted 32bit floats, effectively ""quartered"" number data points. Which could explain image 4 times smaller (and hence accessing datapoints bounds = nan?), two them.",ros kinect
8601,Choosing proper sampling time PID controller,"I robotic system I'm controlling Arduino, heuristic way determine proper sampling time PID controller? Considering I things compute sketch require time, course good sampling time crucial. Basically I distance sensor needs detect constant rate object moving, sometimes slow, sometimes fast. I don't good model system I can't actually tell physical frequency system.",pid
8605,Mechanical robustness/shock resistance LiPo batteries,"How mechanically robust LiPo batteries? How much force acceleration maximally withstand failure? What (mechanical) shock resistance? For electrical components used robots, IMU's, found datasheets suffer mechanical failure accelerated loaded beyond given values. For IMU's, typically somewhere $2000g$ $10000g$ (where $1g = 9.81 m/s^2$). I'm wondering similar values known LiPo batteries, since known vulnerable components. But, quantification known claimed vulnerability?",battery
8607,Open source implementations GPS+IMU sensor fusion?,"Are Open source implementations GPS+IMU sensor fusion (loosely coupled; i.e. using GPS module output 9 degree freedom IMU sensors)? -- kalman filtering based otherwise. I find open source implementations IMU sensor fusion merge accel/gyro/magneto provide raw-pitch-yaw, haven't found anything includes GPS data provide filtered location speed info.",kalman-filter imu sensor-fusion gps
8611,IPhone controlled RC car,I R.C car program computer I code car perform movements.I would like application visual design.Where shows cars path. Is available software code this? Saves lots time.,software research
8612,Combustion engine controlled remote,How one control combustion engine using remote control. Or would make car controlled using remote.,robotic-arm first-robotics
8617,What $\alpha \sin(\theta) + \beta \frac{d \theta}{d t}$ inverted pendulum problem?,"I preparing exam neural networks. As example self-organizing maps showed inverted pendulum problem want keep pole vertical: Now part I don't understand: $$f(\theta) = \alpha \sin(\theta) + \beta \frac{\mathrm{d} \theta}{\mathrm{d} t}$$ Let $x= \theta$, $y=\frac{\mathrm{d} \theta}{\mathrm{d} t}$, $z=f$. Solution SOM: three-dimensional surface $(x,y,z)$ adapt two-dimensional SOM surface Method control For given $(x,y)$ find neuron $k$ wich $w_k = [w_{k1}, w_{k2}, w_{k2}, w_{k3}]$ $f(\theta)$ $w_{k3}$ I guess use SOM learn function $f$. However, I would like understand $f$ comes / means model.",control stability machine-learning
8618,Does C advantages C++ robotics?,"I want build robots, right I aim work Arduino boards I know compatible c c++, wondering language better robotics general? I know write java, fact c++ object oriented makes look like better choice c advantages c++?",arduino c++ c
8621,Forward kinematic computing transformation matrix,"I moment trying compute transformation matrix robot arm, made 2 joints (serial robot arm), I issues. L = 3, L1 = L2 = 2, q = ($q_1$,$q_2$,$q_3$) = $(0 , \frac{-\Pi}{6},\frac{\Pi}{6})$ Based information I compute forward kinematic, calculate position joint. Problem though, I compute angle around x,y,z.. transformation matrix. Using sin,cos,tan course possible, angle corresponds? axis correspond to? I tried using @SteveO answer compute $P_0^{tool}$ using method provided answer, I somehow mess something, value doesn't resemble answer given example..",kinematics forward-kinematics orientation
8631,IMU sensor compensation,"Hi I'm using ""minImu 9"" 9 DOF IMU (gyro, accelerometer compass) sensor gives pitch roll yaw values slope desktop (no touch, vibration, steady). Y axis angle degree X axis time second. X axis length 60 seconds. How fix this? Pitch Roll Yaw Note1: minIMU code",sensors imu sensor-fusion
8636,sum_error PID controller,"I'm trying implement PID controller I've question sum_error I control. Here short code based PID theory. Now, I start commands: Phase 1, If t=0, I set target=1.0, controller begins drive motor go target=1.0, Phase 2, then, t=N, I set target=2.0, controller begins drive motor go target=2.0 My question is, beginning phase 1, error=1.0, sum_error=0, phase 1, sum_error zero anymore, it's positive. And beginning phase 2, error=1.0 (it also above), sum_error positive. So, iTerm t=N much greater iTerm t=0. It means, curves phase 2 phase 1 different!!! But end-user, command 1, command 2 almost same, drive effort. Should I set sum_error zero bound it? Can anyone tell handle sum_error typical? Any comment much appreciated!! Kevin Kuei",pid
8642,Discontinuity device orientation,"Why discontinuity quaternion representation device orientation? I'm using SENtral+PNI RM3100+ST LSM330 track orientation. I performed following test: Place device center horizontal rotating plate (""lazy susan""). Pause seconds. Rotate plate 360° clockwise. Pause seconds. Rotate plate 360° clockwise again. I got output, appears discontinuous sample #1288-1289. Sample #1288 , sample #1289 (Qx,Qy,Qz,Qw) = (0.7079, -0.6969, -0.0807, 0.0818). Plugging formulas page 32 document, corresponds change orientation (Heading, Pitch, Roll) = (108°, 0°, 142°) (Heading, Pitch, Roll) = (-89°, 0°, 83°). The graph (Heading, Pitch, Roll) also continuous mod 90°. Does output make sense? I expect discontinuity first plot, since unit quaternions covering space SO(3). Is hardware problem, I interpreting data incorrectly? Edit: The sensor code central.c main.c. It read Python script.",sensors calibration orientation
8644,Is RobotBASIC outdated?,"I found website talks language used programming things related robotics, I want make sure whether it's worth investing time energy compared languages I wipe browser bookmarks good. Nowadays, better languages methods going things talks about? I mean, site looks pretty old, like something late 90s pre-2010, plus I never heard anywhere except site, I wonder it's relevant ever was.",control software
8654,Finding cubic polynomial equation 3 joints,"My professor gave us assignment find cubic equation 3-DOF manipulator. The end effector resting A(1.5,1.5,1) moves stops B(1,1,2) 10 seconds. How would I go this? Would I use Jacobian matrix would I use path planning coefficient matrix solve problem. I'm assuming coefficient matrix I given original position angle form. I taught use path planing original angles given.",motion-planning inverse-kinematics motion jacobian
8657,P gain tuning quadcopter (Is perception P-gain high correct?),"Good day, I currently working project using Complementary filter Sensor fusion PID algorithm motor control. I viewed lot videos youtube well consulted various blogs papers expect setting P gain high low. P Gain low easy correction easy turn hand P Gain high oscillates rapidly I sample video I think high P gain (3 case) looks like. Do look like P gain high? From video: I noticed quad sometimes corrects orientation immediately turning degrees (4-5 deg). However, consitent manner. It also overcorrects. The reason behind doubt quadcopter doesn't react immediately changes. I checked complementary filter. It updates (fast) filtered angle reading sudden angular acceleration gyro well updates long term filtered angle changes accelerometer (albeit slowly). If I right, P gain responsible compensating ""delay""? The formula I used complementary filter following: Here video P gain 1: Your help would appreciated :)",quadcopter pid sensor-fusion tuning filter
8661,Calculating required torques given trajectory using Lagrange-Euler,"I 2DOF robot 2 revolute joints, shown diagram below. I'm trying calculate (using MATLAB) torque required move answers don't match I'm expecting. Denavit-Hartenberg parameters: $$ \begin{array}{c|cccc} joint & & \alpha & & \theta \\ \hline 1 & 0 & \pi/2 & 0 & \theta_1 \\ 2 & 1 & 0 & 0 & \theta_2 \\ \end{array} $$ I'm trying calculate torques required produce given acceleration, using Euler-Lagrange techniques described pages 5/6 paper. Particularly, $$ T_i(inertial) = \sum_{j=0}^nD_{ij}\ddot q_i$$ $$ D_{ij} = \sum_{p=max(i,j)}^n Trace(U_{pj}J_pU_{pi}^T) $$ $$ J_i = \begin{bmatrix} {(-I_{xx}+I_{yy}+I_{zz}) \over 2} & I_{xy} & I_{xz} & m_i\bar x_i \\ I_{xy} & {(I_{xx}-I_{yy}+I_{zz}) \over 2} & I_{yz} & m_i\bar y_i \\ I_{xz} & I_{yz} & {(I_{xx}+I_{yy}-I_{zz}) \over 2} & m_i\bar z_i \\ m_i\bar x_i & m_i\bar y_i & m_i\bar z_i & m_i \end{bmatrix} $$ As I trouble I've tried create simplest example I'm still getting wrong. For I'm attempting calculate inertial torque required accelerate $\theta_1$ constant 1 ${rad\over s^2}$. As $\theta_2$ constant 0, I believe remove gyroscopic/Coriolis forces. I've made link 1 weightless pseudo-inertia matrix 0. I've calculated pseudo-inertia matrix link 2: $$ I_{xx} = {mr^2 \over 2} = 0.0025\\ I_{yy} = I_{zz} = {ml^2 \over 3} = 2/3 $$ $$ J_2 =\begin{bmatrix} 1.3308 & 0 & 0 & -1 \\ 0 & 0.0025 & 0 & 0 \\ 0 & 0 & 0.0025 & 0 \\ -1 & 0 & 0 & 2 \\ \end{bmatrix} $$ My expected torque joint 1: $$ T_1 = I\ddot \omega \\ T_1 = {ml^2 \over 3} \times \ddot \omega \\ T_1 = {2\times1\over3}\times1 \\ T_1= {2\over3}Nm $$ The torque calculated code joint 1: $$ T_1={4\over3}Nm $$ So problem, code $T_1$ doesn't match simple mechanics $T_1$. The key functions called shown below. function inertial_torque_n = calc_inertial_torque(n, T, J, qdd) inertial_torque_n = 0; j = 1:2 Mnj = 0; joint_accel = qdd(j); = 1:2 Uij = calcUij(T, i, j); Ji = J(:,:,i); Uin = calcUij(T, i, n); Mnj = Mnj + trace(Uin*Ji*transpose(Uij)); end inertial_torque_n = inertial_torque_n + Mnj * joint_accel; end end function U=calcUij(T,i,j) T(:,:,j) = derivative(T(:,:,j)); U = eye(4,4); x = 1:i U = U*T(:,:,x); end end function T = derivative(T) dt_by_dtheta = [0 -1 0 0 1 0 0 0 0 0 0 0 0 0 0 0]; T = dt_by_dtheta*T; end I realise fairly simple robot, complicated process - I'm hoping scale DOF I'm happy works.",dynamics matlab torque
8663,How program NXT brick always hit ball?,"I using mindstorm robot NXT brick, using graphical interface create program. Part course robot take includes black line white background. At end line gap, gap semi circular line. There ball robot hit soon robot crosses gap. The robot small code follow black line certain amount time, enough time stops gap. The robot runs forward 1 second across gap, robot swings arm hit ball, I code line-following again. However, crosses gap, robot stops different place every time, arm usually misses ball. Is possible program robot hit ball every time/almost every time GUI? Among things I tried using ultrasonic sensor detect ball, sensor pick up.",nxt mindstorms
8665,Color sensor alternatives,"I making white line follower. I using IR sensor module based TCRT5000. I directly taking 8bit ADC reading Arduino Uno printing values serial monitor. I observe values white around 25-35, ok. The problem arises I try detecting Orange (158C) surface. The sensor gives values close white around 25-40. I use color sensor bulky I sure I get readings faster since take finite time sampling 'R','G' 'B' pulses. Can someone please tell alternate approach detecting colours possible solution problem. EDIT: I would like add line I wish follow 3cm width. Hence I plan use three sensors. Two outside line either sides one exactly centre. The sampling frequency Arduino UNO around 125KHz. Sampling IR issue quick using color sensor takes lot time.",sensors line-following
8667,Visual servoing - tracking point,"I trying resolve issues inverse kinematics. robot arm using camera end it, object tracked. I camera frame retrieve position, relative frame convert position frame, robot state, set joint manner camera keep object center frame?... -- My approach -- From image analysis retrieve position object tracking positioned => (x,y) - coordinate. I know time position (a) end tool T_base^tool - matrix, image analysis know position (b) object relative camera frame compute difference c = b - a. I compute image jacobian, given C, distance object focal length camera. So... thats moment.. I sure whether position change retrieved cam frame seen position tool point, equation become un undetermined length state vector would become 7 instead 6. The equation must $$J_{image}(q)dq = dp$$ J_image(q)[2x6]: image jacobian robot current state q dq[6x1]: wanted change q-state dp[2x1]: computed positional change... Solution would found using linear least square.. don't get robot appearing equation, let doubt approach..",inverse-kinematics visual-servoing
8670,Robotic Manipulator,"I started working robotic manipulators got project deals control robotic manipulator using artificial neural networks (solution inverse kinematics trajectory generation, precise!). Can someone please suggest start I prior knowledge robotic manipulator ANN code them?",arduino robotic-arm inverse-kinematics machine-learning
8671,Is RoboCup still vivant significant robotic issue?,"A couple years ago RoboCup competitions seems quite vivant issue. Now I'm looking info it, seems kind insignificant may first impression (I looking 2D simulator league seems even exist anymore). So RoboCup still alive significant robotic issue?",soccer
8673,Is .NET library conveyor belt automation?,I'm software developer I work company I think could use automation warehouse. I thought would fun put together prototype conveyor system automates manual sorting process warehouses. I'm primarily .NET developer I'm wondering .NET SDK conveyor automation. Any information start would helpful main question here.,automation
8680,calculating position based accelerometer data,"Please help following task. I MPU 9150 I get acceleration/gyro magnetometer data. What I'm currently interested get orientation position robot. I get position using quaternions. Its quite stable. Rarely changes staying still. But problem converting accelerometer data calculate displacement. As I know required integrate twice accel. data get position. Using quaternion I rotate vector acceleration sum it's axises get velocity get position. But doesn't work way. First moving sensor position moving back doesn't give position before. The problem I put sensor back stays without movement velocity doesn't change zero though acceleration data coming sensors zeros. Here example (initially like this): gravity: -0.10 -0.00 1.00 raw accel: -785 -28 8135 accel scaling +-g: -0.10 -0.00 0.99 result rotating accel vector using quaternion: 0.00 -0.00 -0.00 After moving sensor putting back it's acceleration becomes as: 0.00 -0.00 -0.01 0.00 -0.00 -0.01 0.00 -0.00 -0.00 0.00 -0.00 -0.01 on. If I'm integrating I get slowly increasing position Z. But worst problem velocity doesn't come back zero For example I move sensor put back velocity at: -0.089 vx 0.15 vy After several movements becomes: -1.22 vx 1.08 vy -8.63 vz another movement: vx -1.43 vy 1.23 vz -9.7 The x doesnt change sensor moving Z changing slowly. Though quaternion changing all. What correct way task? Here part code integrations: Currently set speed 1 test works. EDIT 1: Here code retrieve quaternion accel data, rotate compensate gravity get final accel data. // display initial world-frame acceleration, adjusted remove gravity // rotated based known orientation quaternion mpu.dmpGetQuaternion(&q, fifoBuffer); mpu.dmpGetAccel(&aaReal, fifoBuffer); mpu.dmpGetGravity(&gravity, &q); //Serial.print(""gravity\t""); Serial.print(gravity.x); Serial.print(""\t""); Serial.print(gravity.y); Serial.print(""\t""); Serial.print(gravity.z); Serial.print(""\t""); //Serial.print(""accell\t""); Serial.print(aaReal.x); Serial.print(""\t""); Serial.print(aaReal.y); Serial.print(""\t""); Serial.print(aaReal.z); Serial.print(""\t""); float val = 4.0f; float ax = val * (float)aaReal.x / 32768.0f; float ay = val * (float)aaReal.y / 32768.0f; float az = val * (float)aaReal.z / 32768.0f; theWorldF.x = ax; theWorldF.y = ay; theWorldF.z = az; //Serial.print(""scaled_accel\t""); Serial.print(ax); Serial.print(""\t""); Serial.print(ay); Serial.print(""\t""); Serial.print(az); Serial.print(""\t""); theWorldF.x -= gravity.x; theWorldF.y -= gravity.y; theWorldF.z -= gravity.z; theWorldF.rotate(&q); //gravity.rotate(&q); //Serial.print(""gravity_compensated_accel\t""); Serial.print(theWorldF.x); Serial.print(""\t""); Serial.print(theWorldF.y); Serial.print(""\t""); Serial.print(theWorldF.z); Serial.print(""\t""); Serial.print(deltaTime); Serial.println(); EDIT 2: dmpGetQuaternion, dmpGetAccel functions reading FIFO buffer MPU. dmpGetGravity is: uint8_t MPU6050::dmpGetGravity(VectorFloat *v, Quaternion *q) { v -> x = 2 * (q -> x*q -> z - q -> w*q -> y); v -> = 2 * (q -> w*q -> x + q -> y*q -> z); v -> z = q -> w*q -> w - q -> x*q -> x - q -> y*q -> + q -> z*q -> z; return 0; } EDIT 3: library using MPU 9150: EDIT 4: Another example gravity vector: -1.00 -0.02 0.02 raw accel data: -8459 -141 125 accel data scaled (+-2g range): -1.03 -0.02 0.02 gravity compensation rotation accel data: -0.01 0.00 0.33",accelerometer algorithm
8684,Is way use stress-ball-like device acceleration control interface,"I thinking project proposal robotics course required make one potential application physical therapy medical fields. One thing came across mind motorized wheelchair moves stress ball control squeezed user. As robotics novice, I wonder I could integrate sensor circuit rubber ball pressed, perhaps stroke patient, triggers driver circuit. possible? so, how? My experience robotics limited arduino, servo motors basic sensors.",wheeled-robot
8686,increase current draw serial port icreate 2,"This icreate 2's document: ""Pins 1 2 (Vpwr) connected Roomba battery 200 mA PTC resettable fuse. The continuous draw two pins together exceed 200 mA. Do draw 500 mA peak pins, fuse reset."" My project need draw bit number. So anyway disable - short circuit - fuse replace fuse bigger one? fuse reside bot's circuit board? If 2 possible (because fuse embedded inside chip difficult access example), safe run small wire battery pole pin pass fuse? I know I run wire directly battery pole circuit draw power motor wires, I love running serial port keep things simple.",power irobot-create serial
8689,How I know quad powerful enough take vertically smoothly I calculate max Thrust(g) given current(A) voltage(V)?,"If I build quadcopter following components, take vertically smoothly? Frame: F450 glass fiber polyamide nylon [280g] Landing Gear: High Landing Gear F450 [90g] Battery: 3000mAh 20C (30C burst) 3s/1p [260g] Motor: XXD A2212 1400KV brushless outrunner motor [4x50g] ESC: 30A (40A burst) Brushless BEC - 2A/5V [4x25g] Prop: 1045 Propeller set Assume total weight quad ~1.1Kg I would like payload upto 400g, making quad weigh ~1.5Kg From I've learnt, Thrust:Weight ratio never fall 1.7:1 (and 2:1 recommended better control) creates problems lifting quad vertically smoothly. I'm neither planning high maneuverability cruise sky pushing quad's limits. I want fly. Here's motors pull(g)-amps(A)-voltage(V)-power(W)-specificThrust(g/W) information A2212 1400kv 10 x 4.5 Props Since battery's discharge rate limited 20C, I'm wrong, give 60A (since 3000mAh) entire circuit four motors, take 15A max, table would produce ~600g thrust, 2400g four motors. Does mean I get 1.6:1 Thrust:Weight 100% throttle? Can quad still take vertically smoothly? I'm also confused efficacy motor, meaning I buy bigger motor, get 600g thrust 15A/11.1V same/bigger props? If not, efficient combination motor prop? If yes, maximum thrust (practical pulling force g, N) I get outta 15A/11.1V? Which equation tells defines exact relation, provided I fly quad usual conditions (1013hPa/25degC extTemp/80%-90% relHumidity/max15mAlti)? PS: I tried ecalc, Prop Power Thrust Efficiency Calculations, online stuff. Update: Will replacing 3000mAh-20c/30c battery 5000mAh-20c/30c 3s1p keeping everything solve problems increase flight time, provided I keep everything else same?",quadcopter brushless-motor battery lithium-polymer
8692,What max thrust 30W brushless motor produce? Can produce 300g?,"newbie, got 30W motor here, They claim 300g thrust,however compaired motors like hobbyking, motor seems good ((power input )/thrust) ratio. could true? Besides,esc 6 amp (30/7.4) seems sufficient,why recommend 20amp? Also,what max thrust get motor w.r.t. power consumed decent price.",quadcopter brushless-motor
8693,How perform odometry arduino differential wheeled robot?,"I using differential wheel robot project. I need know current coordinates robot respect it's initial position taken origin. I computation Arduino UNO sensory input I get two encoders. I function updateOdomenty() called loop() it's corresponding code: This code team mates made reading paper. I wondering best possible way solve problem Arduino. If not, odometry done differential wheeled systems?",arduino kinematics odometry differential-drive
8698,What exactly PPM controlled ESCs? Are ESCs available build quadcopters PPM Controlled?,"First, I don't see manufacturer online store telling whether ESC PPM controlled not. Second, I also Googling asking comments ESCs youtube videos long, I couldn't find anything useful. Why I need PPM controlled ESCs? I'm project based AndroCopter clearly mentioned specifically requires use PPM controlled ESCs. Can I use ESCs available market project? It's also mentioned Github repo PPM controlled ESCs common ones. However explained ESCs Youtube video commented back doubt telling common ESCs PWM controlled contradicting previous statement. PS: I need use Arduino Mega control four ESCs. And Arduino Mega programmed send PPM signals exactly I need PPM controlled ESCs. Correct I made mistakes.",arduino quadcopter esc
8700,inverse kinematics osciliations..,"I moment issues Jacobian going towards singularity (i think)as values becomes close zero, robot oscillates, therefore thought form optimization linear least square solution needed. I heard interior point method, I sure apply here. My equation this.. J(q)dq = du How would implement optimization, would needed?",inverse-kinematics c++
8702,Malfuction motors using L298N,"I purchased undermentioned robot chassis DC motors supported plastic gears local store. There 3A battery holder I connect robot put ground motors working fine smooth. But I connect L298N motor controller made tested proteus, one motor working. When I switch wires motors, still motor worked working motor never runs unless I manually give little rotation wheel. I use PIC18F4431 control motor controller tried USB power 5V regulator created result occasions. What could issue here? If I tried oiling malfunctioning motor work? I heard one friends issue, one motor working. But motors work two pen torch batteries can't think valid reason motor faulty. May motor controller? But I swap wires faulty working one, working one still works I've mentioned above.",mobile-robot
8703,PixHawk Naza M V2 Aerial Imaging Small Study Area Hexacopter,I project going involve capturing ~80 images 35m x 50m agricultural study area image processing. I wondering whether use NAZA v2 PixHawk controller outfit ship (on DJI F550 Flamewheel airframe). My understanding Naza limited far amount waypoints I particular mission. Can I break imaging mission 8 10 sub-missions? I also understand PixHawk many ways superior getting running finicky - I limited time frame project.,gps uav radio-control
8704,Using another device instead RC transmitter,"I want make pc controlled quadrotor. All tutorials/projects made rc receiver. I want use arduino xbee instead rc receiver pc control quadrotor. How I this. Note: I arduino, beaglebone, xbee, hc-05, KK2 multiwii parts.",pid quadcopter
8705,Problem HC-SR04 sensor,"I three HC-SR04 sensors connected PIC18F4431 schematic provided below. Before building PCB I've tried testing three sensors bread board worked fine. But I PCB I connect tried testing, work seconds stop working. I set timers set LEDs lit item 40cm sensor. As I've tried bread board, I cross arm withing range, appropriate bulbs lit I take arm bulbs lit. But using PCB, I upload code PICKIT2 work fine seconds freeze. If I reset MCLR pin works another seconds freeze again. And sometimes randomly I touch receiving part sensor works happens randomly. Not always working. What could issue? Is oscillator burnt I soldering it? Once I connected two 0.33uF polar capacitors found one second, takes one minute blink bulb.",mobile-robot
8709,BiRRT: Getting path array 7 DOF angle configurations,"I've kind finished implementing BiRRT 7 DOF arm, using KD-tree numpy.spatial order get nearest queries. A picture below: I'm currently trouble fact impossible retrieve path start node particular node using KD-tree, I array nodes, edges calculated subsets array, edges useful order. Can anyone give tips I'd retrieve path starting node first array, ending node second array? Are useful data structures would let this? Below code",inverse-kinematics motion-planning planning rrt
8710,ROS Raspberry Pi Model 2: UbuntuARM vs ROSBerryPi,"Before I ask question, I'd better confirm I've read prominent post running ROS Raspberry Pi devices. That post contains valuable information, it's bit dated, ROS support ARM devices much better days. In fact, ROS 2.0 evidently going excellent support running embedded devices like Raspberry Pi. I got Pi model 2 birthday, I'm really eager get ROS running I build robot I've working on, based Wild Thumper 6WD platform. From perspective, pros & cons regarding UbuntuARM ROSBerryPi: UbuntuARM Pros: Ubuntu official ROS distro well-supported ROS OS The best documentation ROS wiki running ARM devices written UbuntuARM Cons: Raspbian (on ROSBerryPi based) official distro Rasbperry Pi thus best support board. ROSBerryPi Pros: Raspbian (on ROSBerryPi based) official distro Rasbperry Pi thus best support board. Cons: ROS well supported OS's Ubuntu To use ROSBerryPi distro, must build ROS source. My question is: anyone provide insight dilemma? If you've running ROS Raspberry Pi 2 (model 2 please; model B+ completely different issues, like well-supported Ubuntu), what's experience been? Which distro would/did choose, why?",ros raspberry-pi arm
8711,How convert rotation matrix equivalent Quaternion using Eigen Library.,"Eigen library (), used extensively ROS PCL. Thank you.",ros
8717,3 degrees freedom analytical solution,I got robot exactly looks like shown figure above. I worked inverse kinematics analytical solution without base rotation (considering 2 dof alone) I able find analytical solution including base(3 dof). How I find anlytical solution robot ??,robotic-arm
8719,Mean shape initializing training face shape regression tree,"I studying article estimating facial points using forests regressions (random forests). In order train trees forest, training algorithm initialized mean shape. I don't understand mean shape is. I looked internet came across articles talk face detection facial shape estimation, clear explanation it. Can please tell exactly mean shape?",computer-vision artificial-intelligence
8720,Which algorithms used autonomous robot,"I working proposal autonomous fire fight robots I'm little bit confused sensor algorithms. My friend suggested path finding algorithms like BFS, DFS, A*, Dijkstra's Algorithm used robots, I didn't believe it. I want ask: Are algorithms used real world robots genetic algorithms? How robot discover path detect, differentiate, human fire? I want explanation gives knowledge.",algorithm machine-learning
8722,Microcontroller flashing,"Can micro controller flash itself? What mean say is, I STM32F103RG 1Mb Flash Size. I UART Communication modem connected it. Can send firmware (.HEX .BIN) microcontroller via radio verify checksums, sucess microcontroller saves file SD Card ( via SPI ) restarts start flashing reading file ( sD card )? Can something like done external MCU required carry flashing? The purpose microcontroller radio sitting remote location need way change microcontroller's firmware sending firmware update file remotely.",microcontroller
8726,"How 'Auto Go Home' feature, like DJI Phantom 3, project built quadcopter?","What quadcopter have, access to, order make 'return home' feature work? Is GPS enough? What approach needed make happen? I used Arduino Mega 2560 IMU stable quadcopter.",arduino quadcopter sensors localization gps
8728,DC motor shaft gear installation,"I'm hoping use DC motor drive cog bar horizontally along track. AFAIK, I'd need install (plastic) cog motor shaft, grips (plastic) cog bar. Does anyone know prevent cog shifting shaft? The shaft 10mm long I'd like make sure cog cog sits 5mm, cog bar is. Any help appreciated. Thanks",motor
8731,Sending commands Ubuntu,"I iRobot Create model 4400 I need send commands open interface Ubuntu. I'm using gtkterm 57600 baud I press play button, drives around itself. I tried send commands raw data hexadecimal data doesn't work. What I wrong?",irobot-create roomba linux
8732,Weird magnetometer values,"I bought 3-axis magnetometer (Similar one ) And plugged Arduino order read heading value. I mounted robot I drove robot around 30 meters, turned 180 degrees drove back starting position. I plotted heading value shows inconsistent values. The 180 degrees turn started sec 55, rest driving one direction using joystick following wall reference small deviations expected big image. When robot turning in-place, problem heading variation follows rotation robot. The robot (Turtlebot) little bit shaky magnetometer doesn't always x axes parallel floor I don't think degrees offset cause huge difference. I calculate heading follows: heading = atan2(y field intensity, x field intensity) Why happen? Could form metals electric wires floor? Can suggest robust method/sensor estimating heading indoor environments? EDIT: I drove path pattern similarity making even weirder",mobile-robot navigation magnetometer
8742,Could motor shaft swapped threaded shaft?,I'm looking N20 DC motor fairly popular. Does anyone know shaft could swapped threaded shaft?,motor
8748,Phantom Omni type robot Inverse kinematics solution,"Guys robot looks like this, Thanks @croco I came know looks much similar Phantom Omni. Since looks similar phantom Omni I trying get inverse kinematics geometric solution it. Using inverse kinematics solution I build FPGA design. There good research paper I understand page 2122 find L3 L4 (shown image below). If I find robot project almost done. How I find L3 L4 robot ? Should I bring end effector (0,0,0) position shown Fig2 amd measure L3 L4, would work ?? Would great guys could help. Cheers.",inverse-kinematics geometry
8749,Bulding robot arm neural networks understanding,I thinking building small robotic arm 4 small servo motors arduino uno apply basic neural networks concepts. Is good idea use hand made robotic arm learn power neural networks? Thank time Merry Christmas,control
8751,How I go implementing Kalman Filter pose estimation algorithm?,"I currently process writing pose estimation algorithm using image data. I receive images 30 fps, every image, program computes x,y,z roll, pitch, yaw camera respect certain origin. This means accurate, obvious problems much exposure image, enough feature points image, etc., positions go haywire every while; I want write Kalman filter take care part. I read basics KF, EKF etc. I reading OpenCV tutorial implementation Kalman Filter inside algorithm pose estimation object. While matches use case well, I don't understand using linear Kalman Filter explicitly specifying parameters like (dt*dt) state transition matrix. For reference, state transition matrix considering I'm little confused, main question broken three parts: Would linear Kalman Filter suffice 6DOF pose estimation filtering? Or I go EKF? How I come ""model"" system? The camera really obeying trajectory, whole point pose estimation track position rotation even noisy movements. I don't understand came matrix. Can Kalman Filter understand that, instance, pose estimation says camera moved half meter one frame other, that's plain wrong, 1/30th second, there's way could happen? Thank you!",kalman-filter pose
8752,Automatic activation spray,"I would like wirelessly control button spray pressing spray comes. For example, deodorant bottle. What best way ? What thing I mount bottle this?",robotic-arm
8757,FastSlam 2.0 Implementation?,"I studied Claus Brenner's lectures implement FastSLAM 1.0 algorithm, particle maintains robot pose, maintains EKF's landmarks. However, I'd like implement FastSlam 2.0. Which I understand uses particle filters completely. Is FS 1.0, instead particle maintaining EKF landmark, particle maintains yet another array particle filters landmarks?",slam
8758,2D Robot Motion,"Good day, I robot IMU tells Yaw Rate, Magnetic heading. It also tells Xvelocity YVelocity instance vehicle, vehicle frame. (So irrespective heading, robot moved forward, yvelocity would change example) Assuming robot starts position (0,0) Heading based Magnetic heading, I need calculate next position robot based world frame. How I this?",mobile-robot
8761,Completely autonomous traversal planar graph,"I program autonomous robot traverse grid given following figure. But main problem nodes visit known beforehand, received bot real time. E.g.- reaching node 19, bot go node 6. The shortest path(19-17-7-6) calculated Dijkstra algo don't know make robot traverse path. Any idea ? Edit: Sorry making question clear enough. I facing problem determining current position direction robot facing can't define set commands (turn left/right/forward) traverse next desired node. I thinking extra array previously visited nodes current node extra variable facing direction. But define command sets node every node. Any better idea ?",mobile-robot automatic dynamic-programming
8763,iRobot Create 2 Vacuum?,"I got Create 2 Christmas, I'm planning create (obviously), I'd like use around house vacuum possible. I've heard buy parts Roomba throw chassis, I wanted confirm/refute I bought anything. Is possible I crazy?",irobot-create
8765,Apps Pepper robot,"I recently googled Pepper robot I wonder one could write apps get money them. As far I know app store, sell apps give free? (All info I googled rather incomplete old - probably outdated) Also I believe apps (or similar) robots potential multibillion-dollar market. What think that?",mobile-robot
8768,Moving small plate back forth,"I'm hoping move plate (3MM x 45MM) back forth using DC motor. Here's idea far: The motor drives threaded shaft attached one side plate. To help alignment, rod added side plate (red). My guess it's rod hole, could potentially jam. AFAIK, usually, bigger setups, linear bearing would come handy. However, given plate 3MM thick, better ways help alignment? Could making edge around hole like inside donut help? Something like Is easy make? In fact, concern actually valid? Thanks EDIT The centre area plate needs kept clear. This intended part (~10MM thick) pole climber, several guide rollers fitted left side plate motor driven roller left part (not depicted). So idea press guide roller pole two rollers good grip pole. The whole car fairly light, force expected around 30N. Here's complete depiction: The rollers spring loaded, need released retracted - adjusted different pole widths.",motor linear-bearing tracks
8775,Attaching M5 screw shaft cog wheel,Does anyone know good (low profile) way attach threaded (chamfered) end M5 screw shaft 30MM (30T 1M) plastic cog wheel? Would good idea widen shaft hole let threads grip hole? EDIT The torque around 6kg-cm plastic I'm looking POM.,mechanism torque gearing
8779,Panasonic MSMO22F2G (stepper motor hook-up),"I Panasonic MSMO22F2G Servo Motor I'm using stepper motor. The motor 4 wires coming port farther front, 11 wires coming port towards rear unit (presumed encoder). I trying drive motor arduino motor shield. My question this, hook up? I read stepper 4 leads bipolar stepper, group coil wires together. I found 3 wires stepper coil fourth seems effect stepper. My checking process using ohm meter see connected what, well connecting wires feeling resistance.",arduino stepper-motor
8785,"Roomba schedule opcode: 167, byte 1","Just short question: The iRobot Create 2 Open Interface spec says: Serial sequence: [167] [Days] [Sun Hour] [Sun Minute] [Mon Hour] etc. Can somebody explain me, ""Days"" stands for?",irobot-create
8786,Are Lithium Ion battery monitors designed hobbyists (quadcopters)?,"I friend getting quadcopters good techie buddy, I'm trying find right technology battery monitoring expensive machine fall sky unexpectedly. So far technology hobbyists I seeing voltage monitors, aren't really useful battery chemistry. With flat voltage curve LiIon I'd expect voltage monitor falsely report low battery draw extra current indeed I'm seeing exactly buddy fast maneuvers mid flight. In day job use charge counting battery monitors (BMS) battery chemistry. Usually custom designed battery pack (just like laptop batteries, etc). Sometimes built battery pack, sold cell suppliers. Have I missed product electric aircraft? Are hobbyists battery dark ages?",battery lithium-polymer
8787,Best power solution robot,"I've built quadruped robot using 12 servos (TowerPro SG90 Servo) Raspberry Pi (model B 1). Right I'm ""feeding"" 5V 2.5A charger. How I make un-tethered? What I look selecting batteries? Also, I think I need separate powering RPi servos power ""jumping"" moves isn't good RPi. A little video - Testing Walking Algorithm",mobile-robot raspberry-pi power battery walking-robot
8797,Suitable gear construction robotic extender - plastic?,"I rather simple setup robotic extender. The DC motor turns shaft worm it. The worm connects small worm gear (green) small gear (red) shaft connecting large gear (blue): The DC motor's gearbox gives around 50-100rpm stall torque around 2kg-cm. The small gear around 15MM tall large gear around 45MM tall. If load (on large gear) maximum torque 5kg-cm typical torque 3kg-cm, could two gears made plastic module (metric form pitch, @Chuck pointed out) 0.5? Is higher module needed? How worm, could made plastic (nylon?)? Any help appreciated. EDIT Fixed typos updated diagram.",motor torque gearing
8804,See CC3D actual configuration,"received first hobby-grade quadcopter. Its Eachine racer 250 comes preassembled transmitter receiver also included. It comes kind CC3D flight board, people say original one, configured software. It actually flying well right box im sure want touch FC config. Im mostly interested learning fly manual/acro mode, transmitter seems switch 3 flight modes, first 2 looks like low/high rates self-level mode, im expect third acro mode, im sure right now, couldnt test weather, could third higher rate?. So, way look actual FC config without changing anything? witch software need? flight modes actually set FC transmitter could able see edit them? Thanks advance.",quadcopter
8807,POM gears metal fittings,I'm looking setup: POM bevel gears fitted kind metal (bronze?) tube inside fits shaft. What benefits method provide? Is allow shaft free-spin? The metal fitting wouldn't able grip shaft - right? Is supposed canonical approach fitting POM gear (relatively) high-load applications?,motor mechanism gearing
8810,Gazebo SimMechanics,"I'm considering choose Gazebo SimMechanics simulating quadruped robot. I set standards simulation: Support Real-time application ROS Simulate contact impact well(with ground) (deformable possible) Good rendering Quality. I learned Gazebo months, see limits meet requirements, especially contact friction problems. I didn't use SimMechanics, i'm impressed see video. Anyone experiences Quadruped Simulation share advice? Thank much.",simulator gazebo
8811,Will 5200mAh 30C 22.2V 6S Lipo battery work,"I building Quadcopter I wondering 5200mAh 30C 22.2V 6S Lipo battery work 40Amp Esc's, MT4108 370 KV Motors, GEMFAN 1470 Carbon Fiber Props. The payload 5-6 pounds.",quadcopter
8816,Create 2: Wheel interface board replacement,"Scroll page 3. I'm trying interface Roomba's preloaded navigation system pair motors attached roomba itself- however, I need interface board dimensions one pictured document. It 0.050"" (1.27) contact centers, don't seem commercially available. Can anyone provide help locating PCBs size?",irobot-create electronics navigation roomba
8818,Accurate technique locate position?,"What accurate way locate position orientaion body motion (rotation translation)? I need track body precisely, required accuracy 100-200 microns, rather high frequency - least 1kHz. The body one rotation axis. This axis translate along path. Normally track ellipse like shape, translation path change, that's I need track body. The limit motion 50 cm direction. Maximum velocity 5 m/s. Requirments sensors: it's possible place sensor surface, it's impossible change construction. So it's impossible use encoders rotation axis measure angle. I tried MEMS 9DOF sensors, noise it's difficult understand motion it's noise. Another idea use magnet magnetomemter, possible measure resolution way?",kinematics navigation tracks orientation
8820,Arduino project: Turning fixed front wheel axis,I working Arduino robot project. This project requires base 4 wheels back wheels attached two DC motors controlled independently other. I thinking robot turn giving power one motors I trouble front axis look like. Would possible solid front axis 2 wheels still possible robot turn would friction great?,arduino wheeled-robot brushless-motor
8822,Orienting rectangular plastic bricks,"As part sorting machine, I need orient pile plastic brick-shaped objects (which identical size - 3cm x 2cm x 1.5cm) always end white side facing up: These fed bowl feeder type machine re-orienting. How I accomplish this, preferably without optical sensors? I thinking cutting bricks putting magnets inside, elegant solution?",mechanism orientation
8823,Does mAh battery mean longer power power?,If Lipo battery mAh slower run energy larger power output? Thanks Advance,power battery
8831,Are joint state vectors limited?,"Are joint-state vectors $q$, define position orientation set joints, limited somehow? I know used rotation part transformation matrix => therefore I would think limited within 0 2$\pi$",joint
8833,Erratic motor behavior. Is due faulty remote control Grounding something else?,"I using arduino mega run 4 motors via 4 motor controllers. I using ps2 controller remote control. When joystick rest, motor stop. The problem motor still moves randomly joystick rest. Sometimes, joystick produce forward motion motor backward. Is grounding issue PS2 remote control issue ir others.. Does GND arduino board connected GND external battery? How I troubleshoot this? Thanks.",mobile-robot control power
8835,q-state vector used define transformation matrix? how?,"How used determine transformation matrix? example could computing inverse kinematics small displacements: J(q)$\Delta$q = $\Delta$u $\Delta$U vector defining difference current desired position. The desires position always computed, keep solving manner every time solve $$J(q)\Delta q = \Delta u$$ q:= q + $\Delta$q Compute $T_{base}^{tool}(q)$ Compute difference $[T^{tool}_{base}]_{desired~position} $ $T_{base}^{tool}(q)$. If change less 10^-5 finish output Q, resolve. How would compute The transformation matrix based q state vector.",inverse-kinematics jacobian
8840,RC car circuit: do?,I disassembled RC car (a BBR 1:18 Scale Ferrari Enzo 2005). Attached stepper motor controls steering car small circuit board cog wheel attached it. I trying figure circuit does. My idea responsible keeping track wheels position I certain. Here picture it: As see 5 wires coming I know green one GND. Does anyone idea function might be?,stepper-motor radio-control circuit
8842,Path following precise positioning system (RTK),"Is general problem using precise positioning (centimeter-accurate GNSS RTK system meant) autonomous car guidance given I predefined path car follow? I mean, autonomous cars topic #1 CES 2016 yet simple system seems introduced date... Of course ""path planning"" part ""autonomous package"" problems need solved (collision prevention etc.) I really wonder whether something simple like RTK guidance could used. An RTK system relies little amount live correction data (about 1 kB/s) mobile networks really ubiquitous today I really see technical problem solution given enough RTK base stations around. EDIT: This question using precise positioning follow predefined track obstacle-free environment. I asking systems need implemented autonomous car like collision prevention etc. (such systems may employ LIDAR stereo camera). Surely collision prevention must autonomous system I consider theoretical case only. An updated question may be: Is precise satellite positioning accurate enough guide/navigate full-scale passenger car obstacle-free outdoor environment speed 100 km/h given I precise-enough path prerecorded follow? Some answers already say yes, solved problem. It would nice answers elaborated detail regarding existing solutions (accuracy, possible problems etc.). One solutions may probably open source APM autopilot work rovers (example Emlid) seem use RTK accuracy may rather low.",navigation gps precise-positioning
8844,DC Motor open door,"I want open door using DC motor. I've estimated required power worst case would around 35-40W (considering ~80% efficiency). The whole controlled Particle Photon. I thinking use L298N control output current motor. However, I looked powerful enough motors, would consume much current stalling (> 4A part L298N datasheet). Do ideas overcome this? Maybe there's another dual-bridge handle current, maybe exists DC motor ok L298N, maybe I need simultaneous DC motors? Edit: part question itself. I'll keep future visitors know sub-question about, please ignore answering. As sub-question, would better use brushed brushless DC motor?",motor h-bridge
8845,Exchange air maintain thermal insulation,"My application composting worms outdoors inside styrofoam cooler. I use heat lamp thermo-electric cooler maintain temperature bin temperature outside bounds healthy worms. When temperature outside bounds, I'd like exchange air bin fresh air outside, I don't want permanently compromise insulating properties bin lots air holes. So I'm looking actuator solutions would allow open/close window sorts. I'm considering solenoid air valve I don't necessarily need/want air compressor - simple fan sufficient circulate air. Any suggestions?",actuator valve
8849,Tracking objects camera; PID controlling; Parrot AR Drone 2,"I working project I perform object tracking using camera Parrot AR Drone 2.0. So main idea is, drone able identify specified colour follow keeping distance. I using cvdrone API establish communication drone. This API provides function: moves AR.Drone 3D space vx: X velocity [m/s] vy: Y velocity [m/s] vz: Z velocity [m/s] vr: Rotational speed [rad/s] I written application simple image processing images obtained camera drone using OpenCV finds needed contours object tracked. See example below: Now part I struggling finding technique using I find velocities sent move3D function. I read common way controlling using PID controlling. However, I read could get could related problem. To summarise, question move robot towards object detected camera? How find coordinates certain objects camera?",control pid quadcopter tuning opencv
8852,Quadcopter Charging,"Our thesis Multicopter using two batteries wherein first battery used power goes out, switch placed use charge first battery second battery powering multicopter, process repeats power battery drained. Is process possible achieved? Edit 1: Just clear everything again. The thesis Quadcopter uses two batteries power source. These two batteries attached ""switching circuit system"" allow one battery drained quadcopter transferred battery. The solar panels serve ""charger"" whatever battery standby mode (the discharged battery). So one battery used quadcopter, one connected solar panel charging battery. Once battery drained, quadcopter switch charged battery. This continue go batteries drained. Is achievable?",battery multi-rotor
8855,"How I detect ground collision, hexapod robot?","I'm planning build small (probably around 30 centimeters diameter, rest) hexapod robot, but, currently, would able walk even ground. To improve this, I would to, somehow, detect leg collides ground. Ideally, I would able know much weight leg supporting, I could balance weight adapt moving (up down) terrain (so, put finger one leg lifted it, leg would go up); however, that's possible, simple binary signal would do. Is simple compact method this?",sensors hexapod
8857,imu position without GPS camera,"I IMU 3-axis accelerator, 3-axis magnetometer, 3-axis gyroscope row, yaw, pitch value. I want get location IMU coordinate(the beginning point (0,0,0)) I know using double integration dead reckoning problem. And I found lot paper talking combining IMU GPS camera using Kalman filter. Is possible I use IMU get slightly precise position data? Because future work I use multiple IMUs bounded human arms increase accuracy.",imu gps
8860,Angle Random Walk vs. Rate Noise Density (MPU6050),"I’ve made datalog MPU6050 (IMU: gyroscope accelerometer) 500Hz sample rate. Now I want calculate characteristics gyro evaluate sensor. For gyro I’ve found following values datasheet: Total RMS Noise = 0.05 °/s Low-frequency RMS noise = 0.033 °/s Rate Noise Spectral Density = 0.005 °/s/sqrt(Hz) Now I want ask I calculate values dataset? At moment I’ve following values dataset: Standard deviation = 0.0331 °/s Variance = 0.0011 Angular Random Walk (ARW) = 0.003 °/sqrt(s) (From Allan deviation plot) Bias Instability = 0.0012 °/s Is ARW equal Rate Noise Spectral Density mentioned datasheet? And also RMS Noise datasheet equal standard deviation? edit: I found following website: There statement: ""...Because noise approximately Gaussian, standard deviation histogram RMS noise"" So I guess standard deviation RMS noise datasheet. But ARW?",sensors imu gyroscope sensor-fusion statistics
8863,cracked GPS chip antenna,"My quadcopter onboard GPS unit; crash today I happen come top it. I split apart broken case noticed chip antenna cracked; I unfamiliar type antenna functions, issue? This closed source drone I little insight number GPS locks acquired, signal strengths, would broken antenna cause type signal degradation, I even able acquire lock?",gps
8866,Tf frame origin offset actual base_link,I built differential drive mobile robot solidworks converted URDF file using soliworks2urdf converter. I successfully launched robot simulated tele-operation node. Since intended use navigation stack viewed transform robot rviz resulted below. As see base plate one supports wheels castors tf base plate shown away actual link even odom away model. Where gone wrong fix this. Refer URDF model below.,mobile-robot ros navigation odometry gazebo
8874,How mobile robot rotate perfectly?,"Please look youtube video. When mobile robot operates, rack (which said weight 450 kg) Center Of Mass (COM) distributed location. For example, COM located 5 10 cm center robot. Because this, robot revolves, center rotation center robot anymore. However see video, still rotate many circles perfectly around up-right axis. So think this? Is possible mechanical design only? Or use kind advanced feedback control system counter effect off-center COM?",mobile-robot control mechanism
8877,Need uav perform circle turn,"I've got project require drone perform circle turn drone always facing tangent turning curve. Similiar car performing frictionless banked turn. Just wondering method use achieve it, throttle control ignored since already pid height control. Any suggestions would appreciated.",quadcopter pid multi-rotor
8879,Can use DC Brushed motors building drone?,I want make drone. But budget low. Brushless motors expensive. I want use Brushed CHEAP ones. us ?,quadcopter motor brushless-motor
8882,Canny's Roadmap Algorithm,Where I find general implementation Canny's Roadmap Algorithm(or Silhouette Method) Robot Motion Planning?,motion-planning
8883,How find center disk using robotic arm,"Hello I new field robotics knowledge raspberry pi, arduino, python. I want make Robotic arm used find centre disk. There may disk different diameter coming one another conveyor. I need make hole center disk using robotic arm. How I ? What techniques sensors I use implement mechanical electronic part. (I don't want use camera openCV). Thanks advance.",robotic-arm mechanism electronics movement
8887,How Kirobo robot make sentences / know respond humans?,"Basically, Kirobo, went ISS spoke sentences, think? Does talk itself? Does learn (become intelligent time) better conversations ""experience""?",mobile-robot humanoid
8888,CC3D OpenPilot - Communication port,I building quadrotor CC3D (OpenPilot) RPi. My first idea trying communicate CC3D RPi using main port first one I can't find information communicate board device (or information commands serial configuration). Anybody knows whether possible find info??,raspberry-pi quadcopter
8891,Figure PID values drone specs,"I specs quadcopter, everthing, would possible figure pid specs?",quadcopter pid
8893,Gazebo: moving joint model plugin,"This first week Gazebo. The tutorials clear (except dearth C++ knowledge) I'm working move things getting cloudy. I made model comprising two boxes revolute joint. The file one_r_test.world loads model. A plugin ""loaded"" (?) model.sdf plugin, ModelControl, comes model_push.cc ""Model plugins"" tutorial (), uses SetLinearVel move box. I get behavior model_control.cc I copy tutorial code (and change plugin name appropriate), that's I want. I'm seeking eventually simulate joint control robotic manipulators what's working basic simulation attempt move model joint via ModelControl plugin. It moves GUI I set velocity (or torque) way. The model_control.cc code pasted hopes identify problem. model_control.cc edit: If I change this->jointR1_->SetParam(""vel"", 0, 99); this->jointR1_->SetVelocity(0, 99); joint moves (yes, very, quickly). What's wrong SetParam vs SetVelocity?",simulator joint gazebo
8894,How 3d printer moves header vertically MakerBot printer,I would like know header MakerBot printer moves vertical /down direction. Is detailed explanation including parts involved?,mechanism 3d-printing
8895,Quadcopter PID Control: Is possible stabilize quadcopter considering angle measurements?,"Good day, I student currently working autonomous quadcopter project, specifically stabilization part now. I using tuned propeller system I also already considered balancing quadcopter component placements. I tuning PID's quadcopter past 3 1/2 weeks best I've achieved constant angle oscillation quadcopter +-10 degrees 0 degrees setpoint/desired angle. I also tried conservative 7 degrees setpoint results pitch axis. As PID code takes difference angle measurement complementary filter desired angle. I read somewhere IMPOSSIBLE stabilize quadcopter utilizing angle measurements, adding angular rate must also taken consideration. But I read lot works using single pid loop angle differences (Pitch Yaw Roll) input. In contrast stated above, I read comment article () Edouard Leurent Single PID control loop angle errors Cascaded PID loop (Angle Rate) utilizes angle errors angular velocity errors equivalent Mathematically. If I continue using Single PID loop (Angle) method, I would tune 3 parameters (Kp, Ki & Kd). But I change code utilize Cascaded Loop (Angle Angular Velocity), Would I tune two sets 3 parameters (Kp, Ki & Kd angle Kp, Ki & Kd angular velocity)? Would cascaded PID control loop give better performance single PID control loop? In Cascaded Loop, set point angular velocity stabilized flight also 0 deg/sec? What quadcopter yet desired angle? Thank :)",control quadcopter pid raspberry-pi stability
8900,SLAM : Why marginalization schur's complement?,"Consider system $$ \tag 1 H\delta x=-g $$ $H$ $g$ Hessian gradient cost function $f$ form $f(x)=e(x)^Te(x)$. The function $e(x)=z-\hat{z}(x)$ error function, $z$ observation (measurement) $\hat{z}$ maps estimated parameters measurement prediction. This minimization encountered iteration many SLAM algorithms, e.g.one could think $H$ bundle adjustment Hessian. Suppose $x=(x_1,x_2)^T$, let $x_2$ variables seek marginalize. Many authors claim marginalization equivalent solving smaller liner system $M\delta x_1=-b$ $M$ $g$ computed applying Schur's complement (1), i.e. $$H= \begin{pmatrix} H_{11} & H_{12}\\ H_{21} & H_{22} \end{pmatrix} $$ $$ M=H_{11}-H_{12}H_{22}^{-1}H_{21} $$ $$ b=g_1-H_{12}H_{22}^{-1}g_2 $$ I fail understand equivalent marginalization... I understand concept marginalization Gaussian, I know schur's complement appears marginalization use canonical representation (using information matrix), I don't see link linear system. Edit: I understand Schur's complement appears process marginalizing conditioning $p(a,b)$ $a,b$ Gaussian variables, link supplied Josh Vander Hook. I come conclusions, using canonical notation: If express Gaussian $p(a,b)$ canonical form, $p(a)$ gaussian information matrix Schur complement information matrix $p(a,b)$, etc. Now problem I don't understand Schur's complement appears marginalization bundle adjustment (for reference, recent papers: c-klam (page 3 want look) (part titled marginalization). In papers, single bundle adjustment (BA) iteration performed manner similar I initially described question. I feel like simple connection marginalizing Gaussian marginalization BA I missing. For example, one could say optimizing $f$ (one iteration) equivalent drawing random variable following denstiy $$e^{-\frac{1}{2}(x-\mu)^T\Sigma^{-1}(x-\mu)}$$ $\Sigma$ inverse Hessian $H$ $f$, $\mu$ true value $x$ (or approximation value), marginalizing density equivalent using Schur's compelement bundle? I really confused...",slam computer-vision
8902,Real-time GY-85 IMU sensor interfacing Simulink,"How I read real time values GY-85 IMU sensor Simulink connected via Arduino? Also, I intend interact Virtual Reality environment Simulink using GY-85 IMU sensor. Is possible? How I make MATLAB read real time values GY-85 IMU sensor connected Arduino via I2C communication ? Please help!",imu matlab
8906,How I create portable solar panel lipo charger?,We're working quadcopter carry solar panel top continually charging lipo battery quad. What's smallest easiest way recreate charger allow safe charging lipo battery?,quadcopter battery
8907,Inverse Kinematics DLR/HIT II Hand,"I trying find inverse kinematics formulation DLR/HIT II hand. Till I success finding analytical method described thesis Mavrogiannis, Christoforos I. named Grasp Synthesis Algorithms Multifingered Robot Hands, given appendix B. My question regarding A.28 author calculates q3 mentioned previously text q3 equal q2. Note: q denotes joint angles",inverse-kinematics
8909,Typical Problem Simple Line Follower Using 3 sensors,"I working building line follower robot using ATmega2560 I want movement precise. I facing typical problem. It consists three(3) IR sensors. The thickness line followed 1.2cm gap sensors that, around 1.8cm. So black line comes center side sensors, three sensors white stops. And I need robot stop white, due application. So please anyone suggest good algorithm tackle situation. I think PID control good use, searched Google. But I don't understand implement three sensors. Please Help",microcontroller line-following avr
8910,How interpret result image rectification?,"I've trying understand image rectification. Most time result image rectification illustrated original image (i.e image rectification) rectified image, like this: The original image: The rectified image: To original image makes sense, 'rectified' second one. I mean, result rectification looks like that? supposed interpret it? information contain? An idea dawned : could bizarre shape rectified image dependent method used rectification, polar rectification used (around epipole)?",mobile-robot stereo-vision 3d-reconstruction
8911,How find kinematics differential drive caster robot?,"I'm working little project I simulations small robot. I case I'm using differential-drive robot one wheels bigger robot platform (which two differential-drive casters), I really understand find kinematics order describe model finding speed V_tot platform. This robot I know following parameters distance joint robot costrained blue point joint robot linked robot platform L distance wheels r radius wheel robot spin around blue point THETA angle As I know dimensions, I would like apply two velocities V_left V_right order move robot. Let's assume V_left = - V_right I find analitically ICR (Istantaneous Center Rotation) costrained robot? I mean I cannot understand introduce formula.",mobile-robot kinematics wheeled-robot differential-drive two-wheeled
8916,Quadcopter program execution time optimization using Raspberry Pi increasing i2c baudrate,"Is possible speed execution time c++ program raspberry pi solely increasing i2c baudrate increasing sampling frequency sensors? I issue sudden jerkiness quadcopter found culprit frequency loop excecutes 14Hz. The minimum requirement quadcopter 100-200hz. It similar issue faces Raspberry Pi quadcopter thrashes high speeds He said able increase sampling rate 66hz 200hz increasing i2c baudrate. I confused done. In wiring pi library, says set baudrate using command: What I curious set baudrate achieve desired sampling rate? I plan optimizing achieve least 100Hz sampling rate As now, execution time loop quadcopter program 0.07ms 14Hz. It takes 0.01ms 0.02ms obtain data complementary filter. I already adjusted registers sensors output readings 190Hz (Gyroscope L3GD20H) 200Hz (Accelerometer LSM303) 220Hz (Magnetometer LSM303).",quadcopter pid raspberry-pi sensor-fusion c++
8917,actuate pneumatic muscle signals received emg sensors interfaced raspberry pi?,My aim actuate pneumatic muscle based signals received EMG sensors placed biceps. Is Matlab code process received EMG signals convert form useful muscle actuation? The linked video gives better insight question: exoskeleton arm pneumatic muscle,raspberry-pi matlab
8918,Canny's Silhouette Method,"How construct silhouette curves (roadmap) Canny's Silhouette Method, 3D model environment (obstacles robot) given? I want specifically implement Cannys Roadmap Method, works n dimensional Configuration Space.",motion-planning
8930,Modified DH Parameters?,"Is notation geometry robots Khalil Kleinfinger considered one probably ""many"" Modified DH Parameters?",dh-parameters
8931,How combine odometry information time-shifted information imu,"I'm working differential-drive robot odometry measurements wheel shaft encoders heading information imu (I'm using BNO055 imu mode get Euler angles, primarily heading angle). I'd like use imu header angle augment odometry prone slipping errors, imu lags odometry 100ms. How I combine measurements get best estimate robot pose? Thanks word this.",mobile-robot imu odometry
8934,Autonomous robots hardware structure planning,"I ask question clear concept hardware structure humanoid autonomous fire robot, Here scenario fire robot detect humans fire, vision cameras temperature smoke sensors help perform task. Now days market many processors like Snapdragon process tasks device control system don't think autonomous fire robot use kind processors. Does autonomous robots like fire robot use processors micro controllers. Does require OS Rams environment? Like computer system use kind things.",embedded-systems humanoid
8935,Gazebo laser plug-in fails publish scan results,"I added hokuyo laser plug-in mu urdf file. I successfully launched robot gazebo done required changes visualize rviz. I didn't get error laser scan results published. Fine results Terminal launching gazebo model world Result I also verified tf model rqt fine Aslo find urdf file below, someone help fix this? Link & joint: <link name=""hokuyo_link""> <collision> <origin xyz=""0 0 0"" rpy=""0 0 0""/> <geometry> <box size=""0.1 0.1 0.1""/> </geometry> </collision> <visual> <origin xyz=""0 0 0"" rpy=""0 0 0""/> <geometry> <box size=""0.1 0.1 0.1""/> </geometry> </visual> <inertial> <mass value=""1e-5"" /> <origin xyz=""0 0 0"" rpy=""0 0 0""/> <inertia ixx=""1e-6"" ixy=""0"" ixz=""0"" iyy=""1e-6"" iyz=""0"" izz=""1e-6"" /> </inertial> </link> <joint name=""hokuyo_joint"" type=""fixed""> <axis xyz=""0 1 0"" /> <origin xyz=""0 -0.055 0.2"" rpy=""0 0 0""/> <parent link=""Base_plate""/> <child link=""hokuyo_link""/> </joint> Controller: <gazebo reference=""hokuyo_link""> <sensor type=""gpu_ray"" name=""hokuyo""> <pose>0 0 0 0 0 0</pose> <visualize>false</visualize> <update_rate>40</update_rate> <ray> <scan> <horizontal> <samples>100</samples> <resolution>1</resolution> <min_angle>-1.570796</min_angle> <max_angle>1.570796</max_angle> </horizontal> </scan> <range> <min>0.10</min> <max>30.0</max> <resolution>0.01</resolution> </range> </ray> <plugin name=""gpu_laser"" filename=""libgazebo_ros_gpu_laser.so""> <topicName>/scan</topicName> <frameName>hokuyo_link</frameName> </plugin> </sensor> </gazebo>",mobile-robot ros navigation simulation gazebo
8938,iRobot Create 2 IR bump light sensor specifications,"Can someone tell I find specifications iRobot Create 2 IR bump light sensors? We SDF model Create 2 uses Hoyuko laser range finder sensor simulate behavior IR sensors starting laser scan data. Hence would like additional information IR sensors can't find anywhere web - exact position robot chassis, maximum range, shape obstacle detection field on.",sensors irobot-create
8940,Robotic manipulator Jacobian product exponentials,"I've taken class started thesis robotics reference calculating Jacobian product exponentials seems incorrect, see: Specifically resulting Jacobian matrix SCARA manipulator page 118 would us believe end effector translational velocity depends joints 2 3 rather 1 2. Could someone please explain why?",jacobian manipulator product-of-exponentials
8941,Localization IMU,What best approach get localization accuracy accelerometer gyroscope?,localization imu accelerometer gyroscope algorithm
8946,Modified DH parameters,"Is notation geometry robots Khalil Kleinfinger considered one probably ""many"" Modified DH Parameters?",dh-parameters
8949,mbed dc motor speed control using optocoupler encoder,"playing mbed since week ago would like create test program dcmotor speed control. im using 24V dc motor encoder attach.. test, first test supplying 5v 3.3V mbed motor. thing work fine giving 16 10rpm respectively. later try using 12v give 40rpm. try 24v input, speed wont come out. also counter count on/off tick counting up. possible reason? though maybe move fast ISR routine couldn't catch speed..",control motor
8950,Wheel encoder triggers interrupt many times,"I building simple robot two driving wheel. I want control wheel rotation using wheel encoder like one. Here code I Arduino try understand problem I'm facing: What I notice is: The interrupt triggered multiple times sensor beam cut once. But I digitalRead pin, one change. I also noticed interrupt also triggered going HIGH LOW. Here example ouput I have: 0__0 0__0 0__0 0__0 ... ... 0__0 0__0 0__0 <<< change LOW HIGH... 1__9 <<< interrupt must incremented once... 9 instead ! 1__9 1__9 1__9 ... ... 1__9 1__9 <<< change HIGH LOW. interrupt shouldn't triggered 0__24 <<< still... 15 increments 0__24 0__24 0__24 0__24 ... ... 0__24 0__24 <<< here... 1__51 <<< 26 increments 1__51 ... ... 1__51 <<< here... 0__67 <<< 16 increments 0__67 0__67 The way I explain change state, signal received sensor really square, somehow noisy. Like image : Therefore would have, indeed, many RISING one change.... (However reading output sensor analog pin shows direct variation 880(HIGH) 22(LOW)) Does anyone another explanation? Or solution problem ? EDIT Thanks @TobiasK I know called bouncing effect. By research I came across solution: (Ctrl+F rafbuff). I'm trying i'll let know.",arduino wheel two-wheeled interrupts
8951,Establishing Data Transfer two Raspberry Pi's using GPIO,"Good day I currently implementing autonomous quadcopter stereo vision using raspberry Pi. One (Let's call Pi_1) responsible stereo vision responsible motor control trajectory planning (Pi_2). I looking way transfer 480 element float vector via GPIO Pi_1 Pi_2. Pi_1 stereovision program runs 2Hz Pi_2 motor control runs 210Hz. Is protocol fast enough deliver amount information second raspberry pi via GPIO? I currently looking SPI I saw Raspberry Pi cannot turned Slave making option. I also looked UART however slow needs. All I2c ports Pi currently used stereo vision cameras IMU's. If gpio option feasible, I also open suggestions using hardware (middle man) wireless options.",quadcopter raspberry-pi communication
8954,Software control Arduino setup timing belt stepper motors,I would like know software available control timing belt stepper motors arduino board.Much like done 3d printing. But case wont making 3d printer.Just one simple setup.,arduino robotic-arm stepper-driver
8960,What position control trajectories interrupted?,"What strategies used trajectories, applied robotic joint, interrupted? Say robotic arm hits obstacle, controller keeps applying trajectory. Then end, error gets large, torque get quite strong damage robot snap.",control robotic-arm joint
8962,using brush assembly Aerovac bin space?,"A lot Create 2's interior space taken brush assembly Aerovac bin. I'd like take put stuff, I'm concerned Roomba might get confused fact I've unplugged items. Is anything special I need do, aside adding appropriate amount weight area?",irobot-create
8965,CC3D - Replacing RC emitter RPi,"I trying control quadcopter using te OpenPilot CC3D board RaspberryPi. The main idea first replace signals RC emitter CC3D RC receiver RPi connected directly RC receiver inputs CC3D. As far I know RC signals CC3D PWM RPi able control channels using RPIO library create PWM software. But make tests I haven't find way move motors. I using Ground Control System (OpenPilot Software) configure CC3D. I sure whether I need send PWM signals order something like that. I also sure Flight Mode Switch works, I suposse works way channels, using PWM. Anyone made anything similar this?",raspberry-pi quadcopter uav
8968,Do motors really enough torque lift 130 pounds,"I looking dc motors I converted torque force meter distance I got two able lift 130 pounds, right? There catch seeing",motor torque
8970,Is AllJoyn good ROS alternative regarding message passing cross multiple devices?,"I've used ROS while, environment Raspberry Pi + Ubuntu + OpenCV + ROS + C/C++. I also use several ROS packages (tf2, usb_camera, slam related, laser scanner capture.) Also, projects, nodes multiple devices, I'm using multiple master package one project. I review tutorials AllJoyn, handon experience far. The questions are: regarding message (especially, ROS image) passing cross devices, AllJoyn good ROS alternative? (devices connected wifi bluetooth.) For AllJoyn, still need single master (like roscore ROS) coordinate nodes (or similar)? Thanks.",ros alljoyn
8973,How estimate position multiple static ground targets captured facing camera?,"An aerial vehicle captures images ground using facing camera. From images, multiple targets converted pixel position camera reference frame using pinhole camera model. Since targets static information vehicle attitude orientation, sample converted world referencial frame. Note targets flat, level plane. The vehicle keeps ""scanning"" targets converting world referencial frame. Due quality camera detection algorithm, well errors altitude information, position ""scanned"" targets constant (not accurate). A good representation might gaussian distribution around target true position, however also influenced movement aerial vehicle. What's best approach estimate position targets multiple readings? This basically resumes problem noise removal (as well outlier removal) estimation, I would like know algorithms strategies could solve problem. In end I expect implement test collection different approachs understand performance specific problem. Furthermore, system implemented using ROS, know packages already I'm searching I would glad hear. You also cite papers topic think might interest.",localization ros computer-vision algorithm uav
8975,How one implement third order complementary filter estimating altitude using data accelerometer barometer?,"I working CJMCU build cleanflight small drone. As now, algorithm altitude hold uses first order complementary filter combine data barometer accelerometer (after integrating accelerations twice). However, I noticed considerable lag altitude readings seems hampering control algorithm's performance. The filter question implemented However, I'm unable understand works. Pardon errors I may committed.",quadcopter sensors sensor-fusion
8976,iRobot Create 2 stuck Clean mode?,"I'm using Delphi example command Create 2, I adapted demo code Unicode (DelphiXE). I use original iRobot USB serial cable. My Create 2 seemed responding fine commands send via serial yesterday correctly received sensor data back morning, I recharged battery. Now I send ""7"" ""Soft reset"" robot attempts every time start clean cycle. It also attempts start clean cycle I press clean button. It tells move Roomba new location, normal cleaning mode wheels touching desk. Communication via serial seem fine I still get Soft Reset response texts log memo app I use 2 buttons method soft reset Create 2, still communication ways. I must say I yesterday charging unexpectedly, don't know why, robot responded fine commands. It really seems Create 2 stuck Cleaning mode, I missing something? BTW, I also tried fix problem removing battery.",irobot-create
8981,How I get Create 2 communicate laptop via serial USB cable?,"My computer recognize Serial USB cable. I tried Mac HP. Is driver I need install? If supposed install automatically, not.",irobot-create serial usb
8987,Error building map ROS slam_gmapping,"I recorded rosbag data simulating robot gazebo. I played back logged bag file tried build map using slam_gmapping node ended error [ WARN] [1453398305.145461344]: Laser mounted planar! Z-coordinate 1 -1, gave: -0.03982 After iterations, able build map modifying laser scanner joint origin URDF file origin xyz=""0 -1 0.2"" rpy=""1.5708 -1.5708 0"" robot model become weird (laser scanner away robot). How get around issue without relocating laser scanner. Find URDF file",slam ros navigation mapping simulation
8988,"Building quadcopter, motors, props calculations?","Before I start, I 13 year old, I would like apologise I beginner I wouldn't really understand professional talk, I hobby. I building quadcopter, Flight controller: KK 1.2.5 ESC: Q Brain 25amp Frame: KK 260 / FPV 260 Frame Addon: KK/FPV 250 Long Frame Upgrade Kit Tx & Rx: HobbyKing 6ch tx rx (Mode 2) Battery: Turnigy Nano-Tech 2200 mAh 3S I sure motor propellers I use. All I know is: frame motor mounts are: 16mm 19mm M3 screws I sure 1806 2208 means. Here questions: What calculations I find much thrust quad needs produce / useful calculations Using calculations would best CHEAPEST motors I could And finally, propeller would best suited motor. p.s: I looking durable really cheap motors also, I live London, shipping might problem immense bill. Thanks lot time, Sid",quadcopter motor
8990,Standard equation steering differential drive robot,"I writing code Arduino IDE NodeMCU Board control differential drive 2 wheeled robot. I able steer one direction reason steering response time little awkward. Is perhaps better strategy code I using?` I using app called Blynk virtual joystick controls feeds data Virtual Pins. V1 param 0 1 x y. x would left right joystick would forward back. Information App available here: . I working part, latency since cloud service. The main problem I stuck steering driving forward backward. Any help would appreciated. Thanks!`",differential-drive
8992,"In SLAM Dummies, extra variables Jacobian Matricies?","I reading SLAM Dummies, find Google, link: SLAM Dummies - A Tutorial Approach Simultaneous Localization Mapping. They differentiation matrices page 33 I getting different answers resulting Jacobian matrices. The paper derived $$ \left[ {\begin{array}{c} \sqrt{(\lambda_x - x)^2 + (\lambda_y - y)^2} + v_r \\ \tan^{-1}\left(\frac{\lambda_y - y}{\lambda_y - x}\right) - \theta + v_\theta \end{array}} \right] $$ got $$ \left[ {\begin{array}{ccc} \frac{x - \lambda_y}{r},& \frac{y - \lambda_y}{r},& 0\\ \frac{\lambda_y - y}{r^2},& \frac{\lambda_y - x}{r^2},& -1 \end{array}} \right] $$ I don't get $r$ came from. I got completely different answers. Does anybody know $r$ stands for? If not, different way represent Jacobian matrix?",slam
8994,How implement transmission tracked chassis one motor?,"I see small robots tracked chassis implemented 2 motors, powering one side vehicle, like this: (image stolen here) But real scale tanks I assume one motor must way applying power sides independently.",tracks gearing chassis
8998,Quadcopter PID Controller: Derivative Measurement / Removing Derivative Kick,"Good day, I currently implementing single loop PID controller using angle setpoints inputs. I trying different approach D part PID controller. What bought I able reach 200Hz (0.00419ms) loop rate, adding D gain, quadcopter seems dampen movements non continous manner. This case algorithm running around 10Hz. At angle set point 0 degrees, I would try push one side 5 degrees quad would try stay rock solid resisting movements lets go enabling get 2 degrees (the dampening effect weakens time) tries dampen motion again. This implementation traditional PID: Derivative Error: What I tried implement derivative measurement method article remove derivative output spikes. However Derivative part seems increase corrective force dampen it. Derivative Measurement: //Calculate Orientation Error (current - target) float pitchError = pitchAngleCF - pitchTarget; pitchErrorSum += (pitchError*deltaTime2); float pitchErrorDiff = pitchAngleCF - pitchPrevAngleCF; // <---- pitchPrevAngleCF = pitchAngleCF; float rollError = rollAngleCF - rollTarget; rollErrorSum += (rollError*deltaTime2); float rollErrorDiff = rollAngleCF - rollPrevAngleCF; // <---- rollPrevAngleCF = rollAngleCF; float yawError = yawAngleCF - yawTarget; yawErrorSum += (yawError*deltaTime2); float yawErrorDiff = yawAngleCF - yawPrevAngleCF; // <---- yawPrevAngleCF = yawAngleCF; //PID controller list // <---- The D terms negative float pitchPID = pitchKp*pitchError + pitchKi*pitchErrorSum - pitchKd*pitchErrorDiff/deltaTime2; float rollPID = rollKp*rollError + rollKi*rollErrorSum - rollKd*rollErrorDiff/deltaTime2; float yawPID = yawKp*yawError + yawKi*yawErrorSum - yawKd*yawErrorDiff/deltaTime2; //Motor Control - Mixing //Motor Front Left (1) float motorPwm1 = -pitchPID + rollPID - yawPID + baseThrottle + baseCompensation; My question is: Is something wrong implementation second method? Source: The way I've obtained change time DT taking timestamp start loop taking next time stamp end loop. Their difference obtained obtain DT. getTickCount() OpenCV function. /* Initialize I2c */ /* Open Files data logging */ while(1){ deltaTimeInit=(float)getTickCount(); /* Get IMU data */ /* Filter using Complementary Filter */ /* Compute Errors PID */ /* Update PWM's */ //Terminate Program 40 seconds if((((float)getTickCount()-startTime)/(((float)getTickFrequency())))>20){ float stopTime=((float)getTickCount()-startTime)/((float)getTickFrequency()); gpioPWM(24,0); //1 gpioPWM(17,0); //2 gpioPWM(22,0); //3 gpioPWM(18,0); //4 gpioTerminate(); int i=0; (i=0 ; < arrPitchCF.size(); i++){ file8 << arrPitchCF.at(i) << endl; } (i=0 ; < arrYawCF.size(); i++){ file9 << arrYawCF.at(i) << endl; } (i=0 ; < arrRollCF.size(); i++){ file10 << arrRollCF.at(i) << endl; } (i=0 ; < arrPitchAccel.size(); i++){ file2 << arrPitchAccel.at(i) << endl; } (i=0 ; < arrYawAccel.size(); i++){ file3 << arrYawAccel.at(i) << endl; } (i=0 ; < arrRollAccel.size(); i++){ file4 << arrRollAccel.at(i) << endl; } (i=0 ; < arrPitchGyro.size(); i++){ file5 << arrPitchGyro.at(i) << endl; } (i=0 ; < arrYawGyro.size(); i++){ file6 << arrYawGyro.at(i) << endl; } (i=0 ; < arrRollGyro.size(); i++){ file7 << arrRollGyro.at(i) << endl; } (i=0 ; < arrPWM1.size(); i++){ file11 << arrPWM1.at(i) << endl; } (i=0 ; < arrPWM2.size(); i++){ file12 << arrPWM2.at(i) << endl; } (i=0 ; < arrPWM3.size(); i++){ file13 << arrPWM3.at(i) << endl; } (i=0 ; < arrPWM4.size(); i++){ file14 << arrPWM4.at(i) << endl; } (i=0 ; < arrPerr.size(); i++){ file15 << arrPerr.at(i) << endl; } (i=0 ; < arrDerr.size(); i++){ file16 << arrDerr.at(i) << endl; } file2.close(); file3.close(); file4.close(); file5.close(); file6.close(); file7.close(); file8.close(); file9.close(); file10.close(); file11.close(); file12.close(); file13.close(); file14.close(); file15.close(); file16.close(); cout << "" Time Elapsed = "" << stopTime << endl; break; } while((((float)getTickCount()-deltaTimeInit)/(((float)getTickFrequency())))<=0.00419){ //0.00209715|0.00419 cout << "" DT end = "" << deltaTime2 << endl; deltaTime2=((float)getTickCount()-deltaTimeInit)/(((float)getTickFrequency())); } cout << "" DT end = "" << deltaTime2 << endl; } Here's data:",control quadcopter pid raspberry-pi stability
9001,Robot never goes straight,"I using 2 identical DC motors castor wheel. The motors connected L293D motor driver controlled RPi. The robot going straight. It veers right. I running motors 100% PWM. What I tried correct error: I adjusted PWM wheel going faster 99%, robot turns side; I adjusted weight robot problem still persists. I tried run motor without load. Is cause this, I later told that, running DC motor without load damages them? If cause, please tell solve problem without using sensors controlling it.",control motor wheeled-robot raspberry-pi
9007,Is 2 motors needed arm move anyway circular?,"If I'm limited 4 motors, four legs, could robot rotate go up/down directions? I'd use 2 motors leg? Correct?",stepper-motor
9009,How connect Phone Robot charging phone external battery?,"I controlling robot via usb Android phone running robot's code. This phone poor battery I need extend life USB charger (can't change phones). How I charge android phone via usb, maintaining USB connection robot? I solder wires together needed, buy adapters needed.",mobile-robot usb
9010,Is distortion introduced lens protector significant practice?,"I computer-vision application I made localize robot room; software use working fine. When I calibrated camera got intrinsics lens distortion coefficients lens protector lens, mounted robot's lid. If I take robot's lid (and thus lens protector) localization solution becomes erratic inaccurate, I think lens protector might changing distortion properties significantly. Today lens protector became detached replaced shortly after. So calibration may longer valid localization solution much noisy. Can lens protector greatly effect distortion properties image, someone offer another explanation? I intend recalibrate super-glue lens protector robot's lid, I curious problem, anyone else encountered lens protectors.",computer-vision cameras calibration
9013,How many DOFs required define 3D pose,"I understand able define point 3D space, need three degrees freedom (DOFs). To additionally define orientation 3D space, need 6 DOFs. This intuitive DOFs defines position orientation along one axis orthogonal X-Y-Z system. However, consider robot arm this: . This 6 DOFs, rather DOF defining position orientation X-Y-Z system, defines angular rotation one joint along arm. If joints arranged along single axis, example, 6 DOFs would fact define one angular rotation. So, true DOF independently defines single position orientation. However, case robot arm, reach positions orientations. I'm assuming geometry links joints make DOF define independent position orientation, vague concept intuitive simply one DOF per position orientation. Can somebody offer help understanding concepts?",kinematics
9020,How one calculate distance angle using target known measurements?,"The target shape U horizontal segment 20 inches, two vertical segments 14 inches. We using camera image target, using vision processing isolate target rest image. We know vertical field view, horizontal field view camera. The resolution camera 640x480 pixels. The vertical distance camera robot target constant yet unknown robot hasn't constructed yet. It known, however, target always higher elevation camera. How use data calculate real time robot's distance target, angle target?",computer-vision real-time
9022,The logic implementing Auto-level function PID flight controller,"So I multi-rotor basic PID controller, keeps axis stable gyroscope. However, multi rotor, keep height position. So I would like use accelerometer keeping rough position (auto level). I want use gyro accelerometer, would accelerometer values used, implemented PID ways gyro values (degrees per second, rate I used calculate PID)? And adjusting esc that?? I confused part (the basic logic using accelerometer values)",quadcopter pid imu accelerometer
9023,Is way measure 3 axis orientation without magnetometer?,"I bought STM iNEMO evaluation board order monitor inclination separate magnetic sensor array moves linear scan outside (non-magnetic) stainless steel pipe. I want measure inclination sensor along scan ensure change. The problem I found measured magnetic field integrated magnetometer varies greatly position along pipe, turn, causes large, position dependent error one axis inclination reported iNEMO IMU. In fig. 1 I show set test, I measured inclination IMU moving along length pipe back again. The board change inclination throughout measurement. In Fig 2 I show magnetometer inclination measurements recorded ""iNEMO application"" showing large error one inclinations. My question whether know way correcting magnetic field variation I still accurately determine inclination three directions? My data suggests magnetic field variation measured magnetometer much greater geomagnetic field, inclination measurement always inaccurate. A follow question I is: Is way measure 3 axis orientation WITHOUT using magnetometer?",imu gyroscope magnetometer orientation
9025,Cost material 3D print,Can someone please share typical cost material 3D print object like raspberry pi case? Thank you.,3d-printing
9027,Do walking robots use accelerometers?,"My understanding walking robots (e.g. ) use gyroscope determine current orientation robot, joint robot. This put encoders joint, cumulative error entire robot large maintain stability. Therefore, gyroscope measures ""real"" orientation, used feedback robot walking. However, I'm also aware walking robots use accelerometers maintain stability. What would benefit using accelerometer case? Would used instead gyroscope, together gyroscope? My guess gyroscopes measure acceleration directly (unless numerically calculate based lots orientation readings), accelerometers measure directly (and reliably numerical method). Know acceleration well position enables robot accurately predict future position, hence feedback loop robust. Is correct, I missing point?",control sensors accelerometer dynamics walking-robot
9033,How modular arm joints work,"Hello I'm trying figure modular arm joints designed kind bearings/shafts used modular-type robotic arm. Take ""UR arm"" example. I believe 'T-shaped pipes' include drive bearing system. And see second image, detached easily. So I think it's simple ""motor shaft connecting member want rotate"" mechanism. I'm wondering type mechanism bearing system inside T-shaped pipes. How transfer rotational motion member without using shafts?",mechanism joint arm
9034,"What ""6 degrees freedom"" mean?","I looking page describes various characteristics gyroscopes accelerometers. Close end (where speak IMUs), names items something like this: 9 degrees freedom 6 degrees freedom Can anyone explain mean?",accelerometer gyroscope
9038,How load PUMA robot existing environment OpenRAVE 0.9,"I PR2 robot environment, seen GUI OpenRAVE. Now, I load PUMA robot arm environment?",robotic-arm motion-planning
9039,How I switch Autonomous mode usercontrol?,"I want switch usercontrol autonomous. When I program running 120 seconds, come wont automatically switch autonomous mode? Thanks!",wheeled-robot robotc vex
9040,Metal shaft design 6mm plastic bevel gear,I small POM bevel gear dimensions: It 6mm hole shaft M4 hole set screw. Suppose bevel gear meshed 45T bevel gear give max. output torque 0.4kg/cm. How design 6mm shaft be? Should diameter precisely 6mm? Should flattened 'D' shape (so set screw hold shaft)? I'm planning use metal shaft. Any help appreciated. Thanks,mechanism torque gearing
9043,Joystick Rate Limit Filter For FRC Java Programming,"I programmer school's FRC robotics team received request hardware/driving department limit speed robot's motors accelerate given joystick input telling increase speed motor. For example, robot first starts driver decides move joystick center fully position (0 full motor power), don't want literally go 0 full motor power instant - obviously creates rather jerky, unstable behavior. How might I receive target joystick position joystick, save it, build time (and inputs sent process — like telling turn around — stop current process enact new one)? I using Java WPILib's 2016 robotics library: here's API , here's tutorials . I using ""IterativeRobot"" template class, teleop run method teleopPeriodic(), continuously called every milliseconds program (it's i'm receiving joystick input calling method RobotDrive.tankDrive() inputs). I realize programming question robotics question, I figured would better put stack overflow, etc. If someone could give simple pseudocode conceptual idea might done (not necessarily pertains directly library language I'm using), would great.",software first-robotics
9044,Create 2 Cable 700 Series Roomba,"For last months I playing ROS nVidia Jetson TK1 development board. Up point, mostly playing GPIO header, Arduino Uno, couple physical contact sensors, custom motor servo boards I slapped together. But lately I've eyeing old 700 series Roomba gathering dust (was replaced 800 series). Does anyone know Communication Cable Create 2 work 700 series Roomba? I know DIY designs there, I always fan using off-the-shelf components exist - rarely save money time worth something like cable similar component. So Create 2 cable work, I'll use that. If not, I'll see I make own.",ros irobot-create roomba
9048,L293D won't turn motor backwards,"My small robot two motors controlled L293D controlled via Raspberry Pi. They go forwards one go backwards. I've tried different motors tried different sockets breadboard, luck. Either L293D's chip broken (but wouldn't go forwards) I've wired wrong. I followed tutorial, Controlling DC Motors Using Python With Raspberry Pi, exactly. Here run works. Let 2 motors A B: When I use python script (see end post) motors go ""forwards"". When I change values Python script, pin set HIGH pin set LOW swapped, motor A go ""backwards"", expected. However, motor B move all. If I swap motors' wiring original python script make go backwards swapping pins code make motor A go forwards motor B won't move. So basically, motor A go forwards backwards depending python code motor B changed physically changing wires. This import RPi.GPIO GPIO time import sleep GPIO.setmode(GPIO.BOARD) Motor2A = 23 Motor2B = 21 Motor2E = 19 Motor1A = 18 Motor1B = 16 Motor1E = 22 GPIO.setup(Motor1A, GPIO.OUT) GPIO.setup(Motor1B, GPIO.OUT) GPIO.setup(Motor1E, GPIO.OUT) GPIO.setup(Motor2A, GPIO.OUT) GPIO.setup(Motor2B, GPIO.OUT) GPIO.setup(Motor2E, GPIO.OUT) print(""ON"") GPIO.output(Motor1A, GPIO.HIGH) GPIO.output(Motor1B, GPIO.LOW) GPIO.output(Motor1E, GPIO.HIGH) GPIO.output(Motor2A, GPIO.HIGH) GPIO.output(Motor2B, GPIO.LOW) GPIO.output(Motor2E, GPIO.HIGH) And backwards.py import RPi.GPIO GPIO time import sleep GPIO.setmode(GPIO.BOARD) Motor2A = 21 Motor2B = 23 Motor2E = 19 Motor1A = 16 Motor1B = 18 Motor1E = 22 GPIO.setup(Motor1A, GPIO.OUT) GPIO.setup(Motor1B, GPIO.OUT) GPIO.setup(Motor1E, GPIO.OUT) GPIO.setup(Motor2A, GPIO.OUT) GPIO.setup(Motor2B, GPIO.OUT) GPIO.setup(Motor2E, GPIO.OUT) print(""ON"") GPIO.output(Motor1A, GPIO.HIGH) GPIO.output(Motor1B, GPIO.LOW) GPIO.output(Motor1E, GPIO.HIGH) GPIO.output(Motor2A, GPIO.HIGH) GPIO.output(Motor2B, GPIO.LOW) GPIO.output(Motor2E, GPIO.HIGH) If see diff , see difference: Below pictures. You use colour cables link pictures enter image description",wheeled-robot raspberry-pi
9052,Alternative BeagleBone Black Node.js based remote control project?,"I working remote control project involves using Node.js Socket.io transmit joystick data webpage BeagleBone Black. However, I somewhat disappointed BeagleBone - seems like simple tasks connecting Wi-Fi quite tricky... My question is: Are alternative boards I looking at? Boards also Node.js libraries PWM support, could stream video webcam, easier set larger developer community?",control microcontroller pwm beagle-bone
9054,Mass Matrix Lagrange equation,I want find equations motion RRRR robot.I studied bit I confusion. Here one lectures I found online describes Inertia matrix link Ii computed tilde I also described picture below??? So tilde I computed wrt fixed frame attached centre mass. However another example another source rotation matrix multiplication Ic1 Ic2 shown above.Am I missing something?? What significance multiplying Rotation matrix Ic1 tilde I? I using former approach getting fairly large mass matrix. Is normal long terms inside Mass matrix?? still need know though method correct?? equation used Mass Matrix,robotic-arm dynamics
9057,Is supposed bearing?,"I'm looking assembly tail rotor look like original image I wonder ""tail output shaft stopper"" (circled red) meant bearing piece metal stopper: My reading that, since it's held 2 set screws, whole part rotate rod. While rotating, it'd rub bevel gear tail drive though. Am I missing something?",mechanism torque gearing
9063,iRobot Create 2/Roomba 530 Screw size/thread?,"I've looked everywhere I think find information, haven't come across anything. Does anyone know kind screws I use replace ones top Roomba 530? I realize Create 2 technically 600 series, I would expect same. I'd like replace screws Roomba standoffs I stick mounting plate top it. (Additional sensors, CPU, etc.)",irobot-create roomba
9069,Analogue video digital,"I FPV camera outputs analog video (RCA, PAL). I want capture video image processing, therefore I need way convert analog video digital. Can one recommend it? Is advice shield assist? Please note: I want convert frames minimum latency, real time flying drone. I don't need convert image compressed format (which encoding/ decoding may take time), I get RGB matrix straight, preferred. I thought digital output camera, I need one weighs grams I haven't found yet.",quadcopter cameras
9073,Determine robot's position nearby room,"Scenario I 2 roaming robots, different rooms house, robots connected house wifi. Each robot access equipment itself. Question How robots aware other's exact position using equipment house wifi? EDIT: Additional Info Right robots have: RGBDSLAM via Kinect No initial knowledge house location (no docks, mappings/markings, nada) Can communicate via wifi part open ended I'm hoping able stitch scanned rooms together robots even meet. Compass + altimeter + gps get close goal within inch accuracy makes tough. There IS freedom add whatever parts robots / laptop home needs stay dynamic (robots different home every time).",mobile-robot localization precise-positioning
9074,Software real-time ROS system,"As far I know, hardware real-time robot control system requires specific computing unit solve kinematics dynamics robot interval zero RTX, assigns CPU cores exclusively calculation, DSP board, exactly calculation. This configuration makes sure calculation strictly within, maybe, 1 ms. My understanding ROS, runs Ubuntu, doesn't exclusive computing unit that. Kinematics dynamics run different threads CPU operates Ubuntu system, path plan, everything else. My question ROS achieve software-real time? Does slow sampling time maybe 100ms makes sure calculation done time? Or sampling time changes cycle maybe 5ms, 18ms, 39ms time order fast possible ROS somehow compensates cycle?",microcontroller ros real-time
9077,PID Tuning Unbalanced Quadcopter: When I know I-gain I've set high?,"Good day, I working autonomous flight controller quadcopter ('X' configuration) using angles inputs setpoints used single loop PID controller running 200Hz (PID Implementation Here: Quadcopter PID Controller: Derivative Measurement / Removing Derivative Kick). For I trying get quadcopter stabilize setpoint 0 degrees. The best I able come currently +-5 degrees bad position hold. I first tried using PD controller since quadcopter inherently front heavy due stereo cameras, amount D P gain enough stabilize system. An example image I added small I gain: As see image (at second plot), oscillations occur level zero degrees due quadcopter front heavy. This means quad oscillates level postion 0 degrees negative angle/towards front. To compensate behaviour, I discovered I set DC level oscillations occur using I gain reach setpoint. An image shown [I think] adequate I gain applied: I adjusted PID gains reduce jitters caused much P gain D gain. These current settings (Which two tests corresponding footage below): Test 1: Test 2: I can't seem tune quadcopter reach setpoint least +-1 degrees error. I noticed increasing I-gain longer increases DC offset. When I know I-gain I've set high? How reflect plot? EDIT: The Perr graphs difference setpoint CF (Complementary Filter) angle. The Derr plotted yet divided deltaTime execution time small ~ 0.0047s make errors P I hard see. The Ierr plotted error integrated time. All errors plotted (Perr, Ierr, Derr) yet multiplied Kp, Ki, Kd constants The 3rd plot images response quadcopter. The values Y axis correspond value placed input gpioPWM() function pigpio library. I mapped using scope values 113 209 pigpio integer input corresponds 1020 2000ms time high PWM 400Hz ESC's EDIT: Here current code implementation setpoint 0 degrees:",pid raspberry-pi quadcopter tuning
9082,Optimal location center mass inverted pendulum,"I'm building inverted pendulum controlled DC motors, I've run across conundrum. Personal life experience tells it's better lower center mass maintain balance. On hand, greater moment inertia (e.g. higher center mass), easier maintain balance well. These two views seem plausible, yet also seem contradictory. For inverted pendulum, optimal balance two perspectives? Or one absolutely right absolutely wrong? If one wrong, error thinking?",dynamics balance
9090,XBee xtend recovery/troubleshoot,"I broke xbee xtend 900MHz module. While firmware-writing job I suddenly restarted windows. I've tried recovery procedure XCTU new version work, therefore I'm still working old version. error i'm facing",radio-control
9096,Is alternative manifolds using quaternions orientation representation Pose Graph SLAM?,"I want implement pose graph SLAM following [1]. Since vehicle moving 3D-space represent pose using 3D-translation vector quaternion orientation. [1] tells it's necessary adapt algorithm 1 using manifolds project poses euclidean space. I also studied approach [2]. In section ""IV.B. Nonlinear Systems"" write approach remains valid nonlinear systems. I conclude case it's obligatory make use manifold. But I don't understand avoid it. So questions are: Is correct alternative manifolds? If yes, alternative look like? [1] Grisetti, G., Kummerle, R., Stachniss, C., & Burgard, W. (2010). A tutorial graph-based SLAM. Intelligent Transportation Systems Magazine, IEEE, 2(4), 31-43. [2] Kaess, M., Ranganathan, A., & Dellaert, F. (2008). iSAM: Incremental smoothing mapping. Robotics, IEEE Transactions on, 24(6), 1365-1378.",slam pose
9097,A simple function plotter project,"To plot curve function paper need points curve, draw curve, I store set points processor use motors, markers mechanism draw straight lines attaching points points close resultant look actual curve. So I going draw curve marker pen. Yes project I need motors would change position marker one? With knowledge stepper motor servo motors appropriate sure whether appropriate since I never used them, work? The dimension paper I working 30x30 cms. I two ideas machine a. A rectangular one shown I would make marker holder movable help rack pinion mechanism I sure would precise I may alter mechanism know really help me. b. A cylindrical one Here I would roll paper cylinder paper get unrolled cylinder rotates even marker holder movable X direction rolling paper nothing change Y position. Which one two methods good? I know microcontrollers I want control motors using I decided go Atmega 16 microcontroller. But might need microstepping signals would I able microcontrollers? If know answer atleast one questions answers always welcomed. If need clarifications please leave comment. Thankyou time. Your sincerely, Jasser Edit : To draw lines particular slope I would know slope two points depending slope I would rotate motors particular speed marker move straight fashion slope.",microcontroller stepper-motor servomotor
9099,Reference request: Path accuracy algorithm joint angle space,"I currently reviewing path accuracy algorithm. The measured data points 7 dimensional joint space (the robot test 7 axes Robot, importance question). As far I know path accuracy measured assessed configuration (3 D) space. Therefore I wondering path accuracy definition joint angle space practical value. Sure, one looks joint angle space 7 dimensional vector space example (with Euclidean distance measure) one formally math. But seems odd me. For instance, angle discrepancy measured expected lowest axis much significance discrepancy axis near actuator end effector. So Question: Can anyone point references path accuracy joint space and/or algorithms calculation discussed ? (I quite sure tags use. Sorry I misused some.)",algorithm industrial-robot joint
9100,Finding Center Mass Humanoid Robot,"I've working Humanoid Robot, I face problem finding Center Mass Robot help balancing biped. Although COM simple definition, I'm unable find simple solution problem. My view: I already solved Forward Inverse Kinematics Robot Torso base frame. So, I find position(and orientation) joint base frame, I average get COM. Is approach reasonable? Will produce correct COM? Can anyone offer series steps I follow find COM biped? Any help would appreciated. Cheers!",mobile-robot inverse-kinematics humanoid balance
9103,Connecting CC3D board Raspberry Pi get telemetry data,I want get telemetry data Raspberry Pi connected CC3D board either via USB cable Serial communication. How I get data? I plan wifi communication Pi Laptop. Also OPLink modems used Pi CC3D telemetry. Does anyone python example may help build interface output Linux shell get raw telemetry data RPi?,serial communication
9105,Lag altitude measurements using barometer acclerometer,"I fusing data barometer accelerometer using complementary filter. However, considerable lag readings affecting Alt-Hold performance. Accelerometer : mpu 6050 Baro : ms 5611. Here's code : You find filter implemented function calculateEstimatedAltitude() Does anyone suggestions improve measurements ?",quadcopter sensors sensor-fusion
9106,Sensors identifying stacked books,"I working robotics application involves moving objects (e.g. books) several (around 10) stacks. To measure performance, I'd like able measure book located stacks. The order important I want know book one stacks. The stacks separated least one meter height stacks less 30cm (< 8 Books). If thought putting RFID card every book fixing RFID readers (or below) stack positions. Several readers could attached via SPI I2C arduinos RPis. What think approach? Is simpler way? Could someone maybe recommend sensor could solve problem? // Update: I modify books (e.g. add QR-Marker) extent, can't guarantee orientation stack fixed.",untagged
9111,How make Raspberry Pi?,"I'm currently robotics hobbyist full fledged Arduino I used Raspberry Pi make robots PCs. Currently, I thinking making Raspberry Pi, scratch, breadboard PCB something. I surfed web quite bit I get answer I hoping for. By making Pi, I mean like instead buying Arduino, I make one buying Atmega328, Crystal oscillators, etc. I asking school requires project I make computer gaming console something like I would hate look disappointed face tester I bought Pi , connected devices it. Thanks advance!",arduino raspberry-pi
9114,Simple equation calculate needed motor torque,"Suppose I DC motor arm connected (arm length = 10cm, arm weight = 0), motor speed 10rpm. If I connect 1Kg weight end arm, much torque needed motor complete 360° spin, provided motor placed horizontally arm vertical? Is simple equation I input weight get required torque (provided factors remain same)?",motor torque
9115,"Sphero's logic, work","I'm willing make first robot, I'd like make one similar Sphero. I know I add 2 motors it, make work hamster ball, I don't understand I make rotate x axis aswell axis, assume one front robot x one sides. Any ideas?",design two-wheeled
9119,Weird behaviour Create2 connected via XBEE,"This really problem something strange going on. When Create2 connected PC via USB original connector lead, start-up computer Create2 activated Baud Rate Change (BRC) pulling ground. If I understand correctly, normal behaviour. My Create2 connected XBEE via buck converter, I added switch buck converter XBEE drain battery continuously mentioned specs. I followed Bluetooth pdf connections, working well sending commands I still problems streaming return data resolved. But now, XBEE switched Create2 still activates I start-up PC, possible, BRC pulled ground? There communication PC XB Create2 XB since Create2 XB switched off, PC XB switched starting computer. Its problem, I puzzled. Can anyone explain happening?",irobot-create
9124,Choosing stepper motor hand,"I'm developing robotic hand, decided place motors inside joints (as picture) I'm stuck finding stepper motor fit there. Approximate size motor body radius - 10mm, length - 10 mm. Any suggestions?",stepper-motor
9129,How compute error function graph SLAM 3D poses?,"Given pose $x_i = (t_i, q_i)$ translation vector $t_i$ rotation quaternion $q_i$ transform poses $x_i$ $x_j$ $z_{ij} = (t_{ij}, q_{ij})$ I want compute error function $e(x_i, x_j) = e_{ij}$, minimized like yield optimal poses $X^* = \{ x_i \}$: $$X^* = argmin_X \sum_{ij} e_{ij}^T \Sigma^{-1}_{ij} e_{ij}$$ A naive approach would look like this: $$ e_{ij} = z_{ij} - f(x_i,x_j) $$ $z_{ij}$ current measurement transform $x_i$ $x_j$ $f$ calculates estimate transform. Thus, $e_{ij}$ simply computes difference translations difference turning angles: $$ e_{ij} = \begin{pmatrix} t_{ij} - t_j - t_i \\\ q_{ij} (q_j q_i^{-1})^{-1} \end{pmatrix} $$ Is anything wrong naive approach? Am I missing something?",slam errors
9130,Choosing state vector EKF,"Could someone help understand logic behind choosing particular state space vector EKF? Context: Say 4 wheeled robot operates 2D. It equipped inertial unit (a/g/m) wheel encoders (I understand alone might satisfy accuracy constraints, consider hypothetical case). Now, literature state [q, x, y, vx, vy]' others [q, q_dot, x, y, vx, vy]'. My question is, advantage certain 'rate terms' opposed normal parameters? Also, including bias terms there? How I go selecting appropriate state space vector use-case (in general)? Is set intuitive/mathematical steps consider/follow? Thanks!",wheeled-robot kalman-filter ekf pose
9132,Find orientation Transformation matrix,"I robot 3 rotational joints I trying simulate program I creating. So I 4 frames, one base frame, joint frame. I 3 transformation functions go frame 1 2 3 frame 0. By using transformation matrix, I want know much frame rotated (by X,Y Z axis) compared base frame. Any suggestions? The reason I want I made simple 3D shapes represent joint. By using DH parameters I made transformation matrices. When ever I change θ (it mater θ changes, does), I want whole structure update. I take translation last column. Now I want get rotations.",robotic-arm dh-parameters
9135,Freewheel diode / capacitor board?,"With DC motors, common put freewheel diode and/or capacitor order protect equipment motor induce current system. I plan use board control 24V DC motor Arduino-like microcontroler. In example documentation, don't put protection, I wanted know it's unsafe, board already protects system? The example question:",arduino motor protection
9139,Can I control iRobot Create 2 NI myRIO LabVIEW codes?,I need know iRobot Create 2 controlled NI myRIO programmed LabVIEW. The goal program autonomous robot real-time tracking using Kinect sensor.,mobile-robot irobot-create labview
9143,How homotopy used planning algorithms?,"What intuitive understanding homotopy? At stage homotopy (I understand stretching bending path) planning algorithm? Is homotopy involved, example, implementing algorithm like RRT?",motion-planning rrt
9144,Making car go straight,"I'm trying work car that's controlled Arduino. I'm using following chassis: New 2WD car chassis DC gear motor, wheels easy assembly expansion L298N motor driver. The problem it's hard make car go straight. Giving PWM value motors still makes spin different speeds, trying calibrate value hard every time I recharge batteries value changes. What options making car go straight I want (well, sometimes I'll want turn around course)? I've thought using encoder I wish avoid since complicate whole project, viable option? even using encoder, Does means I need keep track time always adjust motors value continuously? built-in library that?",arduino wheeled-robot calibration two-wheeled
9145,List books similar Thrun's Probabilistic Robotics robot mechanics manipulation,"What? Put together list books (like one C/C++ StackOverflow) spiritually similar Sebastian Thrun's Probabilistic Robotics robotic manipulation mechanics. Why? Thrun's book wonderful resource implementable algorithms also dealing mathematics/theory behind them. In somewhat similar vein robotic mechanics ""A Mathematical Introduction Robotic Manipulation - S.Sastry, Z.Li R.Murray"" lot mathematical/theoretical content. What missing however book algorithms concerned should/would one go implementing theoretical stuff. Requirements Ideally list books dealing diverse areas robotics. The books present algorithms like Thrun book. Algorithms presented language agnostic much possible based packages like MATLAB case categorized appropriately.",kinematics inverse-kinematics algorithm dynamics books
9152,Inverse kinematics calibration,"I working 6DOF robot arm project I one big question. When I first derived inverse kinematics (IK) algorithm decoupling (spherical wrist), I could easily get equations based nominal DH values, alpha either 0 90 degrees many zeros $a_i$ $d_i$. However, kinematics calibration, identified DH parameters longer ideal ones certain small, non-zero, bias added nominal values. So question is, IK algorithm still used actual DH parameters? If yes, definitely end-effector errors actual operation. If not, I change IK algorithm? P.S. I working modular robot arm means DH bias could bigger traditional robot arms.",inverse-kinematics calibration
9155,How import catia assembly Matlab. Simmechanics,In catia .stl format available part file assembly file. Please help import asembly simmechanics .CATProduct .stl Or Is way do?,matlab
9157,regarding finding sensor,I looking sensor able read displayed data LCD display (4 digits). The output sensor must fetched microcontroller. Can anyone suggest sensor please soon?,sensors hall-sensor
9159,Multi-Rate Sensor Fusion using EKF,"Context: I IMU(a/g/m) + Wheel Odometry measurement data I'm trying fuse order localize 2D (ackermann drive) robot. The state vector . I'm using odometry data propagate state time (no control input). The update step includes measurement vector Z = [x_odo y_odo yaw_imu]. I two questions: 1.Does make sense use odometry data(v_linear, omega) prediction well update steps? 2.How I account frequency difference odometry data(10Hz) imu data(40Hz)? Do I run filter lower frequency, I dynamically change matrix sizes way? Thanks!",localization wheeled-robot imu ekf odometry
9161,Robot autonomous variable terrain yaw sensor,"I programming robot drive variable terrain obstacles autonomously. The variable terrain could potentially knock robot initial heading, I would like design autonomous sequence correct change direction. I using accurate sensor compass yaw. What best way correct changes maintain heading? Side side motion stay perfect, heading needs stay same.We currently correcting overpowering one side wheels (depending direction correction needed) heading correct again, seems slightly antiquated method, I'm looking cleaner smooth method.",compass automation
9163,Making VEX central controller,Is way make central controller VEX parts without using VEX Cortex (or anything VEX)? I wondering whether make custom controller VEX parts.,vex
9167,Check collision robot environment OpenRAVE,I robot arm environment. How I check collision robot arm environment?,robotic-arm motion-planning python
9168,memory benchmarking criteria motion planning algorithm,Are still applications memory still criteria respect motion planning algorithms. Are memory efficient motion planning algorithms still relevant?,mobile-robot quadcopter motion-planning
9169,PID Control: Integral error converge zero,"Good day, I recently reading PID controllers stumbled upon something called integral wind up. I currently working autonomous quadcopter concentrating moment PID tuning. I noticed even setpoint zero degrees reached video, quadcopter would still occasionally overshoot bit: Here corresponding data testing roll axis: I noticed I-error converge zero continues increase: Is integral wind-up? What effective way resolve this? I seen many implementations mainly focusing limiting output system means saturation. However I see bringing integral error eventually back zero system stable. Here current code implementation setpoint 0 degrees:",control quadcopter pid stability tuning
9171,Plotting location using wheel encoder data,"Context: I working SFU Mountain Dataset [] The UGV image - via SFU Mountain Dataset website: I used following state update equations (Husky A200 - differential drive) State Update - Prob. Robotics, Thrun et. al After plotting x positions based wheel encoder data (v_fwd w -> dataset provides directly, instead vr vl), curve seems quite weird unexpected. Wheel Odometry Data - Blue - Wheel Odom | Red - GPS Actual path! Question: Is curve expected (considering inaccuracy wheel odometry) something I'm missing? If wheel encoder data bad, EKF (odom + imu) even work? PS: I'm worried EKF (update step) yet. What concerns horrible wheel odometry data.",localization wheeled-robot ekf odometry differential-drive
9174,What kind sensor I use identify fruit (like mango apple)?,"What kind sensor I use identify fruit (like mango apple). Moreover, sensor identify different varieties apples mangoes.",sensors
9175,What best way attach 3D printed part servo robotics use?,"I trying make custom parts fit directly onto servo. Doing proved difficult I've expected far. I hoping avoid incorporating provided servo horns 3D printed part, I've trying method out. Below images current test - 3D printed attachment servo, indentation M3 nut (the servo accepts M3 bolt) attachment servo. The plastic ring doesn't spline (I can't print level detail I think) tight around it. The top piece attaches 3/8"" nut use 3/8"" threaded rod I laying around. So far, I'm difficulty setup working level torque spinning place. So... correct approach? Am I going design piece servo horn inside get servo connect? Are better approaches I haven't considered?",servos 3d-printing
9180,How information gain based exploration differ frontier based?,"I've recently come across concept using information gain (or mutual information criteria) metric minimizing entropy map aid robotic exploration. I somewhat basic question it. A lot papers talk minimizing entropy consider example case something like laser scanner try compute 'next best pose' maximum entropy reduction achieved. Usually mentioned like ""information gain based approaches help finding best spot move robot entropy minimized using raycasting techniques, opposed frontier based exploration greedy"" etc. But I don't understand underlying reason information gain/entropy based exploration better. Let's say robot room three walls open space front. Because range limitations, see two walls: frontier based exploration, robot two choices; move towards third wall realize it's obstacle, move towards open space keep going. How information gain based method magically pick open space frontier wall frontier? When idea what's beyond frontiers, raycasting even help?",mapping exploration information-gain
9183,EKF SLAM (prediction new landmarks),Prediction new landmarks commonly expressed as: However true point landmarks. What I extracting line feature?,slam ekf
9185,Which ultrasonic sensor used detecting hydraulic flow?,"I looking make non contact hydraulic flow meter. I wondering, ultrasonic sensor use? I don't specific ideas go forward. Are articles documented builds subject?",ultrasonic-sensors
9186,Using genetic algorithm tuning controllers,"I've read papers controlling nonlinear systems (e.g. nonlinear pendulum). There several approaches targeting nonlinear systems. The common ones feedback linearizaing, backstepping, sliding mode controllers. In case, I've done theoretical practical parts controlling nonlinear model simple pendulum plus manipulators problems C++. For pendulum, I've utilized backstepping controller solving tracking task angular displacement velocity. The results $$ \ddot{\theta} + (k/m) \dot{\theta} + (g/L) \sin\theta= u $$ $m=0.5, k=0.0001, L=.2$ $g=9.81$. The results good. However, tuning controller time consuming. The majority papers use genetic algorithms tuning controllers PD, PID, backstepping controllers. I'm clueless field I hope someone sheds light concept, preferable MATLAB sample least controlling simple pendulum. So far I've designed simple GUI C++/Qt order tune controller manually. In picture, response controller step function.",control
9187,Ultrasonic flow sensor,"The goal non-invasive flow meter I clamp hydraulic lines. As student hydraulics, I ended looking poking around good way make ultrasonic flow sensor Arduino possibly hc-sr04. Not married either idea. So, I admit, I know nothing, possible this? Is easier way?",ultrasonic-sensors
9194,determines speed quadrotor,How design quadrotor travels particular maximum speed? determine power required quadrotor hover?,mobile-robot quadcopter power
9195,How align solidworks global origin assembly origin exporting solidworks urdf,I created robot model solidworks exported solidworks urdf plug-in. When exporting co-ordinates model misaligned causing problem using ROS. As could see picture Z-axis horizontal assembly whereas vertical solidworks. How align co-ordinates. The generated co-ordinate system must similar solidworks' co-ordinates PS: I mated assembly origin base_link origin,mobile-robot ros navigation odometry gazebo
9200,A Vector Field Histogram implementation Python 2.7,"I trying implement Vector Field Histogram described Borenstein, Koren, 1991 Python 2.7 using SciPy stack. I already able calculate polar histogram, described paper, well smoothing function eliminate noise. This variable stored numpy array, named . However, function computeTheta, pasted below, computes steering direction, able compute proper direction valleys (i.e. consecutive sectors polar histogram whose obstacle density certain threshold) contain section full circle completed, i.e. sector corresponding 360º. To make things clearer, consider two examples: If histogram contains peak angles between, say, 330º 30º, rest histogram valley, steering direction computed correctly. If, however, peak contained between, say, 30º 60º, valley start 60º, go way past 360º end 30º, steering direction computed incorrectly, since single valley considered two valleys, one 0º 30º, another 60º 360º. def computeTheta(self, goal): thrs = 2. s_max = 18 #We start calculating sector corresponding direction target. target_sector = int((180./np.pi)*np.arctan2(goal[1] - self.VCP[1], goal[0] - self.VCP[0])) target_sector < 0: target_sector += 360 target_sector /= 5 #Next, assume best sector. best_sector = -1 dist_best_and_target = abs(target_sector - best_sector) #Then, find sector within valley closest target sector. k range(self.Hist.shape[0]): self.Hist[k] < thrs abs(target_sector - k) < dist_best_and_target: best_sector = k dist_best_and_target = abs(target_sector - k) #If sector still -1, return error. print (target_sector, best_sector) best_sector == -1: return -1 #If not, proceed... elif best_sector > -1: #... deciding whether valley best sector belongs ""wide"" ""narrow"" one. #Assume it's wide. type_of_valley = ""Wide"" #If find sector contradicts assumption, change minds. sector range(best_sector, best_sector + s_max + 1): sector < self.Hist.shape[0]: self.Hist[sector] > thrs: type_of_valley = ""Narrow"" #If indeed wide valley, return angle corresponding sector (k_n + s_max)/2. type_of_valley == ""Wide"": theta = 5*(best_sector + s_max)/2 return theta #Otherwise, find far border valley return angle corresponding mean value best sector far border. elif type_of_valley == ""Narrow"": sector range(best_sector, best_sector + s_max): self.Hist[sector] < thrs: far_border = sector theta = 5*(best_sector + far_border)/2 return theta How I address issue? Is way treat histogram circular? Is maybe better way write function? Thank time.",motion-planning python planning
9203,Helicopter Stabilization Algorithm,"I've hacked rc helicopter, I able control running program computer. I interested writing algorithms stabilize helicopter. For instance, helicopter hovering, shoved balance return previous position stable state. Any help algorithm would awesome.",algorithm stability
9206,iRobot Create: Making Noise Flashing Red Light While Charging,My iRobot Create playing tune every 30 seconds continuously flashing red light I attempt charge it. What issue?,irobot-create
9210,"What difference planning kinematic car, dynamic car, blimp quadrotor","I working sampling based planning library. When I looked implementation, I found kinematic car SE2 state space(x, y, yaw), dynamic car SE2 compound state space (space allowing composition state spaces), blimp quadrotor SE3 compound state space used. I could understand design SE2 SE3 state spaces compound state spaces dynamic car, blimp quadrotor I could comprehend differentiate. difference terms state space motion planning kinematic car, dynamic car, blimp quadrotor?",mobile-robot quadcopter motion-planning
9214,Wireless Mini Camera,"I looking mini, wireless, chargeable, camera stream video real time computer. I put mini camera helicopter send live video feed pic make certain calculations make helicopter navigate certain way. Any help would great.",cameras
9218,Programming 4-digit seven segment display using interrupts,I program autonomous bot (using ATmega2560). It 4-digit seven segment display attached it. I make bot traverse arena continuously displaying time seconds seven segment display. I can't use code display seven segment display function. Any help?,interrupts
9225,How communication old robotic arms NakkaNippon Electric?,"I robotic manipulators NakkaNippon Electric I'm trying communicate using RS232 without success. The robot model microrobots 88-4 88-5. I'm sending commands via COM port, I can't received anything box. I'm using USB-to-DB9 converter (FTDI) DB9-DB25 cable. On net, reference I robot old post year 2000 user @peterkneale. If help, link scanned PDF manual. You see commands page 23-24 pdf (page 21-22 document). Any advice would grateful",robotic-arm
9226,Wind Flow Diagram Of A Quadcopter,"I'm trying determine wind flow diagram around quad-copter action. I looked internet couldn't find reliable source. By wind flow diagram I mean Quad-copter mid-air hovering fixed position. How air moving around it. All directions needed kept mind, Top bottom ( Vertical direction) also Horizontal Direction. Thank You.",quadcopter dynamics
9227,Solar Cells Charging Li-Po Battery,Is way charge Li-Po battery using solar panels increase flight time quadcopter flight?,quadcopter power
9228,Evaluating similarity two 7 Degree Freedom Arms,"I working Baxter robot I first arm configuration bunch arm configurations, I want find closest arm configuration first among many arm configurations. The trick end effector location/orientation exact arm configurations, different ik solutions. Can anyone point towards right direction towards this? Thank you.",robotic-arm inverse-kinematics
9232,How interrupt data ready trigger communications sensor interrupt driven?,"Background: I'm using L3GD20H MEMS gyroscope Arduino library (Pololu L3G) turn relies interrupt-driven I2C (Wire.h); I'd like able handle new reading sensor update calculated angle background using data ready line (DRDY). Currently, I poll STATUS register's ZYXDA bit (which DRDY line outputs) needed. General question: With digital output sensors (I2C, SPI, etc.), datasheets application notes describe using separate (out-of-band) hardware line interrupt microcontroller handle new sets data. But many microcontrollers, retrieving data (let alone clearing flag raising interrupt line) requires using normally interrupt-driven I2C subsystem microcontroller. How new sensor data retrieved ISR interrupt line also using I2C subsystem interrupt-driven manner? Possible workarounds: Use nested interrupts (as @hauptmech mentioned): re-enable I2C interrupt inside ISR. Isn't approach discouraged? Use non-interrupt-driven I2C (polling)--supposedly dangerous approach inside ISRs. The sensor library used depends interrupt-driven Wire library. [Edit: professors' suggestion] Use timer interrupt set sample rate sensor (which settable constant, although measure e.g. 183.3Hz rather 189.4Hz per datasheet). Handling I2C transaction still requires re-enabling interrupts, i.e. nested interrupts performing I2C reads main program. [Edit:] Here's comment I found elsewhere similar issue led believe hang encountered I2C reads failing inside interrupt handler: …during ISR (Interrupt Service Routine) I trying read device determine bit changed. Bad idea, chip uses I2C communications require interrupts, interrupts turned ISR everything goes kinda south.",arduino microcontroller gyroscope i2c interrupts
9233,Uncented Kalman Filter Dummies,"I need help I can't figure Unscented Kalman Filter works. I've searched examples hard understand. Please someone explain works step step trivial example like position estimation, sensor fusion something else?",kalman-filter
9234,Syncing camera signals,"I sure best place ask question, hopefully someone give advice. I device hooked data acquisition system provide sync signal record sync signals. I need synchronize recordings device video feed. I trouble finding camera provide sync signal good way accomplish this. Thanks help.",sensors cameras
9236,Controlling Hubsan X4 Crazyflie USB Dongle,"I Crazyflie USB dongle works Python Crazyflie software, USB dongle control Crazyflie drones well drones operate 2.4 ghz. How I get dongle software work Hubsan X4? Any help would great. The link USB dongle software:",python
9239,Cartesian space velocity profile minimize jerk,"I working 6 DOF manipulator. Currently I implemented simple velocity controler along fixed direction xyz space. I control xyz space velocity (xdot) using predefined velocity profile time. Joint values updated based defined velocity profile. Assume I want move robot along direction parallel z axis, I define trapezoidal velocity profile (z dot) time following, In robot controller program, I convert (z dot) velocity time joint space multiplying inverse jacobian. In way I move robot needed. My question define velocity profile time, total jerk joints time minimized ? Your help really appreciated.",control robotic-arm manipulator
9240,Simulation software KUKA LBR iiwa robot?,"I working KUKA LBR iiwa 7 R800 robot, KUKA's IDE, 'Sunrise.Workbench'. Since virtual platform verify code (simulate), it's quite difficult, I need test code deploying robot. Can anyone suggest simulation software available I test code written using Robotics API Sunrise.Workbench? I came across V-REP simulation software, but, sure I use code workbench platform. Appreciate anyone shed light it. Thanks advance.",robotic-arm simulation
9241,Use MATLAB Compiler SDK generated package KUKA Sunrise.Workbench,"The MATLAB Compiler SDK allows create wrapper MATLAB function accessed Java software. Based understanding, KUKA's Sunrise.Workbench IDE uses standard Java functions. I trying read package generated using MATLAB Compiler SDK (the new version MATLAB Builder JA) workbench platform. I could successfully read package Eclipse IDE, Workbench. The reason using Compiler SDK that, I functions MATLAB, I want use workbench programming. Does anyone experience same? Appreciate help.",matlab robotc
9243,How possible decouple Mimo transfer function robot multi Siso system,Here Mimo transfer function size 3*7 (3 inputs 7 outputs). Is possible decouple interaction loops get multi Siso system G ?,control
9244,ROS tutorials longer working,"Has anyone ever run case fresh install ROS cannot run tutorial packages? I running ROS Indigo nVidia Jetson TK1, using nVidia-supplied Ubuntu image. I fresh install, Ubuntu ROS, keep things clean project. I building kind 'demo-bot' students I teaching; use demo files code. Now, setting things up, I try run talker tutorial check make sure everything running, rospack pretty sure tutorials don't exist. For example, inputting terminal Outputs [rospack] Error: package 'rospy_tutorials' found This case every tutorial file; python C++. Now, I sure tutorials installed. I looking right file system, installed latest versions github. So I think something ROS' side things. Has anyone ever bumped something similar before, ROS package supposedly installed correctly isn't found ROS itself? I would rather reinstall I avoid it. EDIT #1 After playing more, I discovered multiple packages running. All - turtlebot code, packages - returned error above. So I suspect something got messed install ROS. roswtf able run, detect problems. However, going forward. EDIT #2 I double checked bashrc file. One export missing, ROS directory I trying work within. Adding solve problem. I still looking solution, hopefully involve reflashing TK1. EDIT #3 Alright, I've poking days pretty much gave trying get ROS work correctly, decided re-flash necessary. But I think I found something I booted host machine. In downloads folder, I v2.0 v1.2 JetPack. I know I used v2.0 latest install, time I used (it provides useful updates OpenCV bug fixes, among things). I'm going re-flash using v1.2 JetPack time, see things behave better ROS version. Its long shot, I work moment, shouldn't lose ROS capabilities (aside stuff I wanted OpenCV). I'll update everyone seems work. EDIT #4 Ok, everything seems working now. The problem seem issue Jetpack v2.0. I suspect change, somewhere v1.2 v2.0 (made accommodate new TX1 board), messes running ROS indigo TK1. I'm going detailed explanation answer question.",ros
9246,simulation robots,"I designing new mechanism similar robot arm. It would 6 7 axis arms traditional articulated arms. As result, new DH matrix,and inverse kinematics involve. I would like consult robot professionals forum suggest simulation tool mechanism? I plan start start end points. Then I trapezoid velocity plan take sample points sampling time along path. After that, I would like transfer sampling points motor joints DH matrix inverse kinematics. Finally I would basic 3D animation visualize movement temporally. I plan simulate controller behavior application motor drivers deal it. I need focus sending reasonable commands motor drivers. In opinion, Matlab, octave, VC++, third-party tools candidates. Starting ground zero would time-consuming work. I would appreciate experts share tool open source code experience. I search Matlab robotics toolbox I sure fits need expensive optimized ROS. In Octave also robotics toolbox I sure cannot.",robotic-arm matlab simulation c
9250,Quadcopter PID: Controller Saturating,"Good day, I currently creating autonomous quadcopter using cascading PID controller specifically P-PID controller using angle setpoints outer loop angular velocities inner loop. I finished tuning Roll PID last week +-5 degrees error however stable able withstand disturbances hand. I able tune quickly two nights however pitch axis different story. Introduction Problem: The pitch asymmetrical weight (front heavy due stereo vision cameras placed front). I tried move battery backwards compensate however due constraints DJI F450 frame still front heavy. In PID controller asymmetrical quadcopter, I-gain responsible compensating one able ""remember"" accumulating error. Problem Hand I saw tuning pitch gains, I could tune due irregular oscillations made hard pinpoint whether due high P, I D gain. The quadcopter pitch PID settings currently Prate=0.0475 Irate=0.03 Drate=0.000180 Pstab=3 giving error angle setpoint 15degrees +-10degrees. Here data corresponding video. RATE Kp = 0.0475, Ki = 0.03, Kd = 0.000180 STAB Kp=3 Video: Plot: Analysis Results It seen controller saturating. The motor controller currently set limit pwm pulse used control ESC throttle 1800ms 180 code (The maximum 2000ms 205) minimum set 155 1115ms (enough quad lift itselft feel weightless). I make room tuning altitude/height PID controller maintaining throttle ratio 4 motors PID controllers. Is something wrong implementation limiting maximum throttle? Here implementation: Possible solution I two possible solutions mind I could redesign camera mount lighter 20-30 grams. less front heavy I could increase maximum throttle possibly leaving less room altitude/throttle control. Does anyone know optimum solution problem? Additional information The quadcopter weighs 1.35kg motor/esc set DJI (e310) rated 2.5kgs recommended thrust per motor 350g (1.4kg). Though real world test showed capable 400g per motor setup weighing 1600g take-off weight How I tune roll PID gains I set first Rate PID gains. setpoint zero dps Set gains zero. Increase P gain response system disturbances steady oscillation. Increase D gain remove oscillations. Increase I gain correct long term errors bring oscillations setpoint (DC gain). Repeat desired system response achieved When I using single loop pid controller. I checked data plots testing make adjustments increasing Kd minimize oscillations increasing Ki bring oscillations setpoint. I similar process cascaded PID controller. The reason rate PID small rate Kp set 0.1 gains zero already started oscillate wildy (a characteristic high P gain). I set Rate pid's would maintain angle I physically placed (setpoint 0 degrees per second) I used P gain outer loop stabilize PID translate angle setpoint velocity setpoint used control rate PID controller. Here roll axis 15 degrees set point Rate Kp = 0.07, Ki = 0.035, Kd = 0.0002 Stabilize Kp = 2 It stable however reaction time/rise time slow evident video.",quadcopter pid stability
9254,Pure Arduino Quadcopter,"I recently bought set escs, brushless outrunner motors propellers. I'm trying perform calibration esc, I can't find I without using components arduino uno itself. The setup I've managed make one shown picture. The escs mystery, manual found. If helps, buy link : There might also problem battery (LiPo 3.7V, 2500mAh). Can andybody figure I'm wrong? The sample arduino code I found this:",arduino quadcopter esc
9256,3 way check valve,"I working micro dispensing system, using syringe pump. The design involves syringe top moved stepper motor. There would one liquid reservoir form syringe would pull liquid from, push eject liquid end. When pull syringe, liquid sucked syringe, opening shut. When syringe pushed, liquid ejected end. The quantity liquid dispensed would small (400mg) using small syringe 1 2 ml .. per measurement, every 100 dispensing operations, 1 ml syringe would empty would need pull liquid reservoir syringe, dispensing again. My question is, I unsure check valve here. Is 'Single' check valve available would allow kind flow happen ?",motor design
9260,How difficult build simple robots (for example Line follower) using raspberry pi ROS?,"I want build low cost robot, running ROS educational purposes. It simple line follower using raspberry pi IR sensor. Is overambitious beginner project? How difficult make ROS run custom hardware? P.S. I newbie robotics programming I interested building actual robots running simulations. Also, I cant afford buy ROS compatible robots.",ros raspberry-pi electronics
9262,Topics object perception pr2,"I started use ROS hydro (Robot Operating System) ubuntu, using simulator ""Gazebo"" roscpp library, order program robots. In case pick place known objects robots, topics object perception pr2 ROS??",ros gazebo
9263,Are operational space joint space dependent other?,"Some questions this, friends I argued problem. Are operational space joint space dependent other? I know $x_e$ (end effector's pos.) $q$ (joint var.) expressed equation non-linear function $k$: $x_e = k(q)$ But I don't think tells us operational space joint space dependent.",kinematics
9265,Waiting r_gripper_sensor_controller/gripper_action action server come,"I started use ROS hydro (Robot Operating System) roscpp. I tested examples move gripper pr2 Gazebo (especially code : ) catkin package. I launch : roslaunch pr2_gazebo pr2_empty_world.launch I run node code : rosrun pack_name node_name, I get :: Waiting r_gripper_sensor_controller/gripper_action action server come ... Waiting r_gripper_sensor_controller/gripper_action action server come ... I want know cause lines order see results. I do?? notable I launch : roslaunch pr2_gripper_sensor_action pr2_gripper_sensor_actions.launch previous link, I get : [pr2_gripper_sensor_actions.launch] neither launch file package [pr2_gripper_sensor_action] [pr2_gripper_sensor_action] launch file name",ros gazebo
9267,6D localization 6 lasers,"I know multi-rotor is, rectangular room, via 6 lasers, 2 axis. The problem like this: Inputs : Room : square => 10 meters 10 meters 6 positions lasers : Fixed frame 6 orientations lasers : Fixed frame The 6 measurements lasers The quaternion IMU flight controller (PixHawk). The origin centered gravity center multi-rotor defined walls perpendicular axes (the normal wall X (-1,0,0)) Output : Position 3D (X,Y,Z) Angular position (quaternion) Since I got angular position multi-rotor, I rotated laser positions orientations via quaternion, extrapolate via 6 measurements I got 3 walls. (orientations walls trivial, one point enough determine position. Badly, I noticed yaw (rotation z) measurement PixHawk unreliable. Then I measure yaw lasers, I success it. Event 2D problem easy, I lost 3D. Does someone know [Algorithm know XYZ position quaternion 6 measurments] exists somewhere ? Or right way go problem ? The question : How could I get yaw 2 measurements 2 lasers I know original position, orientation pitch roll. NOTE : Green pointers origin position, Red pointers ""final"" position, could rotated around red circle (due yaw).",algorithm geometry
9269,Suggestions object types (features) track ARDrone 2 camera,"UPDATE I aded 50 bounty question StackOverflow I trying implement object tracking camera(just one camera, Z info). Camera 720*1280 resolution, I usually rescale 360*640 faster processing. This tracking done robots camera I want system would robust possible. I list I far results. I tried colour tracking, I would convert image hsv colour space, thresholding, morphological transformations find object biggest area. This approach made fair tracking object, unless object colour. As I looking max objects bigger one I need, robot would go towards bigger one Then, I decided track circled objects specific colour. However, difficult find different angles Then, I decided track square objects specific colour. I used I checked condition (approx.size() >= 4 && approx.size() <= 6) afterwards I checked solidity > 0.85 aspect ratio 0.85 1.15 But still result robust I would expect, especially size. If several squares would find needed one. So, I need suggestions features object could I use improve tracking how? As I mentioned several times, one main problems size. And I know size object. However, I sure I make use it, I know distance object camera I sure represent size pixel representation I eliminate blobs fall range. UPDATE In third step, I described I going detect squares specific colour. Below examples I getting. I used HSV range red colour: Scalar(250, 129, 0), Scalar(255, 255, 255), params OpenCV's inRange function HMIN = 250, HMAX = 255; SMIN = 129, SMAX = 255; VMIN = 0, VMAX = 255; (Would like see suggestions tweaking values well) So, picture see processing; gaussian blurring (5*5), morphological closing two times (5*5). And image label ""result"" shows tracked object (please look green square). On second frame, see cannot detect ""red square"". The main difference two pics I bended lid laptop (please look closer cannot notice). I suppose happens illumination, causes thresholding give desired results. The way, I think two separate processing image. First, thresholding based colour I above. Then I find object move next frame. If use opencv's find squares method. However, method involve much processing image.",quadcopter cameras opencv
9274,Action cost get smooth path,What action cost used get smooth path? Like use distance traversed get shortest path. Will cost get smooth path something related rate change slope path?,motion-planning
9276,Papers Algorithms Robotics,"I'm CS student I need give 30-minute lecture 1-2 papers describing 1-2 algorithms main problems Robotics (navigation, coverage, patrolling, etc.). I background Robotics specifically, I take classes Algorithms AI (including basic AI algorithms A*, IDS, UCS, subjects decision trees, game theory, etc.). The difference simply describing one I need paper refer actual physical robots algorithms, real problems physical world, opposed AI ""agents"" theoretical algorithms. I required lecture 1-2 academic papers, published 2012 onward, ""respectable"" amount citations. Any suggestions papers would greatly appreciated!",navigation algorithm theory coverage
9277,How guide camera circular tube?,"Let's say I 6-DOF flying camera I want make move circular tube autonomously let's suppose camera system makes fly considered point space. Which feature image I get camera I use move camera appropriately, get one end tube get other? For example, I thought I could use edge detection. As camera moves forward tube, due fact far plane infinitely away, dark circle forming camera sees nothing surrounded walls tube. I think ""preserving"" circle might way go (for example becomes ellipse I move camera accordingly become circle again), features help ""preserve"" circle? I would like use image-based visual servoing that. However, troubles following. In visual-servoing applications I seen, control objective make features ""look"" certain way camera point view. For example, projections 4 points want camera move accordingly projections' coordinates specific values. But features actually same. In case I thought example I could say I want projections 4 ""edge points"" circle/ellipse take specific values define circle centered fov camera. But camera moves achive setup features, 4 new ""edge points"" correspond projections 4 different real points pipe theory collapses. Am I right think that? Any way get past it? Any oher ideas relevant literature?",localization cameras motion-planning visual-servoing exploration
9280,Inverse kinematics singularity MATLAB,"I want find general coordinates q=[alpha,beta,gamma] (3 revolute joints) minimizes norm ||rGoal - r||_2 rGoal included manipulator workspace. The problem already solved coordinates rGoal inside manipulator workspace, I really dont know Singularities. A stopping criteria I use is: norm(rGoal-r_BF_inB(q_old(1),q_old(2),q_old(3)))< norm(rGoal-r_BF_inB(q(1),q(2),q(3))) But really give correct answer. How solved general rGoal outside workspace?",inverse-kinematics
9282,Mobile phone power packs,"For robotics project I would like utilise readily available mobile phone 'power banks' simplify power system robot. However, power banks output 5V, great logic systems motors. I wondering I could wire outputs two power banks series get 10V bad idea? Should I wire parallel use boost converter? Is custom solution using 'ordinary' Li-Po batteries associated charging circuit best answer? Additional Information: This two wheeled robot. 5V Logic 7+V Motor driver Power Banks: 5V 2.1Amp 2100mAh",mobile-robot power battery
9290,Micro Powder Dosing,"I process designing micro powder doser metallic powder plastic capsules (the capsule volume would bigger require, traditional capsule filling wont work). The quantity I need dose 400 mg .. What opinion would best approach this? As per research, I found 3 approaches Auger based solution, auger used control powder drop gravitationally. Volumetric As powder quantities would small, metal rods groove proper volume designed dispense powder. For keep powder flowing use vibration motor pour powder groove. A stepper motor rotate rod dispensing powder. I made rod bigger show concept, would mounted cap rotate much volume powder dropped cap. Weight based measurement. Dropping powder weighing balance, control via feedback .. I think would difficult thing do, plus time consuming, provided we'd fill thousands capsules. Prio # 1 accuracy, error margin 1 -2 % .. secondly cost .. I'd like costly .. 300 - 500 $. The metal powder magnetic .. fine .. doesn't clump .. I read articles appears continues tapping powder flow improved lot.",arduino motor
9294,Choosing battery: harbor freight solar battery OK R/C Lawnmower?,"I built R/C Lawnmower. I call Honey Badger, tears stuff (that's good thing). Well, I used used batteries get project going it's long past time get Honey Badger going again. The Honey Badger built electric wheelchair frame, originally used wheelchair deepcycle batteries. U1 I recall. There 4 wired 2 banks series parallel give 24V 24V motors. Going used wheelchair parts place hour drive requires weekend visit get used batteries unknown condition. Contrast Harbor Freight, 20 minutes away solar batteries physical dimensions comparable (?) electrical characteristics. I think coupons, tax, playing game, I get battery ~$50, price used U1. I found Amazon also U1 batteries, ~\$120 2 shipping. Batteries plus sell deepcycle auto batteries greater Ah capacity ~$100 each. Gross solution winds around same: ~\$240 - ~\$300. Is difference technology ""solar battery"" ""wheelchair battery""? Is difference substantial? Given I'm pretty rough thing, particular technology better suited tasks? Is benefit drawback using automotive battery? I charger original wheelchair I recall, it's good capacity room spare. I think put 5 amps.",battery
9296,Why RoboClaw seem ignoring PID gain settings?,"I'm seeing behavior RoboClaw 2x7 I can't explain. I've trying manually tune velocity PID settings (I don't windows box I can't use Ionmc's tuning tool) using command 28 set velocity PID gains, command 55 verify they're set correctly, 35 spin wheel half maximum speed. The problem combination PID gains seems make difference all. I've set 0,0,0 motor still spins roughly set point. I must something wrong, I'm pouring datasheet I don't see is. By rights motor shouldn't spin I use 0,0,0! Any ideas?",control pid
9297,Finding rotation quaternion,"I trying use quaternions robotics one thing I don't understand it. Most likely I don't understand define position quaternions define rotation quaternions difference.. Please watch ""understanding steps"" correct I wrong somewhere. Lets assume I 2 vehicle positions described 2 rotation quaternions: $$ q_1 = w_1 + x_1i + y_1j +z_1k = \cos(\pi/4) + \sin(\pi/4)i $$ This quaternion normalized represents rotation $x$ axis $\pi/2$ angle I understand it. $$ q_2 = w_2 + x_2i + y_2j + z_2k = \cos(\pi/4) + \sin(\pi/4)k $$ And one represents rotation angle $\pi/2$ $y$ axis. $q_1*q_2 = q_3$ would rotation made $q_1$ first $q_2$ second. $$q_3 = \frac{1}{2} + \frac{i}{2} +\frac{j}{2} +\frac{k}{2}$$ QUESTION 1: Given $q_2$ $q_3$ I find $q_1$? QUESTION 2: How find rotation angle vector, given rotation quaternion? For example I want find angle $q_3$ turned $2i+j-k$ quaternion.",kinematics
9298,Finding high torque servo robotic arm,"I new working robotic arms I trouble finding correct servo base arm. It 2 link robot - link weighs 1.2 kg 40 cm long. I gripper 10 centimeters. The servo gripper hold max 4kg. The whole robotic arm, including maximum load carry servos accessories, 8.3 kg. The maximum load needs carry 4 kg end arm 90 cm. What servo could I use move rotary base servo could I use lift arm base? The last one move link would preferable 2 axis servo. The specification I need right servo use energy supply two 12 volts DC batteries connected series 18Ah. I need servo DC. The things worked around servo best work.",robotic-arm servomotor
9301,Direct vs semi-direct methods visual inertial odometry,"I reading papers visual inertial odometry IROS 15: Semi-Direct EKF-based Monocular Visual-Inertial Odometry Robust Visual Inertial Odometry Using Direct EKF-Based Approach I would appreciate someone could explain semi-direct direct methods vary exactly? As far I understand, direct methods use pixel intensities framework. However, papers listed use photometric intensities/pixel intensity values yet one semi direct other's direct.",ekf
9302,Output angle DC motor - current input,"What preferred time-domain method simulate ideal position motor given electrical-current input? Assume goal plot position output motor, based constant electrical-current input. For example, X amps given motor. Plot output Angle Y function time, using time-based tools (not Laplace MATLAB outputs). ========= Two methods =========== Here two methods, yield different results reason. Any ideas identical? Input constant Current . Method 1) Find updated velocity given acceleration acc[k] = (I[k]*Kt - b*vel[k-1]) / J vel[k] = vel[k-1] + acc[k]*dt pos[k+1] = pos[k] + vel[k]*dt + 0.5*acc[k]*dt^2 So, desired, function 'I'. This version less stable, oscillating output, regardless order vel acc computed in. Method 2) Find velocity using difference positions. This could obviously noisy result, practice would need filtered. acc[k] = (I[k]*Kt - b*vel[k]) / J vel[k] = (pos[k] - pos[k-1]) / dt pos[k+1] = pos[k] + vel[k]*dt + 0.5*acc[k]*dt^2 As before, position equation ultimately function I. However, version smoother output. ===================== Appendix 1: For method (1), assume ideal current-driven DC motor Laplace model: angVelocity/current = Kt/(Js+b); Kt motor constant, J rotor inertia, b damping. Then acc*J + b*vel = current*Kt, acc[k+1] = (current[k]*Kt - b*vel[k]) / J. As reminder, vel[k] found using previous acceleration via v[k] = v[k-1] + acc[k-1]*dt noted method #1.",motor kinematics servomotor simulation
9303,Ultrasonic Sensor's Lag (20Hz) effect PID contol loop rate (150Hz),"Good day, I would like ask possible use ultrasonic sensor altitude hold quadcopter sampling rate Ultrasonic sensor (HC-SR04) 20Hz incurring errors polling I tested it. I seen sensor implemented projects however I could find papers explain use sensor better detail. I seen possible solutions raspberry pi one using interrupts using Linux's multithreading. If understanding right, use interrupts, I need sort data ready signal ultrasonic sensor. However available particular sensor. Is possible use echo pin positive edge trigger interrupt service routine (read sonar/calculate distance function). But would introduce inconsistent loop execution times bad consistent PID loop. Another approach use multithreading using wiring-pi library enables run function, let's say function triggers sonar calculates distance along side pid control loop. How would affect PID control loop rate? Which best way implement sonar sensor based altitude hold?",quadcopter pid stability real-time sonar
9305,Create 2 light red/green,"I working project Create 2. Just recently I run problem battery state. The Create 2 charging night clean light shows green. However, I unplug press clean button, shows red consistently run commands Arduino I hooked it. What could problem?",arduino irobot-create battery
9312,KUKA delimiter .NET,"I chance develop user interface program lets user control KUKA robot computer. I know program stuff KUKA utilities, like OrangeEdit, I don't know I want do. I don't even know what's ""best"" language talk robot. My idea control robot arrow buttons, like up/down controls Z axis left/right controls X/Y axes. Can someone help here? I know there's lot libraries control robot even Xbox controller, I limit robot 3 axes I might able control simple buttons. Edit: Now imagine routine consists going P1 P2 P3. I know ""touch up"" points refresh coordinates using console, .net application? like modifying src/srcdat files?",robotic-arm kuka
9313,"How detect wall-corners, fans, lights indoor using CV?","Im currently working autonomous indoor quad-rotor. For purpose I'm using OpenCV enable computer vision drone. I need able detect wall corners, fans (both stationary rotating), lights lamps, wall paintings object associated walls ceiling indoor environment. Until I come two ideas achieve this. 1) Establish ML (machine learning). Use feature descriptors like SIFT, SURF collect set feature descriptors training set try detect objects interest. The main issue access SIFT SURF algorithms available OpenCV 3. 2) Implement SLAM algorithm map environment use information returned identify wall-corners. Of course way I able detect fans lights. So question is, methods I could use ones listed order achieve goal. Am I missing something image segmentation, clustering image transforms (hough line/circle) could utilised situation? Thanks",computer-vision machine-learning opencv
9318,Understanding Drift Simultaneous Localization Mapping (SLAM),"I trying understand effect drift Simultaneous Localization Mapping (SLAM). My understanding drift occurs robot tracks position relative set landmarks storing, landmark small error location. Therefore, accumulation small errors long trajectory causes large error end trajectory. However, I confused would happen robot tracks way back starting positions. Suppose robot starts position A, starts move along path, mapping environment so, reaches position B. Now, robot error stored position B, due drift tracking. But suppose robot makes way back A, tracking relative landmarks created first path. When reaches A, back true position A, i.e. started first path? Or drifted away A? My intuition end true position A, even though landmarks errors them, long error large robot eventually get back position stored landmarks A. And there, landmarks definitely correct, without error, initialized drift errors started accumulate. Any help? Thanks!",mobile-robot localization slam navigation mapping
9320,quadrotor motion planning hard?,"With introduction incremental sampling algorithms, like PRM RRT planning higher dimensional spaces reasonable computation time become possible though PSPACE-hard. But quadrotor motion planning problem still difficult even simplified quadrotor model? I solving dynamic car problem OMPL, produced solution within 10s I set planning time 100s quadrotor, still find solution.",mobile-robot quadcopter motion-planning planning rrt
9321,Having hard time understanding equation monocular EKF SLAM,"Reading paper visual odometry, used bearing vector parameterize features. I hard time understanding state propagation equation bearing vector term means : The vector N mentioned equations, clear does. Would really appreciate someone would help understand :)",localization slam navigation ekf mapping
9323,Lateral load servo motor,"Looking pictures existing designs quadropod robots, servos legs seem usually mounted inside chassis, second attachment back servo well, this: rather putting looks like asymmetrical load, like knees here: Is aesthetics real structural reasons minimize lateral load axle robot size?",joint
9324,Quadcopter PID Tuning Altitude Hold/Position Hold along Z axis,"Good day, I finished tuning Pitch Roll PID's. I setting throttle quad weightless. I tuning axes separately. I would like ask best way tune PID maintaining altitude setpoint. Is best turn Pitch Roll PID controllers tuning altitude PID best already active tuning latter controller? I going use cascaded PID controller using Velocity along z-axis calculated accelerometer output inner PID loop (150Hz) altitude measurement HC-SRO4 ultrasonic sensor (20Hz) outer PID loop.",quadcopter pid stability real-time sonar
9327,Vision-based Position Estimation quadrotor,"As subtask inside main project I need compute position (x,y,z) quadrotor using homography. To I use camera (attached quadrotor) pointing artificial landmark floor. Basically I need compute extrinsic parameters camera know pose respect landmark. I know projective points landmark camera, intrinsic matrix camera I also need real landmark position [X, Y, Z]. I suppose Z coordinate equal 0 landmark plane, I sure compute real [X,Y] coordinates. Any idea that? I also interested put (x,y,z) position quadrotor control path, anybody knows I find info common controllers kind task?",control computer-vision quadcopter uav visual-servoing
9334,Controlling Syma X5C laptop,"Out curiosity, possible control X5C computer? I think I buy transmitter attach laptop. Do think communications transmitter drone proprietary protocol? Or would adhere standard? If links/advice could point right direction, would appreciated.",quadcopter
9336,Jacobian Inverse Kinematics quaternion end effector,"Quaternion four parameters. Calculating Jacobian inverse-kinematics, 3 positions four quaternion parameters make Jacobian $7\times7$ instead $6\times6$. How reduce Jacobian $6\times6$ using quaternion?",robotic-arm inverse-kinematics jacobian
9337,Suitable D star variant non-holonomic motion planning mobile robots,"I working non-holonomic motion planning problem mobile robot completely unknown environment. After going research papers, I found D-star algorithm widely used conditions. But many D-star variants like Focused D*, D*-Lite, Field D* etc... So variants suitable case? Also please suggest better approach problem?",mobile-robot motion-planning algorithm
9341,Computer stereo vision simulator,In research project I deal mobile robot perceives stereo vision. As stereo input data I currently use several datasets taken passenger vehicle contain real world photos. The datasets good get started limited content I would need model traffic situations work stereo vision system. I thinking using kind synthetic graphics simulation input stereo system. What options? I imagine 3D graphics rendering engine whose output would fed input stereo vision could probably used. I found general robotic simulators available like Gazebo since I new robotic simulation I really know begin. EDIT: I forgot write code pure C++. I use OpenCV LIBELAS stereo vision Point Cloud Library (PCL) visualization. All glued together single C++ project compiles single binary.,mobile-robot simulator stereo-vision
9342,ZigBee like network FPV,ZigBee designed video transmission. I need mesh network contains multiple nodes like ZigBee networking robots FPV. Is solution?,communication
9344,Which geo-projection use odometry,"I would like make little survey regarding (geo)spatial projection use elaborating GPS movement data spatial awareness robots. Moving GPS coordinates planar projection seems reasonable choice since distances (for several formulas approximations exist), bearings must computed. Generally, although scales pretty small here, avoiding equirectangular approximation seems good idea order keep consistent system. Avoiding working 3D world (Haversine great-circle stuff) probably good idea keep computations low-cost. Moving world 2D projection hence seems best solution, despite reprojection input GPS coordinates needed. I would like get opinions ideas subject (...if ever anyone interested U_U).",odometry geometry
9346,Pick place robot,I simulate pick place robot (3 DOF). I tried MATLAB. It pick place different objects according geometry. Where I find similar m-codes algorithms?,robotic-arm matlab
9349,Applying MoCap data real life robot,"I Kinect Sensor, iPi software I use create motion capture data use film editing. I looking creating small, Raspberry Pi driven bipedal robot fun, I wondering possible use MoCap control robot? It 20-30 cm tall, six servos (hips, knees, ankles). Is possible apply movement six joints human body robot, like string directly left knee joint left knee servo? It could either real-time, like following actions, using pre-recorded data. (NOTE: If needed, I plug directly Apple/Windows computer, Pi could support this. Also, upper torso moment.)",mobile-robot motion-planning servos
9351,Which kind valve used dispensing food grains?,"I project automated grain dispenser system using PLC control. I need valve dispensing grain hopper packet. I able control flow grain. So kind valve I use flow control grain? There different types grains like rice, wheat, etc., valve controlled PLC (opening closing valve).",automation
9353,Why ESC stop?,"I've built quadcopter four brushless motors ESCs (30A). I'm using Arduino control them. I haven't written complex code; enough get running. Everything fine I send number 920 serial. Then, reason, motors stop spinning. I'm using three freshly bought charged LiPo cells (V = 11.1V). Here link site I bought (I cannot seem find resource them) : 4x A2212 1000KV Outrunner Motor + 4x HP 30A ESC + 4x 1045 prop (B) Quad-Rotor. When I tried turning one motor, I could write 1800 microseconds, 4 1 motor, minimum works 800. Can somebody explain happens I I fix it? Here code:",arduino quadcopter brushless-motor esc
9355,Dynamic model robot lifted balloon (Multibody system),"I'm hard time trying understand obtain dynamic model system similar image. The balloon simple helium balloon, however box actually aerial differential drive platform (using rotors). Now there's basically model balloon another actuated box. However I'm lost combine both. The connection rigid since string. How I it? Is documentation could point to, order help develop dynamics model system? Since I'm lost, help useful. Thanks advance!",mobile-robot kinematics dynamics
9365,"Difference underactuated system, nonholonomic system","What's difference underactuated system, nonholonomic system? I read ""the car good example nonholonomic vehicle: two controls, configuration space dimension 3."". But I thought underactuated system one number actuators less number degrees freedom. So same?",kinematics
9367,Relationship motor torque acceleration,"I working designing building small (1 1/2 lbs), 2-wheeled, differential drive Arduino-controlled autonomous robot. I electronics figured out, I trouble understanding much torque motors actually need move robot. I trying use calculations shown related calculator tool determine speed torque I need. I using wheels 32mm diameter one Pololu's High-Power Micro Metal Gearmotors. I performed calculations robot weight 2 lbs safe found 50:1 HP Micro Metal Gearmotors (625 RPM, 15 oz-in) theoretically work fine, moving robot 3.43 ft/s acceleration around 29 ft/s^2 5-degree incline. However, I found explanation several things I think would important know choosing drive motors. When robot moving motors turned full power, need deliver full stall torque. Based calculations, seems amount torque get robot moving, torque, faster robot's acceleration. Is true? Also, power source cannot supply full stall current motors, robot able start moving? In case, I powering robot 7.2V (6S) 2200mAh NiMH battery pack provide around 2.6A continuously, voltage drops less 1V. Will able power motors? Once robot reaches full speed longer accelerating, theoretically motors providing torque, I think case. Is it, so, I know much torque providing? Will motors I chose enough torque move robot?",mobile-robot motor
9370,Thermal Imaging camera activation upon detection,"So I planning building robot turns detects kind heat source, I currently looking thermal imaging cameras, sure go writing code send ping sort message camera detects heat source. Does anyone know way this? Thanks",wheeled-robot
9371,Reliably establishing communication OI mode Create 2,"I've started tinkering Create 2, I'm issues reliably getting accept commands. I occasionally get right, sometimes, seems ignore me. I'm guessing cleanup code isn't getting state fully reset something. Is good pattern follow fail-safe initialization code? Here's I'm right now: Pulse BRC low 1 second Wait 1 second Send 16x 0 bytes (to make sure it's waiting rest command, completes - seemed help bit I added this) Send 7 (reset) Wait 10 seconds Send 128 (start) Wait 2 seconds Send 149 35 (ask current OI state) Wait 1 second Send 131 (safe mode) Sometimes I'm able issue 137 (drive) commands work. Most times doesn't. The times doesn't, I'm seeing lot data coming Create 2 I'm expecting, looks something like (hex bytes): There's more, logging cut off. I get pattern couple times, seems least partially repeating. I thought maybe it's 16 0-bytes I sent followed 003f 2aff 7321 09cc 0a88, I still don't know interpret that. Sometimes make noise reset command, usually ignores start/safe mode commands completely (I tell green light stays on).",irobot-create
9372,Real-time object classification indoor autonomous quad-rotor,"I designing indoor autonomous drone. I currently writing object classification program OpenCV purpose. My objects interests classification are: ceiling fans; AC units; wall ceiling lamps, and; wall corners. I using BoW clustering algorithm along SVM classifier achieve (I'm still process developing code, I might try algorithms testing). The primary task drone successfully scan (what I mean scanning moving hovering entire ceiling space) ceiling space given closed region successfully avoiding obstacles (like ceiling fans, AC units, ceiling wall lamps). The drone's navigation, scanning process ceiling space, organised pattern, preferably moving tight zig-zag paths entire ceiling space. Having said that, order achieve goal, I'm trying implement following achieve this: On take off, fly around given closed ceiling space use SLAM localise map environment. While running SLAM, run object classier algorithm classify objects interests track real time. Once obtained detail map environment classified objects interest local environment, integrate data together form unified map. Meaning SLAM output, label classified objects obtained classifier algorithm. Now fun comprehensive map environment labeled objects interest real-time tracking (localization). Now pick random corner map plan navigation pattern order scan entire ceiling space. So question is, using object classification real-time yield successful results multiple environments (the quad able achieve mentioned tasks given environment)?. I'm using lot train image sets train classifier BoW dictionary I still feel won't robust method since real-time harder isolate object interest. Or, order overcome this, I use real-situation like train images (currently train images contain isolated objects interests)? Or using computer vision redundant? Is goal completely achievable using SLAM? If, yes, I classify objects interest (I don't want drone fly running ceiling fan mistaking wall corner edge). Furthermore, kind methods sensors, type, detect objects motion? (using optical flow computer vision method useless it's robust enough real-time). Any help advice much appreciated.",mobile-robot quadcopter slam opencv
9373,Drawbacks goal bias RRT,"I working RRT planner remove goal_bias introduce NEW_METHOD direct planner towards goal. I find method good lower dimension. When dimension increases, especially dynamic car, though NEW_METHOD works better, I observe NEW_METHOD along goal_bias works even better. So, possible advantages removing goal_bias I loosing adding along NEW_METHOD?",mobile-robot motion-planning algorithm rrt
9374,Measure weight object using servo,"Assuming quality industrial servo, would possible calculate weight/resistance load? Maybe comparing current draw holding position, time takes lift/lower object. Could accurately measure grams, kilograms? What kind tolerance could achieved? I'm trying eliminate need dedicated weight measurement sensor.",sensors robotic-arm servomotor
9377,Real Time Simulation model Sensors MATLAB,I trying make real time simulink model Leddar Sensor (Ledddar sensor evaluation kit) MATLAB using USB port. But can't use 'data acquisition toolbox' 'Instrument Control Toolbox' leddar vendor isn't listed toolboxes. I would really appreciate someone could help new Real time simulink.,sensors matlab simulator real-time
9380,SLAM Map Quardrant,"Transformation frame global local crucial measurement update keep track direction ? eg: robot location [10,2] [-10,2] requires different sign. Is way set else case general expression ?",slam
9381,PID tuning Quadcopter,"I stabilizing quadcopter. I tuned angle PIDies quadcopter tries stabilize itself, overshooting. Which is, I think, due gyro rates. I read use two PIDies axis. I'm problems attach two PIDies. Can anyone help cascading angle PID rate PID? Will I tune rate PID tuning angle PID?",quadcopter pid
9382,Any books web resources robotics mechanical design?,"I plan build mechanism multiple axis, similar robot. To start, I need define specifications repeatable precision, speed, acceleration, payload. Then motor structure selected designed based parameters. After that, I need choose methods manufacture components. I would like consult experienced experts forum suggested books, textbooks, website resources I learn knowledge?",mechanism manufacturing books
9383,How make robot arm follow shape/path,"First hope stupid question I couldn't find ware solution. I constructed 3 DOF robot arm. I want follow trajectory 2D plane (XY). Tha shapes I want follow lines, cycles splines. I math behind 3 shaped (how defined). I kinematics, inverse kinematics jacobian whole control system (with PID controller). The system receives inputs, Xd(position), Xd'(velocity) Xd''(acceleration) time. I found following image shows (more less) system. So I stuck. How I translate shape position, velocity acceleration joint needs make end effector moves Cartesian space according shape?",pid robotic-arm line-following
9384,PID tuning methods like GA PSO,"I recently started reading PID tuning methods algorithms, I encountered particle swarm optimization algorithm genetic algorithm. The problem is, I don't understand particle/chromosome determines fitness. On real physical system, particle/chromosome checks fitness system? Wouldn't take really long time? I think I missing something here... Can algorithms implemented actual physical system? If so, how?",pid algorithm
9386,Angle circle tangent line,"I want simulate detection moving object unicycle type robot. The robot modelled position (x,y) direction theta three states. The obstacle represented circle radius r1 ( code). I want find angles alpha_1 alpha_2from robot's local coordinate frame circle, shown here: So I trying find angle robot line joining robot circle's centre (this angle called aux_t code), find angle tangent line (called phi_c). Finally I would find angles I want adding subtracting phi_c aux_t. The diagram I thinking shown: The problem I getting trouble code I try find alpha angles: It starts calculating angles correctly (though negative values, sure causing trouble) car circle get closer, phi_c becomes larger aux_t one alphas suddenly change sign. For example I getting this: $$\begin{array}{c c c c} \text{aux_t} & \text{phi_c} & \text{alpha_1} & \text{alpha_2} \\ \hline \text{-0.81} & \text{+0.52} & \text{-1.33} & \text{-0.29} \\ \text{-0.74} & \text{+0.61} & \text{-1.35} & \text{-0.12} \\ \text{-0.69} & \text{+0.67} & \text{-1.37} & \text{-0.02} \\ \text{-0.64} & \text{+0.74} & \text{-1.38} & \text{+0.1} \\ \end{array}$$ So basically, alpha_2 gets wrong form here. I know I something wrong I'm sure what, I don't know limit angles 0 pi. Is better way find alpha angles?",mobile-robot kinematics matlab geometry
9388,Building robotic clamp,If I single stepper motor could I use create robotic clamp could simply grab hold something like plank wood release it? Are standard parts I could use this? I'm trouble finding names parts would be.,robotic-arm
9391,Slam Odometer Requirement,How accurate must odometer reading SLAM ? I writing extra section says question body meet quality standard.,slam
9395,KUKA robot - update coordinates,"I need develop something order update coordinates KUKA KR C4 robot predefined program. After research I've found ways it, non free. I several options, like developing HMI console 3 buttons, touch 3 coordinates I update example. Sending XML file would work I need RSI connection, I can't without proper software (I guess). Do know something like this? Or C++ library allows access /.dat files create new one ""body"" different coordinates? Summing up, imagine I conveyor carries boxes I need develop pick place program. So far good. But every 100 boxes, size changes (and I can't predict it). So operator goes updates coordinates, I want make sure won't change anything else program. Any ideas?",robotic-arm industrial-robot kuka
9397,"If I must fly drone bad weather, I maintain control strong winds?","If I need fly drone strong winds, I stabilize it? Should I use accelerometers gyroscopes keep steady? Or I use flight technique circumstances?",quadcopter navigation accelerometer
9400,Choosing motor type high reliability many cycles,"I designing multi modal stent testing machine bend, twist, compress stents (very thin, light, fragile cylindrical meshes arteries) tube. The machine operate maximum 3.6 Hz months time (> 40 million cycles). As machine lab people, noise minimal. I choosing actuators design overwhelmed range products available. For rotating stents around axis, I need rotary actuator following specs: torque: negligible max angle: 20 deg angular velocity needed: max 70 deg/s hollow shafts plus For compressing stents, I need linear actuator following specs: force: low (<1N) max stroke: 20mm possible 70mm allowing different stent lengths stroke velocity needed: max 120mm/s Price motors driving factor. I looked stepper motors, servo motors, piezoelectric motors. There seems huge selection fits requirements. If motor types reliability suits needs, characteristics/advantages/disadvantages I consider determine selection suitable actuators? I know difference motor types, lot overlap. Concrete suggestions welcome.",actuator reliability
9403,SLAM starting point / quardrant issue,"I question puzzling me. I simple rectangle enclosure extracted Lidar odometer data test run. If put starting position [0,0,90] gives bad map. However shift away [0,0] something like [50,50,90] map seems fine. How ?",slam
9405,VEX Cortex Motor Speeds load,"I trying get robot drive straight trouble. I find running motors load run fine. If I put load one motor accelerates. The performs expected, tries maintain speed. I running 393 motors encoders PID selected. I running robot C. See following video: program follows; Thank you, Mark",pid robotc vex
9409,Why would drone need magnetometer? Are accelerometer gyroscope sufficient?,"Why would drone need magnetometer? What would drone information? I think would tell direction, would need accelerometer gyroscope?",mobile-robot magnetometer
9413,RRT algorithm C++,"I want implement RRT motion planning robotic arm. I searched lot internet get sample code RRT motion planning, I didn't get any. Can someone please suggest good source I find RRT implemented C++ type motion planning.",robotic-arm motion-planning algorithm
9417,How decide battery power robot,"I need motor powered 12V, 5A 1 hour continuously. How decide Ah rate battery. Please suggest lithium ion battery specification",mobile-robot motor power battery lithium-polymer
9420,Why I need I-gain outer-loop?,"I'm implementing set loops control pitch-and-roll angular positions. In inner-loop, motor speeds adjusted achieve desired angular rates rotation (the ""inner-loop setpoints""). An outer-loop decides desired angular rates (the ""inner-loop setpoints"") based aircraft's angular positions. Outer-loop Frequency = ~400Hz Outer PV = input angular position (in degrees) Outer SP = desired angular position - input angular position (in degrees) Inner-loop Frequency = ~760Hz Inner PV = input angular rotation (in degrees-per-second) Inner SP = constant1 * Outer MV (in degrees-per-second) PWM = Inner MV / constant2 (as percentile) I understand I-gain important, I'm able see practical reason also I-gain specified outer-loop. Surely inner-loop would compensate accumulated error, leaving error compensate outer-loop, thinking flawed? Any example gain values elaborate would greatly appreciated.",quadcopter pid
9429,Drone Flight Formation,How one today program fleet drones autonomously fly together formation visual feedback onboard camera?,quadcopter uav
9434,Pose-Graph-SLAM: How create edges IMU-odometry given?,"I want estimate poses vehicle certain key frames. The sensor information I use IMU yields translational acceleration orientation measurments. I obtain 7D pose, i.e. 3D position vector + unit quaternion orientation, I integrate translational acceleration twice propagate orientation measurements. If I want add new edge graph I need constraint edge. In general, pose graphs constraint represents relational transformation $z_{ij}$ vertex positions $x_i$ $x_j$ connected edge. Comparing case literature following questions arised: How I calculate prediction $\hat{z}_{ij}$ I compare measurement $z_{ij}$ computing edge error? Initially, I understood graph slam models vertex poses gaussian distributed variables thus prediction simply calculated $\hat{z}_{ij}=x_i^{-1} x_j$. How I calculate information (preferred) covariance matrix? How I update information matrices? During optimization? Or edge creation? At loop closure? I read chi-square distribution relates Mahalanobis distance. But involved steps? Studying current implementations (e.g. mrpt-graph-slam g2o) I didn't really discover predictions (or probability density function) involved. In contrast, I even confused reading mrpt-graph-slam example one choose raw poses poses treated means probability distribution.",slam imu data-association
9435,Object following robot,"Can please help out? I need car prototype follow object ahead it. I'm using two ultrasonic sensors HC-SR04 sense distance obstacle. I want sensors determine direction servo motor MG995 using Python. How I calibrate servo get appropriate output? If anybody could help code Python it, I'd grateful.",software
9436,What common process place robotic arm gripper,"I implemented simulation robotic arm grab things. This arm 6DOF structure simple gripper top. I made simple CCD IK algorithm control arm. I use two ways: Compute position last joint arm hand part (which means 1 end-effector). Then use analytical method place hand good orientation. Compute directly arm, hand position giving CCD IK algorithm 2 end-effectors 2 finger hand. What used method grabbing arm robot ? I'm willing find solution, know people usually do.",robotic-arm inverse-kinematics
9437,Can simulate actuator strong torque PID controller,"I use gazebo simulate robot arm. To control joints, I use PID controllers. As might know, PID sometimes pretty hard tune case robotic arm. To avoid tuning, I don't need PID values realistic, I set zero derivative integral parameters, increase lot proportional gain add lot damping joints. By this, I get well working arm I disable gravity. My question following. Do idea I could simulate strong actuator necessarily realistic parameters? EDIT 1: Setting integral derivative gain stupid. The integral gain helps correcting effect gravity. The derivative gain counters loss stability speed due integral gain. This question somehow leads another. Do know tuning robotic arm manufacturer (big arms car industry example). I guess arm use actuators strong torque low maximum speed reduces need tuning. EDIT 2: More info setup. I use gazebo 6, ODE. The robot description SDF. I control robot model plugin. As PID controler I use PID class common library gazebo get directly JointControler associated model. Let say I would like actuators robust without tuning needed. This way I could simulation WITH dynamics (by opposition SetPosition method). Do think possible ?",pid power servomotor joint gazebo
9441,create2 commands app called SERIAL,"app called SERIAL, available app store. I've downloaded mac experimenting it, ideas send create2 OI commands using ""Serial""? far seems handy app, I've bypassed need drivers. anyone else use SERIAL/something like? *when SERIAL terminal open number 9 pressed mac seems activate cleaning mode. thats communication I'm getting hours playing around python mac terminal.",mobile-robot irobot-create serial
9443,OpenRAVE ChechCollison command C++,"What equivalent code ""env.CheckCollision(robot)"" C++? Even though said conversion commands python c++ easy intuitive, I find proper documentation conversion?",motion-planning algorithm
9445,"Name large robotic arms (two finger) wrist, arm, hands spinning shoulder axis","I've looking large robotic arms (with two fingers) arm able pick drop things space around arm (and even spin around 'wrist'). I'm sure terminology arm. I've seen this, OWI-535 Robotic Arm Edge, looks close. Is something larger hooked Raspberry Pi instead remote controller? Is particular term generic context? Or way build arm using shelf parts?",robotic-arm raspberry-pi
9447,Programming A Rover,"I part College team planning enter Mars Rover Challenge. In point view programmer, I start? I know C main language NASA used Rover I basic understanding it. Plus, much I look RTOS part making rover? Any books/links topic would greatly appreciated.",programming-languages c
9454,"What correct name ""servo brackets""?","I refer types brackets servo brackets, robot brackets: I know two specific brackets, shown above, known short-U (some vendors refer ""C"", en lieu ""U"") multi-function bracket, respectively, types available, namely: Long U bracket Oblique U bracket bracket L bracket etc. However, I sure correct name types bracket (or range bracket, will), rather servo brackets - either generic name brand name. I seen term before, random web page, name escapes me. They either named creator, or, I recall correctly, institution developed. Does anyone definitive answer, preferably citation web reference, little historical background?",mechanism
9456,How use accelerometer altitude estimation?,"I currently implementing autonomous quadcopter I recently got flying stable, unable correct presence significant external disturbances. I assume insufficiently tuned PID gains tweaked inflight. Current progress: I ruled barometer since scope research indoor flight barometer deviation +-5 meters according colleague. I currently using ultrasonic sensor (HC-SR04) altitude estimation resolution 0.3cm. However I found ultrasonic sensor's refresh rate 20Hz slow get fast enough response altitude correction. I tried use accelerations Z axis accelerometer get height data integrating acceleration get velocity used rate PID cascaded pid controller scheme. The current implementation altitude PID controller single loop pid controller using P controller position input ultrasonic sensor. I taken account negative acceleration measurements due gravity matter much I compute offset, still existence negative acceleration (eg. -0.0034). I computed gravitational offset setting quadcopter still flat surface collecting 20,000 samples accelerometer z axis averaged get ""offset"" stored constant variable. This variable subtracted accelerometer z-axis output remove offset get ""zero"" accelerating. As said question, still existence negative acceleration (eg. -0.0034). My quad proceeds constantly climb altitude. With ultrasonic sensor P controller, quad oscillates 50 cm. How consistent negative acceleration reading effectively dealt with? Possible Solution: I planning cascading PID contoller altitude hold innerloop (PID controller) using accelerometer outer loop (P controller) using sonar sensor. My adviser said even single loop P controller enough make quadcopter hold altitude even slow sensor. Is enough? I noticed P gain, quadcopter would overshoot altitude. Leaky Integrator: I found article explaining dealt negative accelerations using leaky integrator however I bit trouble understanding would work since I think negative error would turn positive error solving problem. I'm quite sure. Single loop PD controller ultrasonic sensor only: Is feasible using feedback slow sensor? Sources: LSM303DLHC Datasheet: Leaky integrator: ArduPilot PID Loop:",quadcopter control pid raspberry-pi sensor-fusion
9459,Building stationary robot talk,"I Computer Science major I basic ideas Robotics. I planning build stationary cubical AI. The main purpose bot that, sensor check door opened immediately asks question ""who opened door?"" I also want recognize correct words interact word, I talking voice recognition word recognition ever speaks correct words(words bot's memory) interact it. Depending opens door(prolly family) I want speak different things. I want respond simple questions like, ""what date time?"" , "" random qoute fact joke"". Is hard achieve? Could anyone give basic idea approach project?",sensors communication first-robotics speech-processing
9463,Quadrocopter PID,I building quadcopter school project. I trying program flight controller using PID algorithm. I'll try make question simple using example two motors Let's say I trying stabilize two motor system using gyro diagram one 1-- ----- ----2 Using formula Output = (gyro - 0) * Pgain Do I need increase output motor 2 would I both: increase output 2nd motor decreasing output first motor? Thank,quadcopter pid ardupilot logic-control
9472,Does controlling system need complex system controlled?,"Is theoretical principle, postulate, states controlling system complex system controlled, formal sense notion ""complex""?",control theory
9476,Remaking RC transmitter controlling aircraft,"I thinking working alternative drone controllers. I looking making easy use natural feel (debating sensor bracelets, rings, etc.). The main issue I is, I've looking standard RC transmitters used control RC aircraft, I sure technology inside them, kind ICs use actual RC signals. I want information make RC transmitter myself, mainly protocol that's used send messages, circuitry needed actually transmit that, kind components I need I implement software? I aiming side project (hobby), I chance use uni project well, I'd like give shot now, I lack proper information getting started. I'd rather take apart current RC controller use oscilloscope decode protocol. Any answers (short long) reading material appreciated. Other questions, protocol implemented software embedded system (Raspberry Pi, Arduino, Intel Galileo, etc.)? I asking frequency 2.4 GHz. This part bigger project, drone related currently, I could use alternative methods sending information, wireless means, first prototype, suggestions welcomed. Need: aircraft RC transmitter protocol info, RC transmitter components & schematics, anything else might help transmission side",microcontroller radio-control
9482,Fastening sheet steel nylon,I'm trying attach small piece sheet steel (30mm x 50mm x 1mm) small piece nylon (50mm x 50mm x 4mm). Does anyone know could fastened using small screws ( Any thought appreciated.,mechanism
9488,Fixed Wing UAV: Do inherently unstable systems desire stable cases closed loop control implemented them?,As know fixed wing vehicles designed inherent instability enables fixed wing vehicles fly. However apply cases? Do inherently unstable systems desire stable cases closed loop control implemented them?,control pid microcontroller uav stability
9491,Can interface Braava Jet?,Is open interface access new Braava jet drive around?,irobot-create
9495,What iRobot products support open interface besides iRobot Create?,I read certain iRobot products support hacked support something close open interace. There even book hacking Roomba. What Robots capability?,irobot-create
9500,APM Mission Planner 2.0.18 Install Firmware Failure Mac OS X 10.11,"I installed Multiple versions (2.0.7, 2.0.17, 2.0.18) Windows 7, Ubuntu 14.04, OSX 10.11. I could connect ArduPilot could install firmware. Here's error I would get: Started downloading Finished downloading /var/folders/r4/s_j4c02s3wvcx6wy41__rnwh0000gp/T/APM Planner.uq1800 Opening firmware file... Unable open file: /var/folders/r4/s_j4c02s3wvcx6wy41__rnwh0000gp/T/APM Planner.uq1800",ardupilot
9502,Use data gyroscope calculate orientation,"From gyroscope I'm getting angular velocities [dRoll, dPitch dYaw] rad/s, sampled intervals dt = 10ms. How I calculate short term global orientation (drift ignored) gyroscope? Pseudo code would helpful.",gyroscope
9505,"Euler-Lagrange systems, autonomous nonautonomous?","I reading article Euler-Lagrange systems. It stated since M(q) C(q,q') depend q, autonomous. As result, cannot use LaSalle's theorem. I uploaded page article highlighted sentence. (ren.pdf) Then, I read Spong's book robotics, used LaSalle's theorem. I confused. (spong.pdf) I research, found non-autonomous means explicitly depend independent variable. Isn't independent variable time systems? So, shouldn't considered autonomous?",control dynamics robotc
9508,"Considerations design actuators, loop feedback systems, robotic arm","Let's say I industrial sized 6DOF robotic arm. I want control one six joints despite non-linearity produced chain structure, gravity weight loads could lift. I don't focus speed power limitations, I want arm respond well. Moreover, I would like avoid use prior knowledge inertial computation. Then I considerations, considering I play actuator design, loop feedback control system: Limit maximum speed actuator smooth error variation. Increase damping actuators avoid high frequency instability. Find good control system, PID, make sure targets reached without oscillations. Do considerations mind? Do know process(es) industrial designers follow? EDIT: As said comments, question concern design adaptive controller robot arm, is, design joint control system (actuator + loop control) don't need inertia masses computed (the controller could adapt structure, loads lifts). I'll much interested know paper adaptive control field robotic arms.",control pid robotic-arm design actuator
9512,DC Motor Control,"My project requires DC motor mobility, similar RC car. If precision isn't critical, I use solid state relay instead motor driver? If vehicle moves extra inch ground, I don't really care.",motor driver
9518,Choose connect camera robot,"There tons cameras devices around us days. There used photo cameras, smartphones, tablets home gathering dust. I wonder, easiest way could get camera module device, connect robot project soldering iron make work software point view. I planning use something like Arduino, STM32 platform, probably Intel Edison. May camera modules easier solder program custom project? Or shouldn't I look way better find camera module specially designed custom projects?",cameras
9521,Difference g-value rhs-value Lifelong Planning A*,"What difference g-value rhs-value Lifelong Planning A* algorithm? According link, D* Lite, g(s) directly correspond g-values A* search, i.e. g(s) = g(s') + c(s',s), rhs(s) given $$ rhs(s) = \begin{cases}0 & = s_{start} \\ \min_{s'\in Pred(s)}(g(s') + c(s', s)) & \text{otherwise} \end{cases} $$ where, Pred(s) denotes set predecessors node 's'. Thus, unless node 's' one predecessor, g-value rhs-value remain same. So, question is, case rhs-value g-value node different?",mobile-robot robotic-arm wheeled-robot motion-planning algorithm
9523,Neural Nework code library MSP430G2553 microcontroller,"I new new neural network also. :P I gone concepts Neural Networks want implement project including microcontroller MSP430G2553 LaunchPad Series. I using sensors want use neural network code manipulate data sensors get threshold. I went post tried implement codes link given giving error less ram, guess due mcu. So, wanted help regarding neural network code library Energia use. Thanks Advance.",microcontroller electronics machine-learning embedded-systems
9532,Quadcopter propeller physics,"In propellers airspeed increases thrust decreases. Is air speed component taken vector quantity perpendicular propeller? If thats true quiet easy visualize case airplanes quadcopters ""copter_airspeed * sin(copter tilt)""?",quadcopter
9535,Anthropomorphic Arm,"I developed anthropomorphic arm (structure aluminium) 6 DOF (3 plus spherical wrist) direct kinematic. I chose magnetic rotary encoders measure angles I satisfied, due causing noise angle measurements. What advise me? To add another sensor perform sensor fusion? To replace magnetic encoders optical ones? or... else?",arm manipulator
9536,Meaning 'sign' Writhe Matrix,"Following equation Writhe matrix article Topology based Representation(page no. 6). What meaning 'sign' second part equation? I sure typo article article Hierarchical Motion Planning(page no. 3), compleletely neglects term 'sign[...]'",mobile-robot control robotic-arm wheeled-robot motion-planning
9538,"Meaning symbol, 'curly N' equation Linear Gaussian system dynamics","In article Topological Based Representation(Page no. 12), equation Linear Gaussian system dynamics given In equation meaning 'curly N'?",mobile-robot control robotic-arm wheeled-robot motion-planning
9542,Meaning equation graphical model,"The paper Topology-based Representations Motion Planning Generalisation Dynamic Environments Interactions Ivan et.al., says page 10 Approximate Inference Control (AICO) framework translates robot dynamics graphical model following equation: What p(x0:T,u0:T) mean? I feel p means 'prior of' uncertain quantity, I'm sure this.",mobile-robot control robotic-arm motion-planning
9544,Enable Bluetooth communication iRobot Create 2,I got new iRobot Create 2. I used use Element Direct BAM (Bluetooth Adapter Module) iRobot Create previously. How I communicate Create 2 using Bluetooth? What accessories I need?,irobot-create
9545,Autonomous Indoor Positioning System Robot based CV approach,"I questions regarding IPS autonomous robot system, Configuration: Mounting camera ceiling room Assume room cube 5mx5mx5m (LxWxH) Assume camera Microsoft LifeCam Studio (CMOS sensor technology, Sensor Resolution: 1920 X 1080, 75° diagonal field view, Auto focus 0.1m ≥ 10m, Up 30 frames per second, Frequency Response: 100 Hz – 18 kHz) A rover Objectives: By putting rover unknown location (x,y) room, system localize rover's position After rover's coordinates known, Navigation next step We want rover navigate known coordinates (x1,y1) (let's say point A) another point B map (x2,y2) Control signals sent rover's servos complete navigation task Methodology: Camera capture environment real time Environment represented cells (occupancy grid mapping) Assume cell represents 5 cm environment Rover localized system point A Determine navigation point B Determine path rover grid map (ex: go x cells horizontal cells vertical) Control Signal sent rover's servos Questions: Can I use camera task I need another type cameras ? What factors affecting system accuracy ? (ex: Sensor Resolution - FOV - FPS - Frequency Response - Distance camera ceiling) What's important factor consider increase accuracy ? I would appreciate opinions regarding project King Regards, Thank",mobile-robot localization slam computer-vision mapping
9547,Reverse engineering commercial drone control algorithms,"I'm wondering way figure actual controllers used commercial drones AR drone Phantom. According AR drone SDK, users allowed access actual hardware platform yet capable sending receiving commands from/to drone. Edit: I'm hoping check actual controller utilized software. When I fly AR drone, seems platform can't stabilize I perform aggressive maneuvers, therefore, I guess use linearized model applicable using simple controllers PD PID",quadcopter control
9552,How Topology-based representation invariant certain change environment,"The article Topology-based representation (page no. 13, line 5) says that, topology-based representation invariant certain changes environment. That means trajectory generated topology-based space remain valid even certain changes environment. But possible? Is simple example understand concept?",mobile-robot control robotic-arm motion-planning
9553,Counting number people entering room,"We making project want count no. people entering leaving room one single entrance. We using IR sensors detectors ,along Aurdino. We problem system, i.e two persons entering leaving room time getting wrong count. Thanks advance valuable time solution.....If better way,please state that.",arduino sensors microcontroller
9554,Quadcopter PID Algorithm,"I'm trying implement PID control quadcopter using Tiva C series microcontroller I trouble making PID stabilize system. While I testing PID, I noticed slow weak response PID controller (the quad shows response small angles). In words, seems quad's angle range relatively large (above 15 degrees) show response. Even then, response always shoots matter I, D gains I choose system. At low P, I prevent overshoot becomes weak. I sure PID algorithm problem kinda bad hardware configuration (low IMU sample rate maybe bad PWM configurations), I strong doubts PID code I noticed changing gains improve system response. I appreciate If someone point whether i'm anything wrong PID snippet pitch component I posted. I also roll PID similar code I posted I leave one out. void pitchPID_adjustment(float pitchPIDcontrol, unsigned char pitch_attitude) { (pitchPIDcontrol>(maximum_dutyCycle-set_dutyCycle)) { pitchPIDcontrol=maximum_dutyCycle-set_dutyCycle; } switch (pitch_attitude){ //change rotor1&2 case 'p': //positive status PWM0_2_CMPA_R += (pitchPIDcontrol);//(RED)//motor1 PWM0_0_CMPA_R += (pitchPIDcontrol);//(Yellow)//motor2 break; //change rotor 3&4 case 'n': //negative status PWM0_1_CMPA_R += pitchPIDcontrol;//(ORANGE)//motor3 PWM1_1_CMPA_R += pitchPIDcontrol;//(green)//motor4 break; } Also, someone please tell motor mixing works?: Front =Throttle + PitchPID Back =Throttle - PitchPID Left =Throttle + RollPID Right =Throttle - RollPID vs I function: void pitchPID_adjustment(float pitchPIDcontrol, unsigned char pitch_attitude)",quadcopter control pid imu pwm
9555,What millisecond rate robot-create respond two different drive commands?,I want issue two slightly different drive commands smallest loop rate robot-create accepts new commands? I know reading documentation appears sensors read every 15ms. Not sure command rate is?,irobot-create
9565,"Best sensor determine ""up"" versus ""down""",I want start designing Arduino project telemetry readings indicate tilt angle placement. Would accelerometer best determining tilt? Are good tutorials?,mobile-robot arduino
9568,What CIM motor?,I'm trying make decisions motors robot build. I keep running across CIM Motors. What CIM Motor? Where designation CIM come from? What CIM mean?,motor
9569,Robotic Arm analysis Matlab/simulink,"I going paper, Kinematic Modelling Simulation 2-R Robot Using SolidWorks Verification MATLAB/Simulink, 2-link revolute joint robotic arm. According paper, trajectory analysis robot done via simulations MATLAB/Simulink. It shows following picture, Trajectory generation 2‐R robot MATLAB/Simulink: then, Simulink - Simulation block calculate trajectory: I think done SimMechanics, I sure. Experienced users, please tell I looking I reproduce this?",robotic-arm matlab simulation
9571,Simulating Dynamixel motors Gazebo,"I'm trying simulate humanoid robot using Gazebo plugins. Since actual model uses Dynamixel motors, I'd like know exactly work make simulation realistic possible. Gazebo offers two options control joints. One PID controller, provided class. The way directly set torque joint. (The PID method ultimately implemented using torques). Currently, I'm trying PID-based implementation. I've used P-only controller damping joints (I've guess values). However, large amount noise, difference actual desired position times much 10-12 degrees (especially foot robot hits ground). Does actual motor use PID controller well? I can't seem find details here, Dynamixel EX-106 User's guide, link, Dynamixel EX-106+ Robot Actuator mentions ""Compliance/PID : Yes"". If motor use PID controller, parameters? And allow us set moving speed then? If motor doesn't use PID controller, pattern torque provided? In manual (first link), I found From current position 200 491 ( 512-16-5=491 ), movement made appropriate torque reach set speed; 491 507 ( 512-5=507 ), torque continuously reduced Punch value; 507 517 ( 512+5=517 ), torque generated. This rather vague though, details provided. Also, I'm aware extremely high damping extremely high P-values might trick. But I want simulate actually happens motors, probably way go. I'd appreciate anyone idea Dynamixel servos do, examples simulated Dynamixel motors anywhere else.",pid simulation gazebo humanoid dynamixel
9572,Transfer function quadrotor position controller,"I'm trying find transfer function quadrotor two controller loops, following next structure: I know calculate attitude stability controller, relate rotor speed desired angles. However, I clear implement translational controller transfer function, whose output desired angle rotors must achieve considering position I want translate. Considering two controllers PD, calculate translational controller transfer function include system? Time domain equations outer loop next, U terms relate thrust axis components. Thanks",quadcopter control
9578,Create2 Serial. Canonical versus Number Bytes interface,There message system appear document OI spec. This appears canonical terminal type serial interface messages come back firmware version stuff. I sure determine end type message is? It fixed number end lines? Bytes. One message seems indicate STR730 would 730 byte string. The open interface spec seems indicate non canonical interface spec read fixed number bytes processing end lines. Is correct?,irobot-create roomba
9580,Ultrasonic sensor range shape,"I looking cheap ultrasonic sensor blind +/-30 cm sensors I could find use following shape, suitable project (because robot design 1 hole, 2..) : Is chance find sensor shape range starting around 5cm ? Actually I wondering 2nd shape makes constraint mandatory I found appropriate product.",ultrasonic-sensors
9583,Servo motors large scale RC car,"I want convert electric ATV (quad) kids (like HIGHPER ATV-6E) radio control robotics project. These small ATVs meter long weigh 40 kg. I need choose servo motors steering braking. What grade servos I need much torque need have? Can I use strongest RC servo I may find (like 115kg/cm one maybe even more, metal gears course) I need ""industrial grade"" servo? I plan use one servo steering one braking. For braking ATV mechanical disc brakes - two discs front one common disc rear (there two brake levers - front/rear). I plan use one servo use either front rear. The plan mount brake wire servo would ""simulate"" lever movement. I guess I could also make ""weak"" servo stronger adding proper gear, I really mechanical engineering much would prefer off-the-shelf component.",servomotor rcservo steering brake
9590,Downgrade ROS Jade Indigo,"Is possible downgrade ROS Jade Indigo? For yet familiar Robot Operating System (ROS), here: ROS",ros
9592,Meaning s_last D star Lite algorithm,"In D*Lite algorithm, described line 21 Figure 3, page 4, D* Lite, starts defining $s_{last}=s_{start}$. But value $s_{last}$ never updated entire algorithm. So purpose defining term mean?",mobile-robot control robotic-arm motion-planning algorithm
9593,Mechanical odometer digital output,"I would like mechanically measure distance kids electric ATV traveled. The ATV used kids mobile robot instead. It common rear axle rear wheels I think could good place put odometer (since chance wheels slip minimal). Regarding suspension single shock rear axle. My plan put bigger gear axle add smaller gear kind sensor would measure number rotations. One rotation axle may something like 20 rotations small gear. What kind sensor I use sensing rotation? Another way making odometer may kind optical solution (disc holes optical sensor) seems rather complicated also direction travel could easily estimated (unless motor running direction). I found term called Wheel Speed Sensor looks interesting seems employ primarily non-contact sensing (which definitely better mechanical gears). Rather optical solution I like Hall effect sensor solution may simple mechanically robust. But still, question open implement this... I would like use odometer speed estimation distance estimation. I need read sensor C/C++ Linux box. EDIT: The thing I looking probably correctly called rotary encoder wheel encoder. The ATV may look like one these:",mobile-robot sensors odometry encoding rotation
9597,Hand-eye calibration?,"I issue hand-eye calibration. So using simple robot tool point stereo camera mounted it. I want perform visual serving/tracking based stereo images extracted camera ""hand"". The camera provides x,y,z coordinates object I want track. I time extract homogenous transformation matrix base tool (not cam) . Firstly... I guess would need perform form robot (vice versa) camera calibration, My idea would consist something like T_base_world = (T_base_tool) (T_tool_cam) (T_cam_world) Where T_tool_cam would entail calibration... since camera tool point, would entail T_tool_cam entail information much camera displaced tool point, rotated according tool point? like that? secondly... How based purely x,y,z coordinate make homogeneous transformation matrix, includes rotation matrix ? thirdly.. Having desired Transformation matrix theory T_base_world = (T_base_tool) (T_tool_cam) (T_cam_world) would provide me, would inverse kinematics solution provide one multiple solution?... In theory provide one, what?",robotic-arm inverse-kinematics rotation
9600,How I determine pose origin transformations?,"Find origin coordinate directions frame resulting rotation $90^{\circ}$ z axis, followed displacement $\begin{pmatrix}1\\7\\3\end{pmatrix}$. Hence find position, original frame, vector $\begin{pmatrix}3\\8\\1\end{pmatrix}$, defined resulting frame.",kinematics inverse-kinematics
9602,ComputeShortestPath() Dstar lite algorithm,"In optimized D*Lite algorithm shown figure (page 5, paper D*Lite), procedure ComputeShortestPath() called first time line 31, U(list inconsistent vertices) contains goal vertex ($s_{goal}$). Thus procedure ComputeShotestPath()(line 10-28), $u = s_{goal}$. And as, $k_{old}=k_{new}$ (because $k_m=0$), condition $k_{old}\leq k_{new}$ satisfied $u = s_{goal}$ inserted U value $k_{old}=k_{new}$. Thus, seems line(11-15) run forever, algorithm able find shortest path goal start. I know algorithm widely used I failing understand it. But I going wrong?",mobile-robot control robotic-arm motion-planning algorithm
9604,Quadcopter heading calculation,"I'm working autonomous quad copter, I two GPS co-ordinates (source destination co-ordinates). I need move quad source destination, I need calculate heading set yaw value quad. How I calculate heading make sure quad headed right direction target co-ordinates? If I use magnetometer declination angle vary place place I keep changing declination angle. If I'm calculating based GPS co-ordinates, it's accurate. What best way this? How I calculate above?",quadcopter gps magnetometer
9608,Quaternion Kalman Filter Algorithm,"I stuck weeks, I really hope someone help this,thank advance. I trying write IMU attitude estimation algorithm using quaternion kalman filter. So based research paper: , I developed following pseudo code algorithm: Predict Stage: Qk+1/k = Ak * Qk; Ak contains gyro measurement. Pk+1/k = Ak * Pk *Ak.transpose() + Q; Q assumed zero. After prediction, use formula get supposed gravity measurement accelerometer Yg body frame : Yg = R * G; // R rotation matrix generated quaternion Qk+1/k G = (0,0,0,9.81). This equation translates following equation allows get measurement model matrix H. H * Qk+1/k = 0; //where H stores value related (Yg-G). Update Stage: K = P * H * (H * P * H.transpose()+R)^(-1); //R adaptively adjusted right initialized identity matrix Qk+1/k+1 = (I-KH)Qk+1/k; Qk+1/K+1 = (Qk+1/K+1)/|Qk+1/k+1|; //Normalize quaternion Pk+1/K+1 = (I - KH)Pk+1/k; The following main part code. The complete C++ code want test. The problem I face code work.The prediction stage works fine updated quaternion state correct first iterations starts drift away correct value. I checked code research paper multiple times ensured accordance algorithm proposed research paper. In test, I rotating around x axis 60 degree per iterations. The number started angle rotation. state updated state predicted updated quaternion respectivly true value, meas, result acceleration due gravity body frame.As test result indicates, everything way rotating 360 degrees. The following test result: 1 started 60 state 0.866025 0.5 0 0 true value 0 8.49571 4.905 meas 0.314533 7.97407 4.98588 updated state 0.866076 0.499913 -2.36755e-005 1.56256e-005 result 0.000555564 8.49472 4.90671 1 started 120 state 0.500087 0.865975 -2.83164e-005 1.69446e-006 true value 0.000306622 8.4967 -4.90329 meas -0.532868 8.79841 -4.80453 updated state 0.485378 0.862257 -0.129439 -0.064549 result 0.140652 8.37531 -5.10594 1 started 180 state -0.0107786 0.989425 -0.0798226 -0.12062 true value -2.35843 -0.0203349 -9.52226 meas -1.39627 -0.889284 -8.74243 updated state -0.0195091 0.981985 -0.151695 -0.110965 result -2.19598 -0.0456112 -9.56095 1 started 240 state -0.507888 0.840669 -0.0758893 -0.171946 true value -3.59229 -8.12105 -4.16894 meas -4.52356 -7.73113 -4.98735 updated state -0.53758 0.811101 -0.212643 -0.0889171 result -3.65783 -8.18397 -3.98485 1 started 300 state -0.871108 0.433644 -0.139696 -0.183326 true value -3.94732 -6.909 5.73763 meas -4.36385 -6.98853 5.39759 updated state -0.86404 0.436764 -0.102296 -0.228487 result -3.69216 -6.94565 5.86192 1 started 0 state -0.966663 -0.0537713 0.0256525 -0.249024 true value 0.749243 0.894488 9.74036 meas -0.194541 0.318586 10.1868 updated state -0.78986 -0.0594022 0.0311688 -0.609607 result 1.1935 0.547764 9.72171 1 started 60 state -0.654338 -0.446374 0.331797 -0.512351 true value 8.74674 2.39526 3.74078 meas 9.36079 2.96653 3.57115 updated state -0.52697 -0.512048 0.221843 -0.64101 result 8.73351 2.50411 3.70018 Can someone help confirm understanding theory quaternion kalman filter pseudo code correct? Also, anyone implemented attitude estimation using maybe different version quaternion kalman filter, I would greatly appreciate provide pseudo code little explanation. Thank guys much!",quadcopter kalman-filter
9609,Most accurate rotation representation small angles,"Assume I rigid body I know rotate respect global reference frame (which considered fixed already given) degrees angle, I describe rotation using small angle approximation. For system, I would like know rotation representation offers accuracy compared representation methods. The main representation methods I considered euler angles pitch-yaw-roll transformation. To perception, I think pitch-yaw-roll representation expected accurate, since angles expressed respect initial coordinate frame. On hand, euler angles defined different frames, I sure resulting angles really small. To sum up, I know body rotate degrees I would like know coordinate representation much probable deliver smallest angles, small angle approximation valid. It could also case general answer (so depends specific configuration) still I haven't found anything topic related literature! Example (no small angle approx used): Assume I coordinate frame describes point space following vector $P2=\begin{bmatrix} 4 \\ 1 \\ 0.05 \end{bmatrix}$. Given another coordinate frame rotated respect previous one, description point given $P1=\begin{bmatrix} 3.8933 \\ 1.3566 \\ -0.0630 \end{bmatrix}$. Using Euler angles, I find rotation matrix $R_{euler}$ characterized angles $0.1,0.2,0.1$ rads, correspond angle rotation around z axis, rotation around resulting axis rotation around resulting z axis, respectively (these basic stuff, explained many books.). So I $P1=R_{euler} P2$. Now I want find corresponding rotation matrix I use pitch-yaw-roll representation. Here I solve optimization problem solution I get (maximum error P1 estimated P1 $3 \times 10^{-8}$) delivers following angles $\begin{bmatrix} -0.0103 \\ 0.0257 \\ 0.0902\end{bmatrix}$, correspond rotation around x,y z axis initial coordinate frame.",inverse-kinematics geometry rotation
9615,Orientation error free rotations,I working inverse kinematics 5DOF arm. The tool symmetric z-axis don't card rotations solution care direction Z-axis. words instead goal states orientation $R = (N_d~ S_d ~A_d)$ care $A_d$. How would I calculate Orientation error (or adjust normal inverse kinematics) account this. Setting $N_d$ $S_d$ zero value forces particular orientation may reachable. full 6DOF situations I previously used following equation orientation error. $$E_o = \frac{1}{2} (N_e(q) \times N_d + S_e(q) \times S_d + A_e(Q) \times A_d)$$ sufficient remove $N$ $S$ equation giving $$E_o = \frac{1}{2} (A_e(Q) \times A_d)$$ else could I handle situation?,robotic-arm inverse-kinematics
9616,Motor upgrade higher torque?,"I assembled 4WD car using kits I bought ebay. I 4 motors similar one: . The description says: Operating voltage: 3V~12VDC (recommended operating voltage 6 8V) Maximum torque: 800gf cm min (3V) No-load speed: 1:48 (3V time) The load current: 70mA (250mA MAX) (3V) This motor EMC, anti-interference ability. The microcontroller without interference. Size: 7x2.2x1.8cm(approx) I fond max speed I reach, I would able provide power, I 12V 2A battery onboard. So far I used 6V, seemed safer voltage choice. Has anybody tried successfully higher voltages, without wearing motor hours (I've read happen)? Alternatively, someone recommend replacement motors would tolerate reliably higher power envelope? I would like preserve gearbox replace motor, possible. I think I could fit motor 2-4 mm longer (replacing transparent strap bonds gearbox), makes difference. BTW, I'm making assumption: higher_voltage => higher_torque => higher_speed I'm sure it's overall correct. I expect would least produce higher acceleration transients.",brushless-motor
9619,Extracting many possible end configurations possible,"I trying implement path planner generate path moves robot q_start q_goal. Q_goal extracted stereo camera mounted tool, I extract x,y,z coordinates desired position, rotation arbitrary. The robot I using industrial ur5 robot arm, software I use capable performing Jacobian based inverse kinematics given transformation matrix rotation translation. inverse kinematics provide one solution, ok, doesn't provide flexibility path planning... How I using inverse kinematics determine possible q-configurations fulfills criteria desired x,y,z coordinates?",robotic-arm inverse-kinematics
9620,Mobile robot path following using Model Predictive Control (MPC),"I'am trying implement path following algorithm based MPC (Model Predictive Control), found paper : Path Following Mobile Robot Presence Velocity Constraints Principle: Using robot model path, algorithm predict behavior robot N future steps compute sequence commands $(v,\omega)$ allow robot follow path without overshooting trajectory, allowing slow sharp turn, etc. $v:$ Linear velocity $\omega:$ Angular velocity The robot: I non-holonomic robot like one (Image extracted paper above) : Here problem: Before implementing mobile robot, I'am trying compute needed matrices (using Matlab) test efficiency algorithm. At end matrices computation dimension mismatch What I did: For interested, calculation §4 (4.1, 4.2, 4.3, 4.4) p6-7 paper. 4.1 Model $z_{k+1} = Az_k + B_\phi\phi_k + B_rr_k$ (18) with: $A = \begin{bmatrix} 1 & Tv \\ 0 & 1 \end{bmatrix}$ $B_\phi = \begin{bmatrix} {T^2\over2}v^2\\ Tv \end{bmatrix}$ $B_r = \begin{bmatrix} 0 & -Tv \\ 0 & 0 \end{bmatrix}$ $T$: sampling period $v$: linear velocity $k$: sampling index (i.e. $t= kT$) $z_k:$ state vector $z_k = (d_k, \theta_k)^T$ position angle difference reference path $r_k:$ reference vector $r_k = (0, \psi_k)^T$ $\psi_k$ reference angle path step k 4.2 Criterion The predictive receding horizon controller based minimization criterion $J= \Sigma^N_{n=0} (\hat{z}_{k+n} - r_{k+n})^T Q(\hat{z}_{k+n} - r_{k+n}) + \lambda\phi^2_{k+n}$, (20) Subject inequality constraint $ P\begin{bmatrix} v_n \\ v_n\phi_n \end{bmatrix} \leq q,$ $n=0,..., N,$ $\hat{z}$ predicted output, $Q$ weight matric, $\lambda$ scalar weight, $N$ prediction horizon. 4.3 Predictor An n-step predictor $\hat{z}_{k+n|k}$ easily found iterating (18). Stacking predictions $\hat{z}_{k+n|k},n = n,...,N$ vector $\hat{Z}$ yields $\hat{Z} = \begin{bmatrix} \hat{z}_{k|k} \\ \vdots \\ \hat{z}_{k+N|k}\end{bmatrix} = Fz_k + G_\phi\Phi_k + G_rR_k$ (22) $\Phi_k = \begin{bmatrix} \phi_k, \ldots, \phi_{k+N}\end{bmatrix}^T$, $R_k = \begin{bmatrix} r_k, \ldots, r_{k+N}\end{bmatrix}^T$, $F = \begin{bmatrix}I & A & \ldots & A^N \end{bmatrix}^T$ $G_i = \begin{bmatrix} 0 & 0 & \ldots & 0 & 0 \\ B_i & 0 & \ldots & 0 & 0 \\ AB_i & B_i & \ddots & \vdots & \vdots \\ \vdots & \ddots & \ddots & 0 & 0 \\ A^{N-1}B_i & \ldots & AB_i & B_i & 0 \end{bmatrix}$ index $i$ substituted either $\phi$ $r$ 4.4 Controller Using N-step predictor (22) simplifies criterion (20) $J_k = (\hat{Z}_k - R_k)^T I_q (\hat{Z}_k - R_k) + \lambda\Phi^T_k\Phi_k$, (23) $I_q$ diagonal matrix appropriate dimension instances Q diagonal. The unconstrained controller found minimizing (23) respect $\Phi$: $\Phi_k = -L_zz_k - L_rR_k$, (24) $L_z = (lambda + G^T_wI_qG_w)^{-1}G^T_wI_qF$ $L_r = (lambda + G^T_wI_qG_w)^{-1}G^T_wI_q(Gr - I)$ I'am trying compute $\Phi_k = -L_zz_k - L_rR_k$ dimension $L_r$ $R_k$ match matrix multiplication. Parameters : $T=0.1s$ $N=10$ $\lambda=0.0001$ $Q=\begin{bmatrix} 1 & 0 \\ 0 & \delta \end{bmatrix}$ $\delta=0.02$ I get : $R_k$ (11x2) matrix (N+1 elements size 2x1, transposed) $G_w$ (22x11) matrix $G^T_w$ (11x22) matrix $I_q$ (22x22) matrix $F$ (22x2) matrix $G_r$ (22x22) matrix Lz computation gives (according matrix sizes) $L_z=(scalar + (11x22)(22x22)(22x11))^{-1} (11x22)(22x22)(22x22)$ (11x2) matrix. $z_k$ (2x1) matrix, $L_zz_k$ (24) fine. Lr computation gives (according matrix sizes) $L_r=(scalar + (11x22)(22x22)(22x11))^{-1} (11x22)(22x22)((22x22) - (22x22))$ (11x22) matrix. $R_k$ (11x2) matrix, $L_rR_k$ (24) possible. I (11x22) matrix multiplicated (11x2) matrix. I'm sure I'm missing something big unable see exactly. Any help appreciated. Thanks",mobile-robot navigation
9621,Electric vs. internal combustion engine propulsion,"What main differences electric motor internal combustion engine ATV-sized mobile robot platform terms functionality, implementation difficulty (""RC"" conversion, ""electronic"" operation), durability maintenance used autonomous platform? A full sized ATV/UTV like Polaris Ranger (EV) question. Are advantages/disadvantages basically differences electric nitro RC cars bigger scale adds something important game? I think main differences like bigger range faster ""refueling"" IC less maintenance electric I interested detailed comparison. The transmission IC engine considered automatic. EDIT: The fuel injection IC considered electronic (EFI) I know whether also means ""electronic"" throttle (no mechanical wire carburetor?). Whatever throttle may I see lag ""actuation"" engine running higher RPM giving power/speed main disadvantage IC control - however, may probably quite easy dealt software (by adding timeout checking desired RPM).",mobile-robot electronics engine electric propulsion
9622,inverse kinematics 6 jointed robots,"I uncertain compute right homogeneous transformation matrix compute inverse kinematic Q-configuration. Looking robot like Where end robot I camera mounted it. The purpose application make robot follow object, basically tracking it. The camera provide X,Y,Z coordinate, position want place robot arm. First question - How set desired homogenous transformation matrix? The way see it, I 2 transformation matrices T_world_tool become T_world_base = (T_tool_base) (T_world_tool) My question compute desired transformation matrix. I think know setup transformation matrix camera would like T_world_tool = 0 0 0 x 0 0 0 0 0 0 z 0 0 0 1 (Second question regarding rotation matrix, prescribe rotation arbitrary long endpoint desired position world frame?) t_tool_base entail? entail transformation current state desired transformation, extract desired t_tool_base transformation?...",robotic-arm kinematics inverse-kinematics
9625,Bayesian filter 2-D grid localizaton,"I data obtained experiment terms movements observations odometry sensor data. My task find probability mass grid cells set motion observation. I'm bit lost figuring compute probability mass grid cell. My odometry information terms rotation, translation rotation sensor information terms range bearing angle. How I calculate probability robot present grid cell? I formula belief motion summation(P(x|u, x')xBel(x')) How I compute motion model noise?",localization filter
9629,Quadcopter refuses fly Yaw PID component added,"Good day, I would like ask I add Yaw control PID controller motor. The quadcopter refuses take maintain altitude. I curently using Cascaded PID controller attitude hold using Accelerometer, Magnetometer Gyroscope, 40Hz Ultrasonic Sensor Altitude Hold. Since scope indoor I done away barometer due +-12m error. Resulting Response Without Yaw Control, plot shows response quadrotor. With Yaw Control, plot shows response quadrotor. Debugging I found outputs PID's give high value summed together goes way PWM limit 205 Full Throttle. Without yawPID contribution The limiter kicks without damaging desired response system thus still able fly albeit oscillatory motion along z axis height With yawPID contribution The added yaw components increases sum PID's way limit thus limiter compesates excess much resulting lower PWM output motors thus quad never leaves ground. //Motor Front Left (1) float motorPwm1 = pitchPID + rollPID + yawPID + baseThrottle + baseCompensation; //Motor Front Right (2) float motorPwm2 = pitchPID - rollPID - yawPID + baseThrottle + baseCompensation; //Motor Back Left (3) float motorPwm3 = -pitchPID + rollPID - yawPID + baseThrottle + baseCompensation; //Motor Back Right (4) float motorPwm4 = -pitchPID - rollPID + yawPID + baseThrottle + baseCompensation; Background The PID parameters Pitch, Yaw Roll tuned individually meaning, base throttle set minimum value required quadcopter able lift itself. The PID parameters Altitude Sensor tuned controllers active (Pitch Roll). Possible Problem Limiter algorithm A possible problem algorithm I used limit maximum minimum throttle value may caused problem. The following code used maintain ratio motor values instead limiting them. The code used two stage limiter. In 1st stage, one motorPWM less set baseThrottle, algorithm increases motor PWM value none that. In 2nd stage, one motorPWM set maxThrottle, algorithm decreases motor PWM value none that. This obtained pixhawk. However difference employ upper bound compensation limiting, mine also performs lower bound compensation limiting may cause saturation reaches second stage. From: Gains set high. It also possible I've set P gains high thus exceeding max RPM limit motors causing Limiter algorithm overcompensate. Current PID Settings: The minimum motor value quad lift 160 maximum limit 200 PWM time high 2000ms Pitch (Cascaded P-PID controller) Rate P = 0.07 Rate I = 0.03 Rate D = 0.0001 Stabilize P = 2 Roll (Cascaded P-PID controller) Rate P = 0.09 Rate I = 0.03 Rate D = 0.0001 Stabilize P = 2 Yaw (Cascaded P-PID controller) Rate P = 0.09 Rate I = 0.03 Rate D = 0.0001 Stabilize P = 2 Hover (Single loop PD controller) P = 0.7 D = 35 Possible Solution I think I set PID parameters particularly P D gain high computed sum outputs controller beyond limit. Maybe retuning would help. I would like ask anyone encountered problem suggestions. Thank :) EDIT I added plots response control loop fast (500Hz) Slow (300Hz) 500Hz: Does fly 300Hz: Flies",quadcopter control pid raspberry-pi stability
9636,Regarding Kalman filter estimating heading magnetic compass,"I trouble estimating heading close ""pivot"" point compass, could use input solve it. I set angles 0-360 degrees testing using radians (-pi, pi) on. The setup differential robot IMU, wheel encoders magnetic compass. A complementary filter used fusing gyroZ odo measurements estimate heading, correct Kalman filter using magnetic compass. My problem occurs robot heading close -pi/pi . The estimated heading useless even though robot even moving. I thinking must common problem probably better solution I came with, either re-initializing integrator crossing zero, adding 180 degrees time error larger, ignoring compass error large... It's first Kalman filter I may made poor implementation common issue... Edit: trudesagen's solution solved problem.",mobile-robot kalman-filter compass
9637,How write STOP continuous Servo?,"I'm using processing send strings Arduino, using functions like processing side Arduino side I'm using calls like case 'z': z.write(v); v = 0; break; case 'L': z.write(0); //v = 0; break; } yet I can't get servo stop all. How I make shut off? If regular servo I wouldn't even ask that's easy I write 0 90 LOW nothing, keeps spinning one direction meets one conditions statements switches polarity/direction that's good - I want I made function make stop so, anyone ideas ? I using Parallax Continuous Rotation Servo.",arduino
9640,Steadier wheels - Pin lock springs,"When running hard surface, Create shake sometimes turns acceleration. Has anyone ever removed springs pinned wheels place can't move down?",irobot-create roomba
9642,What's difference holonomic nonholonomic system?,"I wondering 1D point mass (a mass move line, accelerated external time-varying force, see Wikipedia - Double integrator) holonomic nonholonomic system? Why? I think nonholonomic since cannot move direction configuration space (which 1D, $x$ axis). E.g. point mass moving $$x=10$$ velocity 100 m/s positive $x$-direction cannot immediately go $$x=9.9$$ due inertia. However, I feeling thoughts wrong... The background following: I trying understand holonomic nonholonomic systems are. What I found far: Mathematically: Holonomic system systems constraints integrable positional constraints. Nonholonomic systems systems constraints nonintegrable positional constraints. Intuitively: Holonomic system robot move direction configuration space. Nonholonomic systems systems velocities (magnitude direction) derivatives position constraint.",dynamics movement
9646,Forward kinematics DH parameters,I started learning robotics school I problems solve forward kinematics DH parameters. I don't really understand I get image. I would appreciate somebody could help it. .,forward-kinematics dh-parameters
9647,What rating Li-Po battery I get configuration?,"I configuration: A2212 Brushless Motor 1000KV - 4 ECS - 30A Electronic Speed Control (ESC) - 4 Propeller - 1045 Propeller CW & CCW Pair 10 inch * 4.5 pitch Arduino Mega - 2560 board Raspberry Pi 3 Open pilot CC3D flight controller I want know rating Li-Po battery I get configuration. The reason behind asking simple google search able satisfy explanation... Also, weight 1.5 kg quadcopter, I need stable current discharge. This first quadcopter, I Computer Science guy, I little knowledge electronics, I'm learning, need help...",quadcopter arduino raspberry-pi battery
9652,Smart Home Model Raspberry Pi,I'm still new RPi I currently trying smart home model. I planned use RPi control 5 servos (which controlling open/close doors setting angle) 5 LEDs. Will I need use external circuit supply power servos fine connect RPi?,raspberry-pi rcservo
9654,How know payload chassis motors?,"I'm mobile robot project robotic arms, I wanted buy chassis robot carry enough weight, many websites don't give definitive answers maximum payload. Is way figure knowing details motors?",mobile-robot
9657,Dynamic Model Manipulator,"I'm stuck equation 4.30 page 176 This equation: $\frac {\partial M_{ij}} {\partial \theta_k} = \sum_{l=\max(i,j)}^n \Bigl( [A_{ki} \xi_i, \xi_k]^T A_{lk}^T {\cal M}_l' A_{lj} \xi_j + \xi_i^T A_{li}^T {\cal M}_l' A_{lk} [A_{kj} \xi_j, \xi_k] \Bigr)$ seems impossible process requires adding 2x1 1x2 matrix. going ROWSxCOLUMNS notation. Matrices M A 6x6 $\xi$ 6x1, addition statement fit rules matrix addition? This must mistake, I don't see how.",dynamics matlab
9659,find maximum force robot joint,"I want know equation calculates maximum force robot joint. The force exceed. For example human leg, apply big external force knee, break. find necessary force make leg move without breaking knee. I programme generates robot morphologies randomly different sizes, I know force exceed joint. I think depend weight, mass, inertia robot part. I trial error I hundreds different morphologies. This video shows behaviour robot I apply big force. It Gazebo robotic simulator. Thanks advance!",simulation joint force
9662,Implementing analytic version inverse kinematic,"People recommended implement analytic version inverse Jacobian solver, I won't forced least square solution, would local area solution near one I desire. I can't seem implement correctly, I mean much differ least square inverse kinematics I implemented here? I want vector solution - I get that? Q related How construct transformation matrix given x,y,z tool position? The robot used UR5 -",robotic-arm inverse-kinematics industrial-robot c++
9668,Directly observing lidar laser rays,I working SICK lidars mount/unmount quite often robot. The mounting process tedious especially comes making sure lidars horizontal. I thought using IR goggles (like night vision ones) fog machine (like one nightclubs) order see surface covered lidar's rotating laser ray. As result I would expect see something like planar. Before thinking trying get hands hardware I wanted ask: Do sick laser enough intensity observed goggles? Does anybody tried approach?,laser lidar
9669,What type actuator I use?,"I need find There way get least 60 Hz linear Motion least 5 mm stroke I intend make linear persistence vision device(not rotating one)It must small light possible. ( maybe 50 mm long 10-15 mm diameter around these) (less 500 grams) The Load around 50 grams. There voice coils expensive, I use solenoids instance recommend? Thanks",actuator motion
9673,"Is ""follow me"" Roomba/Create works like BEAMBot?","The diagram shows old BEAMBot strategy: Is code example using method? I would rather avoid OpenCV, ultrasonic, GPS etc. I want Roomba wheels react I go straight, turn left right. Finally, I could add front wheel servo try Roomba turn me. Also anybody added big, terrain wheels Roomba replace originals?",control irobot-create roomba
9675,Suitable uC atonomous robot,"I going build autonomous robot Kalman-filter localization integrated Lidar, encoder, IMU GPS. I also add obstacle avoidance moving required position. Is ATmega32 8-bit suitable (or Arduino Mega) I use avr32, ARM, PIC32 better?",mobile-robot arduino localization microcontroller
9677,Kuka KR16L-2 robot simulation base wrist rotation inconsistent original robot,"The issue regarding simulation Kuka robot KR16L6-2 MATLAB using Robotics toolkit Peter Corke. I wish simulate kinematic passing command real robot motion. I attached DH-Parameters. Apart I also tried many combination orientations useful effect. The problems robot base rotates counter-clockwise default positive increases , original robot moves opposite direction. Similarly wrist roll, i.e. Joint 4, direction simulation reversed. In order confirm it's mistake only, I searched similar ready made simulation software. Although include KUKA robot, similar variant (KUKA_KR_5_sixx_R650) available. Hence, KUKA_KR_5_sixx_R650 one set motions base wrist RoKiSim v1.7 positive increases joint angle reverse motion roboanalyzerv7 . NOTE: Only rotation J1 (base) J4 (Wrist Roll) reversed I want recreate results RoKiSim v1.7 Matlab rotations similar real world robot spec provided KUKA.",matlab industrial-robot simulation kuka
9680,Getting “rospack package found error” ROS,I created package catkin workspace put publisher.py node inside src directory package worked fine. Then added another node subscriber.py node used catkin_make build. Now I try run nodes find package getting error. Am I missing step ? Thanks.,ros
9682,What frames supported Dynamixel XL-320 OLLO?,"I recently looking purchasing either Dynamixel AX-12A XL-320. The XL seems use OLLO frames, seem available toy-like set. I wondering frames available I get AX-12?",servos walking-robot dynamixel
9683,Choosing right Mecanum wheel,"I part college robotics team preparing Robocon 2017. We used Mecanum wheels last Robocon competition, faced huge slip vibration. I looked kinematic dynamic formulas stuff Mecanum wheels, still can't get conclusion problem. Video problem The robot around 25 kg Mecanum wheel diameter 16 cm 15 rollers (single type). Please help happened like that!? Also suggest - Should I design new Mecanum wheel bring market? If I design, parameters I consider, please help design CAD software like SolidWorks? And then, shall I give 3D printing? If I buy directly market, I buy?",design wheel
9684,Cannot disable sleep passive mode iRobot Create 2,"I tried disable sleep pulsing BRC pin low one second every minute suggested OI, Create 2 still goes sleep 5 minutes. My firmware r3_robot/tags/release-3.2.6:4975 CLEAN The Create 2 connected Arduino, BRC driven one Arduino pins. I verified DMM voltage indeed toggling. I able send receive serial data Arduino Create2. Pseudo-code: Initialize roomba. Connect serial 115200 baud. Toggle BRC: high 200 ms, low 200 ms, high again. Leave high. Ask roomba stream sensor data passive mode. Wait 1 second BRC toggle give extra time wake-up. Then send opcode 7 (reset), wait reset message complete looking last characters, wait another second good measure. Next, send opcode 128 (start passive mode), wait 100 ms let opcode stick, ask stream data (opcode 148 followed number packet IDs packet IDs themselves). Main loop: Echo data Create2 serial-USB output Arduino I view Create2 data. The data sent Create2 look valid (good checksum) sent expected time interval ~15 ms. The main loop also toggles BRC low 1 second every minute. For full gory details, complete Arduino sketch shown",irobot-create
9686,Performing inverse kinematics based displacement end effector?,"I think simple problem, can't head around resolve it... My setup looks like this: The grey box end effector supposed camera, measures dx,dy,dz object camera. These used position camera dz object camera equal 0.5, dx = dy = 0. I know I using inverse kinematics determine Q positions according given rotation position, I provide position only? How extract Q make dx = dy = 0, dz = 0.5, keeping object sight time? An example could object placed base (see second image), find possible configurations case would consist arm rotating around object, camera keeps object sight... Update I realized possible solution would create sphere object centrum radius dz, use sphere extract pairs rotations position... But would one come solution?",robotic-arm inverse-kinematics stereo-vision
9691,Generate transformation matrices rotating around object?,"How compute transformation matrices places robot endeffector shell sphere, end effector pointing toward object center. I know time far object relative endeffector, radius sphere desired distance want object endeffector. I want using inverse kinematics pan around object sphere shaped trajectory. Each transformation matrix contain different positions sphere rotation oriented arm looks object. The position relative easy compute, already know distance object, radius sphere. But rotation matrix position still mystery me.",robotic-arm rotation
9696,Vector Field Histogram: Is possible generate occupancy grid without position feedback?,"I currently working autonomous quadcopter project using stereo vision obstacle detection. I planning use VFH+ 2D trajectory planning, meaning movements quadcopter available X Y axes movement permitted along Z axis Altitude. I currently methods implemented position tracking. Accelerometers known generate lot errors integration. I tried look optical flow sensors low computation needed however found luck stock (probably due company change (Agilent/Avago Pixart)). From I understand, certainty/occupancy grid constructed reduced polar coordinate system, robot's heading aligned computed unblocked sector. Is possible generate occupancy grid without position feedback? I planning run quadcopter slow constant velocity due data throughput raspberry pi stereo vision system 2Hz. I plan use obtained angle direction VFH algorithm align quadcopter's heading. The motor control scheme used quadcopter mostly yaw pitch based. Yaw heading control pitch forward control. Two raspberry pi b+'s used. One motor control currently running PID control loop 530Hz. Another Stereo vision currently running 2Hz.",quadcopter motion-planning stereo-vision vector-field-histogram vfh
9697,How determine angles UAV sphere,"I UAV modeled three dimensions let's say position coordinates $p_{uav} = (x_1,y_1,z_1)$ moving direction $d = (d_x,d_y,d_z)$ moving obstacle modeled sphere known centre coordinates $p_{sph}=(x_2,y_2,z_2)$ radius $ r_{sph}$. If I plane $p$ direction movement UAV intersects sphere, I want able calculate angles respect vehicle's movement formed tangents sphere plane $ p$. In figure, I would like know calculate angles $α_1$ $α_2$. If helps, I looking extension three dimensions this: Which vehicle two dimensions ;it obviously easier problem requires centre circle. However I really sure make work 3D, supposedly plane intersect sphere two points, necessarily centre. Thanks advance help.",localization kinematics geometry
9700,Implementation inverse kinematics solution c++,"I issue implementing least square solution inverse kinematics problem. The q configuration I get rather large, makes sense, I hoping someone could help find error program. What I trying do, I trying orbit robot endeffector around object center. The trajectory endeffector sphere endeffector always point object. The sphere function compute transformation matrices move robot arm different position sphere given rotation, inverse kinematics compute different Q-states, given x,y,z actual displacement object itself. I quite sure error could at, I think might either transform function I generate desired transformation matrix, invKin I create du, I think I might made mistake creating du(3), du(4), du(5) The libraries I've using Eigen, robwork (basically rw::) anyone want look syntax through. Update Based @ghanimmukhtar I began checking singularities jacobian.. Which seems general supringsly low. I computed list random Q configurations resulted this... Determinant: -0.0577779 Determinant: -0.0582286 Determinant: 0.0051402 Determinant: -0.0498886 Determinant: 0.0209685 Determinant: 0.00372222 Determinant: 0.047645 Determinant: 0.0442362 Determinant: -0.0799746 Determinant: 0.00194714 Determinant: 0.0228195 Determinant: 0.096449 Determinant: -0.0339612 Determinant: -0.00365521 Determinant: -0.030022 Determinant: 0.021347 Determinant: 0.0413364 Determinant: 0.0041136 Determinant: -0.0151192 Determinant: 0.0682926 Determinant: -0.0657176 Determinant: 0.0915473 Determinant: -0.00516008 Determinant: -0.0394664 Determinant: -0.00469664 Determinant: 0.0494431 Determinant: -0.00156804 Determinant: -0.0402393 Determinant: -0.0141511 Determinant: 0.0203508 Determinant: -0.0368337 Determinant: -0.0313431 Determinant: -0.0566811 Determinant: -0.00766113 Determinant: -0.051767 Determinant: -0.00815555 Determinant: 0.0564639 Determinant: 0.0764514 Determinant: -0.0501299 Determinant: -0.00056537 Determinant: -0.0308103 Determinant: -0.0091592 Determinant: 0.0602148 Determinant: -0.0051255 Determinant: 0.0426342 Determinant: -0.0850566 Determinant: -0.0353419 Determinant: 0.0448761 Determinant: -0.0103023 Determinant: -0.0123843 Determinant: -0.00160566 Determinant: 0.00558663 Determinant: 0.0173488 Determinant: 0.0170783 Determinant: 0.0588363 Determinant: -0.000788464 Determinant: 0.052941 Determinant: 0.064341 Determinant: 0.00084967 Determinant: 0.00716674 Determinant: -0.0978426 Determinant: -0.0585773 Determinant: 0.038732 Determinant: -0.00489957 Determinant: -0.0460029 Determinant: 0.00269656 Determinant: 0.000600619 Determinant: -0.0408527 Determinant: -0.00115296 Determinant: 0.013114 Determinant: 0.0366423 Determinant: 0.0495209 Determinant: -0.042201 Determinant: -0.036663 Determinant: -0.103452 Determinant: -0.0119054 Determinant: 0.0692284 Determinant: -0.00717832 Determinant: 0.00729104 Determinant: 0.0126415 Determinant: -0.00515246 Determinant: -0.0556505 Determinant: 0.000670701 Determinant: -0.0545629 Determinant: 0.00251946 Determinant: 0.0405189 Determinant: 0.010928 Determinant: -0.00101032 Determinant: 0.0308612 Determinant: 0.0536183 Determinant: -0.0439223 Determinant: -0.0113453 Determinant: -0.0193872 Determinant: 0.0660165 Determinant: -0.00184695 Determinant: -0.106904 Determinant: 0.01246 Determinant: -0.00883772 Determinant: 0.0601036 Determinant: 0.0468602 Determinant: 0.0513812 Determinant: -0.000663089 Determinant: -0.00392395 Determinant: 0.0710837 Determinant: 0.0629583 Determinant: -0.0464579 Determinant: 0.0257618 Determinant: -0.0193227 Determinant: 0.00388693 Determinant: -0.02003 Determinant: 0.0191158 Determinant: -0.00159198 Determinant: -0.0702308 Determinant: -0.0242876 Determinant: -0.00934638 Determinant: -0.00221986 Determinant: -0.0268925 Determinant: 0.0596055 Determinant: -0.00925273 Determinant: -0.0167357 Determinant: 0.0596476 Determinant: -0.00515798 Determinant: -0.00324081 Determinant: -0.00321565 Determinant: 0.0669645 Determinant: -0.0342913 Determinant: -0.000342155 Determinant: -0.0104422 Determinant: -0.0410489 Determinant: -0.0246036 Determinant: 0.0208562 Determinant: -0.0692963 Determinant: 0.000839091 Determinant: -0.049308 Determinant: -0.0349338 Determinant: 0.0016057 Determinant: -0.00214381 Determinant: -0.0332965 Determinant: 0.0168007 Determinant: -0.0748581 Determinant: -0.00864737 Determinant: -0.0638044 Determinant: -0.00103911 Determinant: -0.00690918 Determinant: 0.000285789 Determinant: 0.0215414 Determinant: 0.0560827 Determinant: -0.0063201 Determinant: -0.00677609 Determinant: -0.00686829 Determinant: 0.0591599 Determinant: 0.0112705 Determinant: 0.0874784 Determinant: -0.0146124 Determinant: -0.0133718 Determinant: -0.0203801 Determinant: -0.0150386 Determinant: -0.102603 Determinant: -0.077111 Determinant: 0.021146 Determinant: 0.089761 Determinant: -0.0532867 Determinant: -0.0620632 Determinant: -0.0165414 Determinant: -0.0461426 Determinant: 0.00144256 Determinant: 0.00844777 Determinant: 0.0893306 Determinant: -0.0814478 Determinant: -0.0890507 Determinant: -0.0472091 Determinant: 0.0186799 Determinant: -0.00224087 Determinant: -0.0242662 Determinant: -0.00195303 Determinant: 0.014432 Determinant: 0.00185717 Determinant: -0.0354357 Determinant: -0.0427957 Determinant: -0.0380409 Determinant: 0.0627548 Determinant: 0.0397546 Determinant: 0.0570439 Determinant: 0.106265 Determinant: 0.0382001 Determinant: -0.0240826 Determinant: -0.0866264 Determinant: 0.024184 Determinant: 0.0841286 Determinant: -0.0303611 Determinant: -0.0337029 Determinant: -0.0202875 Determinant: 0.0643731 Determinant: -0.0475265 Determinant: -0.00928736 Determinant: -0.00373402 Determinant: 0.0636828 Determinant: 0.0122532 Determinant: 0.0398141 Determinant: -0.0563998 Determinant: -0.0778303 Determinant: 0.0164747 Determinant: 0.0314815 Determinant: 0.0744507 Determinant: -0.0897675 Determinant: 0.0260324 Determinant: -0.0734512 Determinant: 0.000234548 Determinant: -0.0238522 Determinant: -0.0849523 Determinant: 0.0204877 Determinant: -0.0715147 Determinant: 0.0703858 Determinant: -0.0142186 Determinant: -0.101503 Determinant: 0.03966 Determinant: 4.69111e-05 Determinant: 0.0394428 Determinant: 0.0409131 Determinant: 8.90995e-05 Determinant: -0.00841189 Determinant: -0.0671323 Determinant: 0.00805167 Determinant: -0.00292435 Determinant: 0.0507716 Determinant: 0.0493995 Determinant: 0.00629414 Determinant: -0.0428982 Determinant: -0.0446924 Determinant: 0.0776236 Determinant: 0.00440478 Determinant: -0.0463321 Determinant: -0.00247224 Determinant: -0.0199861 Determinant: 0.0267022 Determinant: 0.0184179 Determinant: 0.0104588 Determinant: 0.116535 Determinant: -0.0857382 Determinant: -0.0477216 Determinant: 0.0286968 Determinant: 0.0387932 Determinant: 0.042856 Determinant: -0.0964 Determinant: 0.0320456 Determinant: -0.0676327 Determinant: 0.0156632 Determinant: 0.0548582 Determinant: 0.0394791 Determinant: 0.0863353 Determinant: -0.0568753 Determinant: -0.00953039 Determinant: -0.0534666 Determinant: 0.0506779 Determinant: 0.00521034 Determinant: 0.0353338 Determinant: 0.0845463 Determinant: -0.00847695 Determinant: 0.015726 Determinant: -0.0648035 Determinant: 0.0170917 Determinant: 0.0045193 Determinant: -0.0195397 Determinant: 0.00630076 Determinant: -0.0137401 Determinant: 0.0209229 Determinant: 0.00382077 Determinant: -0.0588661 Determinant: -0.0923883 Determinant: -0.00726003 Determinant: -0.0411533 Determinant: 0.00544489 Determinant: 0.0101791 Determinant: 0.0903306 Determinant: -0.0590416 Determinant: -0.0377112 Determinant: -0.0150455 Determinant: 0.0793066 Determinant: 0.0425759 Determinant: -0.040728 Determinant: -0.0376792 Determinant: -0.0387703 Determinant: -0.0232208 Determinant: 0.0506747 Determinant: -0.0284409 Determinant: 0.000536999 Determinant: -0.0289103 Determinant: -0.00586449 Determinant: -0.0805586 Determinant: 0.0133906 Determinant: -0.00311773 Determinant: 0.0184798 Determinant: -0.00981978 Determinant: -0.0491601 Determinant: 0.0452526 Determinant: 0.00411708 Determinant: -0.0515142 Determinant: 0.0121114 Determinant: 0.00636972 Determinant: -0.0126048 Determinant: -0.0412662 Determinant: 0.00195264 Determinant: -0.0726478 Determinant: 0.0692254 Determinant: -0.0256477 Determinant: 0.0702529 Determinant: -0.0052493 Determinant: 0.0625172 Determinant: 0.00282606 Determinant: 0.0229033 Determinant: 0.0558893 Determinant: 0.0766217 Determinant: -0.00388679 Determinant: -0.0193821 Determinant: -0.00718189 Determinant: -0.0864566 Determinant: 0.0809026 Determinant: -0.0398232 Determinant: -0.00224801 Determinant: 0.0333072 Determinant: -0.0212002 Determinant: 0.00371396 Determinant: 0.0162035 Determinant: -0.0811845 Determinant: 0.0148128 Determinant: 0.0372953 Determinant: 0.00351286 Determinant: -0.00103575 Determinant: 0.0384813 Determinant: 0.00752738 Determinant: -0.0248252 Determinant: -0.106768 Determinant: -0.0192333 Determinant: -0.026543 Determinant: -0.0222608 Determinant: -0.0487862 Determinant: 0.00376402 Determinant: -0.0329469 Determinant: 0.00266775 Determinant: 0.0762491 Determinant: 0.0159609 Determinant: -0.0190175 Determinant: -0.0338969 Determinant: -0.0631867 Determinant: -0.0238901 Determinant: 0.107709 Determinant: -7.74935e-05 Determinant: -0.0468996 Determinant: 0.0462787 Determinant: 0.0387825 Determinant: 0.0753388 Determinant: -0.000279933 Determinant: 0.00638663 Determinant: -0.00458034 Determinant: 0.0185849 Determinant: -0.00543503 Determinant: -0.0520309 Determinant: -0.0234638 Determinant: 0.0593986 Determinant: -0.00036774 Determinant: 0.00960819 Determinant: -0.00685314 Determinant: -0.000176925 Determinant: 0.0207583 Determinant: -0.0337003 Determinant: -0.0534818 Determinant: 0.0142158 Determinant: -0.0728077 Determinant: 0.0246877 Determinant: -0.0660952 Determinant: -0.0466 Determinant: 0.0915457 Determinant: -0.00340539 Determinant: 0.00815076 Determinant: -0.0751806 Determinant: -0.00617677 Determinant: 0.0019761 Determinant: -0.0016673 Determinant: 0.0310364 Determinant: 0.0483121 Determinant: -0.00664964 Determinant: 0.0659273 Determinant: -0.019015 Determinant: 0.0087627 Determinant: 0.0267279 Determinant: 0.0253497 Determinant: 0.00246292 Determinant: -0.0684746 Determinant: -0.0234524 Determinant: -0.0197933 Determinant: 0.0120796 Determinant: -0.0192703 Determinant: 0.0853956 Determinant: 0.0388196 Determinant: -0.0599305 Determinant: -0.0626148 Determinant: 0.0258541 Determinant: -0.0341273 Determinant: 0.0972889 Determinant: -0.0306585 Determinant: 0.0188553 Determinant: 0.00247702 Determinant: -0.00368989 Determinant: -0.0951982 Determinant: 0.0113578 Determinant: 0.000762509 Determinant: -0.0225219 Determinant: 0.0414059 Determinant: -0.0244409 Determinant: -0.0425728 Determinant: 0.04275 Determinant: -0.0413427 Determinant: -0.00556264 Determinant: -0.0894398 Determinant: -0.0193197 Determinant: -0.00788038 Determinant: -0.00455421 Determinant: -0.0788177 Determinant: 0.0415381 Determinant: -0.0346766 Determinant: -0.0748027 Determinant: 0.0087688 Determinant: -0.0968796 Determinant: 0.0683526 Determinant: -0.00996678 Determinant: 0.00955922 Determinant: -0.0914706 Determinant: 0.0728304 Determinant: 0.0541784 Determinant: 0.0457072 Determinant: -0.0299529 Determinant: -0.0096473 Determinant: -0.0142643 Determinant: -0.0684794 Determinant: 0.00281004 Determinant: -0.03252 Determinant: -0.0144637 Determinant: 0.0294154 Determinant: 0.00574353 Determinant: -0.019569 Determinant: 0.00492446 Determinant: -0.0526394 Determinant: -0.000870143 Determinant: -0.0180984 Determinant: -0.0144104 Determinant: 0.0456077 Determinant: -0.0113433 Determinant: 0.00377549 Determinant: -0.0775854 Determinant: -0.0336789 Determinant: -0.0744995 Determinant: -0.0427397 Determinant: 0.0300061 Determinant: -0.0326518 Determinant: -0.0333735 Determinant: -0.0284057 Determinant: -0.00999835 Determinant: -0.0380404 Determinant: 0.00648521 Determinant: 0.0449298 Determinant: 0.0120318 Determinant: -0.0230653 Determinant: -0.00934067 Determinant: -0.0175326 Determinant: -0.0799447 Determinant: 0.0679027 Determinant: -0.00670324 Determinant: -0.0841748 Determinant: 0.0236213 Determinant: 0.0386624 Determinant: -0.0239495 Determinant: 0.076976 Determinant: -0.00997484 Determinant: 0.025157 Determinant: -0.0654046 Determinant: 0.0090564 Determinant: 0.00129045 Determinant: -0.105119 Determinant: 0.0976925 Determinant: -0.105149 Determinant: -0.0465851 Determinant: 0.00237453 Determinant: -0.0456927 Determinant: 0.0328236 Determinant: -0.0914691 Determinant: -0.0157904 Determinant: -0.00170804 Determinant: -0.014797 Determinant: 0.00464912 Determinant: -0.035118 Determinant: -0.0242306 Determinant: 0.0081405 Determinant: 0.0733502 Determinant: -0.0860252 Determinant: -0.0511219 Determinant: -0.0925647 Determinant: 0.0495087 Determinant: -0.0515914 Determinant: -0.044318 Determinant: 0.000900043 Determinant: 0.0632521 Determinant: 0.00957955 Determinant: 0.00598059 Determinant: 0.0179513 Determinant: 0.0952263 dx,dy,dz distance tcp object want keep sight. The sphere like safety zone, mainly used compute orientation tool.",inverse-kinematics c++
9701,Designing Ackerman's Steering Principle autonomous robot,"I working high speed autonomous robot (about 6-7 m/s), obstacle detection well senses traffic lights (I used Raspberry Pi 3 Arduino Uno). For steering mechanism, I wanted implement Ackerman's steering. I've read principle understood basics. Now actually make design, I currently using switchboards, sold India, surprisingly strong, lightweight, waterproof(they switchboards) cheap. Now I got 1 big axle small axle cut already, along two L-shaped pieces join 2 axles together... I'm confused connect wheels axle make rotate along side it. The site won't let upload pics right now, I'll try ASAP. I switchboard, electric drill anything make happen ( ;P ). I don't access 3D Printer. Any help would greatly appreciated... P.S- And suggestions own, might better robot, feel free share them, I'm looking good steering method robot.",arduino raspberry-pi navigation steering
9702,How I improve ZED Camera precision?,"I'm using Stereolabs ZED camera computer vision project. I small research several sensors market ultimately decided go ZED Camera. However I'm finding precision camera isn't great. And Point Cloud takes much storage space. Anyone found problems? And so, managed them? Thank you!",computer-vision stereo-vision
9704,motor inertia tensor?,"In modeling dynamics robot ,in servo motor adjusted inside link, need find inertia tensor motor itself,Right? So needed get inertia tensor motor since couldn't find solid works model internal components,i mean gears stuff(with related specified materials)?",servomotor dynamics
9709,Is servo fried?,"I got new servo days back (RC Servo, Futaba FP-S148). I first tested Sweep sketch Arduino, powering Arduino 5v GND pins only. It working, fine. Today I trying use robot I tried powering 2 LiPo batteries (Samsung ICR16850 2200mAh, old laptop battery) connected series, giving 8.32v. As soon I connected servo, started rotating randomly, I connected Arduino yet. I quickly took out. Next, I used L7805 get 5.13v regulated supply batteries I used earlier. When I connected batteries servo, servo Arduino, uploaded sketch, servo started behaving rather strangely, first complete turn stopped. Only humming sound came servo. Strange thing is, whenever I connect one Multimeter leads power cables, servo immediately turned opposite direction long lead contact either positive negative wire. Otherwise, servo gives humming sound. Have I fried servo? Or issue? UPDATE 1 I stripped servo checked motor. It working fine, seems like gear problem.",arduino battery rcservo
9711,Testbed testing navigation algorithms,I'm looking testbed (simulator web-based interface lets control robot) testing different routing navigation algorithms. Is system web?,navigation routing
9716,Quality check robot,How develop robot based system continuously monitor check products defeat moving conveyer belt using sensors kick defect product queue?,microcontroller
9720,8 wheeled vehicle model,"I want dynamic model 8 wheeled robot. I expected find easily like 4 wheeled bicycle model, I couldn't. Here effort rotation feedback. From I calculate steering angle, messy manage all. I need model controlling.",wheeled-robot dynamics motion robotc
9724,How apply A bang-bang signal amplitude 1 N 1 width input force reproduce certain results Matlab?,"I working dynamic modeling simulation mechanical system (overhead crane), I obtained equation motion, form: $$ M(q)\ddot{q}+C(q,\dot{q})\dot{q}+G(q)=Q $$ All matrices know inertia, $ M(q)$, Coriolis-Centrifugal matrix $ C(q,\dot{q})$, gravity $ G(q)$ functions generalized coordinates $q$, derivatives $\dot{q}$. I want solve $q$, using Matlab ODE (in m-file), I got response initial conditions zero input, but, I want find response, aforementioned control signal (A bang-bang signal amplitude 1 N 1 width), I'm trying regenerate results literature, authors work said, regrading input signal following: ""A bang-bang signal amplitude 1 N 1 width used input force, applied cart gantry crane. A bang-bang force positive (acceleration) negative (deceleration) period allowing cart to, initially, accelerate decelerate eventually stop target location."" I didn't grasp mean bang-bang signal, I know Matlab could step input, impulse, ...etc. But bang-bang signal, I'm familiar with. According site bang bang controller rather. Could anyone suggest figure issue implement input signal? preferably m-file. The code I'm using given bellows, two parts: And: clear all; close all; clc; t0 = 0;tf = 20; x0 = [0.12 0.5 0 0, 0 0 0 0,0 0 0 0]; % initional conditions % % spectifications Mp = [0.1 0.5 1]; % variable mass payload figure plotStyle = {'b-','k','r'}; = 1:3 mp = Mp(i); mc = 1.06; mr = 6.4; % mass kg L = 0.7; J = 0.005; % m, kg-m^2 respe. spec = [mp mc mr L J]; % % Call function [t,x] = ode45(@(t,x)AlFagera(t,x,spec),[t0 :0.001: tf],x0); legendInfo{i} = ['mp=',num2str(Mp(i)),'kg']; fx = diff(x(:,9))./diff(t); fy = diff(x(:,10))./diff(t); tt=0:(t(end)/(length(fx)-1)):t(end); % time vector % plot cart positions x direcitons subplot(1,2,1) plot(t,x(:,1),plotStyle{i}) axis([0 20 0 0.18]); grid xlabel('time (s)'); ylabel('cart position x direction (m)'); hold legend(legendInfo,'Location','northeast') subplot(1,2,2) plot(t,x(:,2),plotStyle{i}) axis([0 20 0 1.1]); grid xlabel('time (s)'); ylabel('cart position direction (m)'); hold legend(legendInfo,'Location','northeast') end % plot input torque, (bagn-bang signal), one sample figure plot(tt,fy) grid set(gca,'XTick',[0:20]) xlabel('time (s)'); ylabel('input signal, f_y (N)'); Furthermore, results I'm getting I supposed get shown: Major difficulties, initial conditions clearly stated paper, input force direction, (which be), different direction. I appreciate help. paper I'm trying recreate is: R. M. T. Raja Ismail, M. A. Ahmad, M. S. Ramli, F. R. M. Rashidi, “Nonlinear Dynamic Modelling Analysis 3-D Overhead Gantry Crane System System Parameters Variation.,” International Journal Simulation–Systems, Science & Technology, vol. 11, no. 2, 2010.",control robotic-arm dynamics matlab input
9727,"How robot find position given map without GPS, including initial point given?","Consider map The Contest arena shown figure 1 consists two sub arenas, sides identical scientists safe zone locations similar. Each sub arena 3 different colored rooms fourth shared room. Each robot placed identical start locations, respective arena. These locations random anywhere map. Each room (other shared room) two entry exit gates. Both gates open times. The robot enter exit gate chooses.",localization
9728,How check sharp angle line follower?,"I mBot robot I want program follow line. So far pass kind line >90°. I want able pass 90°-ish angles well. Like one: The problem mBot robot 2 line following sensors (they 5 mm apart line 2 cm wide) I can't use sensors. Most times goes line it's supposed turn misses line (goes white) goes back get back track. Once it's back black line tries go forward goes white instead taking turn. This happens endlessly. Sometimes passes angle going back forth accidentally turning, that's even workaround, let alone solution. Here's test course first round competition. My robot pass without problem, gets stuck (poorly edited, sorry) course: It can't pass 20 block robot enters 15 20 block (so basically gets stuck it's coming angle hits 90 degree turn). The sensor value could read either 0, 1, 2 3 depending robot currently sees: 0 - line 1 - right line 2 - left line 3 - line Pseudo code current program: So would I go taking sharp turns?",arduino motor line-following
9729,Diffrence Degrees Freedom (DOF) Degrees Motion (DOM),Could anyone expain shortly diffrence degrees freedom (DOF) degrees motion (DOM)? I know DOF number independent movements manipulation arm make robot system max 6 independent DOF unlimited number DOM I distinguish other.,manipulator theory
9738,How quadcopter made hover perfectly still?,"I need get drone flying still enough I rest glass water it. I've tried KK boards APM 2.6 (3.1 software). I've balanced props, set PID settings, auto-trim / autotune drone still tends inconsistently drift little one way another. What plausible way completely isolate drift?",quadcopter
9739,Quadcopter Flight Controller:Why Using gyroscope data give better results?,"I succeeded making first quadcopter scratch readymade frame. I designed flight controller help YMFC-3D youtube series videos. But process, I discovered using euler angles 'ypr' values MPU6050 feeback PID loop makes super difficult tune quadcopter even doesn't fly great. Whereas although intuitive me, using gyroscope values complementary filter instantly made quad respond much better tuning also difficult. Let clearly define response cases. Using ypr values:- +Always keeps overshooting 'underreaching' +Very small range values let quad fly stable +Drastic Reactions extreme values P (Kp)values Using gyro values:- +Reaction much stable +Tuning PID also simple + Even high values P(Kp) quad might crash due oscillations flip react extremely Below portion PID loop:",quadcopter pid gyroscope
9741,Principle virtual force - General help understanding / explanation,"I'm Electronics student taking module Robotics. From example, I understand line 1 Jacobian found time derivative kinematics equation relates joint angles velocity. I understand transpose taken line 3 line 4 produced.",kinematics jacobian
9751,Measuring vehicle's forward lateral acceleration using smartphone,"I want measure acceleration (forward lateral separately) using android smartphone device order able analyse driving behavior. My approach would follows: 1. Aligning coordinate systems Calibration (no motion / first motion): While car stationary, I would calculate magnitude gravity using rotate straight z-axis (pointing downwards assuming flat surface). That way, pitch roll angles near zero equal angles car relativ world. After this, I would start moving straight forward car get first motion indication using Sensor.TYPE_ACCELEROMETER rotate magnitude straight x-axis (pointing forward). This way, yaw angle equal vehicle's heading relativ world. Update Orientation (while driving): To able keep coordinate systems aligned driving I going use Sensor.TYPE_GRAVITY maintain roll pitch system via A_x,y,z acceleration gravity. Usually, yaw angle would maintained via Sensor.ROTATION_VECTOR Sensor.MAGNETIC_FIELD. However, reason behind using I going use application also electrical vehicles. The high amounts volts ampere produced engine would presumably make accuracy sensor values suffer. Hence, best alternative I know (although optimal) using GPS course maintain yaw angle. 2. Getting measurements By applying aforementioned rotations possible maintain alignment smartphone's vehicle's coordinate systems and, hence, giving pure forward lateral acceleration values x-axis y-axis. Questions: Is approach applicable I miss something crucial? Is easier/alternative approach this?",sensors accelerometer gps
9752,E: Unable locate package ros-jade-desktop-full,"I want install ROS Xubuntu 16.04, Xenial Xerus. I followed ROS's site instruction: , following: First, setup sources.list: Second, set keys: sudo apt-key adv --keyserver hkp://ha.pool.sks-keyservers.net:80 --recv-key 0xB01FA116 Then, make sure package up-to-date: sudo apt-get update Last, try install ROS jade: sudo apt-get install ros-jade-desktop-full And get error: E: Unable locate package ros-jade-desktop-full Where I go wrong, I get ROS (any version ok) running Xubuntu 16.04?",ros
9754,Are Flight Controllers Remote Controls using protocol?,"I'm start project, I'm sniffing data remote controls flight controllers RC copters stuff information. Do (or most) flight controllers use protocol communicate remote controls, vary based one buy? I would testing drones (DJI phantom like). So, real question is: If I want write something read data, I need buy different flight controller protocol used, use protocol, I buy one flight controller, info I get types flight controllers? Also, protocols spoken ground remote control flight controller? Does receiver care protocol used, middle man?",quadcopter radio-control research
9755,Dead Reckoning: Obtaining Position Estimation Accelerometer Acceleration Integration,"Good day, I reading papers position integration accelerometer readings. I consulted paper freescale achievable article regarding leaky integrators help preventing accumulation errors integration. I testing algorithm moving imu approximately 0.1 meter. The algorithm get right instant arrives approx 0.1 meter however left still position, integrated position goes zero. It turns velocity readings become negative certain period reaching 0.1 meters. Does anyone suggestions dealing error? Plots (Red position, Blue velocity.) The imu(accelerometer) moved alternating positions 0 meters 0.1 meters stop approximately 3-5 seconds moving next position Actual Data Desired Data output (Green - Desired position integration) Code:",quadcopter sensors localization integration dead-reckoning
9756,Step size numerical differentiation,"I get position information corresponding timestamp motion tracking system (for rigid body) 120 Hz. The position sub-millimeter precision, I'm sure time stamp, I get floating point number seconds motion tracking software. To get velocity, I use difference two samples divided $\Delta t$ two samples: $\dot{\mathbf{x}} = \dfrac{\mathbf{x}[k] - \mathbf{x}[k-1]}{t[k]-t[k-1]}$. The result looks fine, bit noisy times. A realized I get much smoother results I choose differentiation step $h$ larger, e.g. $h=10$: $\dot{\mathbf{x}} = \dfrac{\mathbf{x}[k] - \mathbf{x}[k-h]}{t[k]-t[k-h]}$. On hand, peaks velocity signal begin fade I choose $h$ large. Unfortunately, I didn't figure I get smoother signal bigger step $h$. Does someone hint? Is general rule differentiation step size optimal respect smoothness vs. ""accuracy""? This sample plot one velocity component (blue: step size 1, red: step size 10):",motion pose
9770,Mobile robot algorithm implementation error,"I working reproducing robotics paper, first simulating MATLAB order implement real robot afterwards. The robot's model is: $$\dot{x}=V(t)cos\theta $$ $$\dot{y}=V(t)sin\theta$$ $$\dot{\theta}=u$$ The idea apply algorithm avoid obstacles reach determines target. This algorithm uses cone vision measure obstacle's properties. The information required apply system is: 1) The minimum distance $ d(t) $ robot obstacle (this obstacle modelled circle know radius $ R $). 2) The obstacle's speed $ v_{obs}(t) $ 3)The angles $ \alpha_{1}(t)$ $ \alpha_{2}(t)$ form robot's cone vision, 4) heading $ H(t) $ robot target First safe distance $ d_{safe}$ robot obstacle defined. The robot reach target without closer $ d_{safe}$ obstacle. An extended angle $ \alpha_{0} \ge arccos\left(\frac{R}{R+d_{safe}} \right) $ defined, $ 0 \le \alpha_{0} \le \pi $ Then following auxiliary angles calculated: $ \beta_{1}(t)=\alpha_{1}(t)-\alpha_{0}(t)$ $ \beta_{2}=\alpha_{2}(t)+\alpha_{0}(t)$ Then following vectors defined: $ l_{1}=(V_{max}-V)[cos(\beta_{1}(t)),sin(\beta_{1}(t))]$ $ l_{2}=(V_{max}-V)[cos(\beta_{2}(t)),sin(\beta_{1}(2))]$ $ V_{max}$ maximum robot's speed $ V $ constant fulfills $ \|v_{obs}(t)\| \le V \le V_{max} $ This vectors represent boundaries cone vision vehicle Given vectors $ l_{1} $ $ l_{2}$ , angle $ \alpha(l_1,l_2)$ angle $ l_{1}$ $ l_{2} $ measured counterclockwise direction, $ \alpha \in (-\pi,\pi) $ . Then function $f$ The evasion maneuver starts time $t_0$. For robot find index h: $h = min|\alpha(v_{obs}(t_0)+l_j(t_0),v_R(t_0))|$ $j={1,2}$ $v_R(t)$ robot's velocity vector Then, two vectors $v_{obs}(t_0)+l_j(t_0)$ choose one forms smallest angle robot's velocity vector. Once h determinded, control law applied: $u(t)=-U_{max}f(v_{obs}(t)+l_h(t),v_R(t))$ $V(t)=\|v_{obs}(t)+l_h(t)\| \quad \quad (1)$ This sliding mode type control law, steers robot's velocity $v_R(t)$ towards switching surface equal vector $v_{obs}(t)+l_h(t)$. Ideally robot avoids obstacle surrounding While robot avoiding obstacle follows control law: $u(t)=0$ $V(t)=V_{max} \quad \quad (2) $ Hence rules switch two laws are: R10 Switching (2) (1) occurs whenthe distance obstacle equal constant C, means $d(t_0)=C$ distance becoming smaller time i.e. $\dot{d(t)}<0$ R11 Switching (1) (2) occurs $d(t_*)<1.1a_*$ vehicle pointing towards obstacle, i.e. $\theta(t_*)=H(T_*)$ $a_*=\frac{R}{cos\alpha_0}-R $ Ideally result similar But I'm getting instead While I understand theory there's obviously flaw implementation I haven't able solve. In opinion robot manages avoid obstacle certain point (in red circle), robot turns wrong side, making impossible condition $H(t) = \theta(t) $ achieved. I feel I measuring properly angle alpha $v_{obs}(t)+l_h(t)$ $v_{R}(t)$ , debugging I see certain point stops switching negative positive values become positive, leading robot's wrong side. It also seems related problem here: Angle circle tangent line",mobile-robot kinematics matlab geometry
9772,Is singularity incorrect implementation inverse kinematics?,"I moment trying compute Q configuration moves robot current state described transformation matrix. rotation position this: -0.0882761 -0.255069 0.183645 To rotatation 0 0.942755 -0.333487 1 0 0 0 -0.333487 -0.942755 position 8.66654 19.809 115.771 Due drastic change Z direction, I thought could split path start end small chunks creating data inbetween interpolating, compute inverse kinematics small position. Problem output getting pretty large.. Which making suspect output might wrong. The simulation using constrains rotation 360 degrees.. I think something goes wrong.. The reason I could think would this, would jacobian using singularities... Which assumed running singualarity issue.. setQ{22.395444, 319.402231, 90.548314, -228.989836, -295.921218, -336.808799} setQ{8.209388, 362.472468, 108.618073, -232.346755, -299.935844, -334.929518} setQ{8.479842, 399.892521, 127.432982, -234.017882, -303.852583, -335.063821} setQ{8.224516, 362.232497, 108.666778, -232.319554, -299.899932, -334.928688} setQ{7.718908, 286.832458, 71.150606, -228.913831, -291.982659, -334.658147} setQ{7.468625, 249.092444, 52.400638, -227.206436, -288.018036, -334.522738} setQ{7.220023, 211.325766, 33.656081, -225.496018, -284.049424, -334.387237} setQ{-6.134091, -2538.260148, -1283.375216, -96.331289, 7.920957, -324.531125} setQ{-6.261661, -2577.946595, -1301.730132, -94.403263, 12.176863, -324.388990} setQ{-6.634286, -2697.165915, -1356.762411, -88.601053, 24.968521, -323.962029} setQ{-6.991781, -2816.625206, -1411.745985, -82.771641, 37.796090, -323.534239} setQ{-7.334148, -2936.324468, -1466.680853, -76.915029, 50.659572, -323.105620} setQ{-7.661386, -3056.263702, -1521.567017, -71.031215, 63.558965, -322.676171} setQ{-8.642914, -3457.794271, -1704.169136, -51.222052, 106.816303, -321.238686} setQ{-8.988457, -3619.153075, -1777.058457, -43.213761, 124.230964, -320.661112} setQ{-9.382564, -3821.451508, -1868.048346, -33.135395, 146.089069, -319.937071} setQ{-9.528439, -3902.557525, -1904.406419, -29.082892, 154.860242, -319.646810} setQ{-9.667591, -3983.770196, -1940.742846, -25.018300, 163.647376, -319.356179} setQ{-9.734645, -4024.416527, -1958.902942, -22.981471, 168.046928, -319.210726} setQ{-9.986053, -4187.268484, -2031.489209, -14.803929, 185.685040, -318.627992} setQ{-10.210564, -4350.547057, -2103.988889, -6.578030, 203.386994, -318.043783} setQ{-10.312734, -4432.346324, -2140.206259, -2.446947, 212.261912, -317.751125} setQ{-10.453381, -4555.245201, -2194.491727, 3.772345, 225.604215, -317.311448} setQ{-10.496902, -4596.264820, -2212.576060, 5.851488, 230.059630, -317.164705} setQ{-10.538741, -4637.311102, -2230.654980, 7.933652, 234.519035, -317.017869} setQ{-10.617377, -4719.483658, -2266.796587, 12.107048, 243.449816, -316.723922} setQ{-10.812941, -4966.641247, -2375.091527, 24.699772, 270.337923, -315.839868} setQ{-10.839651, -5007.927501, -2393.121742, 26.809138, 274.833240, -315.692203} setQ{-10.888029, -5090.579998, -2429.165939, 31.036936, 283.835844, -315.396596} setQ function simulation, numbers actual Q values starting 0 - 5. (I using 6 jointed robot (UR5)) Update I using sphere compute desired transformation matrix.. The idea want arm sphere, point inward center. std::vector<Transform3D<>> pathPlanning::sphere(double dx, double dy, double dz) { double r = 5.0; // Radius sphere - set 5.0 cm (TODO: checked also accurate) cout << ""Create sphere"" << endl; double current_x = this->device->baseTframe(this->toolFrame,this->state).P()[0]; double current_y = this->device->baseTframe(this->toolFrame,this->state).P()[1]; double current_z = this->device->baseTframe(this->toolFrame,this->state).P()[2]; // Formula sphere (x-x0)²+(y-y0)²+(z-z0)²=r² // x: x = x_0 + rcos(theta)sin(phi) // y: = y_0 + rsin(theta)sin(phi) // z: z = z_0 + rcos(phi) // Angle range: 0 <= theta <= 2M_PI ; 0 <= phi <= M_PI double obj_x = current_x + dx; double obj_y = current_y + dy; double obj_z = current_z + dz; std::vector<Transform3D<>> out; int count = 32; for(double azimuthal = 0; azimuthal <= M_PI ; azimuthal+=0.01 ) { for(double polar = 0.35; polar <= M_PI-0.35 ; polar+=0.01 ) { double sphere_x = obj_x + r*cos(azimuthal)*sin(polar); double sphere_y = obj_y + r*sin(azimuthal)*sin(polar); double sphere_z = obj_z + + r*cos(polar); //string text = to_string(sphere_x) + "" , "" + to_string(sphere_y)+ "" , "" + to_string(sphere_z); //positions << text << endl; Transform3D<> transformation_matrix = transform(obj_x,obj_y,obj_z,sphere_x,sphere_y,sphere_z); if(0.1<(transformation_matrix.P()[0] - current_x) || 0.1<(transformation_matrix.P()[1] - current_y) || 0.1<(transformation_matrix.P()[2] - current_z)) { cout << ""Interpolate: "" << endl; std::vector<Transform3D<>> transformation_i = invKin_LargeDisplacement(transformation_matrix); out.insert(out.end(),transformation_i.begin(),transformation_i.end()); cout << out.size() << endl; cout << ""only returning one interpolation onto sphere!"" << endl; return transformation_i; } else { cout << ""OK"" << endl; out.push_back(transformation_matrix); } if(count == 32) //TODO: Why...... occuring? { //cout << ""Theta: "" << theta << "" Phi: "" << phi << endl; //cout << sphere_x << "" , "" << sphere_y <<"" , ""<< sphere_z << endl; count = 0; } else { count++; } } } return out; } This function provides point sphere, use create rotation matrix using transform. Transform3D<> pathPlanning::transform(double obj_x, double obj_y, double obj_z, double sphere_x, double sphere_y ,double sphere_z) { // Z-axis oriented towards object. // Rot consist 3 direction vector [x,y,z] describes axis oriented world space. // Looking simulation z-axis camera out. X, Y describes orientation camera. // The vector direction purposes, normalized.... // TODO: case [0 0 -1]... Why happening done undo it? cout << ""inside Transform"" << endl; cout << obj_x << "","" << sphere_x << "" ; "" << obj_y << "" , "" << sphere_y <<"" ; ""<< obj_z << "" , "" << sphere_z << endl; Vector3D<> dir_z((obj_x - sphere_x), (obj_y - sphere_y), (obj_z - sphere_z)); //Vector3D<> dir_z((sphere_x-obj_x), (sphere_y - obj_y), (sphere_z-obj_z)); dir_z = normalize(dir_z); Vector3D<> downPlane(0.0,0.0,-1.0); Vector3D<> dir_x = cross(downPlane,dir_z); dir_x = normalize(dir_x); Vector3D<> dir_y = cross(dir_z,dir_x); dir_y = normalize(dir_y); Rotation3D<> rot_out (dir_x,dir_y,dir_z); // [x z] Vector3D<> pos_out(sphere_x,sphere_y,sphere_z); Transform3D<> out(pos_out,rot_out); cout << ""desired: "" << << endl; return out; } The transform basically computes rotation matrix. The math based post @Ben, answer similar problem having.. Update Error rotation matrix due polar coordinate 0 => sin(0) = 0. I made plot displaying determinant jacobian, compute inverse kinematics large displacement. For inverse kinematics iteration, I set robot new q_i use current continue computing reach end configuration. It seems alot goes toward singularity general pretty low number.. Update Again think singularities might culprit here.. determinant: 0.0424284 Q{13.0099, -46.6613, -18.9411, 2.38865, 5.39454, -4.53456} determinant: -0.0150253 Q{47.1089, -0.790356, 6.89939, -2.725, -1.66168, 11.2271} determinant: -0.0368926 Q{15.7475, 8.89658, 7.78122, -2.74134, -5.32446, 1.11023} determinant: -0.0596228 Q{180.884, 66.3786, 17.5729, 9.21228, -14.9721, -12.9577} determinant: -0.000910399 Q{5426.74, 5568.04, -524.078, 283.581, -316.499, -67.3459} determinant: -0.0897656 Q{16.6649, -37.4239, -34.0747, -16.5337, -3.95636, -7.31064} determinant: -0.00719097 Q{-1377.14, 167.281, -125.883, -10.4689, 179.78, 56.3877} determinant: 0.0432689 Q{22.2983, -10.1491, -15.0894, -4.41318, -2.07675, -3.48763} determinant: -0.0430843 Q{82.6984, -39.02, -24.5518, 13.6317, 4.17851, -14.0956} determinant: -0.0137243 Q{425.189, -9.65443, 20.9752, 7.63067, 25.4944, -52.4964} Everytime compute new Q I set robot state, perform inverse kinematics state.. Q joint angles 6 joints. Update Interpolation done lineary dividing path start end specified amount data points. This plot shows tranformation matrices generated interpolation position part plotted. The red dots path (every 1000th position). The blue ball object want track, green dots represents sphere.. As I first point sphere, hits one point sphere, top point, plot also shows. Rotation doesn't show much change, also makes sense based difference current desired rotations. Update My InvKin Implementation LargeDisplacements: std::vector<Q> pathPlanning::invKin_largeDisplacement(std::vector<Transform3D<>> t_tool_base_desired_i) { Device::Ptr device_backup = this->device; //Read device parameter WorkCell::Ptr workcell_backup = this->workcell; //Read workcell parameter State state_backup = this->state; std::vector<Q> output; for(unsigned int = 0; i<t_tool_base_desired_i.size(); ++i) { Transform3D<> T_tool_base_current_i = device_backup->baseTframe(this->toolFrame,state_backup); //Read Current transformation matrix Eigen::MatrixXd jq(device_backup->baseJframe(this->toolFrame,state_backup).e().cols(), this->device.get()->baseJframe(this->toolFrame,state_backup).e().rows()); jq = this->device.get()->baseJframe(this->toolFrame,state_backup).e(); // Get jacobian current_configuration //Least square solver - dq = [j(q)]T (j(q)[j(q)]T)⁻1 du <=> dq = A*du Eigen::MatrixXd A (6,6); //A = jq.transpose()*(jq*jq.transpose()).inverse(); A = (jq*jq.transpose()).inverse()*jq.transpose(); Vector3D<> dif_p = t_tool_base_desired_i[i].P()-T_tool_base_current_i.P(); //Difference position Eigen::Matrix3d dif = t_tool_base_desired_i[i].R().e()- T_tool_base_current_i.R().e(); //Differene rotation Rotation3D<> dif_r(dif); //Making rotation matrix difference rotation RPY<> dif_rot(dif_r); //RPY rotation matrix. Eigen::VectorXd du(6); //Creating du du(0) = dif_p[0]; du(1) = dif_p[1]; du(2) = dif_p[2]; du(3) = dif_rot[0]; du(4) = dif_rot[1]; du(5) = dif_rot[2]; Eigen::VectorXd q(6); q = A*du; // computing dq Q q_current; q_current = this->device->getQ(this->state); Q dq(q); Q q_new = q_current+ dq; // computing new Q angles output.push_back(q_new); store output vector device_backup->setQ(q_new,state_backup); //Set robot calculated state. } return output; } I pretty sure interpolation works, plot shows. My inverse kinematics hand sure.. Update @Chuck mentions answer would good idea check core functionality, might shed light could going wrong. I tried inv.kin function know would work, didn't return result, make doubt whether transformation function create accurate? The robot simulation one shown above.. The Transform function shown above, function use compute desired, provide inverse kinematics.. Is something incorrectly setup? Update @Chuck came different approach problem, 3 DOF, position. I choose change track, peform simple inverse kinematics given distance dx,dy,dz.. Which reason isn't working quite good me? even small differences... Here code: std::vector<Q>pathPlanning::invKin(double dx, double dy , double dz) { kinematics::State state = this->state; Transform3D<> t_tool_base_current = this->device.get()->baseTframe(this->toolFrame,state); cout <<""Current: ""<< t_tool_base_current.P().e()<< endl; Vector3D<> P_desired(0.000001+t_tool_base_current.P().e()[0],t_tool_base_current.P().e()[1],t_tool_base_current.P().e()[2]); cout <<""Desired: "" <<P_desired << endl; Transform3D<> t_tool_base_desired(P_desired,t_tool_base_current.R()); Eigen::MatrixXd jq(this->device.get()->baseJframe(this->toolFrame,state).e().cols(), this->device.get()->baseJframe(this->toolFrame,state).e().rows()); jq = this->device.get()->baseJframe(this->toolFrame,state).e(); //Least square solver - dq = [j(q)]T (j(q)[j(q)]T)⁻1 du <=> dq = A*du Eigen::MatrixXd A (6,6); //A = jq.transpose()*(jq*jq.transpose()).inverse(); A = (jq*jq.transpose()).inverse()*jq.transpose(); Vector3D<> dif_p = t_tool_base_desired.P()-t_tool_base_current.P(); cout <<""difference: "" <<dif_p << endl; Eigen::VectorXd du(6); du(0) = dif_p[0]; du(1) = dif_p[1]; du(2) = dif_p[2]; du(3) = 0; du(4) = 0; du(5) = 0; Eigen::VectorXd q(6); q = A*du; Q q_current; q_current = this->device->getQ(this->state); Q dq(q); Q q_new = q_current+ dq; std::vector<rw::math::Q> output; if(!collision(q_new)) { output.push_back(q_new); } else { cout << endl; cout << q_new << endl; } return output; } outputs Current: -0.000799058 -0.282 0.99963 Desired: Vector3D(-0.000789058, -0.282, 0.99963) difference: Vector3D(1e-05, 0, 0) setQ{1.559142, 110474925659325248.000000, -1834.776226, 55426871347211368.000000, 0.068436, 88275880260745.328125} setQ state moves robot desires state.. Either something wrong implementation, singularity.. Especially moving much (0.00001)!!! Updates I think I solved mystery.. It must sphere function creates points outside reach robot.!!",robotic-arm inverse-kinematics
9776,How I compute inverse kinematics given desired transformation matrix?,"I moment trying implement inverse kinematics function function take desired transformation matrix, current transformation matrix, compute Q states needed move robot arm current state end state. I already written code, since simulation isn't showing right path, I would expect be, makes unsure whether implementation correct. Could someone comment implementation maybe spot error? Example output: Q{-1.994910, -94.421754, -123.448429, 15.218864, 6.602184, -13.742988} Q{2627.867315, -2048.863588, -51.340574, 287.654959, 270.187026, 258.581800} Q{12941.812459, -536.870516, -294.362593, -2145.963577, -31133.660814, -4742.343433} Q{32.044799, -14.220020, -14.312226, -12.444921, 12.269179, -24.393637} Q{125.537278, 28.626924, -55.646716, -20.945348, 17.536762, -2.656717} Q{9.514525, -107.455064, -17.009190, -15.245588, -0.960273, -2.010570} Q{8.255582, -3.010934, -4.882207, -1.369533, 0.848644, 1.175172} Q{208.655993, -28.443465, -64.413952, -3.129896, 13.063806, -6.042187} Q{-73.706483, -20.381540, -5.306434, -1.204419, -4.035149, 21.806934} Q{10.003481, 10.867394, 13.256192, -6.491445, -1.711469, 2.896646} Q{24.890626, -72.265307, -94.886507, 12.327304, -4.425786, 4.188531} Q{7.111258, 31.500732, -0.111033, -20.434697, 5.302118, 1.781690} Q{477.993581, 659.221820, 19.819916, -88.627757, 65.850191, -77.267367} Q{-30.672145, -53.496243, -18.170871, 83.648574, 48.311796, -28.015005} Q{-36.677982, -15.908633, 17.751008, 0.995766, -0.500259, 9.409435} Q{114246.358249, -10664.813432, -75.904830, 462.907904, 7992.514723, -18484.319327} Q{83.827086, -75.899321, -38.576446, 37.266068, 47.843725, 39.096061} Q{-119.682661, -774.773093, -251.969174, 23.212110, -42.662580, 53.247454} Q{98.608881, -28.013383, 132.896921, 17.121488, 36.916894, -14.627180} Q{-11519.051453, 5761.564318, -364.916044, -1188.567128, -2582.813750, -462.784007} Q{54802.605226, 40971.776641, 10204.739981, -654.963987, -244.277958, -8618.970216} Q{-21.334047, -14.314134, 17.714174, 2.463993, 0.963385, 5.304530}",robotic-arm inverse-kinematics c++
9783,Perspective n Point - RPnP algorithm,"I need caculate pose camera using image artificial landmkark. For porpouse I trying use Perspective n Point approach I calculate using intrinsic camera matrix, world coordinates landmark (I using 4 points) projection image. There algorithms solve (PnP, EPnP, RPnP, etc) I trying use RPnP. I found implementation here: I used code I problems I can't obtain correct pose. I using P.Corke's Robotics Toolbox MATLAB create CentraCamera known pose calculating projection landmark camera, rotation translation RPnP returns I defined before. Anyone used RPnP algorithm solve kind problems?",computer-vision cameras 3d-reconstruction
9786,"How PID parameters (Kp, Ki, Kd) affect heading differential driving robot increased individually?","Question: A PID controller three parameters Kp, Ki Kd could affect output performance. A differential driving robot controlled PID controller. The heading information sensed compass sensor. The moving forward speed kept constant. The PID controller able control heading information follow given direction. Explain outcome differential driving robot performance three parameters increased individually. This question come past paper likely won't show year still worries me. It's question thinking quite time. I'd love answer simple terms. Most stuff i've read internet don't make much sense goes heavy detail topic case. My take this: I know proportional term, Kp, entirely based error that, let's say, double error would mean doubling Kp (applying proportional force). This therefore implies increasing Kp result robot heading wrong direction Kp increased ensure robot goes right direction least tries reduce error time passes increase Kp would affect robot way adjust heading robot stays right path. The derivative term, Kd, based rate change error increase Kd implies rate change error increased time double error would result double force. An increase double change robot's heading would take place robot's heading doubled error previous feedback result. Kd causes robot react faster error increases. An increase integral term, Ki, means error increased time. The integral accounts sum error time. Even small increase error would increase integral robot would head right direction equal amount time integral balance zero. I would appreciate much better answer would great confident similar upcoming question finals.",pid wheeled-robot differential-drive
9797,What wheel base distance create2?,What wheel base distance used create2 calculate angle? I seen 230.8mm code samples manual seems indicate 235.0 mm.,irobot-create roomba
9798,How compensate brushless DC motor voltage drop?,"I working quadcopter project based Arduino board, system powered 4S LiPo battery (14.8V) motors behave differently battery voltage drops, discharging. Is way I make motors behave minimum value of, say, 5 volts? My current system works fine range 14.8 10 volts, I can't even hover.",quadcopter
9801,Low latency control laptop,Lets say I needed send sensor readings increments 100 bytes micro controller laptop sub 2 ms latencies real time (the data needs processed acted upon immediately (to control robot)). What interfaces would one use? FTDI usb-serial converters aren't option introduce 5-10 ms latencies ways. PCI cards option though.,low-latency laptop
9802,All-in-one GNSS localization solution (hardware+software),"Is something like all-in-one satellite based localization solution would contain hardware software GNSS localization robotics? I mean package would also contain IMU, would fuse GPS filter result accordingly provide software API query location/speed etc. I interested rather affordable solution professional hardware too? I trying implement mobile robot I realize smartphone-grade GPS (Samsung J5) gives better preliminary results u-blox eval board (this NEO-M8T integrated antenna ground plane) - I wonder why, I guess Android may fuse IMU better readings even worse antenna?",localization software gps gnss hardware
9803,TCP Communication PCDuino,"I'm working robot controlled xbox controller connected windows computer commands sent pcduino tcp connection. I working sending string 1's 0's tell pcduino motors turn on. I'm trying optimize sending int using bit masks make decisions pcduino I can't get pcduino receive int correctly. I tested windows function sending command sokit sending correct values pcduino receiving number even commands changing. This doing: Windows -> PCDuino command = 1 -> sendBuff = 73932 cmdstring = 1 -> n = 1 command = 1025 -> sendBuff = 73932 cmdstring = 1025 -> n = 4 My windows functions are: bool sendCommand() { cmdbuffer << command; cmdstring = cmdbuffer.str(); (!client->Send((char *)cmdstring.c_str())) { std::cout << ""Disconnected Server. Press Enter Exit""; std::cin.ignore(); std::cin.get(); return false; } return true; } PCDuino Loop Function void loop() { recBuff = 0; deviceFlag = 0; //Read Socket /******************************************************************************/ read(connfd, sendBuff, strlen(sendBuff)); recBuff = atoi(sendBuff); /******************************************************************************/ //Set Current Device Receive Instructions From checkAuto(recBuff, currDevice); //Find Current Device Command deviceFlag = checkDevice(recBuff); //If Current Device Set Device Same Parse Command (deviceFlag == currDevice) { parseHex(recBuff); } usleep(50000); } I printf read call that's I getting 73932 number. I think I everything guys need there's anything else I need add let know. I'm stumped...I don't know casting problem what. Update 1 What I everything setup loop functions PCduino run is: int listenfd = 0, connfd = 0; int n; struct sockaddr_in serv_addr; char sendBuff[1025]; time_t ticks;",communication c++ c
9819,Dji Wookong-M - To unstable take,I've built quadcopter using Dji Wookong-M. As couple weeks ago I able get everything work except one small thing. When I throttle Drone tends flip side. I tested motors I know spinning right direction I right props right motors. I tested grass concrete times flipped. It starts flip throttle past 50%. I don't know catching something balance although I don't think problem since quadcopter tips different directions almost every time. If one could tell wrong I would appreciate lot since project due 2 1/2 weeks. Thanks Advance,quadcopter
9822,Intropection ROS objects using python client library,"How I see attributes methods ROS objects ? Can I use inspect module Python ? Like python I use dir(), type() commands.",ros python
9825,Stability PID values update function quadrotor,"A reviewer last paper I sent replied dangerous update PID next kind formula (paper quadrotor control): $$ K_p (t + 1) = K_p (t)+e(t) (μ_1 (Pe(t)) + μ_4 (Pe(t))) $$ $Pe(t)$ % relationship desired angles real angles, $e(t)$ difference angles. $μ_1$ $μ_4$ membership functions fuzzy function. I think reviewer talking time increment update rather fuzzy usage specific formula. How stability formula tested, please? EDIT: membership functions represented following graph: $e(t)$ absolute difference angles, difference. It negative",quadcopter control pid
9826,Angular momentum rimless wheel Passive Dynamic Walking,"In Tad McGeer's work, Passive Dynamic Walking, 1990, mentions rimless wheel model, used approximate bipedal locomotion. I can't understand angular momentum written follows. $H^-=(\cos 2\alpha_0+r^2_{gyr})ml^2\Omega^-$ I following questions: Isn't angular momentum $I*\omega$, $m^2l\Omega$ paper's notation? If $\alpha_0$ $\frac{\pi}{2}$ $r_{gyr}$ approaches 0, shouldn't angular momentum impact, $H^-$, negative? Then conservation goes?",wheel walking-robot
9828,Brushless motor RC car won't spin even small resistance,"I recently bought RC car kit 10 minutes stopped going. When I throttle, I see motor trying spin grind get hot quite fast. The motor move I disconnect big gear, fast new still get hot. Also, I stop fingers slight touch. I don't know anything motors ESCs, I'm sure problem motor ESC. Did I burn out?",brushless-motor esc radio-control
9832,What biggest challenges build highly performant robotic hand?,"When looking robotic hands made researchers said rather close real human hand, easily cost tens thousands dollars. What makes much expensive? Sure lots joints parts must move, it's still hard figure cost much even highly precise servomotors. What much expensive trying build humanoid hand? How make less expensive? What expensive hands do, diy cheap hand project can't? Thank you.",humanoid
9839,Which mechanical device could repeatedly present ID tag card-reader,"I'm trying build test-automation robotic arm repeatedly present ID-tag (such RFID NFC card fob) card reader. I suspect reader fails either (a) hundreds presentations due fast presentations (b) specific moment reader duty cycle. The tag needs move well-controlled manner: Quickly present card, Pause (mark) Quickly remove card, Pause (space) Repeat 1. I'm calling present/remove sequence mark-space ratio simplicity. The tests I want perform involve varying (a) frequency (b) mark-space ratio, (a) stress-test (b) boundary-test re-presentation guard times built reader debounce presentations. The guard times around 400ms, response around 100ms, I need something move 5-10cm range quickly repeat within sorts timescales. The distance card needs move depends reader model, different field ranges. I want get edge field quickly avoid inconsistencies testing. I'm able programming (professional) simple electromechanical design build (ex-professional, hobbyist). I need build one, doesn't particularly robust, need fairly accurate regard timings second test. What I've done far: I've built one version already using Raspberry Pi, GPIO, stepper motor aluminium arm screwed wheel. It works, it's bit jerky slow, even 30cm arm amplify motion. It probably repeat test, it's time-accurate enough timing tests. My design ideas were: Servo (are also slow?) Solenoid (fast, limited range? might cause EM?) Motor (too uncontrollable, require much mechanical work me) Rotating drum (fast, stable, cannot control mark-space ratio) I'm electro-mechanical design expert, I'm wondering I'm missing electrical device mechanical design easily.",robotic-arm raspberry-pi stepper-motor industrial-robot automation
9840,The velocity profile robot fluctuating,"I presently robotics project. I using USARSIM (Urban Search Rescue Simulation) spawn robot. I trying create different behaviors, like: goal following behavior; obstacle avoidance behavior, and; wall following behavior robot. I first generate robots USARSIM. Then I specify goal location robot provide speed. The robot moves goal location specified speed. USARSIM provides (x, y, z) coordinates vehicle every time stamp. Based coordinates received, I trying calculate instantaneous speed robot every time stamp. The instantaneous speed graph fluctuating lot. In specific case, I providing robot 0.2 m/s. The velocity profile shown below. I unable understand reason behind it. Here observations I made. As I increase speed robot, variations decreasing. Suppose, I provide straight trajectory robot, doesn't follow straight trajectory. Does explain velocity profile fluctuating lot ? Please let know one provide possible explanation variance velocity profile.",mobile-robot
9842,Generalized Voronoi Diagram,"I need compute Voronoi diagram map obstacles I can't find pseudo-code example MATLAB. The ""voronoi"" function MATLAB works points, case obstacles polygons (convex non-convex). You see map attached image. Because obstacles polygons I found Voronoi algorithm needed GVD (Generalized Voronoi Diagram). Can anyone help code examples internet explaining compute GVD?",mobile-robot motion-planning geometry
9845,Path planning vs. linear interpolation?,"I moment trying convince I need simple path planning algorithm, instead linearly interpolating current desired state. I moment working robot arm (UR) camera mounted TCP. The application trying create simple ball tracking application tracks movement ball, always keeping object within sight. meant I needed form path planning algorithm plans path current state desired state. The path ball always kept focus arm moves desired state. But I began question whether bit overkill, whether simple straight line interpolation wouldn't suffice?.. I actual sure form benefit would choosing pathplanner, simple interpolation.. Interpolation would also generate path I desire, choose pathPlanner all? would someone elaborate? It noted obstacle avoidance also part task, could cause trouble straight line interpolating.",robotic-arm
9848,Path planning visual servoing,"I moment trying implement visual servoing application. robot I using UR5, TCP stereo camera mounted it. The idea move end effector according object tracked. The path-planning algorithm system comply rules. The path creates collision free, always keep object tracked sight time. Having path keeps object sight bit problem. Sometime end effector rotate around itself, messing measurements taken thus tracking itself. It able maneuver away static obstacles. A Possible solution? I thought possible solution. Since current state desired state defined two different sphere, A possible solution would create straight line center sphere, current position desired position, straight path could computed easily. always keeps oriented toward object. Problems I sure I handle collision here. Update Or use heuristic heuristic based path planning?",robotic-arm motion-planning algorithm
9850,Holonomic Non-holonomic UAV's: Gliders vs Quadcopters,Good day I would like ask fixed wing aircraft glider(without thrust capability therefore needs external forces air flow move constraining movement) considered non-holonomic system considering fact cannot move freely compared quadcopter holonomic. I found information from: What's difference holonomic nonholonomic system? Mathematically: Holonomic system systems constraints integrable positional constraints. Nonholonomic systems systems constraints nonintegrable positional constraints. Intuitively: Holonomic system robot move direction configuration space. Nonholonomic systems systems velocities (magnitude direction) derivatives position constraint.,quadcopter control uav glider
9851,How I evaluate minimum requirements processor camera visual SLAM robot?,"I would like build visual SLAM robot (just self-learning purpose) I get frustrated I know processor camera used visual SLAM. First, processor, I seen three articles, shows different systems used implementing SLAM algorithm: Implementing SLAM algorithm (however uses ultrasonic sensor rather visual sensor) Raspberry Pi (processing power 700 MHz) Implementing Odometry SLAM Algorithms Raspberry Pi Drive Rover I also seen Boston Dynamics use Pentium CPU, PC104 stack QNX OS Big Dog project, BigDog Overview November 22, 2008 Then, I also found project uses modern XILINX Zynq-7020 System-on-Chip (a device combines FPGA resources dual ARM Cortex-A9 single chip), Synchronized Visual-Inertial Sensor System, A synchronized visual-inertial sensor system FPGA pre-processing accurate real-time SLAM But reading those, I clue end decisions use kinds processors, stacks even OSes project. Is mathematical way, general practice, evaluate minimum requirement system (as cheap power efficient possible) algorithm run? If not, could I know processor system I prepare visual SLAM robot? If simple answer, also cool recommend something I could read good start. Secondly, I also cannot find clear information camera I use visual SLAM robot. I also idea evaluate minimum requirement camera. I found lot papers saying use RGB-D camera I Google find one, commercially available. The one I found Xtion Pro Live ASUS Global (for $170 quite affordable me), stock. Are practice I choose suitable camera system visual SLAM too? Sorry question long. I feel choosing system camera looks like thing requires lot experience background knowledge. So rather direct suggestions, cool ideas/recommended resources learn general ways people make decisions general similar projects, any.",slam
9852,Vector Field Histogram: (VFH) Certainty value,Good day I currently trying implement vector field histogram algorithm. May I ask anyone knows certainty value pertains to? From understanding like point system cell increment certainty every sensor read. Is right? Thank you.,quadcopter motion-planning vfh
9853,Maximum distance robotic arm throwing,"I 6DOF robotic arm I using throw ball. Each joint achieve maximum velocity 30 RPM (180 deg/s). I trying generate joint angles manually feeding see far I throw ball now. This shown it's like less 2 meters. But I feel I may combining motions various motors order get better throwing distance. I wanted know simple way theoretically determining maximum distance I throw. I read papers appear complicated, I need accurate value, estimate I decide whether I move different arm.",robotic-arm
9856,Cosine interpolation two transformation matrices?,"Is possible perform cosine interpolation two transformation matrices? It make sense translation part, rotational part?",robotic-arm stereo-vision
9863,Configuration space obstacle - calculating collision,"I need calculate configuration space obstacle planning path mobile robot. The idea divide obstacles robot triangles test whether triangle robot colliding triangle obstacles. The approach solve test two triangles time I need look 6 edges (3 triangle) divide triangles 3 vertex one lie one side 3 vertex lie side line. I wrote code calculate line equation (y = m*x + b) I think correct, I problems line vertical (this means = -Inf) MATLAB gives NaN I calculate equation it. I sure handle this. Here see snippet code I test 3 edges robot triangle: Anyone could help issue?",mobile-robot motion-planning matlab
9870,Quadcopter starts max speed,"I new Quadcopters. Just recently started 4, 1000kV motors 2 ESC 490Hz / 2 ESC 50 Hz (got eBay, found software) CC3D OpenPilot (now LibrePilot) FlySky FS-T6 (6 channel) Problem: When I configure calibrate LibrePilot software, motors run fine radio, slow min fast max. But soon I remove USB cable runs directly radio, suddenly min go max speed. I calibrated manually also ESC cable receiver radio, works perfectly process cable move CC3D runs again, shows behaviour. I calibrated motors directly, using LibrePilot configuration software works fine connected USB cable.",quadcopter calibration
9871,convert toolframe coordinate world frame coordinates?,"I sure explain this, I looking way plot trajectory robot arm. An object seen toolFrame frame, I plot position joint, frame uses same. One way would use world frame reference, would plot position object related world frame?",kinematics matlab visualization
9876,Connect 3S Li-Po Battery 4 ESC,"I 4 ESC Male XT60 Connector Battery 3 Male JST connectors. I want connect 4 ESC one battery. I following connectors: XT60 Male XT60 Female JST Female But connect one ESC battery. How I connect 4 ESC battery. I know last option soldering, I want avoid I CSE guy.",quadcopter battery esc connector
9882,Madgwick sensor function algorithm: two issues,"I studying popular Madgwick algorithm IMU, stumbled two issues: In magnetic distortion compensation, used following: Why assigned _2bx _bx? By formula (46) article, _bx. Is understanding correct? The raw gyro information used as: qDot1 = 0.5f * (-q1 * gx - q2 * gy - q3 * gz); qDot2 = 0.5f * (q0 * gx + q2 * gz - q3 * gy); qDot3 = 0.5f * (q0 * gy - q1 * gz + q3 * gx); qDot4 = 0.5f * (q0 * gz + q1 * gy - q2 * gx); Shall bias drift compensation done step? Assuming track bias formula (48), bias value shall applied as: gx = gx - gyro_bias_x; gy = gy - gyro_bias_y;gz = gz - gyro_bias_z; qDot1 = 0.5f * (-q1 * gx - q2 * gy - q3 * gz); qDot2 = 0.5f * (q0 * gx + q2 * gz - q3 * gy); qDot3 = 0.5f * (q0 * gy - q1 * gz + q3 * gx); qDot4 = 0.5f * (q0 * gz + q1 * gy - q2 * gx); Is understanding correct?",sensors imu calibration
9890,iRobot Create 2: Has anyone used emss iRobot Create framework control create 2?,I trouble using emss Interface connect iRobot Create 2? Can I use framework Create 2 strictly made Create 1? Sorry advance I'm new robotics field.,irobot-create software roomba
9891,How programme iRobot Create using serial USB cable?,"I trying programme iRobot Create using Serial USB cable. I connected Serial end cargo bay connector port iRobot. I using software called Realterm () send commands iRobot. I set correct Baud Rate parameters. I downloaded required driver . Inspite this, iRobot responding commands.",irobot-create
9892,Issues Running Multiple Instructions Sequence,"I tried use Microsoft Robotics Dev Studio (sample 4) write code able robot go square path one clicked. However, one problem. When I try put DriveDistanceRequest RotateDegreesRequest loop. It would execute last request. The problem Arbiter.Choice within DriveDistance activated immediately soon drive operation starts. Did anyone kind problem before? If so, I solve it? If no, I able fix problem? Thanks much. //----------------------------------------------------------------------- // This file part Microsoft Robotics Developer Studio Code Samples. // // Copyright (C) Microsoft Corporation. All rights reserved. // // $File: RoboticsTutorial4.cs $ $Revision: 22 $ //----------------------------------------------------------------------- using Microsoft.Ccr.Core; using Microsoft.Ccr.Adapters.WinForms; using Microsoft.Dss.Core; using Microsoft.Dss.Core.Attributes; using Microsoft.Dss.ServiceModel.Dssp; using Microsoft.Dss.ServiceModel.DsspServiceBase; using System; using System.Collections.Generic; using System.Security.Permissions; using xml = System.Xml; using drive = Microsoft.Robotics.Services.Drive.Proxy; using W3C.Soap; using Microsoft.Robotics.Services.RoboticsTutorial4.Properties; using Microsoft.Robotics.Services.Drive.Proxy; using System.ComponentModel; namespace Microsoft.Robotics.Services.RoboticsTutorial4 { }",mobile-robot control irobot-create mrds
9893,Computing Jacobian Matrix -- chain rule?,"I learning robot kinematics Jacobian matrix, I'm trying understand compute Jacobian matrix given kinematic chain, robot arm. I understand theory behind Jacobian matrix, I'm sure actually would calculated practice. So, let's say I 7 DoF robot arm, 7 joints 6 links joints. I know compute transformation matrix joint, applying forward kinematics, I know pose end effector configuration joint angles. To calculate this, I written code stores transformation matrix, multiplies series create transformation matrix first joint end effector. However, I go computing Jacobian matrix? My solution far, write transformation matrix hand, multiply hand, yield overall transformation matrix, respect joint angles. I could differentiate create Jacobian matrix. The problem though, maths becomes very, complicated I move along kinematic chain. By end, many terms result multiple matrix multiplications, becomes tedious hand. Is better way this? In case calculating forward kinematics, I didn't hand, I wrote code multiply individual matrices. But I want Jacobian matrix, seems like I need compute derivative overall transformation matrix computed, I need hand. What's standard solution this? Is something chain rule differentiation...? I'm sure exactly applies though... Thank you!",robotic-arm kinematics inverse-kinematics jacobian manipulator
9894,"Using Accelerometer, Gyroscope sensor track speed, position,","Problem Currently working reverse engineering application . This wearable device track users speed positional tracking object makes contact another one 3-D Rendering Currently using accelerometer gyroscope get yaw, pitch, roll(orientation) device, know use information calculate speed, device collided another object?",imu accelerometer precise-positioning
9895,Estimating displacement drone three dimensions,"Assuming drone two dimension, predict future position calculating future displacement: For real quad-rotor, estimate displacement robot three dimensions also change orientation robot, linear velocity angular velocity?",quadcopter motion-planning uav
9899,VFH+ (Vector Field Histogram+) : Is possible choose candidate sector without set goal point?,"Good day I currently implementing VFH algorithm. Is possible configure algorithm reactionary motion generated presence obstacle? I able generate obstacle map, primary polar histogram binary polar histogram. How one prioritize sector pass through? I seen implementation labview possible implement simple vector field histogram path planning without goal points",mobile-robot motion-planning mapping c++ vfh
9904,Solving Inverse Kinematics Gradient Descent,"I trying implement inverse kinematics solver robot arm. My solution standard iterative one, step, I compute Jacobian pseudo-inverse Jacobian, compute Euclidean distance end effector target, I compute next joint angles following gradient respect end effector distance. This achieves reasonable, smooth path towards solution. However, reading, I learned typically, fact multiple solutions, particularly many degrees freedom. But gradient descent solution I implemented reaches one solution. So questions follows: How I compute solutions? Can I write full forward kinematics equation, set equal desired end effector position, solve linear equations? Or better way? Is anything interest particular solution achieved using gradient descent method? For example, guaranteed solution reached fastest robot? Are cases gradient descent method fail? For example, possible could fall local minimum? Or function convex, hence single global minimum?",robotic-arm kinematics inverse-kinematics jacobian
9916,"What's difference term ""pose estimation"" ""visual odometry""?","I'm reading paper: Choi C, Trevor A J B, Christensen H I. RGB-D edge detection edge-based registration[C]//Intelligent Robots Systems (IROS), 2013 IEEE/RSJ International Conference on. IEEE, 2013: 1568-1575. refers: Visual features corners, keypoints, edges, color widely used computer vision robotic perception applications object recognition pose estimation, visual odometry, SLAM I previously assume pose estimation roughly equal visual odometry, yet text seems deny. So what's difference? I didn't find much info google. IMHO, seems pose estimation estimating pose moving object camera static, visual odometry estimating pose camera static(mostly) scene, precise enough?",slam odometry pose
9918,Tring run 12 V DC geared motor using Samsung Li Ion ICR16850 batteries,"I trying run motor. Using batteries stated title. The motor requires 12 V I supplying 11.98V motor, motor driver. After while, motor keeps slowing battery voltage drops 5-6 V, I remove battery motor driver shows 11.9V. Is battery capable enough run motors, I need new one?",motor battery
9923,Change Message Interval ArduPilot,"I using Mavlink protocol (in c++) communicate ArduPilotMega, I able read messages ATTITUDE example. I currently getting 2Hz (message rate) I would like increase it. I found I use MESSAGE_INTERVAL order change it, I probably need use command set it. So question is, I send command using mavlink c++? I tried code work, I guess I use command I mentioned I don't know how. mavlink_message_t command; mavlink_message_interval_t interval; interval.interval_us = 100000; interval.message_id = 30; mavlink_msg_message_interval_encode(255, 200, &command, &interval); p_sensorsPort->write_message(command); Update: I also tried code below, maybe I giving right system id component id. mavlink_message_t command; mavlink_command_long_t interval; interval.param1 = MAVLINK_MSG_ID_ATTITUDE; interval.param2 = 100000; interval.command = MAV_CMD_SET_MESSAGE_INTERVAL; interval.target_system = 0; interval.target_component = 0; mavlink_msg_command_long_encode(255, 0, &command, &interval); p_sensorsPort->write_message(command); Maybe I missing something difference target_system, target_component sysid, compid. I tried values nothing worked. Is ack able tell even got command?",quadcopter c++ ardupilot mavlink
9925,VFH (Vector Field Histogram+): Obtaining Primary Polar Histogram,"Good day Note: I found code works. I placed minor explanation expounded. I trouble obtaining right directional output implementation. I noticed every time I put obstacle right, gives left, gives right steering direction, problem presence left obstacle still tends steer towards obstacle. I checked occupancy map generated using matlab found correct. I couldn't pinpoint exactly wrong code I debugging almost week hoping someone see error I cannot. Here code implementation:",mobile-robot motion-planning vfh path-planning
9926,Calculate uncertainty 6-dof pose graph-based SLAM,"This question strongly related question here. I estimating 6-DOF poses $x_{i}$ trajectory using graph-based SLAM approach. The estimation based 6-DOF transformation measurements $z_{ij}$ uncertainty $\Sigma_{ij}$ connect poses. To avoid singularities I represent poses transforms 7x1 vector consisting 3D-vector unit-quaternion: $$x_{i} = \left( \begin{matrix} \\ q \end{matrix} \right)$$ The optimization yields 6x1 manifold increment vectors $$ \Delta \tilde{x}_i = \left( \begin{matrix} \\ log(q) \end{matrix} \right)$$ applied pose estimates optimization iteration: $$ x_i \leftarrow x_i \boxplus \Delta \tilde{x}_i$$ The uncertainty gets involved hessian update optimization step: $$ \tilde{H}_{[ii]} += \tilde{A}_{ij}^T \Sigma_{ij}^{-1} \tilde{A}_{ij} $$ $$ \tilde{A}_{ij} \leftarrow A_{ij} M_{i} = \frac{\partial e_{ij}(x)}{\partial x_i} \frac{\partial x_i \boxplus \Delta \tilde{x}_i}{\partial \Delta x_i} |_{\Delta \tilde{x}_i = 0}$$ $$ e_{ij} = log \left( (x_{j} \ominus x_{i}) \ominus z_{ij} \right) $$ error function measurement $z_{ij}$ estimate $\hat{z}_{ij} = x_j \ominus x_i$. Since $\tilde{A}_{ij}$ 6x6 matrix we're optimizing 6-DOF $\Sigma_{ij}$ also 6x6 matrix. Based IMU measurements acceleration $a$ rotational velocity $\omega$ one build 6x6 sensor noise matrix $$ \Sigma_{sensor} = \left( \begin{matrix} \sigma_{a}^2 & 0 \\ 0 & \sigma_{\omega}^2 \end{matrix} \right) $$ Further process model integrates acceleration twice rotational velocity obtain pose measurement. To properly model uncertainty sensor noise integration noise considered (anything else?). Thus, I want calculate uncertainty $$ \Sigma_{ij}^{t} = J_{iterate} \Sigma_{ij}^{t-1} J_{iterate}^T + J_{process} \Sigma_{sensor} J_{process}^T$$ $J_{iterate} = \frac{\partial x_{i}^{t}}{\partial x_{i}^{t-1}}$ $J_{process} = \frac{\partial x_{i}^{t}}{\partial \xi_{i}^{t}}$ current measurement $\xi{i}^{t} = [a,\omega]$. According formula $\Sigma_{ij}$ 7x7 matrix, I need 6x6 matrix instead. I think I include manifold projection somewhere, how? For details take look following publication, especially algorithm 2: G. Grisetti, R. Kümmerle, C. Stachniss, W. Burgard, “A tutorial graph-based SLAM,” IEEE Intelligent Transportation Systems Maga- zine, vol. 2, no. 4, pp. 31–43, 2010. For similar calculation uncertainty take look end section III A. in: Corominas Murtra, Andreu, Josep M. Mirats Tur. ""IMU cable encoder data fusion in-pipe mobile robot localization."" Technologies Practical Robot Applications (TePRA), 2013 IEEE International Conference on. IEEE, 2013. .. section III A. IV A. in: Ila, Viorela, Josep M. Porta, Juan Andrade-Cetto. ""Information-based compact Pose SLAM."" Robotics, IEEE Transactions 26.1 (2010): 78-93.",slam ekf jacobian
9927,graph-based SLAM optimization fails numeric error,"I implementing graph-based SLAM system works fine, i.e. converges, I assume constant covariance matrix $\Sigma_{ij}$ constraints. However, I model $\Sigma_{ij}$ realistically, i.e. increasing entries progress time (see question) fails one successful iteration, i.e. solving system applying pose increments $\Delta \tilde{x}_{ij}$ poses $x_{ij}$ first time. I use cholesky based sparse solver implementation Eigen fails numeric error. Of course, failure might occur due bug implementation. But maybe there's also problem representing math computers, e.g. overflow double representation something similar. Could anybody comment assumption, please? My implementation makes use manifolds based algorithm 2 in: G. Grisetti, R. Kümmerle, C. Stachniss, W. Burgard, “A tutorial graph-based SLAM,” IEEE Intelligent Transportation Systems Maga- zine, vol. 2, no. 4, pp. 31–43, 2010.",slam
9932,How split tasks interrupts main loop bare metal controller?,"I'm working robotics project I 3 services running. I sensor DAQ, logic ISR (motor controller 20kHz) EtherCAT slave controller. DAQ EtherCAT run idle logic runs interrupt. The logic calculations controls motor. The EtherCAT service (kinda like CANbus) runs together DAQ idle loop. I run DAQ interrupt leaves less 100ns EtherCAT service run. I'm sure whether right way especially considering scary things i've read regarding data corruption using interrupts. Does anyone nice ideas handle services? I'm running code Zynq 7020 (on ARM Cortex) it's written C++. Here example code:",c++ interrupts
9935,How find Friction Viscous force b (nmsec) DC motor,PLease guide How find Friction Viscous force b (nmsec) DC motor particlar speed. The motor connected gear ration 26:1 I want find 200 rpm motor load speed 4900rpm please guide,quadcopter wheeled-robot brushless-motor stepper-motor
9936,Path planning - Quadtree decomposition (cell decomposition),"I need solve path planning problem using cell decomposition method, precisely quadtree decomposition. I need MATLAB I would like know whether exmaple code I could make tests. I read MATLAB function I couldn't anything useful. In addition I would need decompose cells path found functionality previous function. Anyone knows could I program quadtree decomposition?",mobile-robot matlab path-planning
9937,Do stop first switching direction proper encoding readings?,"Since encoder square wave quadrature, stop first changing directions proper measurements? In words, commanding along one direction low speed like 50mm/s less want change direction -50mm/s, would first need command zero wait encoder read 0 speed, command reverse direction, order get accurate possible encoder readings?",irobot-create roomba
9941,Suggestion correct battery pack,"I trying run 2 12V Geared DC motors No-load current = 800 mA(Max), Load current = upto 9.5 A(Max). Runtime atleast 3-4 hours. The motor takes 10-12 V operation. I need proper battery pack these, I determine specs I go for?",motor battery
9946,Quadcopter: X-Y Velocity PID Controller,"Good day, Introduction I currently working autonomous quadcopter project. I currently implemented cascaded PID controller consisting two loops. The inner rate loop takes angular velocity gyroscope measurements. The outer stabilize/angle loop takes angle measurements complementary filter (gyroscope + accelerometer angles). Question: I would like ask effective cascade Lateral Velocity (X Y - axis) PID controller Angle Controller (Roll Pitch) control drift along X-Y plane. For outermost PID controller, setpoint 0 m/s measured velocities obtained integrating linear accelerations accelerometer. This controls PID controller responsible Pitch (if Y velocity PID) Roll (if X velocity PID).",quadcopter control pid raspberry-pi stability
9947,"Starting out, dissertation project using computer controlled drone","For final year Computer Science university I dissertation includes controlling drone computer communication onboard camera computer vision. The first step obtaining drone suits needs, I clue go it. Basically needed drone able communicate computer movement ""stream"" video computer analysis. So, would I go store bought drone, rasperry pi microcontroller based one etc. What I need take consideration etc? P.S. project going based indoors, I don't need crazy range, powerf",quadcopter control microcontroller computer-vision
9951,Why series elastic actuators accurate stable force control?,"The day, somebody telling robot lab, mentioned ""series elastic"" actuators. But bit Googling, I'm still sure means, unable find simple explanation. It seems something link actuator load spring-like quality it, rather vague... In case, I really interested advantages disadvantages series elastic actuators. Specifically, I read one advantages allows ""more accurate stable force control"". However, appears counter-intuitive me. I would thought link actuator load ""springy"", would lower ability accurate control force send load, force would stored dissipated spring, less directly transferred load. So: Why series elastic actuators ""more accurate stable force control""?",robotic-arm actuator dynamics torque
9953,kalman filter redundant sensors,"Suppose I one robot two 3D position sensors based different physical principles I want run Kalman filter. I construct observation matrix two represent two sensors vertically concatenating two identity matrices. $H = \begin{bmatrix} 1&0&0\\0&1&0\\0&0&1\\1&0&0\\0&1&0\\0&0&1 \end{bmatrix}$ $\hspace{20pt}$ $\overrightarrow x = \begin{bmatrix} x\\y\\z \end{bmatrix}$ $H \overrightarrow x = \begin{bmatrix} x\\y\\z\\x\\y\\z \end{bmatrix}$ represents sensors reading exact position robot. Makes sense far. The problem comes I compute innovation covariance $S_k = R + HP_{k|k-1}H^T$ Since $H H^T = \begin{bmatrix} 1 & 0 & 0 & 0 & 0 & 1 \\ 0 & 1 & 0 & 1 & 0 & 0 \\ 0 & 0 & 1 & 0 & 1 & 0 \\ 0 & 1 & 0 & 1 & 0 & 0 \\ 0 & 0 & 1 & 0 & 1 & 0 \\ 1 & 0 & 0 & 0 & 0 & 1 \\ \end{bmatrix}$ then, matter $P$ is, I'm going wind $x$ innovations first sensor correlated $z$ innovations second, seems intuitively wrong, I'm interpreting right. Proceeding here, gain matrix ($K = P_{k|k-1} H^T S_k^{-1}$) winds pretty odd stuff (swapping rows like) that, updating static system ($A = I_3, B = [0]$) constant measurement $\overrightarrow z = [1,0,0]$ I wind predicted state $\hat x = [0,0,1]$. If I separate sensors update filter measurement separately, $H H^T = I_3$, I get sensible results. I think I confused technical points one steps. Where I going wrong? Does make sense vertically concatenate observation matrices? I suppose I could set off-diagonal 3x3 blocks $S_k$ 0, since I know sensors independent, anything theory suggests incorporates step?",kalman-filter
9954,Using FRI ATICombinedDAQFT simultaneously visual studio,"I trying force control experiment KUKA LWR IV. I mini45 ATI force sensor. Our data acquisition board PCIe-6320 supported using Linux seems I use windows. One Lab guys previously tried use ""FRI"" ""ATICombinedDAQFT"" simultaneously windows hopeful. Two libraries work other. Did anybody experiment KUKA? Or least encounter problem another sensor FRI? It noteworthy force sensor ""NET box"" use ""UDP"". I bit hurry I really appreciate suggestions. Thanks.",force-sensor kuka
9955,I'm looking hands-on experience different types leg hip designs walking robots,"I'm looking find out, How human-like legs compare chicken legs four-leg systems. In terms cost, performance, speed, strength accuracy. I'm interested things like speed, agility, turning radius, complexity cost. For design large enough person ride, rider fatigue also important -- compare terms achievable ride smoothness, vibration, on? Are quantitative benefits 3 DOF hip joints, compared 2 DOF? I realize factors come play well, actuators, joint designs control systems. However, interest moment basic leg designs compare one another. Edit: I'm looking someone used mechanisms first hand.",kinematics walking-robot
9956,Need help implementing EKF based SLAM,"I started learning slam I trying simulate robot moving around set landmarks past 3 days. The landmarks known correspondences. My problem is, I add motion noise covariance matrix prediction step, robot starts behave weirdly. If I don't add motion noise prediction step, robot move around perfectly. I trying figure happening 3 days cannot find anything wrong code. I attached link github files pertaining project. In folder named 'octave' file 'prediction_step' 'correction_step' contains code prediction correction steps respectively. The ekf_slam file main loop calls two functions. My github repository also contains 3 videos correspond robot motion noise, robot motion noise another video shows robot ideally go about. Please help figuring wrong code 'prediction_step' 'correction_step'. Link github repository: please click",slam ekf
9962,Linearize non linear system,"How I linearize following system using taylor series expansion: $\dot x = v cos\theta \\ \dot = v sin\theta \\ \dot \theta = u$ Here, $\theta$ heading direction robot, measured counter clockwise respect $x$ axis. $v$ linear velocity robot, $u$ angular velocity robot.",mobile-robot localization
9963,Distance calculation two robots two obstacles,"I problem two robots two obstacles space. Each robot communicate measurements measure angles distances. The two obstacles environment identical other. Each robot see obstacles other. Therefore angle theta 1 2 combined distance 1 2. Can distance two robots calculated? So far I placed circles radius measured distance landmark (triangles workings), provides 4 possible positions robot. Red black circles correspond robot 1 blue green robot 2. Using relative size angle measurements I discount two positions per robot. This still leaves two possible positions robot shown filled hashed circles. Is possible calculate side robot landmarks distance other? Robot 1 two measurements angle distance therefore assign id obstacle, information transmitted robot 2, robot 2 know obstacle designated id 1 2.",localization kinematics
9965,How get manufactured part CAD file?,"I working book Learning Robotics using Python, Python programmers want learn robotics. Chapter 2 shows use LibreCAD design plates poles form chassis turtlebot-like robot. For instance, base plate looks like this: Then, nothing suddenly later chapter picture fully manufactured plates assembled chassis, author acts something know do: How that? We CAD drawings, suddenly plates manufactured via magical process book never discusses, never gives things like tolerances, material supposed made of, etc., kinds things discussed here: I know nothing stuff, terms go CAD design specs getting actual part manufactured. What kinds companies I use, reasonable price expect, process? In general, I go CAD design manufactured item? Do I find local machine shop specializes robotics, bring CAD drawings, work try build parts? I totally noob, I hope isn't question like this:",design software manufacturing chassis hardware
9967,How understand computed torque model controller,"For following controller $q_{des}$ $q_{act}$ stand for? Also, general principle controller? Thanks!",control microcontroller torque
9969,augmenting room magnetic field smartphone sensors,possible enhance (or redirect) earth's magnetic field room house one write small program makes smartphones hall-effect sensors detect reliably direction pointing? I presume fridge magnet won't job...,sensors hall-sensor
9971,What software use send (OI) commands Create 2. Using windows laptop supplied Create 2 cable?,"I read iRobot Create 2 Open Interface (OI). It says send serial commands Create 2 get described action, suggestion software use send serial commands USB interface. I install FTDI Drivers enable USB serial connection. Question: What serial software I use communicate Create 2? Is tool verify supplied usb serial cable supplied Create 2 functioning Create 2 functioning? (I reset Create 2 using Spot Dock buttons)",irobot-create serial
9972,Issue using Digit LEDs Raw (op code 163) Create2,"If I understand manual, leg 7 segment displays labeled letter A-G. These letters map specific bits byte - 1 byte 4 displays. Setting bit turns corresponding leg setting leaves off. With understanding, I tried turn A segments sending Instead A segment display turning on, displays showed 1. Further testing shows I send numbers 1-9 displays, display number sent. Sending number 10 greater turns various combinations segments. I able activate individual segments following numbers: 63 G 64 A 65 B 66 C 67 D 68 E 69 F However, I haven't able determine bytes sent affect individual segments. Either I don't understand manual Digit LEDs Raw work manual specifies. UPDATE 03JUNE2016 I confirmed behavior exists following firmware versions: r3-robot/tags/release-3.4.1:5858 CLEAN r3_robot/tags/release-3.2.6:4975 CLEAN",irobot-create
9978,Can much input current destroy motor driver?,"I 18 V rated driver I'm using drive two 12 V DC gear motors using Arduino. I bought new battery pack rated 3300 mAh 25C, 11.1V making total current input 82.5 A. My driver rated 7 V min 18 V max, current rating given. My motors 12V max current load 9.5 A. So sure, using battery destroy motor driver? This datasheet.",motor battery current
9985,Is algorithm using Kinect depth image (not point cloud) registration?,"I know given intrinsics (where fx, fy horizontal vertical focal length, (cx, cy) location principal point camera pinhole camera model assumed) Kinect depth camera(or range sensor?), depth pixel px=(u, v, d) ((u, v) pixel coordinate, depth value) converted 3D point p: p=(x, y, z) x=(u-cx)/fx*d y=(v-cy)/fy*d z=d depth image converted point cloud, indeed, depth Image represents unique point cloud physically. SLAM systems e.g. KinectFusion use point clouds ICP based registration obtain camera pose time fuse new point cloud previously reconstructed model. However, mentor told depth Image cannot inveribly converted point cloud since it's 2D->3D mapping ambiguity (which I disagree), claims I use depth Image time (i-1) (i) registration, derived point cloud. （If I obey mentor's order) I've reading papers found one using Gradient Descent solve camera pose (tx, ty, tz, qw, qx, qy, qz): Prisacariu V A, Reid I D. PWP3D: Real-time segmentation tracking 3D objects[J]. International journal computer vision, 2012, 98(3): 335-354. uses RGB Images known model pose estimation. However, I've NEVER found paper (e.g., KinectFusion later RGB-D SLAM algorithms) deals depth data plane image point cloud registration. So could someone give hint (papers opensource code) about: How depth image registration without converting point clouds?",localization slam kinect
9986,Need help motors high load,"I need select motors wheeled robot I'm planning build. My requirements are: robot able carry 35 kg platform size around 20 cm x 35-40 cm speed = 6 mph 3m/s planning use 4 driven wheels, increase enough. Other parameters like diameter wheels, acceleration fixed. Please help calculate required torque RPM motors. It would great provide equations. Or post lessons related problem.",motor design wheeled-robot torque
9987,How compile arm compatible binary x86 precompiled library pc host run arm target?,I using library precompiled x86 pc (x86_64). Does exist toolchain compile x86 library end generate executable armv7l ubuntu?,arm linux
9988,Instantaneous velocity calculation accelerometer?,"I trying derive velocity accelerometer (MPU9250 sensor-tag board). I saw lot blogs talk noise exact estimation problems. I started seeing velocity derivation (integration accelerometer data time) yielding towards ramp noise presence MPU9250. Is velocity estimated accelerometer need assistance another sensor GPS gyroscope, etc.. Please let know I see velocity calculations never converge all. Also I limitation compute power, Kalman filter kind estimation techniques difficult implement. Can please suggest whether I right direction not.",sensors accelerometer
9994,Why wouldn't robot stop?,"I working Arduino based robot engages braking mechanism detecting anything front. I using ultrasonic sensor, detect obstacles worked well robot table (i.e construction). But I ran ground, doesn't stops crashes. The robot programmed anything detected 50 cm ahead robot, braking mechanism stops wheels. But testing, robot wouldn't stop. My robot running average 7.5m/s . Thinking doppler's effect might rendered sensor useless, I tried little IR sensor I lying around (range 25 cm approx), didn't work well. What I wrong here?",arduino motor ultrasonic-sensors
10002,Control WMR (Wheeled Mobile Robot) 3D,I've implemented SMC (Sliding Mode Controller) WMR X-Y X-Z plane. Now want combine control WMR 3D. For purpose I'm trying use resultant vector simulation XY plane track resultant vector XZ plane value X previously designed code. Tracking control resultant vector shown figure 1 Vector sum decomposed rectangular coordinates simulation shown figure 2. Am I going wrong? What tecniques I apply 3D control vehicle using Sliding Mode Controller. Can reduce time delay offset? I've implemented right equations SMC tracking controller equations simulation gives exact results.These equations work well control vehicle two dimensions (X-Z plane).,wheeled-robot matlab simulation
10003,How go around circle?,"I mBot robot I'm trying get go side cylindral obstacle. Something like this: What I know: Radius cylinder - r Robot's distance cylinder Wheel thickness - 1.5 cm Distance middle wheel - 11.5 cm How would I achieve path? The thing I saw SO question says: The distance left right wheel robot 6 inches. So left wheel travel distance 2(pi)(radius+6) And right wheel travel distance 2(pi) (radius-6) The problem robot can't tell go 20cm right, tell turn 90 degrees right. All set motor's speed 0-255, there's way put formula disatance = time x speed. I assume I set motor's speed different value would go circle radius x exit half circle (like shown picture)",arduino wheeled-robot
10004,Solving Inverse Kinematics Non-Linear Least Squares,"I want write inverse kinematics solver, I recommended use Google's Ceres Solver help. Now, according documentation, Ceres Solver usually used non-linear least squares problems (). This minimises sum squared differences measured target values, data. What I confused about, relates inverse kinematics. In inverse kinematics, example robot arm, goal determine joint angles robot positioned in, order reach target end effector pose. There exists single equation determines end effector pose, given set joint angles, want determine parameters equation (the joint angles). But relate least-squares problem, multiple measurements? Is problem I trying solve essentially same, except number measurements one? And case, using Ceres Solver's non-linear least squares solver really necessary? Thanks!",robotic-arm inverse-kinematics
10006,Build simple robot learn ROS,I beginner ROS I wanted know I could build simple robot learn ROS. I currently following components available: Arduino Uno Simple two wheeled robot chassis Some motors L293D motor driver Some ultrasonic sensors Some infrared sensors,arduino slam ros beginner ultrasonic-sensors
10007,How produce continuous variation discontinuous function?,"I differential equation connects ""velocity"" point FOV camera velocities robot's joints, $$\dot s=J(s) \dot q$$ vector $x$,$y$ coordinates point FOV, $J$ interaction matrix $q$ vector joint positions. If I certain point whose velocity I tracking point remains FOV, $\dot s$ well defined. But I change point online, time instant $t$ I point $s_t$ time instant $t+dt$ I point $s_{t+dt}$, $\dot s$ defined. Can I create filter produce continuous variation $\dot s$? If not, I do? More specifically, I want perform occlusion avoidance. In order I want compute minimum distance feature point target object possibly occluding object. But, obviously, distance discontinuous due fact another possibly occluding object appear FOV nearer target previously measured.",cameras visual-servoing filter
10011,Stabilising inverted pendulum,"With problem stabilising inverted pendulum cart, it's clear cart needs move toward side pendulum leans. But given angle $\theta$, much cart move, fast? Is theory determining distance speed cart trial error? I've seen quite videos inverted pendulum, it's clear distance speed determined.",mobile-robot sensors accelerometer gyroscope
10014,Design robotics world,"Apologies isn't really right place asking, I wondering whether third party design firms ever contracted design industrial consumer robots? If something usually done house, within org would usually take care process? Thanks.",design
10018,What sensor equation odometry Kalman Filter?,"I would like use Extended Kalman Filter localization wheeled robot. With filter I would like sensor fusion 2 encoder sensors IMU gyro accelero sensors. The method I find odometry data blend filter, add input [uk] system xk = f(xk-1,uk). I would like add odometry data normal measurement data (so zk vector). But I need measurement equations g(xt). This I had: Nkleft = ((T*n0)/(2*pi*r))sqrt(xv²+yv²)+((Tn0*b)/(2*pi*r))tauv + n Nkright = ((Tn0)/(2*pi*r))sqrt(xv²+yv²)-((Tn0*b)/(2*pi*r))*tauv + n with: Nkleft/Nkright = number odometry pulses sample period T = sample time n0 = total pulses one wheelspeed sensor r = wheel radius xv = speed x-direction yv = speed y-direction tauv = angular velocity n = sensor noise But I test implementation, I don't get results I expect, I think something wrong equations. Does anyone know example odometry inserted sensor measurement, system equation?",kalman-filter odometry
10019,Should I use gyro encoders robot moving straight line?,"I've recently succeeded building first collision-avoidance Arduino robot 2 DC motors, works pretty well. However, doesn't move straight line yet, should. I'm studying method I implement make robot go straight. I've heard using IMU encoders feedback control. I pretty much understand use encoders, I'm sure gyro. Should I use one combination them?",mobile-robot arduino control gyroscope
10023,What realistic grasping simulator?,"I looking physics simulator accurately model robot hand picking object. The main requirement accuracy / realism, rather speed. It needs able model soft bodies, rubber ""skin"" robotic finger tips. It also needs dynamics engine, object actually moved around hand, modelling effects slippage. From research I already done, two good candidates. First, GraspIt! (). This open-source, specifically designed grasping, rather physics simulation general. Second, MuJoCo (). This general simulator, commercial product, adopted big names DeepMind. I tried using Bullet physics engine robot grasping simulation, soon realised going strong enough, Bullet really designed games, hence sacrifices realism speed. However, I'm much interested something realistic possible, even computation slow. Does anyone suggestions I proceed? Anybody experience GraspIt! MuJoCo? Thanks!",robotic-arm simulator simulation
10026,"Raspberry pi 3 location set field, gps","I'm developing project involves raspberry pi 3 remote control rover I need know exact location raspberry pi rover set field. Let's say I four logs, one corner square field (the goal right extend shape field, number corners), every equipped (some kind wave technology) allows triangulate position (based signal intensity) raspberry pi rover. The distance logs bigger 30m (~100feet) line sight guaranted. The question is: Which kind technology I use, infrared, wifi, bluetooth, radio, ultrasound, etc? or, better approach problem?",wireless
10029,Damping vs Friction,"I using physics simulator simulate robot arm. For revolute joint arm, two parameters need specified: damping, friction. If torque applied joint, damping friction seem reduce resultant force torque. But difference damping friction?",robotic-arm dynamics
10033,"First build - Quadcopter , need help deciding hardware connections","I building first drone, Objective: - Need control drone wifi phone laptop using ground station software Openpilot I Arduino 2560 , cc3d Openpilot flight controller , raspberry pi wifi bluetooth built... Now able understand , go forward , connect arduino openpilot cc3d flight controller , raspberry pi directory cc3d flight controller .... Do really need arduino 2560 ? also connect r pi cc3d flight controller , mock PWM signals ?",quadcopter arduino raspberry-pi
10034,S-curve motion profile: discontinuous acceleration profile multipoint trajectory,"I trying implement s-curve motion profile reduce effects jerk mobile robot. I succeeded calculating equations trajectory case point-to-point trajectory. My problem case multipoint trajectory. First I introduce robot start position stop position initial speed, max speed, max acceleration max jerk. Then, running, I introduce new stop position I re-calculate equations trajectory. When I generated trajectory, I found acceleration profile becomes null suddenly. What I fixe problem?",mobile-robot
10035,Handling 4WD robot frame 2 wheel differential drive,"I 'Baron' robot frame 4 static wheels, driven motor. At moment I'm thinking handling like 2 wheel differential drive. Left right wheels would receive signal. Actually interpret tank caterpillars, exept link two tires. Does anyone different idea this? Ps: The purpose robot know it's exact location. I use kalman filter (EKF) sensor fusion odometry IMU accelero, gyro magnetometer. So kalman filter I add odometry model differential drive robot.",differential-drive
10040,Rotate 3d vector value single axis using rotation quaternion,I want rotate whole value 3d vector one axis using quaternion rotations. The reason behind I want align X Y Axis smartphone X Y Axis vehicle order detect lateral longitudinal acceleration separated two axis. Therefore I want detect first straight acceleration car rotate whole acceleration value heading axis (X-Axis) phone assuming straight forward motion. How I achieve this?,sensors accelerometer rotation
10045,What information IMU gives drone?,"An Inertial Measurement Unit (IMU) important sensor used aerial robotics. A typical IMU contain accelerometer rate gyroscope. Which following information robot get IMU? Position Orientation Linear velocity Angular velocity Linear acceleration Angular acceleration I don't think gets orientation information IMU. The last time I took test, I said first two true. I failed.",imu
10048,Double/Triple inverted pendulum always cart?,All examples keeping double/triple inverted pendulum balanced using PID controller I've seen seem cart. Like one How come PID controller always controls cart rather servo holds first pendulum? The second/third pendulum could connected loosely first pendulum PID controller controls first pendulum. Is servos tend slow reasons?,motor mechanism servos
10049,Question sampling proposal distribution gmapping algorithm,"I'm trying reimplement gmapping algorithm (which based paper Grisetti et al. 2007) purposes therefore would like understand detail algorithm default parameter values people use. To understanding, gmapping uses proposal distribution particle whose moments determined sampling around scan-matching estimate. My questions are: How many samples $K$ standard gmapping implementation use estimate mean covariance proposal distribution? The samples $\{x_k\}_{k=1}^K$ drawn $x_k \sim \{x_j|x_j - \hat{x}^{(i)}| < \Delta\}$, $\hat{x}^{(i)}$ scan-matching estimate particle $i$. How $\Delta$ determined? How much parameter matter? I couldn't find values used neither paper implementation gmapping openslam.org. Any pointers regarding practical significance parameters highly appreciated!",slam particle-filter
10050,What Simultaneous Localization And Mapping (SLAM) software do?,"I took course better understanding drones design. At end course test question I got wrong I would like understand why. I supposed select choices best describe SLAM. possible answers were: Estimates location features environment? Controls robot's flight environment? Causes robot avoid obstacles environment? Navigate cluttered environment? Estimates position orientation robot respect environment? At first I knew least 3 4 right I watched drone things. I also thought last answer linked two I said yes too. Finally, I thought thing still controlled user would flight... Yet I failed again... Therefore Simultaneous Localization And Mapping (SLAM) software do?",slam
10052,Position Control vs Velocity Control vs Torque Control,"Please somebody explain difference Position Control, Velocity Control, Torque Control? Specifically, I thinking terms robot arm. I understand position control tries control position actuators, error signal difference current position desired position. Velocity control trying control velocity actuator, torque control trying control torque actuator. However, I don't understand thing. If want send robot arm certain position, could use position control. But order move actuator certain position, need give velocity. And order give velocity, need give torque. Therefore, whether error position, velocity, torque, always seems come back error torque. What I missing?",control kinematics dynamics roboti-arm
10053,Load pre-built occupancy map Gazebo,"I built occupancy map using gmapping package ROS (real) hallway. Now I want use map Gazebo I simulate robot environment. It seems Gazebo support map built models, external occupancy map. Is way I use occupancy map Gazebo simulators? It easier obtain occupancy map real world building physical world simulator...",mapping gazebo occupancygrid
10056,Choice motor robotic arm,"This first post here, hello all. I really hope I learn lot guys. I trying build robotic arm carry object put inside different boxes placed different fixed locations. I found robotic arms it, I still trying find right motor job. I read lot on-line different motors, I sure pick. Since boxes located fixed places, motors move precise way, so, according research, Servo motors ones I use. Since low budget project (I college student), I wasn't sure motor choose (there lot servo motors there). I found several Servo motors on-line, example , Analog Feedback Servo, I wondering best servo motor I buy really low cost project? I think I spend 10-20$ per motor (I need 5 motors). I already Rpi I know pin 18 PWM pin controls motor's precision movement, I purchase PWM controller additional motors I need run testing find precise motor is. By way, I calculate amount weight motor handle? Any ideas information greatly appreciated. Thank",robotic-arm raspberry-pi servomotor python
10059,In many ways six propellers drone fly rotate?,"I thought twelve ways: Six ways two propellers Six others rotation ways. But according Vijay Kumar Dean Penn Engineering , seems I wrong... Then I read article modeling robust trajectory tracking control novel Six-Rotor Unmanned Aerial Vehicle one navigation autonomous control Hexacopter indoor environments never able find information. I guessed 3 rotors could go one direction three others another would add 6 ways rotating therefore 6 others simply flying guess.",multi-rotor
10060,Motor Choice given size constraint load requirement,Good day everyone :) I undergraduate student working project involving use high torque small-sized DC motors use designing person following trolley bag. Where problem use small sized motors still maintain usability efficiency carrying loaded luggages. I looking motors local stores well RS components well Element 14. However I sure choices right fit I loss specifications look selecting particular motor application. I also tried look motors used current products used application todays electric skate boards unfortunately luck finding suppliers. Basically question I would like ask specifications calculations I perform select proper motors given size constraints weight carrying requirments. Or anyone suggestions common motors already normally used application. My target maximum load capacity 20kg. Thank you!,mobile-robot motor gearing
10063,Rostock Delta Robot 3D Printer Degrees Freedom (DOF),What degrees freedom (DOF) Rostock delta robot 3d printer (delta mechanism consists three prismatic joints)? Here's link delta mechanism I'm referring to: . Thanks advance help!,kinematics inverse-kinematics actuator manipulator 3d-printing
10070,Tracked robots dimensioning,I'm designing tank tracked robot. I would like know calculate minimum height difference sprocket wheel axis boogie wheel axis( maximum height obstacle 16 cm)?,design mechanism tracks
10072,How make robot?,"For instance, would hook electric pump communicate motherboard? Let's say I buy electric pump, I hook sort metal structure pump turned moves metal structure, would I hook pump motherboard I program it?",control motor robotic-arm microcontroller machine-learning
10076,problem vex updating,Hi I problem vex robot updating system. Right I using VEX IQ Firmare Update mac states everything date. However I look online new update out. I use radios controller I can't update brain.,vex
10077,How industrial robotics components purchased?,"For hobbyists, go store buy products. The prices products clearly listed store catalog, easily search parts lowest price read customer reviews products. For industrial engineers building complex machines, buy components? Or don't worry cost, leave employer eat cost part line work? Is possible ""shop around"" low-cost engineering components? It unclear someone building robot small one-man startup make step world toy robots, larger industrial robotic components. Most non-hobbyist stuff hidden away exposed world. While product catalog might available, prices listed anything. For larger industrial components, seem realistic way shop around lowest price best value, since pricing much big stuff basically unavailable. For personally, I interested trying build powered exoskeleton middle class American income, I can't afford paying 1000 bucks single electrohydraulic proportioning servo valve, I'll need probably 50 them. But shopping around low cost ones basically impossible far I determine, pricing info generally available searchable majority manufacturers.",industrial-robot
10087,Task space joint motion space conversion,"I moment trying read understand paper Task Constrained Motion Planning Robot Joint Space seem hard time understanding math. The paper describes perform task constrained motion planning cases frame constrained specific task. problem paper tackles sampling joint space, randomized planners typically produce samples lie outside constraint manifold. method proposed methods use specified motion constrain vector formulate distance metric task space project samples within tolerance distance constrain. Given I seem bit confused simple terms define paper. Examples. How task space coordinate defined ? information have? compute $$\Delta x = T_e^t(q_s)$$ transformation matrix end effector respect task frame. What I don't get end effector? end effector respect task frame? Secondly. Later paper write expression relates task space joint space motion. They using Jacobian, seem miss explaining (in opinion) $E(q_s)$ actually do. $$J(q_s) = E(q_s)J^t(q_s)$$ What said paper Given configuration $q_s$, instantaneous velocities linear relationship $E(q_s)$ need instaneous? definition instantaneous component? differ information given jacobian? Basically don't understand mapping is?..",robotic-arm motion-planning jacobian
10088,Send Quad copter control signals Arduino Raspberry PI receiver Open pilot CC3d,"I open Pilot CC3D attached receiver accept signals RC transmitter configuration GCS .. Objective - Send control signals ( YAW/THROTTLE/ROLL/PITCH ) R Pi Arduino ( whichever best transmit signals) using simple Radio transmitter , like 433 mhz TX, I want use USB based Game controller , connected Raspberry PI transmit signals radio receiver... Is feasible need scrapped...",quadcopter arduino raspberry-pi radio-control
10089,Locking yaw direction laser pointer,"I laser pointer handle grip I'm trying keep laser pointer's yaw direction, rotate around 10deg/s. So I laser pointer stepper motor accelerometer/gyro handle, what's good way maintaining yaw direction? Could I simply turn shaft according accelerometer/gyro's yaw readings control theory (PID) needed? That is, stepper makes 4096 steps/rev, one gives 0.0879 deg. If handle turned by, say, 0.879 deg, turn 10 steps reverse (instantaneously). Would jerky PID needed? Any thought appreciated.",sensors stability
10092,Arduino Raspberry Pi?,"I want make object tracking quadcopter project. While I'm using Arduino Mega 2560 flight controller, I thinking using additional offboard microcontroller/board getting data onboard camera,which would send appropriate command onboard Arduino. I hoping someone could provide clarification advantages/disadvantages object tracking either choice. Thanks!",quadcopter arduino raspberry-pi
10096,"How I charge 11,1 volt LiPo akku?","I didn't found modules charge 11,1 volt LiPo akku, 3,7 volt 5 volt power supply. How I handle micro-USB connector robotplatform?",arduino power lithium-polymer
10098,Storing 3D map,I trying build 3D map using two cameras. I found coordinates objects. What best way store data.I would also like display map later. My range 5-6 meters(500-600 cms). The accuracy I managed achieve within 1 cm. I used openCV python laptop.I would like shift Raspberry Pi later Pi perform well enough. My main issue store 3D Map.,cameras mapping 3d-reconstruction opencv
10099,Hubsan x4 drone camera recording black,"I'm unsure correct community ask question (vs StackExchange Electronics Aviation, example), I recently purchased Hubsan x4 HD video drone Amazon. This second Hubsan drone I already familiar using recording feature. However, every recording, recordings correct length, correct audio, image black. I tried formatting micro SD, using different micro SDs, reading forums, etc. nothing seems trick. Is mine defective, someone issue able solve it? Thanks",quadcopter cameras
10101,Ultrasonic Sensor column,"I trying measure height water inside column. The column 50mm dia 304mm long. I mounted sensor column. To measure accuracy sensor, I filled column known value (a) got average sensor reading (b). a+b give height sensor base column. Repeating different values a, I got different values (a+b). see attached chart. My question Is sensor expected error order? Is setup confining sensor column producing errors. Any ideas get water column height. Please note actual test, water inside oscillating (up down).I thinking making capacitive sensor using aluminium foil. Water work dielectric level water determine capacitance. P.S. I also open tests (not column) get distance fixed object, quite accurate. Any help appreciated. Arduino Code",arduino ultrasonic-sensors
10103,Is way combine sync two 2K cameras @ 90fps ICs,I searching way minimize size stereo vision module cannot find ICs combine sync two MIPI CSI-2 (4 lane) data streams without FPGA much code. one online (MAX7366A 3D Video Combiner/Synchronizer two MIPI CSI-2 Input one MIPI CSI-2 output) product publicly available. Does anyone knowledge arrangement ICs I could try?.,computer-vision
10106,How use opcode start?,"I new robotics.Recently came contact code.So teacher let use Serial port app Android enter opcode.But robot reaction. I use Communications Cable Adapter android phone. App Use [DroidTerm: USB Serial port] Serial Port Settings Baud: 115200 (19200 also used) Data bits: 8 Parity: None Stop bits: 1 Flow control: None I try enter opcode, response.--> enter:128,135,134..... But show reaction phone robot. I hope according Opcode instructions control robots make specified action.",irobot-create
10110,Visualizing raw accelerometer gyro data,"I arduino wired MPU6050 breakout board. The arduino continuously collects accelerometer gyroscope data MPU6050 calculates angle velocity. Simply plotting vector components (x,y,z) data allow one reason motion sensor robot. It's possible, though easy, sanity checks (Is sensor oriented expected? Is gravity working?). But it's difficult look x,y,z plot accelerometer log data imagine robot instance. I wondering sort tool Python library visualise accelerometer gyro, IMU data? (I'm looking something like this- )",arduino accelerometer gyroscope visualization
10115,SLAM - odometry motion model,"I making project 4 wheeled differential robot make visual SLAM using stereo rig. I encoders measure de displacement steering angle robot I want use odometry motion model fastSLAM algorithm. To use odometry motion model need calculate values needs odometry reading (incremental encoders), $u_t=(\bar{x}_{t-1},\bar{x_t})$ $\bar{x}_{t-1}=(\bar{x}\>\bar{y}\>\bar{\theta})$ $\bar{x}_t=(\bar{x}'\>\bar{y}'\>\bar{\theta}')$ previous current pose extracted odometry vehicle. My question obtain values encoders. I guess case I would need obtain equations geometric model differential robot: $D_L=\frac{2\cdot\pi \cdot R_L}{N_c}\cdot N_L$ $D_R=\frac{2\cdot\pi \cdot R_R}{N_c}\cdot N_R$ $D_T=\frac{D_L+D_R}{2}$ $\Delta\theta=\frac{D_L-D_R}{L}$ $D_L$ advance left wheel, $D_R$ advance right wheel, $R_L$ lecture left encoder, $R_R$ lecture right encoder, $N_C$ total number pulses encoder type, $D$ total distance achieved robot $\theta$ angle steered. $L$ distance wheels. Using equations possible obtain pose every time step: $\bar{x}_{t}=\bar{x}_{t-1}+D\cos(\theta_{t-1})$ $\bar{y}_{t}=\bar{y}_{t-1}+D\sin(\theta_{t-1})$ $\bar{\theta}_{t}=\bar{\theta}_{t-1}+\Delta\theta$ So last values I need inject modometry motion model add gaussian noise them. Am I right? Or another way computing pose odometry differential 4-wheel robot?",mobile-robot slam odometry movement
10117,How preprogram iRobot Create 2,I want program set path iRobot follow without tethered time computer. What best way that?,programming-languages
10118,How decide torque motor gearbox ratio robotic arm?,"How decide torque motor gearbox ratio (say 6 DOF) robotic arm, 5 kg payload capacity instance. I mainly concerned inertial mismatch. How I calculate it? Are factors I consider?",motor robotic-arm torque manipulator
10119,How create model temperature control?,"I heated compartment, inside which, another object heated independent heater. I want control temperatures chamber object. I could achieve simple PID (or PI) controllers chamber object, I would like try thoughtful approach :) I two temperature sensors, two PWM outputs heaters. How I identify model object I want control?",control pid automation
10125,What kind torque needed small 5-6 axis robotic arm?,"I'm new robotics I'm looking make 5-6 axis robotic arm stepper motors I honestly dont know much torque I part. Below I described detail current plan I'm really sure much I really spending joints. My general plan project make arm fully extended would around 40-50(max) cm long. It would consisted light weight aluminum I hoping weigh couple pounds done. Anyway current list actuators joints: (Bottom = 1, Top = 6) 1st Joint, (I cant actually post link I don't enough rep, called amazon: Nema 23 CNC Stepper Motor 2.8A) 2nd 3rd Joints 4th, 5th 6th Joints My real questions is, overkill enough I'm really trying make. I really don't need able pick lot weight, 1 2 kilos I highly doubt I ever picking anything that. Anyway I wanted see sufficient enough project... I know isn't really best place ask I really need help I new I don't want throw money I don't need to. Thanks advanced ;)",robotic-arm stepper-motor actuator
10127,PID position velocity goal?,"I'm trying design control system robot tracks moving object. Thus I want robot match position velocity state object. I don't want robot simply arrive position, I want arrive position velocity object. Object velocity position data provided externally. I'm sure traditional PID controller (with velocity controls) position based error enough. Wouldn't position state goal result tracking always lagging behind? Is PID I want I looking something else like trajectory controls?",pid
10129,Disable MAVLINK Heartbeat Using Telemetry,"I using APM 2.6 connected Odroid USB via Telemetry port (UART USB). I trying get MAVLINK messages without need keep sending HEARTBEAT message. If I switch USB connection (not telemetry) I get MAVLINK messages continuously without sending HEARTBEAT messages APM. I want able using Telemetry port. Is place firmware (ArduCopter) code I change? Or maybe parameter? I using 57600 Baud-Rate, I tried also 115200. And USB cable connected.",quadcopter ardupilot mavlink
10130,Detect physical touch/hit,"I'm making target outdoor robot competition. The target detect robot got touched got hit automatically. target get hit 360 degree. I'm searching perfect sensor detect hit, without get false positive wind. My option right are: 1- ultrasonic sensor (bad coverage) 2- tilt sensor (bad FP rate) 3- wooden conductive I would like know someone ideas (that affordable - less 30$ dollar per target might o.k) Edit: target static, waiting robot touch it. Edit: The specs are: 1- The target dimension 1 meter height, 0.5 meter width , 0.3 depth. 2- To trigger target ,the robot around 10 centimeter long point target surface. 3-To trigger target robot needs get close 10 centimeter even press around 1 Newton force. robot might even throw object satisfy previous condition. 4-Detection must intentional touch. 5-Wooden conductive trigger human Electrically conductive. might option throw object. 6- Target placed outdoor, sensor need wind-resistance (not extreme wind condition- around 20-25 km/h) 7- I prefer sensor detect touch (more proximity)because might make solution cheap reliable(in factor amount sensors estimate). Thanks. Guy",arduino sensors force-sensor
10132,What best way plug 3 stepper motors Arduino Uno board?,"I'm developing 5 axis robotic arm stepper motors I getting around ordering parts. I plan using 5 EasyDriver shields drive motors. I also planning using basic arduino uno board go it. So questions: Is alternative instead buying ton Easy Drivers connecting single board? And isn't, would setup look use 3 stepper motors? This useful picture I found, however It shows 3 I know I could plug 4th I unsure whether I could plug 5th.",stepper-motor
10136,iRobot Create2: Granularity drive control?,"I iRobot create2 I planning implement control algorithm. After playing different drive commands, I noticed changing desired velocity values marginally doesn't seem anything. Even Drive PWM command ranges -255 255 seems internal granularity bigger 1. In video create seems change driving direction nearly seamlessly, I able reproduce described behavior. Does anyone suggestions?",control motor irobot-create
10148,What's new drone technology?,"In recent years, we've heard lot drones. What new technology enabling new devices? Why making news? When I kid, used call things (similar call drones) remote control RC. But, apparently it's nomenclature change new FCC regulations, commercial applications like Amazon Prime Air, news military applications I still see RC labeled devices stores. So, this, new drone stuff about? And now? What new technology recently emerged enables devices?",untagged
10150,How ODE determine contact points Gazebo?,"I looking contact points Atlas DRCsim package. Each foot 4 contact points vertex rectangle. I'd like know points determined. I've tried looking ODE code, C++ isn't strong suit I difficulty figuring going on. What I understand ODE compares geometries one one however it's possible compare points compare select points. What I'm trying understand basis particular points selected? Why Atlas 4 contacts set way are, additional points heel? Can I add myself? Thanks.",gazebo
10153,APM 2.6 response REQUEST_DATA_STREAM,"I trying get mavlink messages APM 2.6 via telemetry connected Ordoid U3 USB port. I able read messages I send REQUEST_DATA_STREAM message, sends once, I want able get continuously without needing send request again. Any ways solve this?",quadcopter communication ardupilot mavlink
10154,Bldc motors erratic behavior Arduino program,"I've making quadcopter flight controller using Arduino Mega. This sample code I wrote order test esc timers motors: However, issue bldc motors i'm using don't work smoothly connected Arduino. They erratically stop even change direction rotation throttle input. I've tested connecting directly transmitter work fine perfect rotation speed. Can someone please help tell I might going wrong? EDIT: I realize posting entire Arduino code might overkill, I've trying solve problem three days (as 22nd June,16) I really hope someone point improvements/corrections code.",quadcopter arduino brushless-motor esc
10159,iCreate 2 Arduino (Just getting going),"I new iRobot Create 2 I know thing two Arduino (don't assume much though). However, case, I beyond stumped I sure something simple somehow obvious me. Three people confirmed wiring Create 2 Arduino correct code I looks similar many examples I seen forum. However, I cannot get Create 2 ANYTHING. I sure wrong I starting wonder robot even receiving commands let alone anything them. Is anything wrong code anybody suggest way verify robot receiving data (since beep provide return messages)? Thank you. EDIT (06/24 01:10 EST); Updated code (with notes).",arduino irobot-create
10167,Getting I2C sensor output Ardupilot Arduino,"I trying get airspeed ArduPlane Erle Brain 2 ( Ardupilot) I2C port, send Arduino. What I discovered: There already exists I2C_driver.cpp, I use send data, using functions Arduplane.cpp. However, I lost implement sending part, I use functions? The functions like write accept arguments address, length, data. How I know that? And I send data binary? Any help really appreciated! Thanks!",arduino ardupilot i2c
10169,What prerequisites learning ROS?,"It helpful robotics first learn ""Linux kernel development"" ""device driver development Linux"" I start learning ROS? I know C JAVA! In brief, I want know prerequisites essential understand ROS better.",ros linux
10172,Covering Up Ultrasonic Sensor,"I'm using basic trig/echo Ultrasonic Sensor Arduino Uno. I get accurate readings I cover sensor point I receive large numbers. Why this? Program Example Output I moved hand 10"" away I cover sensor 10.20 distance: // hand 10"" away sensor 10.01 distance: 9.51 distance: 8.71 distance: 7.85 distance: 6.90 distance: 5.20 distance: 4.76 distance: 3.44 distance: 2.97 distance: 1.65 distance: 1211.92 distance: // hand pressed sensor 1225.39 distance: 1197.16 distance: 1207.43 distance: 1212.66 distance: 1204.60 distance: EDIT I changed amounts inches milimeters get precise reading. I held sensor ~100mm granite counter-top quickly lowered tabletop covered front sensor. distance: 103.27 // 100mm tabletop distance: 96.50 distance: 79.84 distance: 76.72 distance: 62.66 distance: 65.78 distance: 54.85 distance: 47.04 distance: 44.95 distance: 38.71 distance: 28.81 distance: 25.69 distance: 27.08 distance: 25.17 distance: 27.77 distance: 22.04 // sensor continues toward table values start increase would logically decrease ?? distance: 23.95 distance: 26.73 distance: 28.81 distance: 46.52 distance: 2292.85 // sensor flush tabletop distance: 2579.59 distance: 2608.75 distance: 2595.56 distance: 2591.57 distance: 2583.75 distance: 2569.87 distance: 2570.91 distance: 2600.07 distance: 30579.64 // extreme high & low values sensor place tabletop distance: 37.66 distance: 30444.43 distance: 37.66 distance: 30674.23 distance: 38.71",arduino ultrasonic-sensors
10178,Switch activated microcontroller,I'm working project I'm using voltage higher microcontrollers handle. I'm looking kind switch connect power source electromagnet controlled microcontroller. I also thought using potentiometer control speed two high voltage DC motors via microcontroller please tell good idea aswell. Thanks time Zakary,arduino microcontroller
10187,Proper naming PID regulators,"I wondering either special naming regulators that: Outputs unit inputs, ie. velocity [m/s] input velocity output [m/s]. Outputs unit different inputs, ie. position input [m], velocity output [/m/s] I would appreciate help.",pid
10190,Can robot mechanical part programmed exert specific force,So I thinking projectiles don't need propellant like gunpowder I've seen coils gun that's little way. I wondering I know force required propel object could I program robot exert force propel object way (in linear propelled fashion).,force-sensor
10192,Create2 incremental encoder rollover method,"I never yet Create2's incremental encoder rollover want write code prepared happen test it. When encoder rolls past 32767 (14.5m), rollover -32768 count start 0 count there? One odd thing big deal. When I reset Create2, first value 1 0.",irobot-create roomba
10193,What LIADAR alternative indoor RC CAr,"I new robotics working autonomous RC car indoor purpose only. I wondering I detect expected collision (I planning put dummy cars near RC car). Please guide alternative one worked similar project. reference:What low cost alternatives lidar? Thanks, Sandy",mobile-robot
10195,Starting out: Arduino vs Raspberry Pi drone,"For dissertation project, I use drone. What look object closed space. What I deffinately need are: A camera Sensors avoid collision PC communication: stream video receive directions (the pc control drone, give directions etc) Now I'm wondering would best platform build considering requirements I absolutely idea what's going microcontroller world. So I don't know two shields whatnot would suitable needs.",quadcopter arduino raspberry-pi
10196,Using Quaternions feed quadcopter PID stabilizing controller avoid Gimbal lock,"I trying control F450 dji quadcopter using PID controller. From IMU, I getting quaternions, I convert Euler's angles, causing Gimbal lock issue. However, way I directly use quaternions generate control commands without converting Euler's angle? This conversation discusses similar issue without mentioning clear answer problem. The three errors far I trying drive 0 are: Master generates desired rotation Slave IMU. UPDATE: Here pieces code: Getting current reference quaternions bot Master Slave ROTATION_VECTOR: /** Master's current quaternion */ double x = measurements.get(1); double = measurements.get(2); double z = measurements.get(3); double w = measurements.get(4); /** Slave's current quaternion */ double xS = measurements.get(5); double yS = measurements.get(6); double zS = measurements.get(7); double wS = measurements.get(8); /** Master's Reference quaternion */ double x0 = measurements.get(9); double y0 = measurements.get(10); double z0 = measurements.get(11); double w0 = measurements.get(12); /** Slave's Reference quaternion. * If code initialized yet, save current quaternion * slave slave's reference orientation. The orientation * slave henceforth computed relative initial * orientation. */ (!initialized) { x0S = xS; y0S = yS; z0S = zS; w0S = wS; initialized = true; } Then I want know orientation current quaternion relative reference quaternion Master Slave. /** * Compute orientation current quaternion relative * reference quaternion, relative quaternion given * quaternion product: q0 * conj(q) * * (w0 + x0*i + y0*j + z0*k) * (w - x*i - y*j - z*k). * * <pre> * See: * * </pre> */ // For Master double wr = w * w0 + x * x0 + * y0 + z * z0; double xr = w * x0 - x * w0 + * z0 - z * y0; double yr = w * y0 - x * z0 - * w0 + z * x0; double zr = w * z0 + x * y0 - * x0 - z * w0; // For Slave double wrS = wS * w0S + xS * x0S + yS * y0S + zS * z0S; double xrS = wS * x0S - xS * w0S + yS * z0S - zS * y0S; double yrS = wS * y0S - xS * z0S - yS * w0S + zS * x0S; double zrS = wS * z0S + xS * y0S - yS * x0S - zS * w0S; Finally, I calculate Euler angles: /** * Compute roll pitch adopting Tait–Bryan angles. z-y'-x"" sequence. * * <pre> * See * * </pre> */ double rollMaster = Math.atan2(2 * (wr * xr + yr * zr), 1 - 2 * (xr * xr + yr * yr)); double pitchMaster = Math.asin( 2 * (wr * yr - zr * xr)); double yawMaster = Math.atan2(2 * (wr * zr + xr * yr), 1 - 2 * (yr * yr + zr * zr)); I thing Slave. At beginning, reference quaternion equal current quaternion Slave Master, thus, relative roll, pitch yaw zeros, not!",quadcopter pid stability
10200,Create 2 Reading Sensor Values,"I trying solve Create 2 sensor reading problem I I came across @NBCKLY's posts (Part 1 Part 2) I believe exactly I looking for. I copied code original post project updated code second post best I could interpret...but something going according plan. For example, I printing angle serial monitor (for now) I constantly getting value 0 (sometimes 1). Can @NBCKLY anybody please check code tell I'm wrong? I would appreciate it. Thank much. # What I asking I get angle rotation 0 1 degrees robot moving circle. The angle incrementing robot moving. The output I getting serial monitor shows line looks like garble I assume supposed bytes sent back Create followed ""Angle: 0 (or 1)"" What I expecting see increasing angle value. (1,2,3...360, on).",arduino sensors irobot-create
10202,"The 3 key components robot controller, servo, reducer. Can someone give us ""official"" explanation respectively?","I've googled lot wasn't able find official definitions 3 parts. Maybe explanations servo controller good enough, I'm still trying look ""official"" one. Any ideas? Thanks, snakeninny",microcontroller servos
10210,Is right way motor mixing PID outputs quadcopter?,These motor mixing formulas I've written quadcopter's flight controller (Arduino-Mega) I wondering right use three (roll-pitch-yaw) esc's signals.,quadcopter arduino pid esc
10213,Triangulation calibrated stereo rig,"I using stereo rig SLAM, calibrated using MATLAB Calibration Tool. I need compute 2D coordinates landmark using observation model obtained triangulation (the images rectified). The equations obtained triangulation ones presented blue box here. Because I SLAM 2D coordinates I need use $Z_p$ $X_p$. The parameters needed compute values $f$, $T$ $disparity (x_L - x_R)$. After calibration intrinsics matrices $K_L$ $K_R$ obtained common intrinsic matrix stereo rig calculated $K = 1/2*(K_L +K_R)$ I get parameters needed triangulation common matrix. The focal length supplied manufacturer, Logitech C170 2.3mm. The baseline $T$ calibration 78.7803 mm. To compute disparity I obtaining SURF points using RANSAC discard outliers I get x coordinates rectified images. The problem values I can't obtain correct values $Z_p$ $X_p$ I sure I wrong step. Anyone help this? Are correct steps triangulation rectified stereo images? EDIT: My stereo rig looks like figure I attach: If compare coordinates system one used link easy see $X_r$ corresponds $Z_p$ link $Y_r$ corresponds $X_p$, equations calculate distance using triangulation coordinate system figure are: $x_r=\frac{fb}{x_L-x_R}$ $y_r = \frac{(x_L-p_x)b}{x_L-x_R}-\frac{b}{2}$ Being $f$ focal length, $b$ baseline, $p_x$ x coordinate central point $x_L-x_R$ disparity. The $X_r$ $Y_r$ coordinate system situated two cameras, meaning $\frac{b}{2}$ displacement equations. Calibration To obtain cameras calibration I using Stereo Camera Calibrator Toolbox chessboard pattern. After calibration, I made tests using MATLAB functions triangulate reconstructScene know whether parameteres well calculated. The distances I obtained using functions (which use stereoParams object created calibrator) works well I obtain distances similar actual ones. So I suposse calibration works well. The problem, I explained before, I try calculate distances using equations $x_r$ $y_r$ I sure obtain common matrix $K$ stereo rig (the calibrator gives one intrinsic matrix camera, two matrices). The value baseline given calibration make sense, I made measurement ruler gives 78 mm approximately. The $f$ value I assume pixels calibration gives $f_x$ $f_y$ value I sure one I use. Those intrinsic matrices I obtain: Left: $\begin{pmatrix} 672.6879&-0.7752&282.2488\\0&674.3705&240.1287\\0&0&1 \end{pmatrix}$ Right: $\begin{pmatrix} 681.7049&0.0451&331.2612\\0&681.8235&246.1209\\0&0&1\end{pmatrix}$ Being parameters $K$: $\begin{pmatrix}f_x&s&p_x\\0&f_y&p_y\\0&0&1\end{pmatrix}$",mobile-robot slam computer-vision stereo-vision
10215,Piezo sensors multiplexers,"I got asked make sort trigger pads foot section organ working midi electric piano friend wants pressure sensitive program note velocity he's using organ sound. That I try achive. I want pads on/off also able control velocity midi note. Im planning use Adruino Uno MUX Shield II Mayhew Labs get 36 analog inputs. Not exactly sure wiring yet looked guides videos google get feel made. All 36 piezo-""sensors"" planned register hard push pedals send MIDI signal specific note correspondig pedal, velocity electric piano control low notes feet. Just like pedals lot cheaper. Will Arduino able read analog output piezo sensor even though it's going multiplexer?",control electronics
10220,Quadcopter carry heavy things?,"So, I drinking couple friends, one us said something like 'man, wouldn't cool beer came us?' got thinking. We seen crazy things people quadcopters (or polycopters even), would possible (and expensive) build quadcopter could carry, say, crate beer? (16-20kg) I'm bit tinkerer I've built minor things rasp. pi's never tried quadcopter, quite big piece work, able fly crate beer right front would pretty awesome. That aside, strong would quadcopter be? In terms motors, propellers, battery & frame. I'm complete noob comes RPM like, I wouldn't even know begin. I have, course, read available tutorials internet, don't answer question exactly look I want quadcopter able carry something specific.",quadcopter raspberry-pi
10221,Should I use EKF Baro-Acc altitude estimation?,"I've recently implemented kalman filter estimate altitude small robot IMU+Baro sensor mounted it. My objective get max precision I have, using two sensor, small computing power MCU provide me. I've tuned filter seems work pretty well. Can I obtain significant improvement using Extended Kalman Filter instead normal Kalman Filter worth time implement it? More detail, since request specific application, Model function use Baro Accel states linearized used EKF improve data reliability compared simply KF?",kalman-filter accelerometer ekf
10224,landmark extraction algorithm,"Hi Landmark used SLAM , Algorithme used Extract , robot diferentiate landmark , detecte one point A Xt another Xt+1 robot know Its ? Sorry bad english :/",slam ekf lidar ransac
10227,Are others alternatives PID controllers line following robots?,Are better/ advanced ways steering line following robot pid controller? If them?,pid line-following steering
10229,How select dc motors line following robot?,What criteria consider ordering dc motors line following robot? Is way calculate torque required?,motor line-following
10233,"Generate synthetic accelerometer data based (x,y,z) coordinate","I would like create simulation model (basically signal generator) allow generate 3 output signals accelerometer based 3 location input signals (x,y z). I would like realistic model data produced accelerometer (with noise bias offsets). How I convert series points simulated accelerometer output? Specifically: I series positions describe trajectory 3D space...If accelerometer moving along trajectory described series positions, I interested knowing (simulating!) data accelerometer would produce result moving along described trajectory. I could calculate 2nd derivative trajectory, would probably ideal. I looking model realistic.",accelerometer simulation
10237,What internal sparking motor mean?,"My Arduino + Raspberry Pi robot working fine morning. I tested it, ran perfectly, I switched off. Now evening I'm trying run again, batteries everything, doesn't move! I stripped motor compartment found I try run main motor, I see sparks translucent plastic back. Does mean motor gone?",arduino motor raspberry-pi battery
10239,What pitfalls ultrasonic sensor?,"I'm using HC-SR04 sensor detect obstacles. What pitfalls ultrasonic sensor? Here couple I've found testing: The signal bounce one wall another get picked up, distorting latency Absorbent materials sometimes don't bounce signal back Check datasheet supported range (min/max)",ultrasonic-sensors
10241,CC3D PWM control signal characteristic (to simulated Raspberry PI),"My goal control drone Raspberry PI. The Raspberry PI uses camera OpenCV, sends control commands AVR microcontroller generate PWM control signal. Meaning simulate pilot transmitter-receiver setup. In words (to make clear). Raspberry tells Atmega8 drone needs go forward. Atmega8 generates custom PWM signals 8 pins. Those signals sent directly CC3D pins responsible roll, pitch etc. Atmega8 replaces controller receiver setup. It generates signal based user input Raspberry tells it. In order I need parameters (period, voltage etc.) PWM signal CC3D accepts properly simulate it. I found topic: CC3D - Replacing RC emitter RPi He problem I found solution. Unfortunately I can't send pm I can't comment I'm new site... basically way contact him. So help would appreciated.",quadcopter arduino raspberry-pi uav avr
10247,Doosan lynx 220 find inputs outputs,"I want add robot machine Doosan lynx 220 lsy. For I need inputs output: INPUTS: Cycle start, Chuck1 open, Chuck1 close, Chuck2 open, Chuck3 close OUTPUTS: Cycle finished, Check chuck1 opend, Check chuck1 closed, Check chuck2 opend, Check chuck2 closed I already found book found inputs outputs justs says example Cycle start (SB373). I cant find number i/o board anywhere else. Can someone help find listed outputs?",cnc
10248,Compass sensor robot,"What's appropriate compass sensor use robot? There ton cheap digital compass sensors, I thinking using MPU9250 combined accel/gyro/magnetometer compass, I'm finding terribly unreliable need constant calibration via ""wave figure 8 pattern"" method whenever gets near electronics small magnets, robot obviously won't able do. Is digital compass technology mimics traditional compasses requires little calibration, appropriate installation robot?",magnetometer compass
10249,Fence avoidance manually controlled robot,"I'm trying find known techniques keeping manually controlled robot within known polygon fence. More specifically, pilot controls robot issuing desired velocity vectors, autopilot adjusts velocity distance boundary always least stopping distance robot. My goal implement system that: Tries follow pilot's desired velocity closely possible. Is robust changes position desired velocity. At minimum, I want velocity change continuously respect position robot desired velocity pilot. Informally, means sufficiently small changes position desired velocity pilot induce arbitrarily small changes velocity. The second point particularly important. Suppose policy find intersection boundary direction desired velocity slow smoothly point. The figure depicts couple scenarios would continuous. In figure, black lines represent fence boundary, red dot position robot, blue line desired velocity pilot. In figure (a), small perturbation position left cause large increase allowed velocity desired velocity intersect far edge instead near edge. In figure (b), small clockwise rotation velocity vector result large decrease allowed velocity desired velocity intersect near edge instead far edge. I searched relevant papers, papers I've seen dealt fully autonomous obstacle avoidance. Moreover, I haven't seen papers address robustness/continuity system. :EDIT: The robot knows location location boundary times. I also equations maximum velocity allow smooth ramp-down single line boundary (though I'd interested seeing better one). I would like velocity limits continuous position desired velocity pilot. I want continuously throttle user's input minimum safe distance robot boundary maintained, see figure I added question. The hard part (I think) make sure small changes position (e.g. due sensor noise) small changes desired velocity (e.g. due pilot noise) don't cause huge changes autopilot allows. I want continuity I think provide much nicer experience pilot still enforcing fence boundary. There trade-off optimally I think worth it. Even though physical world smoothes discontinuities velocity, big changes could still cause large jerk somewhat disturbing pilot. The goal autopilot introduce large oscillations intended pilot. This Will implemented On physical system sensors provide estimation position, boundary shape known unchanging. The actual system I'm targeting quadcopter.",control geometry reference-request
10252,Obstacle Avoidance Navigating,"I need ideas strategies algorithms apply strategies perform obstacle avoidance navigating. At moment I'm offline path planning obstacle avoidance known obstacles occupancy grid. And running A* algorithm created matrix. After robot follows along resulting trajectory. This done splitting whole trajectory sub-path. The robot adjust it's heading new target follows straight line. The robot controlled fuzzy logic controller correct deviations ideal line (steering) adjusting velocity according steering action distance target. So far good. And it's working well. As sensor system, I solely use Google Project Tango (Motion Tracking Area Learning proper path following). Now I want use depth perception capability device. Getting appropriate depth information extracting possible obstacle done quite simple strategy. The robot analyses depth information front robot object robot target point sub-path, obstacle must there. Now I'm wondering bypass obstacle efficiently. The robot aware height width obstacle, clue depth (only front obstacle scanned). Feeding occupancy grid new obstacle running A* algorithm effective, missing depth. One possible strategy I could imagine estimating depth length grid cell, re-plan continue navigation. If robot faces obstacle again, depth increased size one additional grid cell length. But I think extremely ineffective. The requirement use Google Project Tango additional sensors, ultrasonic sense sides. Update 1 The first picture illustrates given trajectory path planning (orange). The gray blue data points sensed obstacles front robot. The notch behind blue obstacle actually wall, shadowed blue obstacle. Image 2 shows scene different perspective. The issue I treat is, optimally bypass blue obstacle even I don't know deep is. Driving left right capture better data points (to generate 3D model) possible. Update 2 Yes, I'm using depth sensor, one integrated Google Project Tango. It's visual measurement. A infra-red laser beams grid onto objects RGB-IR camera capture information evaluates appropriate depth information.",control motion-planning algorithm
10253,Steering using different speeds DC motors using servo?,"I trying assess pros cons steering robot car using different speeds 2 DC motors versus using servo steering mechanism? From experience better terms of: Steering accuracy (e.g. prompt responsiveness skidding higher speeds) Efficiency electrical power consumption Durability maintenance Control complexity (coding electronics) I researched understood approaches work, I need practical insight select suitable approach. Any hint research direction appreciated.",motor servos steering
10256,Dynamic torque simulation 6 DOF robotic arm,"I working 6 DOF robotic arm(industrial manipulator). I basic structural specs (dimensions, weights etc) links joints me. Basically, I want simulate static torque(Due weight arm) dynamic torque(due accelerating joint's motion) Torque joints need bear given set motions. I looked web found tools like ROS-MoveIt Visualiser, Gazebo, V-REP let visually see robotic arm simulate position logic external factors like collisions etc. But I unable simulate/calculate dynamic torque values tools. Ideally, I'd want define fixed motion end effector(i.e. move robot 2 positions) measure Torque(both static dynamic) particular move. These torque values essential selecting optimum motors gearboxes design payload.",robotic-arm dynamics torque simulation manipulator
10259,Find object using distance,"I'm working extremely simple robot (very first project) attempts find source Bluetooth signal. There two motors drive platform encoder. We've already used Kalman filter calculate approximate distance Bluetooth beacon within reasonable error. I worked manual solution using trig solves problem theory, fails error (For example, attempts turn 73 degrees, turns 60). My question I reasonably drive motors based encoder data continuously minimize distance signal? Furthermore, generic solution problems like these? (I guess might call stochastic ""Hotter/Colder"" problem) Thanks Advance.",raspberry-pi wheeled-robot
10265,How QuadCopter Startup work ? Will tune every copter releasing market?,"We know quadcopter needs tuned perfect PID values minimise pitch, roll , yaw errors etc., Before releasing market tune every unit ship ? Or different algorithm used doesn’t require tuning ? Because every motor/ESC chassis exactly same, add noise.",quadcopter
10267,Path planning 2 arm 4dof Robot,"I working path planning 2 arm 4dof (2 dof arm) robot. I currently using centralised planning methodology (considering multi robot system single one higher dof, 4 case) A* algorithm find shortest path. The problem algorithm high computation time.Is way reduce computation time still obtaining shortest route ? Note:decentralised path planning good enough case.",robotic-arm motion-planning path-planning
10272,Stereo Vision Using Compute Module: Pi camera synchronization,"Good day, I currently working obstacle avoiding UAV using stereo vision obtain depth maps. I noticed quadcopter would sometimes steer correct direction. I using Raspberry Pi Compute Module IO board comes two CSI ports used two v1 Pi Cameras. Issue I soon found due latency cameras, left right images sync thus errors depth map result. Steps taken: I noticed image blur moving cameras around I adjusted shutter speed setting UV4l/raspicam driver. With shutter speed, I also tried increase framerate I've read, improves latency issue. In code uses opencv library, I used grab() retrieve() commands replace read() command frames cameras grabbed nearest time possible however didn't help much. Does anyone know possible solutions?",computer-vision stereo-vision c++ opencv
10277,What thread/screw size iRobot Create 2 internal screw bosses described Open Interface Spec doc,"In “iRobot_Roomba_600_Open_Interface_Spec.pdf” provided iRobot Create 2, section titled “Roomba Internal Screw Boss Locations”. It states “Screws may replaced threaded standoffs.” Does anyone know screw/thread size standoffs used match screw threads? (I saw another similar thread solution listed re-thread holes, I would like avoid possible.) Thanks!",irobot-create
10284,Mounting gimbal BLDC motor,"I'm trying build motorised camera gimbal using BLDC like this, shaft hollow. Does anyone know camera platform mounted? Should shaft somehow pressed hole? Any thought appreciated.",brushless-motor
10285,Using six wire stepper motor l298n,using l298n IC (not driver shield) arduino. I would like know use IC arduino run six wire stepper motor. Apparently new electronics.Can detailed explaination wiring IC connections breadboard arduino. Thanks,stepper-motor
10286,Question motor use opening window,"first off, transparent, I'm total newbie comes DC motors (and pretty much anything robotic). I've got couch that's right window lever type openings (anderson windows). With couch, I clearance turn lever open it. Given I've replaced house switches/outlets home automatable ones, I figured I'd see I build small motor I automate open also. To absolutely honest, I've got clue start. I problem coding automation part, I don't even know kind motors look would able turn knob (or rather actuate thing knob connects to)... Help! Thanks :)",motor
10294,Lidar problems multi-robot setup,"Consider multiple mobile bases driving around area. In order get meaningful data lidar base, sensors mounted horizontal possible. Due safety regulations, lidars also mounted height 15 cm floor. When I checked data sheet SICK lidars, shows models use wavelength 904 nm. Does mean mobile bases equipped lidars coplanar scan lines end mutually blinding other? If case, problem solved? (I don't consider tilting lidars solution defeats purpose ""2D"" lidars even tilting angle known, lidar observes becomes dependent robot's pose distance eventual obstacles)",sensors lidar rangefinder
10295,CompressedImage Image node,"Update Hey I following subscriber Nvidia TX1 board running agricultural robot. following issue subscribing Sensor_msgs::Compressed: And callback function void imageCallback(const sensor_msgs::CompressedImageConstPtr& msg) When I compile I get error: /home/johann/catkin_ws/src/uncompressimage/src/publisher_uncompressed_images.cpp:1: /usr/include/boost/function/function_template.hpp: In instantiation ‘static void boost::detail::function::function_void_mem_invoker1<MemberPtr, R, T0>::invoke(boost::detail::function::function_buffer&, T0) [with MemberPtr = void (ImageConverter::*)(const boost::shared_ptr<const sensor_msgs::CompressedImage_<std::allocator<void> > >&); R = void; T0 = const boost::shared_ptr<const sensor_msgs::Image_<std::allocator<void> > >&]’: /usr/include/boost/function/function_template.hpp:934:38: required ‘void boost::function1<R, T1>::assign_to(Functor) [with Functor = void (ImageConverter::*)(const boost::shared_ptr<const sensor_msgs::CompressedImage_<std::allocator<void> > >&); R = void; T0 = const boost::shared_ptr<const sensor_msgs::Image_<std::allocator<void> > >&]’ /usr/include/boost/function/function_template.hpp:722:7: required ‘boost::function1<R, T1>::function1(Functor, typename boost::enable_if_c<boost::type_traits::ice_not<boost::is_integral<Functor>::value>::value, int>::type) [with Functor = void (ImageConverter::*)(const boost::shared_ptr<const sensor_msgs::CompressedImage_<std::allocator<void> > >&); R = void; T0 = const boost::shared_ptr<const sensor_msgs::Image_<std::allocator<void> > >&; typename boost::enable_if_c<boost::type_traits::ice_not<boost::is_integral<Functor>::value>::value, int>::type = int]’ /usr/include/boost/function/function_template.hpp:1069:16: required ‘boost::function<R(T0)>::function(Functor, typename boost::enable_if_c<boost::type_traits::ice_not<boost::is_integral<Functor>::value>::value, int>::type) [with Functor = void (ImageConverter::*)(const boost::shared_ptr<const sensor_msgs::CompressedImage_<std::allocator<void> > >&); R = void; T0 = const boost::shared_ptr<const sensor_msgs::Image_<std::allocator<void> > >&; typename boost::enable_if_c<boost::type_traits::ice_not<boost::is_integral<Functor>::value>::value, int>::type = int]’ /home/johann/catkin_ws/src/uncompressimage/src/publisher_uncompressed_images.cpp:27:126: required The red error statement was: /usr/include/boost/function/function_template.hpp:225:11: error: match call ‘(boost::_mfi::mf1<void, ImageConverter, const boost::shared_ptr<const sensor_msgs::CompressedImage_<std::allocator<void> > >&>) (const boost::shared_ptr<const sensor_msgs::Image_<std::allocator<void> > >&)’ BOOST_FUNCTION_RETURN(boost::mem_fn(*f)(BOOST_FUNCTION_ARGS)); I using BOOST, searching around hasn't helped solve",ros c++ opencv
10296,RVIZ Transform error Base_link Camera_link,I working differential drive robot two motor wheels encoders caster wheels. The robot also intel realsense depth camera. When I launch RVIZ : Thee Global option > Fixed frame set Base_link shows transforms differential driver nodes. But error appears Depth camera nodes message saying : No transform Camera_depth_frame baselink No transform Camera_depth_optical_frame baselink No transform Camera_link baselink No transform Camera_rgb_frame baselink If I change Global option > fixed frame Camera_link I see transforms depth camera differential drive transforms available Hope help.,ros
10297,12 volt input 5 volt ouput Arduino,I accidentally ended supplying 12 v Arduino 5v output pin instead Vin pin. Does mean I can't use 5v output pin anymore i.e. fried?,arduino
10301,books suggest beginner like ?,studying bacholar dental surgery intrest learning subjet tell good book read.,mobile-robot
10312,Difference 3D Camera(using IR projection) Stereo Camera?,"I currently busy final year project requires track people walking doorway. I initially thought may possible using normal camera using motion detection functions given OpenCV, I however come conclusion camera mounted low work effectively.(Height shown image below) I looking using 3D camera stereo camera try get around problem. I seen similar examples Kinect(from Xbox 360) used generate depth map processed used tracking, however done higher vantage point, I found minimum operating range Kinect 0.5m. From I found, Kinect uses IR projector receiver generate depth map, looking Orbbec Astra S uses similar system minimum working distance 0.3m. My question now: What exactly would difference depth maps produced 3D camera uses IR projector receiver, stereo camera DUO/ZED type options? I looking insight people may used types cameras On side note, going right way? looking Time Flight Cameras instead? ----EDIT----: My goal count people moving train doorway. I began using OpenCV, initially background subtraction blob detection method. This worked one person time test video filmed higher vantage point ""blob-merging"" problem encountered shown left image below. So next method tested involved optical flow method using motion vectors obtained OpenCV's dense optical flow algorithm. From able obtain motion vectors higher test videos track shown middle image below, densely packed easily detected motion vectors simple cluster them. But system attempted footage taken inside train lower height, unable give consistant output. My thoughts reasons low height camera, single camera tracking able function sufficient space camera top person. But distance minimized, area frame moving person takes becomes larger larger, space person compared reduced (or atleast I understand it). Below right see image color persons clothing almost uniform, Optical flow therefore unable detect motion cases. I started working computer vision months ago please forgive I missed crucial aspects. From seen research, commercial systems make used 3D cameras, stereo cameras Time-of-Flight cameras, I unsure specifics would best suited application.",computer-vision cameras stereo-vision
10314,OpenRAVE output torques simulation timestep,"I'm using OpenRAVE simulate quadruped, order get idea torque requirements. To get started I made single DOF, single link pendulum test controllers etc on. I've whipped inverse dynamics based PD controller using ComputeInverseDynamics(), I set outputs using SetDOFTorques(). I set desired position, desired velocity zero. This appears work well I start simulation, pendulum driving desired position settling. My concern value output torques. My pendulum modeled simple box length 1, mass manually set 1, COM 0.5. When I run simulation, I output gravity component ComputeInverseDynamics(). This gives 4.9NM, matches hand calculated torques I expect pendulum (eg static case) driven desired position (from horizontal). But output torques SetDOFTorques() much higher vary depending I set simulation timestep to. If I maintain controller update rate 0.001 seconds, simulation update 0.0001 seconds, output torque approximately 87NM. If I alter simulation timestep 0.0005 seconds, keeping controller rate output torques drop 18NM. As experiment I removed inverse dynamics controller replaced plain PD controller, I still see large output torques. Can anyone shed light this? It's possible I'm missing something here! Thanks much Edits: I'm adding main section code. There trajectory generation, really. I'm trying get fixed static position. In code, I keep dt fixed, alter env.StartSimulation(timestep=0.0001), I get issues popping up. Here data dt = 0.001 env.StartSimulation(timestep=0.0001) In data, taus torque command simulation, torquegravity+torquecoriolis returned inverse dynamics a_cmd controller command M*a_cmd command multiplied mass matrix The gravity coriolis parts appear correct steady state, 4.9NM taus, torquegravity+torquecoriolis, a_cmd, M*a_cmd 3464.88331508, 0.48809828, 5329.83879509, 3464.39521681 330.67177959, 1.47549936, 506.45581573, 329.19628023 -785.91806527, 2.45531014, -1212.88211601, -788.37337541 -1065.4689484, 3.23603844, -1644.16151823, -1068.70498685 -1027.47479809, 3.80261774, -1586.58063974, -1031.27741583 -877.83110127, 4.18635604, -1356.94993433, -882.01745731 -707.25108627, 4.4371714, -1094.9050118, -711.68825767 -554.34483533, 4.6006198, -859.91608481, -558.94545512 -432.22314217, 4.70818921, -672.20204828, -436.93133138 -327.797496, 4.7768792, -511.65288492, -332.5743752 -240.77203429, 4.82021019, -377.83422228, -245.59224448 -172.18942128, 4.84807059, -272.3653721, -177.03749186 -117.58895761, 4.86591166, -188.39210657, -122.45486927 -74.51920719, 4.87743369, -122.14867828, -79.39664088 -39.91183436, 4.88473444, -68.91779816, -44.7965688 -12.82321495, 4.88971433, -27.25066043, -17.71292928 8.45349476, 4.89281357, 5.47797105, 3.56068118 25.35468725, 4.89489884, 31.47659755, 20.45978841 38.84080509, 4.896309, 52.22230167, 33.94449609 48.72668147, 4.89724689, 67.42989936, 43.82943458 56.78552877, 4.89790152, 79.82711885, 51.88762725 65.515892, 4.89836756, 93.25772991, 60.61752444 68.81359264, 4.89867903, 98.33063633, 63.91491362 73.86961896, 4.89891052, 106.10878221, 68.97070844 76.67416578, 4.89907489, 110.42321674, 71.77509088 79.62549808, 4.89919702, 114.96354008, 74.72630105 85.17343708, 4.89928669, 123.49869291, 80.27415039 85.13686188, 4.89934963, 123.44232654, 80.23751225 85.75675034, 4.89939931, 124.39592466, 80.85735103 86.55192592, 4.89943807, 125.61921208, 81.65248785 86.39672231, 4.89946802, 125.38039121, 81.49725429 87.4299925, 4.89949202, 126.97000073, 82.53050048 87.42776523, 4.8995098, 126.96654682, 82.52825543 87.15472709, 4.8995251, 126.54646461, 82.255202 86.97240783, 4.89953825, 126.26595319, 82.07286958 86.98023044, 4.89954905, 126.27797137, 82.08068139 86.75364661, 4.89955809, 125.92936696, 81.85408852 86.9853716, 4.89956526, 126.28585591, 82.08580634 88.01679721, 4.89957062, 127.8726563, 83.1172266 89.2610231, 4.89957348, 129.78684557, 84.36144962 88.47969399, 4.89957495, 128.58479851, 83.58011903 88.77623594, 4.89957711, 129.04101359, 83.87665884 90.87280518, 4.89957739, 132.2665043, 85.9732278 88.9513552, 4.89957707, 129.3104279, 84.05177813 89.14100099, 4.89957773, 129.60218964, 84.24142327 And data dt = 0.001 env.StartSimulation(timestep=0.0005) taus, torquegravity+torquecoriolis, a_cmd, M*a_cmd -313.62240349, 0.98927261, -484.01796324, -314.61167611 -242.03525463, 2.00886997, -375.45249938, -244.0441246 -199.82226305, 2.79259699, -311.71516928, -202.61486003 -190.02605484, 3.39367572, -297.56881625, -193.41973056 -162.08293067, 3.8525617, -255.28537288, -165.93549237 -125.84847045, 4.17559368, -200.03702174, -130.02406413 -103.89936813, 4.40068949, -166.61547326, -108.30005762 -82.32305905, 4.5566127, -133.66103347, -86.87967175 -64.56801352, 4.66415211, -106.51102404, -69.23216563 -49.68124446, 4.73812107, -83.72210081, -54.41936553 -37.91265825, 4.78890663, -65.6947152, -42.70156488 -27.99189838, 4.82374208, -50.48560071, -32.81564046 -19.81225948, 4.84762415, -37.9382825, -24.65988362 -12.55978349, 4.8636252, -26.80524414, -17.42340869 -6.89165107, 4.87470983, -18.10209369, -11.7663609 -3.13313345, 4.88256746, -12.33184754, -8.0157009 0.69831646, 4.88796162, -6.44560793, -4.18964516 3.86277859, 4.89166745, -1.58290594, -1.02888886 6.12163439, 4.8941598, 1.88842245, 1.22747459 8.58189707, 4.89593332, 5.67071346, 3.68596375 9.1580546, 4.89712981, 6.55526891, 4.26092479 11.81854706, 4.89798468, 10.64701905, 6.92056238 12.40540565, 4.89856409, 11.54898701, 7.50684156 14.04109075, 4.89897979, 14.06478609, 9.14211096 14.39924399, 4.89926951, 14.61534535, 9.49997448 14.98060951, 4.89947252, 15.50944153, 10.08113699 16.08890875, 4.89961544, 17.2142974, 11.18929331 16.01955973, 4.89971637, 17.10745133, 11.11984337 17.06493791, 4.89978831, 18.71561478, 12.16514961 17.35364328, 4.89983976, 19.15969772, 12.45380352 17.62239334, 4.89987688, 19.57310225, 12.72251646 17.84455913, 4.89990387, 19.91485424, 12.94465525 17.43825648, 4.89992362, 19.28974286, 12.53833286 17.58436934, 4.89993826, 19.51450935, 12.68443108 17.70571012, 4.8999492, 19.70117065, 12.80576093 18.40852272, 4.89995746, 20.78240808, 13.50856525 18.49492461, 4.89996372, 20.91532445, 13.59496089 18.56575802, 4.89996852, 21.02429154, 13.6657895 18.62430693, 4.89997223, 21.11436108, 13.7243347 16.54216482, 4.89997511, 17.91106109, 11.64218971 18.71146936, 4.89997747, 21.24844907, 13.81149189 18.13316504, 4.89997923, 20.35874741, 13.23318581 18.77330006, 4.89998067, 21.34356829, 13.87331939 Despite differences torque command (a_cmd) I still get similar performance, arm drives right position fairly quickly. As another experiment I set initial position pi/2 fed back gravity term torque output. My understanding arm float, ala gravity compensation sort thing. But drops small torque applied. Thanks again!",robotic-arm torque
10322,possible get possible solutions inverse kinematics 6 DOF arm?,I would like know way get possible solutions inverse kinematics 6 DOF robotic arm? I found good Matlab codes gives one solution like Peter corke's book . Thank advance.,inverse-kinematics
10324,When first time robot killed human?,"Scott Adams, creator Dilbert, recently shared article robot police used kill suspect detonating bomb close range. This made wonder -- first time robot took human life? Good comments made leads clarify I mean pureposeful taking life. I shy away term ""murder"" involves legal concepts, I mean intentional killing. An interesting subdivision would robots active human direction (""remote control"") degree autonomy.",mobile-robot
10325,Is horsepower related torque electric motors?,"Is torque related size power electric motors? And gas motors too? I go kart 2.5hp it's 50cc 1ft x 2ft x 1ft size. I also see online .21 cubic inch gas motors R/C cars also 2.5hp, difference R/C motor spins 32k rpm go-kart motor spins 12k rpm. If I put gear reduction R/C motor, would preform less go kart motor? Why size difference? Same electric motors. I buy RC car electric motor that's 10hp size pop can. The CNC machine work 10hp motor size 5 gal bucket. Again, difference RPM. If I reduce setups spun RPM, would preform same? The reasons I could think 1. Cooling 2. RPM control (For PID loops sensors)",motor power torque engine
10326,SLAM iRobot Create 2,I iRobot Create 2 working gotten point I control via Bluetooth. This great I also want able autonomous navigate room room example. Are SLAM iRobot tutorials materials you'd recommend autonomous navigation?,mobile-robot slam irobot-create
10330,Localising robot placed unknown position known environment,"I third-year electrical engineering student working intelligent autonomous robot summer vacations. The robot I trying make supposed used rescue operations. The information I would know position person (the coordinates person JSON file) rescued building fire. I would also know rooms building map, I don't know robot may placed inside building start rescue operation. That means I localise robot placed unknown position known environment, robot plan path person rescued. But, since domain I would like guide best method localising given I use IMU ( gyro, accelerometer, magnetometer) ultrasonic sensors localising job. I cannot use GPS module camera purpose. I, however, know path planning. As far research Internet concerned I found method called ""Kalman filtering"" maybe localising job. But I think filtering methods well. Which one I use? Or simpler/better method I don't know yet? I also attaching map building known me. Edit: The terrain flat, I would like know robot map like coordinate 0,4 etc.",mobile-robot localization imu accelerometer gyroscope
10334,Autonomous Navigation without Distance Sensors,I'm project iRobot Create 2. I want able map room navigate point example. My problem robot doesn't distance sensors. What detect obstacle ahead (0 1) measure far traveled millimeters. Any good techniques best buy IR sensor?,mobile-robot irobot-create
10335,Typical laser scanner noise values,"I building application executes graphSLAM using datasets recorded simulated environment. The dataset produced MRPT using GridMapNavSimul application. To simulate laserScans one issue bearing range error standard deviation range finder. Currently I using dataset recorded range_noise = 0.30m, bearing_noise = 0.15deg. Am I exaggerating values? Could somebody provide typical values quantities? Do laser scanner manufacturers provide values? Thanks advance,",slam laser rangefinder
10348,quaternion implementation,"I trying implement quaternions using CC2650 sensortag board TI. This board MPU9250 invensense Digital Motion Processor (DMP) it. This DMP gives quaternion, understanding implemented quaternion. I used Gyroscope acceleorometer values coming DMP (which calibrated ) calculate angle rotation. I feed angle, 3 directions (x,y,z), quaternion. I able match quaternion values DMP quaternion values. In fact it's way off, wondering I done wrong. Following detailed steps : 1) Tapped Gyro sensor values function “read_from_mpl”. 2) Converted gyro values float diving 2^16. As gyro values Q16 format. 3) Now used Gyro values 3 axis found resultant using formula : Gr = sqrt(Gx^2+Gy^2+Gz^2) Where Gx,Gy Gz Gyro values along x-axis,y-axis z-axis respectively. 4) Now Angle derived using found resultant Gr : *Angle = Gr*1/sample_rate* Where sample_rate found using API call ,mpu_get_sample_rate(&sample_rate) 5) This Angle fed angle_to_quater function basically converts angle axis quaternion multiplication. 6) I also added angle calculations accelerometer follows : Here also accelerometer converted float dividing 2^16, acceleorometer values also Q16 format. *//acc_data[0]->Ax, acc_data[1]->Ay, acc_data[2]->Az temp = (acc_data[0]*acc_data[0]) + (acc_data[1]*acc_data[1]); acc_angle[0]=atan2(acc_data[2],temp)*RAD_TO_DEG; temp = (acc_data[1]*acc_data[1]) + (acc_data[2]*acc_data[2]); acc_angle[1]=atan2(acc_data[0],temp)*RAD_TO_DEG; temp = (acc_data[1]*acc_data[1]) + (acc_data[0]*acc_data[0]); acc_angle[2]=atan2(acc_data[1],temp)*RAD_TO_DEG;* *Find resultant angle also : inst_acc_angle = (sqrt(acc_angle[0]*acc_angle[0] + acc_angle[1]*acc_angle[1] + acc_angle[2]*acc_angle[2]));* 7) Then complimentary filter : *FinalAngle = 0.96*Angle + 0.04*inst_acc_angle; This Final Angle fed step 5 get quaternion.* Quaternion multiplication done normailized get new quaternion (q). quater_mul : q3.w = -q1.x * q2.x - q1.y * q2.y - q1.z * q2.z + q1.w * q2.w; q3.x = q1.x * q2.w + q1.y * q2.z - q1.z * q2.y + q1.w * q2.x; q3.y = -q1.x * q2.z + q1.y * q2.w + q1.z * q2.x + q1.w * q2.y; q3.z = q1.x * q2.y - q1.y * q2.x + q1.z * q2.w + q1.w * q2.z; quat_normalize: double mag = pow(q->w,2) + pow(q->x,2) + pow(q->y,2) + pow(q->z,2); mag = sqrt(mag); q->w = q->w/mag; q->x = q->x/mag; q->y = q->y/mag; q->z = q->z/mag; When check quaternion values DMP, WAY off. Can please provide insights could wrong here. Source code : acc_data[0]=data[0]/65536.0; acc_data[1]=data[1]/65536.0; acc_data[2]=data[2]/65536.0; double temp = (acc_data[0]*acc_data[0]) + (acc_data[1]*acc_data[1]); acc_angle[0]=atan2(acc_data[2],temp)*RAD_TO_DEG; temp = (acc_data[1]*acc_data[1]) + (acc_data[2]*acc_data[2]); acc_angle[1]=atan2(acc_data[0],temp)*RAD_TO_DEG; temp = (acc_data[1]*acc_data[1]) + (acc_data[0]*acc_data[0]); acc_angle[2]=atan2(acc_data[1],temp)*RAD_TO_DEG;* gyro_rate_data[0]=data[0]/65536.0; gyro_rate_data[1]=data[1]/65536.0; gyro_rate_data[2]=data[2]/65536.0; float inst_angle = (sqrt(gyro_rate_data[0]*gyro_rate_data[0] + gyro_rate_data[1]*gyro_rate_data[1] + gyro_rate_data[2]*gyro_rate_data[2])); gyro_rate_data[0] = gyro_rate_data[0]/inst_angle; gyro_rate_data[1] = gyro_rate_data[1]/inst_angle; gyro_rate_data[2] = gyro_rate_data[2]/inst_angle; inst_angle = inst_angle *1.0/sam_rate; float inst_acc_angle = (sqrt(acc_angle[0]*acc_angle[0] + acc_angle[1]*acc_angle[1] + acc_angle[2]*acc_angle[2])); inst_angle = WT*inst_angle + (1.0-WT)*inst_acc_angle; angle_to_quat(inst_angle,gyro_rate_data,&q); /* The function angle quaterinion multiplication,normalization */ void angle_to_quat(float Angle,float *gyro_axis,struct quat *qt) { struct quat temp; struct quat res; temp.w = cos((Angle*1.0/RAD_TO_DEG)/2); temp.x = sin((Angle*1.0/RAD_TO_DEG)/2); temp.y = sin((Angle*1.0/RAD_TO_DEG)/2); temp.z = sin((Angle*1.0/RAD_TO_DEG)/2); temp.x = temp.x *gyro_axis[0]; temp.y = temp.x *gyro_axis[1]; temp.z = temp.x *gyro_axis[2]; res = quat_mul(*qt,temp); quat_normalize(&res); *qt = res; } This variation coming keeping device stationary. Y-Axis : Resultant 3 gyro axis. X-axis : The number samples. (have converted time) Sample_rate 3Hz.",sensor-fusion
10350,Q Learning And Kohonen Maps For Line Follower Robot,I'm trying build line follower robot I'm interested predicting curves track. I 8 binary sensor array(qre1113). My goal make system generalize learned curves give predictions line pass fast possible. How I integrate system like Q learning I train it? And also I combine system Type C PID controlller ? There paper ot willing explain This important project kinda running clock quick help would appreciated,differential-drive
10357,"PID Gains: Drop control loop rate, need retune?","Good Day, I working autonomous quadcopter. May I ask significant difference control loop dropped 500Hz 460Hz due added lines code would require retuning PID gains? And retuning required, correct assume I D gains retweaked since constants time dependent? Thank :)",quadcopter mobile-robot control pid stability
10367,Battery damaged?,Could please see attached battery images tell safe continue using battery I discard it?,battery lithium-polymer
10369,What specifications digital compass used iPhone 6S,"What specifications digital compass used iPhone 6S? I trying measure yaw angle using magnetometer. I observed magnetometer/digital compass iPhone really stable. The north direction always same, magnetometer I using (or magnetometer used Nexus) needs calibrated function properly. I found digital compass AK8963C used iPhone 6, needs calibration. So I sure inside iPhone 6S works without calibration procedure.",imu sensor-fusion magnetometer
10371,Understanding correct drift using BreezySLAM (aka tinySLAM / CoreSLAM),"I looking Python implementation SLAM stumbled upon BreezySLAM implements tinySLAM aka CoreSLAM. My robot equipped hokuyo urg-04lx-ug01. I odometry hence passing updater: As I start moving robot starts discovering room A room B & C already map seems rotated. I come back room A return initial pose end=start using path. Now I noticed room A significantly rotated relation room. Consequently map isn't correct all, neither path travelled robot. Wasn't SLAM supposed store keep boundaries first room discovered? Why rotation may happening? How could I try troubleshoot issue data I collected (odometry, calculated position, liDAR scans)? Can I tune SLAM better job robot? SLAM pretty new me, please bear me, pointers literature may clarify moderate expectations SLAM do. Extra ... Here best video I found understand particle filter",localization slam mapping
10377,Need help regarding odometry using Encoder motor raspberry pi,"I project odometry using raspberry pi. I know encoder motor tell much distance robot covered, I idea ho implement completely. I need guideline steps follow. Till I interfaced motor raspberry pi counted number rotation. I questions follow? How plot map odometry using language library? If know anything, give guideline steps follow.",motor raspberry-pi odometry
10378,Robot positioning using IMU quaternion data?,I want use MPU9150 give position (XY) heading (angle) wheeled robot. This MPU9150 invensense Digital Motion Processor give quaternion. But I convert quaternion data XY-coordinate angle I plot position vehicle?,wheeled-robot imu sensor-fusion
10379,battery question DW558 Explorer (small quadrocopter),"I recently bought DW558 Quadrocopter (). After minutes, battery dead. Which understandable since battery tiny. It 3.7V 250mAh battery, included Quadrocopter. I thinking buying spare batteries it, I questions this: 1: Can I buy kind battery 3.7V 250mAh size property I pay attention? 2: Can I buy batteries 3.7V 350mAh (100 included battery) expect Quadrocopter ""energic""? Is bad buy batteries mAh ? 2b: If I buy 3.7V 350mAh batteries, I able charge charger I got 3.7V 250 mAh batteries I buy specific charger too? (these batteries I want buy, comment greatly appreciated: 350mAh batteries x5 and/or 4x 250mAh batteries + charger ) Thank much input. I think I discovered new hobby I can't wait spare batteries!",quadcopter battery
10382,Need help regarding development Extended Kalman Filter sensor-data fusion odometry IMU data,"I'm trying develop Extended Kalman Filter (EKF) positioning wheeled vehicle. I 'Baron' robot frame 4 static wheels, driven motor. On 2 rear wheels I encoder. I want fuse odometry data data 'MPU9150' 9 DOF IMU. This mathlab code I call 'medium-size' EKF. This uses data encoders, accelerometer x axis gyroscope z-axis. Medium-size EKF Inputs: x: ""a priori"" state estimate vector (8x1) t: sampling time [s] P: ""a priori"" estimated state covariance vector (8x8) z: current measurement vector (5x1) (encoder left; encoder right; x-acceleration, y-acceleration, z-axis gyroscope) Output: x: ""a posteriori"" state estimate vector (8x1) P: ""a posteriori"" state covariance vector (8x8) State vector x: 8x1 vector $\begin{bmatrix} x \rightarrow X-Position In Global Frame \\ \dot x \rightarrow Speed In X-direction Global Frame \\ \ddot x \rightarrow Acceleration In X-direction Global Frame \\ \rightarrow Y-Position In Global Frame \\ \dot \rightarrow Speed In Y-direction Global Frame \\ \ddot \rightarrow Acceleration In Y-direction Global Frame \\ \theta \rightarrow Vehicle Angle In Global Frame \\ \dot \theta \rightarrow Angular Speed Of The Vehicle \end {bmatrix}$ Measurement vector z: 5x1 vector $\begin{bmatrix} \eta_{left} \rightarrow Wheelspeed Pulses On Left Wheel \\ \eta_{right} \rightarrow Wheelspeed Pulses On Right Wheel \\ \dot \theta_z \rightarrow GyroscopeMeasurementInZ-axisVehicleFrame \\ a_x \rightarrow AccelerometerMeasurementX-axisVehicleFrame \\ a_y \rightarrow AccelerometerMeasurementY-axisVehicleFrame \end {bmatrix}$ end This filter schematic : These state transition equations I use : $$\ x_{t+1} = x_{t} + T \cdot \dot x_{t} + \frac{T^{2}}{2} \cdot \ddot x_{t}$$ $$\ \dot x_{t+1} = \dot x_{t} + T \cdot \ddot x_{t} $$ $$\ \ddot x_{t+1} = \ddot x_{t} + u_{1} $$ $$\ y_{t+1} = y_{t} + T \cdot \dot y_{t} + \frac{T^{2}}{2} \cdot \ddot y_{t}$$ $$\ \dot y_{t+1} = \dot y_{t} + T \cdot \ddot y_{t} $$ $$\ \ddot y_{t+1} = \ddot y_{t} + u_{2} $$ $$\ \dot \theta_{t+1} = \dot \theta_{t} + T \cdot \ddot \theta_{t} $$ $$\ \ddot \theta_{t+1} = \ddot \theta_{t} + u_{3} $$ These observation equations I use : $$\ \eta_{left} = \frac{T \cdot n_{0}}{2 \cdot \pi \cdot r} \cdot \sqrt{\dot x^{2} + \dot y^{2}} + \frac{T \cdot n_{0} \cdot b}{2 \cdot \pi \cdot r} \cdot \dot \theta + n_{1}$$ $$\ \eta_{right} = \frac{T \cdot n_{0}}{2 \cdot \pi \cdot r} \cdot \sqrt{\dot x^{2} + \dot y^{2}} - \frac{T \cdot n_{0} \cdot b}{2 \cdot \pi \cdot r} \cdot \dot \theta + n_{2}$$ $$\ \dot \theta_{z} = \dot \theta + n_{3}$$ $$\ a_{x} = \ddot x \sin \theta - \ddot \cos \theta + n_{4}$$ $$\ a_{y} = \ddot x \cos \theta + \ddot \sin \theta + n_{5}$$ Small-size EKF I wanted test filter, therefore I started smaller one, I give odometry measurements input. This I know I always receive amount pulses left right encoder, vehicle driving straight line. Inputs: x: ""a priori"" state estimate vector (6x1) t: sampling time [s] P: ""a priori"" estimated state covariance vector (6x6) z: current measurement vector (2x1) (encoder left; encoder right) Output: x: ""a posteriori"" state estimate vector (6x1) P: ""a posteriori"" state covariance vector (6x6) State vector x: 6x1 vector $\begin{bmatrix} x \rightarrow X-Position In Global Frame \\ \dot x \rightarrow Speed In X-direction Global Frame \\ \rightarrow Y-Position In Global Frame \\ \dot \rightarrow Speed In Y-direction Global Frame \\ \theta \rightarrow Vehicle Angle In Global Frame \\ \dot \theta \rightarrow Angular Speed Of The Vehicle \end {bmatrix}$ Measurement vector z: 2x1 vector $\begin{bmatrix} \eta_{left} \rightarrow Wheelspeed Pulses On Left Wheel \\ \eta_{right} \rightarrow Wheelspeed Pulses On Right Wheel \end {bmatrix}$ % Check input matrixes correct size [rows columns] = size(x); (rows ~= 6 && columns ~= 1) error('Input vector size incorrect') end [rows columns] = size(z); (rows ~= 2 && columns ~= 1) error('Input data vector size incorrect') end % Constants n0 = 16; r = 30; b = 50; Q = zeros(6,6); Q(2,2) = sigma_ax; Q(4,4) = sigma_ay; Q(6,6) = sigma_atau; %[Q(1,8),Q(3,6),Q(6,3)] = deal(small); dfdx = eye(6); [dfdx(1,2),dfdx(3,4),dfdx(5,6)] = deal(t); dfda = zeros(6,6); [dfda(2,2),dfda(4,4),dfda(6,6)] = deal(1); dhdn = eye(2,2); R = zeros(2,2); [R(1,1),R(2,2)] = deal(sigma_odo); %[R(2,1),R(1,2)] = deal(small); % Predict next state % xk = f(xk-1) xtemp = zeros(6,1); xtemp(1) = x(1) + t*x(2); u1 = normrnd(0,sigma_ax); xtemp(2) = x(2) + u1; xtemp(3) = x(3) + t*x(4); u2 = normrnd(0,sigma_ay); xtemp(4) = x(4) + u2; xtemp(5) = x(5) + t*x(6); u3 = normrnd(0,sigma_atau); xtemp(6) = x(6) + u3; x = xtemp % Predict next state covariance % Pk = dfdx * Pk-1 * transpose(dfdx) + dfda * Q * transpose(dfda) P = dfdx * P * transpose(dfdx) + dfda * Q * transpose(dfda); % Calculate Kalman gain % Kk = P * transpose(dhdx) [dhdx * P * transpose(dhdx) + dhdn * R * transpose(dhdn)]^-1 dhdx = zeros(2,6); if((x(2) < 10^(-6)) && (x(4)< 10^(-6))) [dhdx(1,2),dhdx(2,2)] = deal((t*n0)/(2*pi*r)); [dhdx(1,4),dhdx(2,4)] = deal((t*n0)/(2*pi*r)); else [dhdx(1,2),dhdx(2,2)] = deal(((t*n0)/(2*pi*r))*(x(2)/sqrt(x(2)^2+x(4)^2))); [dhdx(1,4),dhdx(2,4)] = deal(((t*n0)/(2*pi*r))*(x(4)/sqrt(x(2)^2+x(4)^2))); end %[dhdx(1,2),dhdx(2,2)] = deal(((t*n0)/(2*pi*r))*(x(2)/sqrt(x(2)^2+x(4)^2))); %[dhdx(1,4),dhdx(2,4)] = deal(((t*n0)/(2*pi*r))*(x(4)/sqrt(x(2)^2+x(4)^2))); dhdx(1,6) = (t*n0*b)/(2*pi*r); dhdx(2,6) = -(t*n0*b)/(2*pi*r); Kk = P * transpose(dhdx) * ((dhdx * P * transpose(dhdx) + dhdn * R * transpose(dhdn))^(-1)) % Update state H = zeros(2,1); n1 = normrnd(0,sigma_odo); H(1) = (((t*n0)/(2*pi*r))*sqrt(x(2)^2+x(4)^2))+(((t*n0*b)/(2*pi*r))*x(6)) + n1; n2 = normrnd(0,sigma_odo); H(2) = (((t*n0)/(2*pi*r))*sqrt(x(2)^2+x(4)^2))-(((t*n0*b)/(2*pi*r))*x(6)) + n2; x = x + Kk*(z-H) % Update state covariance P = (eye(6)-Kk*dhdx)*P; end Odometry observation equations If would wonder I come observation equations odometry data: $\ V_{vl} = V{c} + \dot \theta \cdot b \rightarrow V_{vl} = \sqrt{ \dot x^{2} + \dot y^{2}} + \dot \theta \cdot b$ Problem If I try small-size EKF, using Matlab user interface, seem drive straight line, heading 0° like I would expect. Eventhough I start state vector $\ x= \begin{bmatrix}0\\0\\0\\0\\0\\0\end{bmatrix}$ meaning starting position [0,0] global coordinate frame, speed acceleration zero angle 0°. In top right corner see measurement data I give input, 5 wheelspeed counts every wheel, every sampling period. (Simulating straight driving vehicle) In top left corner see plot X Y coordinate (from state vector) end one predict+update cycle filter, labeled timecycle. Bottom left corner plot angle state vector. You see 12 cycles angle still almost 0° like I would expect. Could anyone please provide insights could wrong here? Solutions I've thinking I could use 'odometry motion model' like explained question. The difference odometry data inserted predict step filter. But I would this, I see 2 problems: 1) I don't see make small-size version testing purposes, I don't know measurements add update-step 2) medium-size version I don't know make observation equations state vector doesn't imply velocity acceleration. I could use 'odometry motion model' update step use Euler-angle, linked $\ \theta $. This Euler-angle I obtain Digital Motion Processor (DMP), implemented IMU. Then problem angular velocity state matrix. But I still problem acceleration observation equations.",kalman-filter imu sensor-fusion odometry
10383,Issue DriveDistance RotateDegree,"Currently, I'm using Microsoft Robotics Dev Studio, Visual Studio C# programming language write code able drive iRobot Create 2 particular path. Moreover, I run code simulation, works fine, I connect actual iRobot Create 2, code executes driveDistance part, stops. The problem that, come simulation works, real robot work? The following code (I edited ""RoboticsTutorial4.cs"" file. So, anyone need additional code, go MRDs sample 4 see entire file):",mobile-robot irobot-create mrds
10387,How I interface drone?,"I recently bought drone(quadcopter). I like drone works I would like create application allow control drone remotely PC Phone. How computer phone interface aerial vehicle? Some initial thoughts Get RF detector detect signals sent drone replicate using new transmitter. Replace control circuit drone Arduino send corresponding signals fly drone Both methods seem kind far fetched hard, I'm sure could otherwise done.",quadcopter software radio-control wireless
10388,How check Gazebo/ODE functions called?,I'm trying take simple event Atlas steps ground plane. I want see functions ODE calls functions ODE uses determine constraint forces. I'd like see happen simulation running. Is way I could that? I'd like know constraint equations constraint forces ODE using particular case. Thanks.,ros dynamics gazebo
10392,view angle distance sensor,I need distance sensor (IR Optical other) 90 degree view angle sense rectangle surface. case sensor must putting level surface area. please help solve this.,mobile-robot
10394,2 DC motors model run different speeds?,"I 2 wheels robot, they're powered battery. yet robot differential motion(as wheels running differnt speeds) this?",mobile-robot motor
10404,Addressing sample impoverishment particle filter,"I implemented particle filter algorithm state estimation mobile robot. There several external range sensors(transmitters) environment gives information distance (radius) robot based time taken receiver robot send back acknowledgement. So, using three transmitters possible triangulate position robot. The particle filter initialized 15000 particles sensor noise relatively low (0.02m). Update Phase: At iteration range information external sensor received. This assigns higher weights particles along radius external sensor. Not particles equally weighted since process noise low. Hence cases, particle relatively closer robot gets lower weight incorrect one happens along radius. The weight pdf. Resampling Phase: At stage, lower weighted particle(the correct one) negligible weight gets lost higher weighted particle gets picked up. All happens first iteration range information another sensor arrives, robot already kidnapped. Googling around, said problem called sample impoverishment common approach resample particle variance low. (Effective Sample Size < number particles / 2) But, particles assigned negligible weights relatively particles higher weights, diversity particles lost resampling phase. So, variance higher resampling done removes lower weighted particle hence diversity particles lost. Isnt completely opposite idea ESS? Is understanding sample impoverishment correct? Is way issue fixed? Any pointers help would highly appreciated.",mobile-robot localization particle-filter probability
10407,What interpretation unsampled particles particle filters?,I implemented Particle Filters years back. I experimenting things Particle Filters. I learned resolve Robot Kidnapping problem introducing new particles. What left particles unsampled e.g. 1% population What interpretation unsampled particles context? How effect localization output?,localization algorithm particle-filter
10408,Localization Robot find Coordinates according Known Map,"I third-year electrical engineering student working intelligent autonomous robot summer vacations. The robot I trying make supposed used rescue operations. The information I would know position person (the coordinates person JSON file changed anytime except challenge) rescued building fire. I would also know rooms building map, I don't know robot may placed inside building start rescue operation. That means I localise robot placed unknown position known environment, robot plan path person rescued. I use gyroscope, accelerometer, magnetometer ultrasonic sensors localising job. I cannot use GPS module camera purpose. The object rescued (whose location known terms coordinates & changed anytime) surrounded walls 3 sides. Hence, adding walls map. According research particle filter best method used localization robot. But I deal landmarks (walls) fixed shown map image variable depending location object rescued provided JSON file? I path planning known position target position, I'm sure determine starting position. More JSON file: (1) json file containing coordinates object rescued change. (2) won't change challenge. (3) json file provided SD card robot read. I successfully written code allow robot read json file hence coordinates object rescued. Here map building known me.",localization particle-filter
10415,Determining graspable range robot arm,"I 6 DOF robot arm, I want object grasping experiments. Here, robot rigidly mounted table, object placed different adjacent table. The robot must pick object gripper parallel normal object's table, pointing directly downwards point grasping. Now, two tables adjustable heights. For given height difference them. fixed range positions robot arm achieve perpendicular pose. What I trying figure out, optimum relative distance tables range positions maximum. Is way compute analytically given robot arm kinematics? Or solution applies robot arms (e.g. optimum tables height)? If important, arm Kinova MICO: . Thanks!",robotic-arm kinematics
10416,Sensors Collaborative Robots,I'm currently research collaborative robotics. One area interest type sensor(s) used kind machines. I look robots FANUC Universal Robots I've noticed come equipped sensors; sold add-on. Is inherent collaborative robots? Do customers need buy sensors add-on - advantages disadvantages. Thanks help.,sensors industrial-robot
10425,IR distance sensor,I trying make IR distance sensor. I seen online. My goal however see distance IR transmitter IR sensor. In example uses IR led's ambient light timing track distance. Is way find distance lets say IR remote sensor? It would accurate 1 meter. I also open ideas accurately tracking distance two objects weither bluetooth/ir/ultrasonic,sensors
10426,Will pseudocode work basis flight controller?,"I'm programming flight controller Arduino. I've researched people written without notes it's often obfuscated I've decided easier better write own. This pseudocode thus far, work? happen inside constant Arduino loop Read RX signal Calculate desired pitch, roll, yaw angles RX input Signal ESCs using PWM order match desired pitch, roll, yaw RX input Gather IMU values (using Kalman filter reduce noise) Compare filtered IMU values vs. RX input find errors desired outcome vs. actual outcome Use PID algo settle errors IMU vs. RX Rinse repeat Suggestions greatly appreciated",arduino microcontroller uav
10427,Is portable accurate sensor measure position hand relative body?,"My team working wearable glove capture data hand movements, use human-computer interface variety applications. One major applications translation sign language, shown here: Right translate letters numbers, signs require person hold hand still one position ('stationary' signs). I want able translate words well, non-stationary signs. Also position hands really matters signing words, example matters whether hand front forehead, eyes, mouth, chest, cheeks, etc. For need portable highly accurate position sensor. We tried getting position 9-DOF IMU (accelerometer, gyroscope, magnetometer) might guess, many problems double integration noise accelerometer bias. So device provide accurate position information? It portable wearable (for example worn chest pocket, headband/cap, etc...be creative!). EDIT (more details): I'm going emphasize certain aspects design weren't clear before, based people's comments: My current problem position detection due errors double integration accelerometer data. So hopefully solution incredibly powerful kalman filter (I think unlikely) uses portable device instead accelerometer. I need absolute position hand space/on earth. I need hand position relative stable point body, chest belly. So maybe device hand measure position relative wearable device body. I don't know technology exists; I guess it'd use either magnets, ultrasound, bend sensors, EM waves sort. Be creative :)",sensors sensor-error precise-positioning
10429,"Difference SLAM ""3D reconstruction""?","I'm reading paper: (The role RGB-D benchmark datasets: overview) see following words: Thanks accurate depth data, currently published papers could present broad range RGB-D setups addressing well-known problems computer vision Microsoft Kinect ranging SLAM [10, 12, 19, 17, 35, 11] 3d reconstruction [2, 33, 38, 32, 1] realtime face [18] hand [30] tracking motion capturing gait analysis [34, 41, 8, 7, 4] I thought term SLAM 3D Reconstruction thing, paper says opposite bunch citations (which still haven't tell two apart). In opinion, Mapping SLAM term 3D Reconstruction, Localization essential part Mapping. So I don't find difference SLAM 3D Reconstruction, I wrong (or author misclassfying)?",slam 3d-reconstruction
10436,What difference ROSberry Pi builds?,I went go install ROS Rassberry Pi found 5 different variants. What difference I go learn differences future updates? Link ROSberryPi downloads I'm talking about:,ros raspberry-pi
10438,I-Robot Create 2 Connectors,Am I correct assuming I-Robot Create 2 25-pin connector like original version I-Robot Create has? Thanks much...Rick,irobot-create
10443,Stereo vision outdoor obstacle detection,"I'm trying detect obstacles distance 10 meters outdoor environment. Up meaning I also want able detect obstacles close robot. I thinking using stereo vision, I unsure fact even possible (before I buy expensive hardware). So possible? Has anyone success? If isn't possible, kind sensors could give decent point cloud range (outdoors)? I need sensor fit medium size robot. Also needs overly expensive since I limited budget. Thanks",sensors stereo-vision
10445,NameError: name 'TK' defined,"I reference following article. I followed article's code, appears: How solve problem?",irobot-create
10447,unable install ros kinetic ubuntu 16.04,"I trying install ros kinetic kame ubuntu 16.04 , trying first step setup sources. list. I getting cannot create /etc/apt/sources.list.d/ros-latest.list: Permission denied",ros irobot-create
10450,"Conversion GPS (longitude,latitude) (x,y) local reference frame?","I would like use GPS data measurement input extended kalman filter. Therefore I need convert GPS longitude lattitude x coordinate. I found information equirectangular projection given formulas: $$\ X = r_{earth} \cdot \lambda \cdot cos(\phi_0) $$ $$\ Y = r_{earth} \cdot \phi $$ However I think formulas use axis x- y-axis local frame parallel north south axis earth. But vehicle starting local reference frame origin heading straight y-direction. In whatever compas angle I put vehicle, always starting position. I measure angle $ \alpha $ north compass vehicle. Now relationship (longitude,lattitude) (x,y) local frame?",kalman-filter gps
10454,How DMP used simulating physics?,"I read paper 2015, ""Structural bootstrapping - A novel, generative mechanism faster efficient acquisition action-knowledge "", introduces concept called, ""Structural bootstrapping semantic event chains dynamic movement primitives,"" confused little bit. According knowledge robotarm controlled PDDL-like planner. The PDDL file ""qualitative physics engine"" predict future events. The paper says ""qualitative physics engine"" consists dynamic movement primitive (DMP) learned motion capture data. My question is: How DMP used simulating physics?",motion-planning algorithm machine-learning
10455,Replacing Wheels Create2,Is possible replace wheels create2 robot? Is standard shaft/coupling?,irobot-create roomba
10461,Measure 2 diffrent battery voltages arduino,Is possible measure voltage 2 different batteries arduino? Currently I able use resistor divider / voltage divider 2x 10K resistors analog pin read voltage battery supplying arduino. Currently system looks like 6v battery -> 5v power regulator Arduino -> resistor divider attached 6v (unregulated) battery. GND common throughout. How could I measure voltage another battery given different circuit? e.g. different ground loop.,arduino power
10462,Name linkage (or carriage) video,I trying find name (nomenclature) linkage (or carriage) driven dual linear servo (actuator) arrangement following Youtube videos: Servo Basic Concepts YouTube - 4 X Linear Servo Application The linkage (carriage) appears able rotate 180 degree arc. What metal linkage (or carriage) system called?,mechanism arm
10463,Reward Function q learning robot,"I 2 wheeled differential drive robot use pid low level control follow line. I implemented q learning uses samples 16 iterations uses decide best position line car takes turn there. This allows pid setup smooth fast following. My question setup reward function improves performance i.e. lets q learning find best Edit What tries learn this, 16 inputs contains line positions last 15 iterations iteration. Line position -1 1 -1 means left sensor sees line 0 means line center. I want learn line position faces input set line position like center take curve according line position. For example error required position - line position let say 16 0 input calculated required 0.4. So car center 0.4 hope helps :) You asked source code post } My Sensor reading returns value -1.0f 1.0f. 1.0f means Outer Sensor right line. I 8 sensors. void LineFollower::Follow(float LinePosition){ float requiredPos = Qpredictor.Process(LinePosition,CurrentSpeed); float error = requiredPos - LinePosition; float ErrorDer = error -LastError; float diffSpeed = (KpTerm * error + (KdTerm * ErrorDer)); float RightMotorSpeed = CurrentSpeed - diffSpeed; float LeftMotorSpeed = CurrentSpeed + diffSpeed; LastError = error; driver->Drive(LeftMotorSpeed,RightMotorSpeed); } Here logic value QPredictor(I call learning part this).And Finally QPredictor float Memory[MemorySize][DataVectorLength] = { {0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0}, {0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3}, {0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6}, {0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8}, {0.000, 0.012, 0.050, 0.113, 0.200, 0.312, 0.450, 0.613, 0.800, 1.000, 1.000, 1.000, 1.000, 1.000, 1.000, 1.000}, {0.000, 0.000, 0.012, 0.050, 0.113, 0.200, 0.312, 0.450, 0.613, 0.800, 1.000, 1.000, 1.000, 1.000, 1.000, 1.000}, {0.000, 0.000, 0.000, 0.012, 0.050, 0.113, 0.200, 0.312, 0.450, 0.613, 0.800, 1.000, 1.000, 1.000, 1.000, 1.000}, {0.000, 0.000, 0.000, 0.000, 0.012, 0.050, 0.113, 0.200, 0.312, 0.450, 0.613, 0.800, 1.000, 1.000, 1.000, 1.000}, {0.000, 0.000, 0.000, 0.000, 0.000, 0.012, 0.050, 0.113, 0.200, 0.312, 0.450, 0.613, 0.800, 1.000, 1.000, 1.000}, {0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.012, 0.050, 0.113, 0.200, 0.312, 0.450, 0.613, 0.800, 1.000, 1.000}, {0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.012, 0.050, 0.113, 0.200, 0.312, 0.450, 0.613, 0.800, 1.000}, {0.000, 0.025, 0.100, 0.225, 0.400, 0.625, 0.900, 1.000, 1.000, 1.000, 1.000, 1.000, 1.000, 1.000, 1.000, 1.000}, {0.000, 0.050, 0.200, 0.450, 0.800, 1.000, 1.000, 1.000, 1.000, 1.000, 1.000, 1.000, 1.000, 1.000, 1.000, 1.000}, {0.000, 0.100, 0.400, 0.900, 1.000, 1.000, 1.000, 1.000, 1.000, 1.000, 1.000, 1.000, 1.000, 1.000, 1.000, 1.000}, {0.000, 0.000, 0.100, 0.400, 0.900, 1.000, 1.000, 1.000, 1.000, 1.000, 1.000, 1.000, 1.000, 1.000, 1.000, 1.000}, {0.000, 0.000, 0.000, 0.100, 0.400, 0.900, 1.000, 1.000, 1.000, 1.000, 1.000, 1.000, 1.000, 1.000, 1.000, 1.000}, {0.000, 0.000, 0.000, 0.000, 0.100, 0.400, 0.900, 1.000, 1.000, 1.000, 1.000, 1.000, 1.000, 1.000, 1.000, 1.000}, {0.000, 0.000, 0.000, 0.000, 0.000, 0.100, 0.400, 0.900, 1.000, 1.000, 1.000, 1.000, 1.000, 1.000, 1.000, 1.000}, {0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.100, 0.400, 0.900, 1.000, 1.000, 1.000, 1.000, 1.000, 1.000, 1.000}, {0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.100, 0.400, 0.900, 1.000, 1.000, 1.000, 1.000, 1.000, 1.000}, {0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.100, 0.400, 0.900, 1.000, 1.000, 1.000, 1.000, 1.000}, {0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.100, 0.400, 0.900, 1.000, 1.000, 1.000, 1.000}, {0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.100, 0.400, 0.900, 1.000, 1.000, 1.000}, {0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.100, 0.400, 0.900, 1.000, 1.000}, {0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.100, 0.400, 0.900, 1.000} }; QPredictor::QPredictor(){ for(int i=0;i<MemorySize;i++){ output[i]=0.0f; input[i]=0.0f; } state = 0; PrevState = 0; } float QPredictor::Process(float linePosition,float currentBaseSpeed){ for(int i=1;i<DataVectorLength;i++){ input[i] = input[i-1]; } input[0] = m_abs(linePosition); int MinIndex = 0; float Distance = 10000.0f; float sum = 0.0f; for(int i=0;i<MemorySize;i++){ sum = 0.0f; for(int j=0;j<DataVectorLength;j++){ sum +=m_abs(input[j] - Memory[i][j]); } if(sum <= Distance){ MinIndex = i; Distance = sum; } } sum = 0.0f; for(int i=0;i<DataVectorLength;i++){ sum += input[i]; } float eta = 0.95f; output[MinIndex] = eta * output[MinIndex] + (1 - eta) * sum; return -m_sgn(linePosition) * output[MinIndex]; } float QPredictor::rewardFunction(float *inputData,float currentBaseSpeed){ float sum = 0.0f; for(int i=0;i<DataVectorLength;i++){ sum += inputData[i]; } sum /= DataVectorLength; return sum; } I average Error currently using learning it's complete without reward function. How adjust according dimensions Robot ?",machine-learning
10467,NameError: global name 'sendCommandASCII' defined,"When I execute following code, errors, Traceback (most recent call last): File ""C:\Python27_2\lib\lib-tk\Tkinter.py"", line 1532, __call__ return self.func(*args) File ""C:/Python27_2/IRobot.py"", line 38, callbackKey sendCommandASCII('131') NameError: global name 'sendCommandASCII' defined 1532 line program: How I solve?",irobot-create python
10468,Inverse Kinematics Computation -- alpha angle values included,"Given desired transform matrix end effector relevant base frame P560: John J. Craig, book, Introduction Robotics Mechanics Control, computes inverse kinematic solutions Puma 560, (correct wrong) Modified DH parameters gets following set equations theta angles: I noticed alpha angles calculations. So question aren't alpha angle values used calculation desired pose given end effector transform. Why independent axes twist angles robot?",inverse-kinematics
10469,Heading Yaw Rate Measurements,"I working field automated vehicles mainly domain passenger commercial vehicles. I studying whatever I get regarding measurement state (relative position, relative velocity, relative heading roation, a.k.a. yaw rate) surrounding objects especially vehicles using sensors. While everything else possible measure precisely using on-board sensors, I found much literature available measuring vehicle heading yaw rate vehicles baffling given extreme precision laser based sensing (albeit using time stamps). I looking for: Reference literature experiments estimation yaw rate vehicle heading. As I see literature available (or lack thereof), direct way measuring yaw rate available using LIDAR Camera consecutive time stamps scans data. However, inherently requires data correct. Hence, I would think due inaccuracies involved, method used! Is correct? Are commercially available sensors give accurate heading yaw rate information vehicles? Sources research papers would welcome! Edit: By inherently requires data correct I mean, given high sensitivity error heading yaw rate high vehicle speeds, values computed using sensor information accurate enough put use practice!",localization
10471,What difference RoboEarth KnowRob?,"I able clearly differentiate two platforms: RoboEarth, and; KnowRob.",theory cloud
10472,I-Robot Create 2 reset sleep issue?,I issues bringing robot sleep mode. Seems goes sleep mode activity 4 minutes. I using i-Robot Create 2 serial cable. When sleep mode I try removing cable end plugged robot connect jumper wire pins 5 6 robot 7 pin connector brief time period. This effectively shorts BRC pin GND short period time ( less 1 second). Then I reconnect serial port cable robot 7 pin connector try giving robot command go. I also read commands 173 173 173 help issue I may mistaken. Any help much appreciated !!!! Rick,irobot-create
10474,"Odometry motion model Kalman filter, error zero mean?","I planning using odometry model prediction stage Extended Kalman Filter. State transition equations: $$ f(X_t,a_t) = \begin{bmatrix} x_{t+1} = x_t + \frac{\delta s_r + \delta s_l}{2} \cdot \cos(\theta_t) +u_1 \\ y_{t+1} = y_t + \frac{\delta s_r + \delta s_l}{2} \cdot \sin(\theta_t) + u_2 \\ \theta_{t+1} = \theta_t + \frac{\delta s_r + \delta s_l}{b} \cdot \sin(\theta_t)+u_3 \end{bmatrix} $$ $\delta s_r$ $\delta s_l = \frac{n}{n_0} \cdot 2 \cdot \pi \cdot r$ $X_t = \begin{bmatrix} x_t & y_t & \theta_t\end{bmatrix}^T$ state matrix containing XY-coordinate heading $\theta$ vehicle global reference frame $\delta s_r$ $\delta s_l$ distance travelled respectively right left wheel $b$ distance center vehicle wheel $n$ encoder pulses count sampling period $n_0$ total pulses count 1 wheelturn $r$ wheel radius $u_1,u_2$ $u_3$ random noise N(0,$\sigma^2$) Now I doubt noise indeed zero mean? Wheelslip always make estimated distance travelled shorter measured distance isn't it?",kalman-filter odometry noise
10479,GPS observation equations Kalman filter?,"In design Extended Kalman Filter position estimation vehicle, I searching observation equations inserting GPS data (longitude, latitude) update step filter. The state vector filter $X_t = \begin{bmatrix} x_t & y_t & \phi_t\end{bmatrix}$ contains X Y coordinate vehicle local reference frame angle vehicle standing relative X-axis. The observation equations look like this: $$H(X_t) = \begin{bmatrix} longitude = f(x_t,y_t) \\ latitude = f(x_t,y_t)\end{bmatrix} $$ Can anybody fill in?",kalman-filter gps
10484,Equations motion 3D pendulum-like system,"I'm trying get equations motion 3D pendulum system (spherical pendulum), however I don't want describe system using spherical coordinates (which lot information about). Instead I want describe system using x,y,z coordinates mass well euler angles phi, theta, psi (the roll, pitch yaw mass). That is, I want assume mass position orientation relation inertial frame. Furthermore 3D pendulum system, mass, symmetric, actuated (notice simplification system needed actuate mass, resulting forces torques taken account): There force F acting x-axis direction mass reference frame There torque T acting z-axis mass reference frame There also gravitational force acting center mass (in negative direction z-axis inertial reference frame In order clear misconceptions forces generated, think mass differential drive robot using fans instead wheels. The cable connecting mass anchor point assumed rigid works distance constraint modeled by: $\|r_{anchor} - r_{mass}\| = cable\_length$ Where $r_{anchor}$ position anchor point mass connected cable $r_{mass}$ position mass. This constraint makes similar two spherical joints: one anchor point another mass. Futhermore cable assumed mass. It's important note rigid connection (calbe) meant modeled distant constraint refered above. I'm looking help solving system obtain equations motion. Thanks advance",kinematics dynamics
10486,Combine individually working cartesian coordinates,"I trying control Dobot arm. The arm moves angles whereas I need work cartesian coordinates. From inverse kinematics equations polar coordinates I implemented x,y z coordinates working well own. But I combine coordinates order work together. When I add going desired place. How I combine coordinates? I got help () could manage successfully move dobot. Edit: I've written codes Qt also I've added triangles used angle calculations. float DobotInverseKinematics::gotoX(float x) //func x-axis float h=qSqrt(qPow(lengthRearArm,2)-qPow(x,2)); //height ground QList<float> zEffect=gotoZ(h); //trying find effect x movement z-axis float cosQ=h/lengthRearArm; //desired joint angle float joint2=qRadiansToDegrees(qAcos(cosQ)); //move range control if(joint2 != joint2) {joint2=0; qDebug()<< ""joint2NAN"";} return joint2; QList<float> DobotInverseKinematics::gotoY(float y) //func y-axis QList<float> result ; float actualDist=lengthForeArm+distToTool; //distance end effector float x=(qSqrt(qPow(actualDist,2)+qPow(y,2)))-actualDist; //calculating x movement caused movement float joint1=qRadiansToDegrees(qAcos(actualDist/(actualDist+x))); //desired joint angle float joint2=gotoX(x); //the angle calculation movement x axis if(joint1 != joint1) {joint1=0; qDebug()<< ""joint1NAN"";} result.append(joint1); result.append(joint2); return result; QList<float> DobotInverseKinematics::gotoZ(float z) //func. z-axis QList<float> result ; float joint3=qSqrt(qPow(160,2.0)-qPow(z,2.0))/ 160; //desired joint angle float temp=160-qSqrt(qPow(160,2.0)-qPow(z,2.0)); float joint2=qSqrt(qPow(lengthRearArm,2)-qPow(temp,2.0))/lengthRearArm; //desired joint angle if(joint3 != joint3) {joint3=0; qDebug()<< ""joint3NAN"";} joint2=qAcos(joint2)*(180/M_PI); joint3=qAcos(joint3)*(180/M_PI); result.append(joint2); result.append(joint3); return result;",robotic-arm inverse-kinematics c++
10487,What type motor hooked bike?,"As title briefly explains, question is, type motor powerful enough cycle? My plan convert cycle electric bike mounting motor controlling either Raspberry Pi Arduino board.",motor electric
10490,Is possible use LiPo charger lab bench power supply?,"I recently thought building lab bench power supply, comes cheaper I love build things... But I also LiPo charger iMax B6AC, I bought quadcopter, came idea whether I use charger lab bench power supply... My questions is, could work could I make work?",power
10491,Examples Zeno Behaviour Real World,"Zeno Behaviour Zeno Phenomenon informally stated behavior system making infinite number jumps finite amount time. While important Control system problem ideal systems, Zeno behavior exist real systems? Any examples? If so, don't noise external factors deviate system achieving Zeno?",mobile-robot control
10492,Why don't cheap toy robotic arms move smoothly?,"Why don't cheap toy robotic arms like move smoothly? Why can't even move smoothly, (even without load)? In words - real industrial robotic arms have, cheap toys don't?",robotic-arm
10502,"What good, low cost, actuators braille tablet controlled arduino?","I want basically make pin matrix controlled either spring, electromagnets small motors(spring viable option), something like what’s shown image. I'm pretty new arduino hardware general input would appreciated. I mostly know arduino end don't clue hardware part. Plus I don't technical expertise, I know electromagnets won't good option I control individual pins clusters. Plus springs disadvantage pushing back option. And viable individual motors many pins.",arduino motor electronics
10503,Running cycle brushless outrunner motors?,"Is possible convert cycle electric bike using brushless outrunner motors usually RC planes, multicopter, helicopter, etc? If possible, specs motors need provide enough power bring cycle speed? Will I need gear system?",motor power electric
10504,How properly calibrate magnetometer IMU precise yaw?,"I'm using Sparkfun Razor IMU 9DOF sensor incorporates accelerometer, gyroscope, magnetometer, giving Euler's angles (yaw, pitch, roll). I'm using firmware link. It Processing sketch calibration magnetometer, doesn't give precise measurements. Especially, yaw imprecise. I'm using sensor measuring azimuth altitude stellar objects. The altitude mostly correct, azimuth (yaw) isn't. I several questions: Is better way calibrate magnetometer? Is calibration sufficient, without using Madgwick Kalman filter? Is nonlinearity present sensor? Since yaw offset isn't constant, changes (around -12 degrees north almost correct value southwest). And is, could I measure nonlinearity apply yaw measurements? If I use Madgwick Kalman, I apply quaternions? I believe applying final yaw measurements wouldn't job.",kalman-filter imu calibration magnetometer precise-positioning
10505,Covariance Check?,I localization data estimated GPS_truth generated [3x3] covariance matrix along them. What would like see covariance correct not? Can check plotting covariance?,localization slam visualization
10507,Do DH parameters change scaled robot 3d model?,I actual DH parameters robot: di's ai's zero. Can I use inverse kinematics analytic closed form computation I measure virtual distances 3d environment? I actually asking theta angles yeld computations dependent scale distances. EDIT: Scale factor unknown,inverse-kinematics dh-parameters 3d-model
10508,Building RC Airbus A340,"I planning build scale version Airbus A340 title suggests I questions build... Are template/plans build? If please reply links... Can I control plane CC3D Revolution fly ground station? If ground telemetry application help me, please send link... How I make landing gears? I don't really fancy spending £50 (I live London)... I want make landing gears shock absorbing I want make nose gear steering mechanism servos... How I make outer shell EDF motors? I ready spend much time effort build, I want build costly, going hobby. And I also built Quadcopter, I hope I apply knowledge build...",servos
10511,"Accelerometer, gyro, magnetometer sensor fusion material resource survey","As hardware engineer, I studied quite lot sensor spec Accel, Gyro Magnetometer including custom made fluxgate. I studied matrix quadarion (complex number) on. I moving calibration arena, I seen lot article calibration sure best solution fix offset mis-alignment axis. Can anyone point best open source code. I'm interested output results related flight quadchopter GPS, interested directional math drilling pipes, toolface, inclination, azimuth position important. What best thesis paper cover topic open-source example code (in C) application. Do I need Kalnman filter advance post data capture processing. Any tip avoid getting involved maths",control kalman-filter imu calibration precise-positioning
10514,Scale factor 3d robot model relative real measurements robot,"I measurements real life robot, 3d model robot (lets say Unity) I want know scale factor, plus I dont want find 3d models measurements divide real world ones find scale factor, order get confused mathematics I already. So, methodology I I mentioned?",3d-model
10515,Basic Components For Having 'Follow Me' mode Quad?,"I want know essential components I need multirotor inorder 'Follow Me' mode (With,me carrying Device/Reference Piece track).?",localization
10516,can't find ros package kinetic driver-base,"I can't find package, ros site , I saw maintainable. How migrate package (jade/indigo) became package kinetic? That important it's dependency quad-gazebo pacakge",ros
10517,Which kind motors powerfull robotic arm,"I building robotic arm specifications: 1 meter long approx. 1kg weight made 4 motors. (2 base. One rotating whole arm left right another one rotating down. 1 motor rotating second half arm, down. 1 claw used grabbing) must able lift least 4kg + 1kg (it's weight), speed 180 degrees 2 seconds = 360 degrees 1 second resulting 60rpm. Which kind motor would best project (servo stepper) much torque need? (Please also give explanation I calculate torque needed). Could also give example two motors I would need and/or gearbox (models links).",motor robotic-arm stepper-motor servos torque
10519,Math dynamic gait,I'm researching dynamic gaits bipedal robots. Can anyone recommend reference reviews explains math behind modern approaches?,walking-robot
10520,"Once matching features computed stereo pair, tracked?","I currently working SLAM-like application using variable baseline stereo rig. Assuming I'm trying perform visual SLAM using stereo camera, initialization routine would involve producing point cloud 'good' features I detect first pair images. Once map created cameras start moving, I keep 'track' original features responsible map, I need estimate pose? Along feature matching stereo pair cameras, I also perform matching initial set images second set see many features still visible (and thereby get coordinates)? Or efficient way this, instance, locating overlap two points clouds?",slam computer-vision stereo-vision
10521,Help finding robot tracks,"I Robot tracks. One tracks broke I need find replacement, tracks use plastic interconnects/pieces this: They popular years back. Does anyone know brand/name?",mobile-robot tracks
10523,Determining position 2D map LIDAR,"We need determine 2D position robot. To so, LIDAR known high, horizontal plane, gives us distance nearest point angular degree (so 360 points one rotation). The environment known, I map position every object LIDAR susceptible hit. My question is, based scatter plot LIDAR returning, retrieve position robot map ? We would need , position map frame also theta angle map frame robot frame. We tried match objects map groups points based distance identifying objects way LIDAR ""sees"" retrieve robot position. But still unsuccessful. To put nutshell, want make SLAM without mapping part. How possible, kind algorithms ? A first step could stop robot acquiring data seems easier process.",localization lidar precise-positioning
10525,Shield IMU magnetic interferences,"I experienced drifting coming near magnetic fields IMU, I wondered possible completely shield IMU external influences. Would theoretically possible IMU rely external fields like earth magnetic field? Are maybe alternatives IMUs less susceptible magnetic interferences? I need rotational data sensor don't use translational output.",sensors imu rotation
10527,Is bad-design decision implement high number moving parts automation-robot?,"I'm currently designing autonomous robotic system manipulate clothes using computer vision complex moving hardware. My current design incorporates quite number moving parts. My biggest worry frame (140 x 80 x 40 cm) rotates 0 90 degrees every time manipulates piece cloth. Other design involves various moving parts achieve successful manipulation cloth. It seems like hardware capable achieving task despite high number complex moving parts. So question is, design considerations I take designing automated system. Should I think alternative design less number parts? Or proceed current design job>? Sorry I position I can't disclose much information project. Thank you.",computer-vision automation
10533,How make simple Arduino Insect Robot?,I want make simple Arduino based programmable insect robot. I want walk legs legs made hard aluminum wire. It needs 4 legs. I planning use Arduino Nano that. I questions like: How arrange servos wire motion? I also want turn sideways? Where I read good theory making insect like robots?,arduino
10536,What difference CC3D Revolution Mini CC3D Revolution,"I recently came across doubt... As title suggests what's difference two flight controller. They big price difference size difference, that's I know... Do function way, two flight controller differ size? Answers appreciated, Sid",quadcopter microcontroller
10537,LIDAR Points Landmarks,"I currently trying implement GraphSLAM/SAM algorithm LIDAR. From papers I've read, generate directed graph expected LIDAR measurements landmarks similar image (taken Square Root SLAM Paper Dellaert). However practice point clouds obtain LIDAR similar (taken KITTI car collected dataset): It seems algorithms SIFT 3D point clouds aren't accurate yet. Is commonly used technique efficiently find features consecutive point clouds find landmarks SLAM algorithms without using >30,000 points point cloud?",localization slam lidar
10544,Programmable Wheeled Vehicle,"Ok, may simple question, goes. I would like build type wheeled vehicle sustain tripod mount also programmable follow programmed path. However, I would like able change path well. This started trying mount Ricoh Theta S RC car create 3D video room. I'm really familiar type robotics I'm convinced it's possible create something better... More efficient will... I've looked drones, I would like I don't think I find something precise I would like (I could completely wrong). Any guidance extremely appreciated.",mobile-robot
10546,Is possible implement robot moves spcific locations based dynamic inputs?,"I'd like build robot move different places(like different rooms) floor based input i'm giving dynamically. I've surfed don't need line follower. Except this, give way implement ?? Thanks advance :)",wheeled-robot
10547,How get live audio robot?,"I building robot I want able hear sounds it's environment (ideally laptop). What best way get live audio robot's microphone computer? I looked solutions hosting live audio streams using packages icecast. I'm wondering better solutions robotic applications. Additional details: - I access hardware Raspberry Pi, Arduino, etc.",real-time digital-audio
10549,Power solution Raspberry Pi robot,I building Pi car 4 gear motors (190-250mAh max). Now I want use 10000mAh USB power bank power raspberry pi along 4 gear motors. I power raspberry pi directly I want use power bank source power Pi Car. How I connect RPi motor controller L298N USB power bank?,motor raspberry-pi power
10554,What types motor I use particular application?,"I want create amateur wire looping machine Arduino, similar functionality machine. I don't need automatic wire feeding purposes part done manually. I want automate wire loop creation process, assuming I already straight wires. I'm new world motors, robotics, etc., please descriptive possible :) From video, I tell two motors: Makes initial wire bending Spins create loop The wire I working galvanized steel 11 gauge (2.0 - 2.5 mm diameter). So type motors would recommended application, taking account: They need accurate positioning repeat ability They need enough torque (specially one creates loop itself) work type material They're fast (or close to) ones video This going industrial grade machine running time Ideally, need expensive.. I don't want bankrupt end project :) If links included recommended products, would great. Thanks!",motor
10555,3 Axis Gimbal Stabilization System replace 3 Axis Accelerometer,"""TAROT ZYX-GS 3-Axis Gimbal Stabilization System ZYX13"" sensor gives value Roll tilt Pan.The 3 axis accelerometer give value x z.so use Gimbal stabiliztion system place accelerometer",quadcopter sensors accelerometer
10556,Quadrature encoder signal dc motor noisy,"I'm starting robotics, got first DC gear motor quadrature encoder (): I ultimately plan hook motor driver connected Tiva Launchpad. However, since I'm noob, curious, I starting playing breadboard, oscilloscope, voltage source. E.g., I plug motor power lines (variable) voltage source axis spins nicely expected 1 12 V. The problems start I try check encoder works. To this, first I plug 5V source encoder GND/Vcc, try monitor encoder output. While motor running, I check Yellow (encoder A output) cable (referencing green (encoder GND) cable). I made video shows representative output one lines (no USB old oscilloscope I took video using phone). As would see video, output doesn't look anything like beautiful square waves typically see documentation. Instead, extremely degraded noisy sin wave (at correct frequency encoder). The amplitude sin constant, changes drastically time. Strangely, sometimes ""locks in"" looks like ideal square wave, second two, gets wonky again. Both lines (encoder A B output) act way, act way time (e.g., lock square time, brief glorious moments clarity). Both motors same, I don't think it's I bad motor. I also checked using Vcc=12V, made difference changing amplitude output. Note I already posted question reddit:",motor quadrature-encoder
10561,Can I use 3D gimbal system simplistic quadcopter IMU(3 axis accelerometer)?,3d gimbal system want use sensor place IMU(3 axsis accelerometer) Quadcopter,quadcopter accelerometer gyroscope
10562,What torque transmission efficiency using bycicle chain/setup robot?,"For robot gear attached motor linked gear attached wheels bicycle chain (I using bicycle wheel transmission set parts robots movements). How using bicycle chain affect power transmission efficiency, impact torque?",mobile-robot torque gearing
10567,Is C++ library I could use program robotic manipulator involving forward inverse kinematics?,"I came across robotics library (RL), quite unclear real purpose. Is FK/IK solver library simply graphical simulator?. RL poor documentation, clear use it. Im looking C++ library APIs solve FK/IF analytically. Thank you.",inverse-kinematics c++ forward-kinematics
10568,What types actuators industrial bots use?,"I particular example robot interests me: See first image, bigger robot left, particular shoulder pitch joint would support weight. I'm curious I know it's really hard balance strength precision types robots, want know close hobbyist could get. Would something similar this: rotary tables w/ worm gears? Looking actuation schemes research, thanks!",motor robotic-arm actuator torque
10573,Technique increase POV resolution,"I thought technique increase resolution POV (persistence vision) display. In usual POV display, LEDs arranged strip spun circle. There two limiting factors increasing radial resolution along circumference one circular path LED follows. One is, depending speed POV wheel, minimum time required (decided microcontroller) change LED's color case RGB. The factor LED's width, increases 'bleeding' color one pixel neighboring pixel LED changes color brightness fast. If one fix slit front LED, |*| <-- like so, would help improve resolution POV display; one would effect reducing width 'pixel' along circumference led would traversing. Thus one use fast enough microcontroller narrow enough slit, one could probably obtain high resolution along one dimension least. To clear I've yet implemented this, looking experienced person tell work not.",microcontroller electronics
10580,How I upload sketches Arduino raspberry pi?,I robotics project Raspberry pi Arduino. The Arduino UNO connected raspberry pi. I using raspberry pi Putty (SSH) now. I want setup user interface raspberry pi also importantly want use Arduino IDE work load Arduino sketch system. How this?,arduino raspberry-pi embedded-systems first-robotics linux
10581,EKF SLAM 2d laser scanned datasets usage,"How understand 2d laser scanner scanned data use implementation ekf slam, someone provide implementation EKF SLAM python pseudo datasets.",slam ekf first-robotics
10584,Communication SWARM robotics,"Hey I trying research SWARM robotics, trying find helpful information even articles/papers read process setting communication protocols different robots. For instance using LAN connection, robot need wireless adapter, would I begin setting network say 5-10 smaller robots? More generally could someone help understand devices connect communicate across networks? I understand basics IP addressing, I haven't researched complexities. Any advice direction appreciated.",wireless
